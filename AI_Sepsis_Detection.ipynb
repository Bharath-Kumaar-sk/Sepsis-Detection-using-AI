{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "U87oC9P_iVej"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "U87oC9P_iVej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastdtw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0YiRIEV4mT5",
        "outputId": "15a704d7-e916-40e7-8498-101f3c8c8bf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastdtw\n",
            "  Downloading fastdtw-0.3.4.tar.gz (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fastdtw) (2.0.2)\n",
            "Building wheels for collected packages: fastdtw\n",
            "  Building wheel for fastdtw (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastdtw: filename=fastdtw-0.3.4-cp312-cp312-linux_x86_64.whl size=567857 sha256=b5cac98a54bbf7da8e09fe41aa230bdd8963040b9668378e1f7be781396f3bda\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/d0/26/b82cb0f49ae73e5e6bba4e8462fff2c9851d7bd2ec64f8891e\n",
            "Successfully built fastdtw\n",
            "Installing collected packages: fastdtw\n",
            "Successfully installed fastdtw-0.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w066bJoCh_Gv",
        "outputId": "f81dbb46-6b25-440d-c9f9-e3cfd0e789b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Preprocessing adapted to specified column names:\n",
        "['patient_id','HR','O2Sat','Temp','SBP','MAP','DBP','Resp','EtCO2',\n",
        " 'BaseExcess','HCO3','FiO2','pH','PaCO2','SaO2','AST','BUN','Alkalinephos',\n",
        " 'Calcium','Chloride','Creatinine','Bilirubin_direct','Glucose','Lactate',\n",
        " 'Magnesium','Phosphate','Potassium','Bilirubin_total','TroponinI','Hct',\n",
        " 'Hgb','PTT','WBC','Fibrinogen','Platelets','Age','Gender','Unit1','Unit2',\n",
        " 'HospAdmTime','ICULOS','SepsisLabel']\n",
        "- Uses ICULOS to create hourly index per patient (if ICULOS present)\n",
        "- Computes IQR ranges from training patients only and applies them\n",
        "- Properly imputes -1 for ALL missing values after normalization\n",
        "- Includes baseline paper exclusion criteria\n",
        "- Three-way split: 15% test, 68% train, 17% validation (matching baseline paper)\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# -------- USER CONFIG --------\n",
        "input_path = '/content/drive/MyDrive/AI_Course_Project/Dataset/merged_sepsis_dataset.csv'  # update path\n",
        "output_dir = '/content/drive/MyDrive/AI_Course_Project'                # output to AI_Fin\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "train_output_csv = os.path.join(output_dir, 'sepsis_preprocessed_train.csv')\n",
        "val_output_csv   = os.path.join(output_dir, 'sepsis_preprocessed_val.csv')\n",
        "test_output_csv  = os.path.join(output_dir, 'sepsis_preprocessed_test.csv')\n",
        "full_output_csv  = os.path.join(output_dir, 'sepsis_preprocessed_full.csv')\n",
        "limits_json_path = os.path.join(output_dir, 'iqr_minmax_limits.json')\n",
        "\n",
        "random_state = 42\n",
        "\n",
        "# -------- FEATURE HOLD INTERVALS (hours) using your column names --------\n",
        "feature_intervals = {\n",
        "    'HR': 4,\n",
        "    'SBP': 4,\n",
        "    'DBP': 4,\n",
        "    'Resp': 4,\n",
        "    'O2Sat': 4,\n",
        "    'Temp': 4,\n",
        "    'MAP': 4,\n",
        "    'EtCO2': 4,\n",
        "    'BaseExcess': 24,\n",
        "    'HCO3': 24,\n",
        "    'FiO2': 4,\n",
        "    'pH': 24,\n",
        "    'PaCO2': 24,\n",
        "    'SaO2': 4,\n",
        "    'AST': 24,\n",
        "    'BUN': 24,\n",
        "    'Alkalinephos': 24,\n",
        "    'Calcium': 24,\n",
        "    'Chloride': 24,\n",
        "    'Creatinine': 24,\n",
        "    'Bilirubin_direct': 24,\n",
        "    'Glucose': 24,\n",
        "    'Lactate': 24,\n",
        "    'Magnesium': 24,\n",
        "    'Phosphate': 24,\n",
        "    'Potassium': 24,\n",
        "    'Bilirubin_total': 24,\n",
        "    'TroponinI': 24,\n",
        "    'Hct': 24,\n",
        "    'Hgb': 24,\n",
        "    'PTT': 24,\n",
        "    'WBC': 24,\n",
        "    'Fibrinogen': 24,\n",
        "    'Platelets': 24,\n",
        "    # demographic / static\n",
        "    'Age': None,\n",
        "    'Gender': None,\n",
        "}\n",
        "\n",
        "# Optional clinical sanity bounds to clamp IQR-based limits (feature: (min,max))\n",
        "clinical_sanity = {\n",
        "    'HR': (30, 250),\n",
        "    'SBP': (40, 250),\n",
        "    'Temp': (30.0, 45.0),\n",
        "    'O2Sat': (50, 100),\n",
        "    'MAP': (30, 200),\n",
        "    'Resp': (5, 60),\n",
        "    'Creatinine': (0.1, 20.0),\n",
        "    'BUN': (1, 200),\n",
        "    'Platelets': (1, 1000),\n",
        "    'Glucose': (30, 1000),\n",
        "}\n",
        "\n",
        "# -------- LOAD --------\n",
        "df = pd.read_csv(input_path)\n",
        "print(f\"Loaded {len(df):,} rows, {df.shape[1]} columns\")\n",
        "\n",
        "# Validate patient_id exists\n",
        "if 'patient_id' not in df.columns:\n",
        "    raise ValueError(\"Input must contain 'patient_id' column (lowercase).\")\n",
        "\n",
        "# -------- EXCLUSION CRITERIA (matching baseline paper) --------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"APPLYING EXCLUSION CRITERIA FROM BASELINE PAPER\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Count patients before exclusion\n",
        "n_patients_before = df['patient_id'].nunique()\n",
        "n_rows_before = len(df)\n",
        "\n",
        "# Exclusion 1: Patients with < 8 hours of ICU data\n",
        "if 'ICULOS' in df.columns:\n",
        "    patient_max_iculos = df.groupby('patient_id')['ICULOS'].max()\n",
        "    valid_patients_duration = patient_max_iculos[patient_max_iculos >= 8].index\n",
        "    df = df[df['patient_id'].isin(valid_patients_duration)].copy()\n",
        "    excluded_duration = n_patients_before - len(valid_patients_duration)\n",
        "    print(f\"Excluded {excluded_duration} patients with < 8 hours ICU data\")\n",
        "else:\n",
        "    print(\"Warning: ICULOS column not found. Skipping ICU duration exclusion.\")\n",
        "\n",
        "# Exclusion 2: Sepsis onset < 4 hours after ICU admission\n",
        "if 'SepsisLabel' in df.columns and 'ICULOS' in df.columns:\n",
        "    # Find first sepsis onset time for each patient\n",
        "    sepsis_patients = df[df['SepsisLabel'] == 1].groupby('patient_id')['ICULOS'].min()\n",
        "    # Keep patients whose sepsis onset is >= 4 hours OR who never develop sepsis\n",
        "    early_sepsis_patients = sepsis_patients[sepsis_patients < 4].index\n",
        "    df = df[~df['patient_id'].isin(early_sepsis_patients)].copy()\n",
        "    print(f\"Excluded {len(early_sepsis_patients)} patients with sepsis onset < 4 hours after admission\")\n",
        "else:\n",
        "    print(\"Warning: SepsisLabel or ICULOS column not found. Skipping early sepsis exclusion.\")\n",
        "\n",
        "n_patients_after = df['patient_id'].nunique()\n",
        "n_rows_after = len(df)\n",
        "print(f\"\\nPatients: {n_patients_before} → {n_patients_after} (excluded {n_patients_before - n_patients_after})\")\n",
        "print(f\"Rows: {n_rows_before:,} → {n_rows_after:,}\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Build synthetic time index using ICULOS if present (ICULOS = hours since ICU admission)\n",
        "time_present = False\n",
        "if 'ICULOS' in df.columns:\n",
        "    # create a synthetic datetime column from ICULOS (so we can resample hourly)\n",
        "    # use an arbitrary epoch date per patient; only relative hourly spacing matters\n",
        "    df['charttime'] = pd.to_datetime('1970-01-01') + pd.to_timedelta(df['ICULOS'], unit='h')\n",
        "    time_present = True\n",
        "    time_col = 'charttime'\n",
        "    print(\"Using 'ICULOS' to build hourly time index as 'charttime'.\")\n",
        "else:\n",
        "    # fallback: check common timestamp names\n",
        "    time_candidates = [c for c in df.columns if c.lower() in ('timestamp','time','datetime','charttime','date')]\n",
        "    if time_candidates:\n",
        "        time_col = time_candidates[0]\n",
        "        df[time_col] = pd.to_datetime(df[time_col], errors='coerce')\n",
        "        time_present = True\n",
        "        print(f\"Using detected time column '{time_col}'.\")\n",
        "    else:\n",
        "        time_col = None\n",
        "        print(\"No ICULOS or timestamp column found. Hourly resampling will be skipped (less ideal).\")\n",
        "\n",
        "# -------- RESAMPLE to hourly grid per patient (use last observed value in hour) --------\n",
        "if time_present:\n",
        "    static_cols = [c for c, v in feature_intervals.items() if v is None and c in df.columns]\n",
        "    parts = []\n",
        "    for pid, g in df.groupby('patient_id'):\n",
        "        g = g.sort_values(time_col)\n",
        "        g_hour = g.set_index(time_col).resample('1H').last()\n",
        "        g_hour['patient_id'] = pid\n",
        "        for s in static_cols:\n",
        "            if s in g.columns:\n",
        "                first_val = g[s].ffill().bfill().iloc[0] if not g[s].isna().all() else np.nan\n",
        "                g_hour[s] = first_val\n",
        "        parts.append(g_hour.reset_index())\n",
        "    df_hourly = pd.concat(parts, ignore_index=True, sort=False)\n",
        "    print(f\"Resampled to hourly grid: {len(df_hourly):,} rows\")\n",
        "else:\n",
        "    df_hourly = df.copy()\n",
        "    print(\"Proceeding without hourly resampling (operating on original rows).\")\n",
        "\n",
        "# -------- PATIENT-LEVEL SPLIT (matching baseline paper: 15% test, 68% train, 17% val) --------\n",
        "patient_ids = df_hourly['patient_id'].unique()\n",
        "\n",
        "# First split: 15% for test (held-out), 85% for train+validation\n",
        "train_val_ids, test_ids = train_test_split(\n",
        "    patient_ids,\n",
        "    test_size=0.15,  # 15% held-out for testing\n",
        "    random_state=random_state\n",
        ")\n",
        "\n",
        "# Second split: Split remaining 85% into 80% train and 20% validation\n",
        "# This results in: 68% train (0.85 * 0.80) and 17% validation (0.85 * 0.20)\n",
        "train_ids, val_ids = train_test_split(\n",
        "    train_val_ids,\n",
        "    test_size=0.2,  # 20% of the remaining 85% for validation\n",
        "    random_state=random_state\n",
        ")\n",
        "\n",
        "train_hourly = df_hourly[df_hourly['patient_id'].isin(train_ids)].copy()\n",
        "val_hourly = df_hourly[df_hourly['patient_id'].isin(val_ids)].copy()\n",
        "test_hourly = df_hourly[df_hourly['patient_id'].isin(test_ids)].copy()\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"DATASET SPLIT (matching baseline paper)\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Test patients:  {len(test_ids):>6} ({len(test_ids)/len(patient_ids)*100:>5.1f}%) - Held-out\")\n",
        "print(f\"Train patients: {len(train_ids):>6} ({len(train_ids)/len(patient_ids)*100:>5.1f}%)\")\n",
        "print(f\"Val patients:   {len(val_ids):>6} ({len(val_ids)/len(patient_ids)*100:>5.1f}%)\")\n",
        "print(f\"Total patients: {len(patient_ids):>6}\")\n",
        "print(f\"\\nTest rows:  {len(test_hourly):>8,}\")\n",
        "print(f\"Train rows: {len(train_hourly):>8,}\")\n",
        "print(f\"Val rows:   {len(val_hourly):>8,}\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "# -------- IQR-limits computation helper --------\n",
        "def compute_iqr_limits(df_src, feature_list, min_obs_threshold=10):\n",
        "    limits = {}\n",
        "    for feat in feature_list:\n",
        "        if feat not in df_src.columns:\n",
        "            continue\n",
        "        s = df_src[feat].dropna()\n",
        "        if len(s) < min_obs_threshold:\n",
        "            continue\n",
        "        q1 = s.quantile(0.25)\n",
        "        q3 = s.quantile(0.75)\n",
        "        iqr = q3 - q1\n",
        "        xmin = float(q1 - 1.5 * iqr)\n",
        "        xmax = float(q3 + 1.5 * iqr)\n",
        "        limits[feat] = (xmin, xmax)\n",
        "    return limits\n",
        "\n",
        "# features to compute IQR for (exclude statics)\n",
        "feature_list_for_iqr = [f for f, v in feature_intervals.items() if v is not None and f in df_hourly.columns]\n",
        "print(\"Computing IQR limits for base features from TRAINING data only...\")\n",
        "iqr_limits_base = compute_iqr_limits(train_hourly, feature_list_for_iqr)\n",
        "print(\"Base IQR limits computed for\", len(iqr_limits_base), \"features\")\n",
        "\n",
        "# -------- Store original missing mask BEFORE any forward fill --------\n",
        "print(\"\\nCreating original missing value masks...\")\n",
        "original_missing_mask = {}\n",
        "for feat in list(feature_intervals.keys()):\n",
        "    if feat in df_hourly.columns:\n",
        "        original_missing_mask[feat] = df_hourly[feat].isna().copy()\n",
        "\n",
        "# -------- TIME-LIMITED FORWARD-FILL on full hourly dataframe --------\n",
        "df_filled = df_hourly.copy()\n",
        "print(\"Applying time-limited forward-fill...\")\n",
        "for feat, hold_hours in feature_intervals.items():\n",
        "    if feat not in df_filled.columns:\n",
        "        continue\n",
        "    if hold_hours is None:\n",
        "        continue\n",
        "    # FIXED: Use new pandas syntax instead of deprecated method parameter\n",
        "    df_filled[feat] = df_filled.groupby('patient_id')[feat].transform(\n",
        "        lambda s: s.ffill(limit=hold_hours)\n",
        "    )\n",
        "\n",
        "# -------- DERIVED FEATURES (using your column names) --------\n",
        "print(\"\\nComputing derived features...\")\n",
        "\n",
        "# ShockIndex = HR / SBP\n",
        "if {'HR', 'SBP'}.issubset(df_filled.columns):\n",
        "    df_filled['ShockIndex'] = df_filled['HR'] / df_filled['SBP'].replace({0: np.nan})\n",
        "    feature_intervals['ShockIndex'] = 4\n",
        "    original_missing_mask['ShockIndex'] = df_filled['ShockIndex'].isna().copy()\n",
        "    print(\"  Computed ShockIndex\")\n",
        "\n",
        "# BUN_Cr = BUN / Creatinine\n",
        "if {'BUN', 'Creatinine'}.issubset(df_filled.columns):\n",
        "    df_filled['BUN_Cr'] = df_filled['BUN'] / df_filled['Creatinine'].replace({0: np.nan})\n",
        "    feature_intervals['BUN_Cr'] = 24\n",
        "    original_missing_mask['BUN_Cr'] = df_filled['BUN_Cr'].isna().copy()\n",
        "    print(\"  Computed BUN_Cr\")\n",
        "\n",
        "# MEWS (partial, without AVPU) using SBP, HR, Resp, Temp\n",
        "def compute_mews_series(df_local):\n",
        "    s = pd.Series(0, index=df_local.index, dtype=float)\n",
        "    if 'SBP' in df_local.columns:\n",
        "        sbp = df_local['SBP']\n",
        "        s += np.where(sbp <= 70, 3, 0)\n",
        "        s += np.where((sbp > 70) & (sbp <= 80), 2, 0)\n",
        "        s += np.where((sbp > 80) & (sbp <= 100), 1, 0)\n",
        "        s += np.where(sbp >= 200, 2, 0)\n",
        "    if 'HR' in df_local.columns:\n",
        "        hr = df_local['HR']\n",
        "        s += np.where(hr <= 40, 2, 0)\n",
        "        s += np.where((hr > 40) & (hr <= 50), 1, 0)\n",
        "        s += np.where((hr > 50) & (hr <= 100), 0, 0)\n",
        "        s += np.where((hr > 100) & (hr <= 110), 1, 0)\n",
        "        s += np.where((hr > 110) & (hr <= 129), 2, 0)\n",
        "        s += np.where(hr >= 130, 3, 0)\n",
        "    if 'Resp' in df_local.columns:\n",
        "        rr = df_local['Resp']\n",
        "        s += np.where(rr <= 8, 2, 0)\n",
        "        s += np.where((rr > 8) & (rr <= 14), 0, 0)\n",
        "        s += np.where((rr > 14) & (rr <= 20), 1, 0)\n",
        "        s += np.where((rr > 20) & (rr <= 29), 2, 0)\n",
        "        s += np.where(rr >= 30, 3, 0)\n",
        "    if 'Temp' in df_local.columns:\n",
        "        t = df_local['Temp']\n",
        "        s += np.where(t <= 35.0, 2, 0)\n",
        "        s += np.where(t >= 38.5, 1, 0)\n",
        "    return s\n",
        "\n",
        "df_filled['MEWS'] = compute_mews_series(df_filled)\n",
        "feature_intervals['MEWS'] = 4\n",
        "original_missing_mask['MEWS'] = df_filled['MEWS'].isna().copy()\n",
        "print(\"  Computed MEWS\")\n",
        "\n",
        "# pSOFA using MAP (no vasopressors), Bilirubin_total, Platelets\n",
        "bili_col = 'Bilirubin_total' if 'Bilirubin_total' in df_filled.columns else None\n",
        "\n",
        "def compute_psofa_series(df_local, bili_column):\n",
        "    s = pd.Series(0, index=df_local.index, dtype=float)\n",
        "    if 'MAP' in df_local.columns:\n",
        "        s += np.where(df_local['MAP'] < 70, 1, 0)\n",
        "    if bili_column and bili_column in df_local.columns:\n",
        "        b = df_local[bili_column]\n",
        "        s += np.where((b >= 1.2) & (b < 2.0), 1, 0)\n",
        "        s += np.where((b >= 2.0) & (b < 6.0), 2, 0)\n",
        "        s += np.where((b >= 6.0) & (b < 12.0), 3, 0)\n",
        "        s += np.where(b >= 12.0, 4, 0)\n",
        "    if 'Platelets' in df_local.columns:\n",
        "        pl = df_local['Platelets']\n",
        "        s += np.where((pl >= 100) & (pl <= 149), 1, 0)\n",
        "        s += np.where((pl >= 50) & (pl <= 99), 2, 0)\n",
        "        s += np.where((pl >= 20) & (pl <= 49), 3, 0)\n",
        "        s += np.where(pl < 20, 4, 0)\n",
        "    return s\n",
        "\n",
        "df_filled['pSOFA'] = compute_psofa_series(df_filled, bili_col)\n",
        "feature_intervals['pSOFA'] = 24\n",
        "original_missing_mask['pSOFA'] = df_filled['pSOFA'].isna().copy()\n",
        "print(\"  Computed pSOFA\")\n",
        "\n",
        "# -------- Compute IQR limits from training set for derived features (after ffill) --------\n",
        "derived_feats = [f for f in ('ShockIndex', 'BUN_Cr', 'MEWS', 'pSOFA') if f in df_filled.columns]\n",
        "train_filled = df_filled[df_filled['patient_id'].isin(train_ids)]\n",
        "iqr_limits_derived = compute_iqr_limits(train_filled, derived_feats)\n",
        "\n",
        "# Merge base + derived IQR limits\n",
        "iqr_limits = dict(iqr_limits_base)\n",
        "iqr_limits.update(iqr_limits_derived)\n",
        "\n",
        "# Apply clinical sanity bounds where provided\n",
        "print(\"\\nApplying clinical sanity bounds to IQR limits...\")\n",
        "for feat, (xmin, xmax) in list(iqr_limits.items()):\n",
        "    if feat in clinical_sanity:\n",
        "        cmin, cmax = clinical_sanity[feat]\n",
        "        new_min = max(xmin, cmin)\n",
        "        new_max = min(xmax, cmax)\n",
        "        if new_min < new_max:\n",
        "            iqr_limits[feat] = (float(new_min), float(new_max))\n",
        "        else:\n",
        "            print(f\"  Warning: Clinical bounds for {feat} resulted in inverted range. Keeping IQR bounds.\")\n",
        "\n",
        "# Save computed limits to JSON for reproducibility\n",
        "with open(limits_json_path, 'w') as f:\n",
        "    json.dump(iqr_limits, f, indent=2)\n",
        "print(f\"Saved IQR min/max limits to: {limits_json_path}\")\n",
        "\n",
        "# -------- Clip and normalize using iqr_limits --------\n",
        "print(\"\\nNormalizing features using IQR limits...\")\n",
        "for feat, (xmin, xmax) in iqr_limits.items():\n",
        "    if feat not in df_filled.columns:\n",
        "        continue\n",
        "    not_na = df_filled[feat].notna()\n",
        "    denom = (xmax - xmin) if (xmax - xmin) != 0 else 1.0\n",
        "    df_filled.loc[not_na, feat] = df_filled.loc[not_na, feat].clip(lower=xmin, upper=xmax)\n",
        "    df_filled.loc[not_na, feat] = 4.0 * (df_filled.loc[not_na, feat] - xmin) / denom + 1.0\n",
        "\n",
        "# -------- CRITICAL FIX: Set ALL originally missing values to -1 (using original masks) --------\n",
        "print(\"\\nImputing -1 for all originally missing values...\")\n",
        "all_features_to_impute = list(feature_intervals.keys()) + derived_feats\n",
        "\n",
        "for feat in all_features_to_impute:\n",
        "    if feat not in df_filled.columns:\n",
        "        continue\n",
        "    if feat not in original_missing_mask:\n",
        "        continue\n",
        "\n",
        "    # Use the ORIGINAL missing mask (before forward fill)\n",
        "    missing_mask = original_missing_mask[feat]\n",
        "    num_missing = missing_mask.sum()\n",
        "\n",
        "    if num_missing > 0:\n",
        "        df_filled.loc[missing_mask, feat] = -1.0\n",
        "        print(f\"  {feat}: Imputed {num_missing:,} missing values with -1\")\n",
        "\n",
        "# -------- Create mask columns (1 = present in original data, 0 = missing in original data) --------\n",
        "print(\"\\nCreating mask columns...\")\n",
        "for feat in all_features_to_impute:\n",
        "    if feat not in df_filled.columns:\n",
        "        continue\n",
        "    if feat in original_missing_mask:\n",
        "        df_filled[f'{feat}_mask'] = (~original_missing_mask[feat]).astype(int)\n",
        "\n",
        "# -------- Drop features missing in >80% of patients (patient-level) --------\n",
        "print(\"\\nFiltering features by patient-level missingness...\")\n",
        "n_patients = len(df_filled['patient_id'].unique())\n",
        "feat_list_all = [f for f in all_features_to_impute if f in df_filled.columns]\n",
        "\n",
        "# FIXED: Remove duplicates from feat_list_all while preserving order\n",
        "feat_list_all = list(dict.fromkeys(feat_list_all))\n",
        "\n",
        "presence_df = df_filled.groupby('patient_id')[feat_list_all].apply(lambda g: g.notna().any())\n",
        "feat_patient_counts = presence_df.sum(axis=0)\n",
        "feat_missing_frac = 1.0 - feat_patient_counts / n_patients\n",
        "keep_feats = [f for f, frac in feat_missing_frac.items() if frac <= 0.8]\n",
        "keep_mask_cols = [f'{f}_mask' for f in keep_feats if f'{f}_mask' in df_filled.columns]\n",
        "\n",
        "print(f\"Kept {len(keep_feats)} unique features after patient-level >80% missing filter.\")\n",
        "print(\"Kept features:\", keep_feats)\n",
        "\n",
        "# Keep other columns (labels, timestamps, metadata)\n",
        "other_cols = [c for c in df_filled.columns\n",
        "              if c not in feat_list_all\n",
        "              and c not in [f'{x}_mask' for x in feat_list_all]]\n",
        "\n",
        "cols_to_keep = ['patient_id']\n",
        "if time_present:\n",
        "    cols_to_keep.append(time_col)\n",
        "cols_to_keep += keep_feats + keep_mask_cols + other_cols\n",
        "\n",
        "# Remove duplicates & preserve order\n",
        "seen = set()\n",
        "final_cols = []\n",
        "for c in cols_to_keep:\n",
        "    if c in df_filled.columns and c not in seen:\n",
        "        final_cols.append(c)\n",
        "        seen.add(c)\n",
        "\n",
        "df_final = df_filled[final_cols].copy()\n",
        "\n",
        "# -------- Split by patient_id and save train/val/test/full CSVs --------\n",
        "print(\"\\nSplitting and saving final datasets...\")\n",
        "df_train_final = df_final[df_final['patient_id'].isin(train_ids)]\n",
        "df_val_final = df_final[df_final['patient_id'].isin(val_ids)]\n",
        "df_test_final = df_final[df_final['patient_id'].isin(test_ids)]\n",
        "\n",
        "df_train_final.to_csv(train_output_csv, index=False)\n",
        "df_val_final.to_csv(val_output_csv, index=False)\n",
        "df_test_final.to_csv(test_output_csv, index=False)\n",
        "df_final.to_csv(full_output_csv, index=False)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"PREPROCESSING COMPLETE\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Saved preprocessed train to: {train_output_csv}\")\n",
        "print(f\"Saved preprocessed val   to: {val_output_csv}\")\n",
        "print(f\"Saved preprocessed test  to: {test_output_csv}\")\n",
        "print(f\"Saved preprocessed full  to: {full_output_csv}\")\n",
        "print(f\"\\nTrain shape: {df_train_final.shape}\")\n",
        "print(f\"Val shape:   {df_val_final.shape}\")\n",
        "print(f\"Test shape:  {df_test_final.shape}\")\n",
        "print(f\"Full shape:  {df_final.shape}\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "\n",
        "# Verify all features are now filled\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"POST-IMPUTATION VERIFICATION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Features with any NaN values: {df_final[keep_feats].isna().any().sum()}\")\n",
        "print(f\"Total NaN count: {df_final[keep_feats].isna().sum().sum()}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "\n",
        "\n",
        "# -------- VISUALIZE ORIGINAL MISSINGNESS PATTERNS --------\n",
        "print(\"\\nGenerating missingness visualization...\")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Calculate missingness percentage for ORIGINAL data (before imputation)\n",
        "# We'll use the mask columns which encode original missingness\n",
        "mask_columns = [c for c in df_final.columns if c.endswith('_mask')]\n",
        "feature_names = [c.replace('_mask', '') for c in mask_columns]\n",
        "\n",
        "# Calculate missingness: 1 - mean(mask) = % originally missing\n",
        "missingness_pct = {}\n",
        "for feat, mask_col in zip(feature_names, mask_columns):\n",
        "    missingness_pct[feat] = (1 - df_final[mask_col].mean()) * 100\n",
        "\n",
        "# Convert to DataFrame for visualization\n",
        "miss_df = pd.DataFrame(list(missingness_pct.items()),\n",
        "                        columns=['Feature', 'Missing %'])\n",
        "miss_df = miss_df.sort_values('Missing %', ascending=False)\n",
        "\n",
        "# Create heatmap\n",
        "plt.figure(figsize=(20, 3))\n",
        "sns.heatmap(miss_df.set_index('Feature')['Missing %'].to_frame().T,\n",
        "            annot=True,\n",
        "            fmt='.1f',\n",
        "            cmap='RdYlGn_r',\n",
        "            cbar_kws={'label': 'Missing %'},\n",
        "            linewidths=0.5,\n",
        "            vmin=0,\n",
        "            vmax=100)\n",
        "plt.title('Original Feature Missingness Pattern (Before Imputation)', fontsize=14, pad=20)\n",
        "plt.xlabel('')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save to drive\n",
        "missingness_plot_path = os.path.join(output_dir, 'feature_missingness_heatmap.png')\n",
        "plt.savefig(missingness_plot_path, dpi=300, bbox_inches='tight')\n",
        "print(f\"Saved missingness visualization to: {missingness_plot_path}\")\n",
        "\n",
        "# Also save missingness statistics as CSV\n",
        "miss_csv_path = os.path.join(output_dir, 'feature_missingness_stats.csv')\n",
        "miss_df.to_csv(miss_csv_path, index=False)\n",
        "print(f\"Saved missingness statistics to: {miss_csv_path}\")\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTop 10 features with highest missingness:\")\n",
        "print(miss_df.head(10).to_string(index=False))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8VMccw5_nGH7",
        "outputId": "fad2e287-f491-47d2-f372-5cec19aa0ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1,552,041 rows, 42 columns\n",
            "\n",
            "============================================================\n",
            "APPLYING EXCLUSION CRITERIA FROM BASELINE PAPER\n",
            "============================================================\n",
            "Excluded 0 patients with < 8 hours ICU data\n",
            "Excluded 530 patients with sepsis onset < 4 hours after admission\n",
            "\n",
            "Patients: 40331 → 39801 (excluded 530)\n",
            "Rows: 1,552,041 → 1,547,195\n",
            "============================================================\n",
            "\n",
            "Using 'ICULOS' to build hourly time index as 'charttime'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n",
            "/tmp/ipython-input-722603645.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  g_hour = g.set_index(time_col).resample('1H').last()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resampled to hourly grid: 1,547,195 rows\n",
            "\n",
            "============================================================\n",
            "DATASET SPLIT (matching baseline paper)\n",
            "============================================================\n",
            "Test patients:    5971 ( 15.0%) - Held-out\n",
            "Train patients:  27064 ( 68.0%)\n",
            "Val patients:     6766 ( 17.0%)\n",
            "Total patients:  39801\n",
            "\n",
            "Test rows:   230,757\n",
            "Train rows: 1,052,708\n",
            "Val rows:    263,730\n",
            "============================================================\n",
            "\n",
            "Computing IQR limits for base features from TRAINING data only...\n",
            "Base IQR limits computed for 34 features\n",
            "\n",
            "Creating original missing value masks...\n",
            "Applying time-limited forward-fill...\n",
            "\n",
            "Computing derived features...\n",
            "  Computed ShockIndex\n",
            "  Computed BUN_Cr\n",
            "  Computed MEWS\n",
            "  Computed pSOFA\n",
            "\n",
            "Applying clinical sanity bounds to IQR limits...\n",
            "Saved IQR min/max limits to: /content/drive/MyDrive/AI_Fin/iqr_minmax_limits.json\n",
            "\n",
            "Normalizing features using IQR limits...\n",
            "\n",
            "Imputing -1 for all originally missing values...\n",
            "  HR: Imputed 152,684 missing values with -1\n",
            "  SBP: Imputed 225,179 missing values with -1\n",
            "  DBP: Imputed 484,552 missing values with -1\n",
            "  Resp: Imputed 237,307 missing values with -1\n",
            "  O2Sat: Imputed 201,867 missing values with -1\n",
            "  Temp: Imputed 1,023,410 missing values with -1\n",
            "  MAP: Imputed 192,477 missing values with -1\n",
            "  EtCO2: Imputed 1,490,011 missing values with -1\n",
            "  BaseExcess: Imputed 1,463,487 missing values with -1\n",
            "  HCO3: Imputed 1,482,455 missing values with -1\n",
            "  FiO2: Imputed 1,418,543 missing values with -1\n",
            "  pH: Imputed 1,440,227 missing values with -1\n",
            "  PaCO2: Imputed 1,461,406 missing values with -1\n",
            "  SaO2: Imputed 1,493,939 missing values with -1\n",
            "  AST: Imputed 1,522,283 missing values with -1\n",
            "  BUN: Imputed 1,441,183 missing values with -1\n",
            "  Alkalinephos: Imputed 1,522,522 missing values with -1\n",
            "  Calcium: Imputed 1,456,420 missing values with -1\n",
            "  Chloride: Imputed 1,477,048 missing values with -1\n",
            "  Creatinine: Imputed 1,453,065 missing values with -1\n",
            "  Bilirubin_direct: Imputed 1,544,253 missing values with -1\n",
            "  Glucose: Imputed 1,282,618 missing values with -1\n",
            "  Lactate: Imputed 1,506,168 missing values with -1\n",
            "  Magnesium: Imputed 1,449,748 missing values with -1\n",
            "  Phosphate: Imputed 1,485,238 missing values with -1\n",
            "  Potassium: Imputed 1,403,406 missing values with -1\n",
            "  Bilirubin_total: Imputed 1,524,300 missing values with -1\n",
            "  TroponinI: Imputed 1,532,556 missing values with -1\n",
            "  Hct: Imputed 1,410,395 missing values with -1\n",
            "  Hgb: Imputed 1,433,155 missing values with -1\n",
            "  PTT: Imputed 1,501,774 missing values with -1\n",
            "  WBC: Imputed 1,448,254 missing values with -1\n",
            "  Fibrinogen: Imputed 1,537,021 missing values with -1\n",
            "  Platelets: Imputed 1,455,441 missing values with -1\n",
            "  ShockIndex: Imputed 88,617 missing values with -1\n",
            "  BUN_Cr: Imputed 344,728 missing values with -1\n",
            "  ShockIndex: Imputed 88,617 missing values with -1\n",
            "  BUN_Cr: Imputed 344,728 missing values with -1\n",
            "\n",
            "Creating mask columns...\n",
            "\n",
            "Filtering features by patient-level missingness...\n",
            "Kept 40 unique features after patient-level >80% missing filter.\n",
            "Kept features: ['HR', 'SBP', 'DBP', 'Resp', 'O2Sat', 'Temp', 'MAP', 'EtCO2', 'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN', 'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct', 'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium', 'Bilirubin_total', 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC', 'Fibrinogen', 'Platelets', 'Age', 'Gender', 'ShockIndex', 'BUN_Cr', 'MEWS', 'pSOFA']\n",
            "\n",
            "Splitting and saving final datasets...\n",
            "\n",
            "============================================================\n",
            "PREPROCESSING COMPLETE\n",
            "============================================================\n",
            "Saved preprocessed train to: /content/drive/MyDrive/AI_Fin/sepsis_preprocessed_train.csv\n",
            "Saved preprocessed val   to: /content/drive/MyDrive/AI_Fin/sepsis_preprocessed_val.csv\n",
            "Saved preprocessed test  to: /content/drive/MyDrive/AI_Fin/sepsis_preprocessed_test.csv\n",
            "Saved preprocessed full  to: /content/drive/MyDrive/AI_Fin/sepsis_preprocessed_full.csv\n",
            "\n",
            "Train shape: (1052708, 87)\n",
            "Val shape:   (263730, 87)\n",
            "Test shape:  (230757, 87)\n",
            "Full shape:  (1547195, 87)\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "POST-IMPUTATION VERIFICATION\n",
            "============================================================\n",
            "Features with any NaN values: 0\n",
            "Total NaN count: 0\n",
            "============================================================\n",
            "\n",
            "Generating missingness visualization...\n",
            "Saved missingness visualization to: /content/drive/MyDrive/AI_Fin/feature_missingness_heatmap.png\n",
            "Saved missingness statistics to: /content/drive/MyDrive/AI_Fin/feature_missingness_stats.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 features with highest missingness:\n",
            "         Feature  Missing %\n",
            "Bilirubin_direct  99.809849\n",
            "      Fibrinogen  99.342423\n",
            "       TroponinI  99.053836\n",
            " Bilirubin_total  98.520225\n",
            "    Alkalinephos  98.405308\n",
            "             AST  98.389860\n",
            "         Lactate  97.348298\n",
            "             PTT  97.064300\n",
            "            SaO2  96.557900\n",
            "           EtCO2  96.304021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build Input Matrices**"
      ],
      "metadata": {
        "id": "_3S_nPDc1HkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# --- USER CONFIG ---\n",
        "preprocessed_train_csv = '/content/drive/MyDrive/AI_Course_Project/Dataset/sepsis_preprocessed_train.csv'\n",
        "preprocessed_val_csv   = '/content/drive/MyDrive/AI_Course_Project/Dataset/sepsis_preprocessed_val.csv'  # ADD THIS\n",
        "preprocessed_test_csv  = '/content/drive/MyDrive/AI_Course_Project/Dataset/sepsis_preprocessed_test.csv'\n",
        "output_dir = '/content/drive/MyDrive/AI_Course_Project/Dataset'\n",
        "WINDOW_HOURS = 4\n",
        "LABEL = 'SepsisLabel'\n",
        "\n",
        "# 21 features as used in the Baseline paper\n",
        "FEATURES = [\n",
        "    'HR', 'SBP', 'DBP', 'Resp', 'O2Sat', 'Temp', 'MAP',\n",
        "    'WBC', 'Platelets', 'Hgb', 'Creatinine', 'BUN', 'Potassium',\n",
        "    'Glucose', 'Lactate',\n",
        "    'Age', 'Gender',\n",
        "    'ShockIndex', 'BUN_Cr', 'MEWS', 'pSOFA'\n",
        "]\n",
        "\n",
        "def build_patient_matrices(df, features, label, window_hours):\n",
        "    data_samples = []\n",
        "    label_samples = []\n",
        "    patient_ids = []  # CRITICAL: Track patient IDs\n",
        "\n",
        "    groupby_key = 'patient_id'\n",
        "    time_key = 'charttime' if 'charttime' in df.columns else None\n",
        "\n",
        "    for pid, group in df.groupby(groupby_key):\n",
        "        g = group.sort_values(time_key) if time_key else group.copy()\n",
        "        g = g.reset_index(drop=True)\n",
        "\n",
        "        if label not in g.columns:\n",
        "            continue\n",
        "\n",
        "        labels = g[label].values\n",
        "        values = g[features].values\n",
        "\n",
        "        if len(values) < window_hours:\n",
        "            continue\n",
        "\n",
        "        for start in range(len(values) - window_hours + 1):\n",
        "            window_x = values[start:start + window_hours]\n",
        "            window_y = labels[start + window_hours - 1]\n",
        "\n",
        "            data_samples.append(window_x)\n",
        "            label_samples.append(window_y)\n",
        "            patient_ids.append(pid)  # CRITICAL: Save patient ID for each window\n",
        "\n",
        "    data_samples = np.stack(data_samples)\n",
        "    label_samples = np.array(label_samples)\n",
        "    patient_ids = np.array(patient_ids)  # CRITICAL: Return patient IDs\n",
        "\n",
        "    return data_samples, label_samples, patient_ids  # RETURN 3 VALUES, NOT 2\n",
        "\n",
        "# --- Load data ---\n",
        "print(\"Loading preprocessed data...\")\n",
        "df_train = pd.read_csv(preprocessed_train_csv)\n",
        "df_val = pd.read_csv(preprocessed_val_csv)      # CRITICAL: Load validation set\n",
        "df_test = pd.read_csv(preprocessed_test_csv)\n",
        "\n",
        "print(f\"Train: {len(df_train):,} rows, {df_train['patient_id'].nunique()} patients\")\n",
        "print(f\"Val:   {len(df_val):,} rows, {df_val['patient_id'].nunique()} patients\")\n",
        "print(f\"Test:  {len(df_test):,} rows, {df_test['patient_id'].nunique()} patients\")\n",
        "\n",
        "# --- Build matrices ---\n",
        "print(\"\\nBuilding sliding window matrices...\")\n",
        "X_train, y_train, pid_train = build_patient_matrices(df_train, FEATURES, LABEL, WINDOW_HOURS)\n",
        "X_val, y_val, pid_val = build_patient_matrices(df_val, FEATURES, LABEL, WINDOW_HOURS)  # CRITICAL: Val set\n",
        "X_test, y_test, pid_test = build_patient_matrices(df_test, FEATURES, LABEL, WINDOW_HOURS)\n",
        "\n",
        "# --- Print statistics ---\n",
        "print(f\"\\nTrain windows: {X_train.shape}\")\n",
        "print(f\"  Class 0: {(y_train == 0).sum():,}, Class 1: {(y_train == 1).sum():,}\")\n",
        "print(f\"  Unique patients: {len(np.unique(pid_train))}\")\n",
        "\n",
        "print(f\"\\nVal windows: {X_val.shape}\")\n",
        "print(f\"  Class 0: {(y_val == 0).sum():,}, Class 1: {(y_val == 1).sum():,}\")\n",
        "print(f\"  Unique patients: {len(np.unique(pid_val))}\")\n",
        "\n",
        "print(f\"\\nTest windows: {X_test.shape}\")\n",
        "print(f\"  Class 0: {(y_test == 0).sum():,}, Class 1: {(y_test == 1).sum():,}\")\n",
        "print(f\"  Unique patients: {len(np.unique(pid_test))}\")\n",
        "\n",
        "# --- Save with patient IDs ---\n",
        "np.savez_compressed(  # Use compressed for smaller file size\n",
        "    os.path.join(output_dir, 'baseline_train_matrices.npz'),\n",
        "    X=X_train,\n",
        "    y=y_train,\n",
        "    patient_ids=pid_train  # CRITICAL: Save patient IDs\n",
        ")\n",
        "\n",
        "np.savez_compressed(\n",
        "    os.path.join(output_dir, 'baseline_val_matrices.npz'),\n",
        "    X=X_val,\n",
        "    y=y_val,\n",
        "    patient_ids=pid_val  # CRITICAL: Save patient IDs\n",
        ")\n",
        "\n",
        "np.savez_compressed(\n",
        "    os.path.join(output_dir, 'baseline_test_matrices.npz'),\n",
        "    X=X_test,\n",
        "    y=y_test,\n",
        "    patient_ids=pid_test  # CRITICAL: Save patient IDs\n",
        ")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"✓ Saved baseline matrices:\")\n",
        "print(f\"  Train: {X_train.shape}\")\n",
        "print(f\"  Val:   {X_val.shape}\")\n",
        "print(f\"  Test:  {X_test.shape}\")\n",
        "print(f\"  Output directory: {output_dir}\")\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xvgpj1nd1KDI",
        "outputId": "7fa9425b-2280-49c2-f12c-3bb8542e7635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading preprocessed data...\n",
            "Train: 1,052,708 rows, 27064 patients\n",
            "Val:   263,730 rows, 6766 patients\n",
            "Test:  230,757 rows, 5971 patients\n",
            "\n",
            "Building sliding window matrices...\n",
            "\n",
            "Train windows: (971516, 4, 21)\n",
            "  Class 0: 955,899, Class 1: 15,617\n",
            "  Unique patients: 27064\n",
            "\n",
            "Val windows: (243432, 4, 21)\n",
            "  Class 0: 239,470, Class 1: 3,962\n",
            "  Unique patients: 6766\n",
            "\n",
            "Test windows: (212844, 4, 21)\n",
            "  Class 0: 209,260, Class 1: 3,584\n",
            "  Unique patients: 5971\n",
            "\n",
            "============================================================\n",
            "✓ Saved baseline matrices:\n",
            "  Train: (971516, 4, 21)\n",
            "  Val:   (243432, 4, 21)\n",
            "  Test:  (212844, 4, 21)\n",
            "  Output directory: /content/drive/MyDrive/AI_Fin\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oversampling using SMOTE"
      ],
      "metadata": {
        "id": "pFFZS-kK2QYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "MEMORY-EFFICIENT SMOTE PIPELINE WITH MASKING LAYER\n",
        "- Added layers.Masking(mask_value=-1.0) at encoder input\n",
        "- Prevents -1 values from affecting LSTM computations\n",
        "- Full patient ID tracking for no data leakage\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import gc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# GPU setup WITHOUT mixed precision (causes dtype issues)\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    print(f\"[OK] GPU memory growth enabled for {len(gpus)} GPU(s)\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================\n",
        "\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/AI_Course_Project/Dataset'\n",
        "SEQUENCE_LENGTH = 4\n",
        "N_FEATURES = 21\n",
        "EMBEDDING_DIM = 64\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 30\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "\n",
        "np.random.seed(RANDOM_STATE)\n",
        "tf.random.set_seed(RANDOM_STATE)\n",
        "\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"MEMORY-EFFICIENT SMOTE PIPELINE WITH MASKING LAYER\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# STAGE 0: LOAD DATA\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nSTAGE 0: Loading data...\")\n",
        "data = np.load(f'{OUTPUT_DIR}/baseline_train_matrices.npz')\n",
        "X_train_orig = data['X'].astype(np.float32)\n",
        "y_train = data['y']\n",
        "patient_ids = np.array([int(pid.replace('p', '')) for pid in data['patient_ids']], dtype=np.int64)\n",
        "\n",
        "\n",
        "print(f\"Training data shape: {X_train_orig.shape}\")\n",
        "print(f\"  Class 0: {(y_train == 0).sum():,}, Class 1: {(y_train == 1).sum():,}\")\n",
        "\n",
        "\n",
        "n_class_0 = (y_train == 0).sum()\n",
        "n_class_1 = (y_train == 1).sum()\n",
        "class_ratio = n_class_0 / n_class_1\n",
        "print(f\"  Class imbalance ratio: {class_ratio:.2f}:1\")\n",
        "\n",
        "\n",
        "del data\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# STAGE 1: TRAIN AUTOENCODER WITH SAMPLE WEIGHTS & MASKING\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STAGE 1: Training LSTM Autoencoder (WITH MASKING LAYER)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "\n",
        "def build_lstm_autoencoder_with_masking(sequence_length, n_features, embedding_dim):\n",
        "    \"\"\"\n",
        "    Build autoencoder with masking layer to handle -1 values.\n",
        "\n",
        "    The Masking layer prevents -1 (missing) values from:\n",
        "    - Affecting LSTM computations\n",
        "    - Being encoded into the embedding\n",
        "    - Causing bias in reconstruction\n",
        "    \"\"\"\n",
        "    # ⭐ ENCODER WITH MASKING\n",
        "    encoder_inputs = layers.Input(shape=(sequence_length, n_features))\n",
        "    x = layers.Masking(mask_value=-1.0)(encoder_inputs)  # ⭐ CRITICAL: Mask -1 values\n",
        "    x = layers.LSTM(64, activation='tanh', return_sequences=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    encoded = layers.Dense(embedding_dim, activation='linear', name='embedding')(x)\n",
        "    encoder = Model(encoder_inputs, encoded, name='encoder')\n",
        "\n",
        "\n",
        "    # DECODER (standard)\n",
        "    decoder_inputs = layers.Input(shape=(embedding_dim,))\n",
        "    x = layers.RepeatVector(sequence_length)(decoder_inputs)\n",
        "    x = layers.LSTM(64, activation='tanh', return_sequences=True)(x)\n",
        "    decoded = layers.TimeDistributed(layers.Dense(n_features))(x)\n",
        "    decoder = Model(decoder_inputs, decoded, name='decoder')\n",
        "\n",
        "\n",
        "    # FULL AUTOENCODER\n",
        "    autoencoder_inputs = layers.Input(shape=(sequence_length, n_features))\n",
        "    encoded = encoder(autoencoder_inputs)\n",
        "    decoded = decoder(encoded)\n",
        "    autoencoder = Model(autoencoder_inputs, decoded)\n",
        "\n",
        "\n",
        "    return autoencoder, encoder, decoder\n",
        "\n",
        "\n",
        "autoencoder, encoder, decoder = build_lstm_autoencoder_with_masking(\n",
        "    SEQUENCE_LENGTH, N_FEATURES, EMBEDDING_DIM\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\n[OK] Encoder architecture:\")\n",
        "encoder.summary()\n",
        "\n",
        "\n",
        "# Stratified split\n",
        "X_ae_train, X_ae_val, y_ae_train, y_ae_val = train_test_split(\n",
        "    X_train_orig,\n",
        "    y_train,\n",
        "    test_size=0.05,\n",
        "    stratify=y_train,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "\n",
        "# Create sample weights for class balance\n",
        "sample_weights_train = np.where(y_ae_train == 1, class_ratio, 1.0).astype(np.float32)\n",
        "sample_weights_val = np.where(y_ae_val == 1, class_ratio, 1.0).astype(np.float32)\n",
        "\n",
        "\n",
        "print(f\"\\n[SAMPLE WEIGHTING] Applied for class balance:\")\n",
        "print(f\"  Class 0 weight: 1.0\")\n",
        "print(f\"  Class 1 weight: {class_ratio:.2f}\")\n",
        "print(f\"  Sample weight shape: {sample_weights_train.shape}\")\n",
        "\n",
        "\n",
        "# Custom weighted autoencoder\n",
        "class WeightedAutoencoder(keras.Model):\n",
        "    def __init__(self, autoencoder):\n",
        "        super().__init__()\n",
        "        self.autoencoder = autoencoder\n",
        "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.autoencoder(inputs)\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_tracker]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, y, sample_weight = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self.autoencoder(x, training=True)\n",
        "            y = tf.cast(y, y_pred.dtype)\n",
        "            sample_weight = tf.cast(sample_weight, y_pred.dtype)\n",
        "\n",
        "            # Per-sample MSE across time & features\n",
        "            loss_per_sample = tf.reduce_mean(tf.square(y - y_pred), axis=[1, 2])\n",
        "            weighted_loss = loss_per_sample * sample_weight\n",
        "            loss = tf.reduce_mean(weighted_loss)\n",
        "\n",
        "        trainable_vars = self.autoencoder.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {\"loss\": self.loss_tracker.result()}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        x, y, sample_weight = data\n",
        "        y_pred = self.autoencoder(x, training=False)\n",
        "\n",
        "        y = tf.cast(y, y_pred.dtype)\n",
        "        sample_weight = tf.cast(sample_weight, y_pred.dtype)\n",
        "\n",
        "        loss_per_sample = tf.reduce_mean(tf.square(y - y_pred), axis=[1, 2])\n",
        "        weighted_loss = loss_per_sample * sample_weight\n",
        "        loss = tf.reduce_mean(weighted_loss)\n",
        "\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {\"loss\": self.loss_tracker.result()}\n",
        "\n",
        "\n",
        "weighted_ae = WeightedAutoencoder(autoencoder)\n",
        "weighted_ae.compile(optimizer=keras.optimizers.Adam(0.001))\n",
        "\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (X_ae_train, X_ae_train, sample_weights_train)\n",
        ").batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (X_ae_val, X_ae_val, sample_weights_val)\n",
        ").batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "print(f\"\\nTraining on {len(X_ae_train):,} samples (weighted + masked)...\")\n",
        "history = weighted_ae.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[\n",
        "        keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, monitor='val_loss'),\n",
        "        keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3, monitor='val_loss')\n",
        "    ],\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "\n",
        "# Save models\n",
        "autoencoder.save(f'{OUTPUT_DIR}/lstm_autoencoder_weighted_masked.h5')\n",
        "encoder.save(f'{OUTPUT_DIR}/lstm_encoder_weighted_masked.h5')\n",
        "decoder.save(f'{OUTPUT_DIR}/lstm_decoder_weighted_masked.h5')\n",
        "\n",
        "\n",
        "final_train_loss = history.history['loss'][-1]\n",
        "final_val_loss = history.history['val_loss'][-1]\n",
        "print(f\"\\n[OK] Final training loss: {final_train_loss:.6f}\")\n",
        "print(f\"[OK] Final validation loss: {final_val_loss:.6f}\")\n",
        "\n",
        "\n",
        "del X_ae_train, X_ae_val, y_ae_train, y_ae_val, sample_weights_train, sample_weights_val\n",
        "del train_dataset, val_dataset, weighted_ae, history\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# STAGE 2: ENCODE IN BATCHES\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STAGE 2: Encoding (Batch Processing)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "\n",
        "def encode_in_batches(data, encoder, batch_size):\n",
        "    n_samples = len(data)\n",
        "    n_batches = (n_samples + batch_size - 1) // batch_size\n",
        "    embeddings_list = []\n",
        "\n",
        "    for i in range(n_batches):\n",
        "        start_idx = i * batch_size\n",
        "        end_idx = min((i + 1) * batch_size, n_samples)\n",
        "        batch = data[start_idx:end_idx]\n",
        "        batch_embeddings = encoder.predict(batch, batch_size=batch_size, verbose=0)\n",
        "        embeddings_list.append(batch_embeddings)\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"  Processed {end_idx:,}/{n_samples:,} samples...\")\n",
        "            gc.collect()\n",
        "\n",
        "    return np.vstack(embeddings_list)\n",
        "\n",
        "\n",
        "print(\"Encoding sequences (with masking)...\")\n",
        "embeddings = encode_in_batches(X_train_orig, encoder, BATCH_SIZE)\n",
        "print(f\"Embeddings shape: {embeddings.shape}\")\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "embeddings_scaled = scaler.fit_transform(embeddings)\n",
        "\n",
        "\n",
        "import pickle\n",
        "with open(f'{OUTPUT_DIR}/embedding_scaler_weighted_masked.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "\n",
        "del embeddings\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# STAGE 3: APPLY SMOTE (WITH PATIENT TRACKING)\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STAGE 3: Applying SMOTE (WITH PATIENT ID TRACKING)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "\n",
        "n_minority = (y_train == 1).sum()\n",
        "n_majority = (y_train == 0).sum()\n",
        "print(f\"Before SMOTE: {n_majority:,} negative, {n_minority:,} positive\")\n",
        "\n",
        "\n",
        "k_neighbors = min(5, n_minority - 1)\n",
        "smote = SMOTE(sampling_strategy='auto', k_neighbors=k_neighbors, random_state=RANDOM_STATE)\n",
        "\n",
        "\n",
        "print(f\"Applying SMOTE with k_neighbors={k_neighbors}...\")\n",
        "n_orig = len(embeddings_scaled)\n",
        "embeddings_balanced_scaled, y_balanced = smote.fit_resample(embeddings_scaled, y_train)\n",
        "n_synthetic = len(embeddings_balanced_scaled) - n_orig\n",
        "\n",
        "\n",
        "print(f\"\\n[OK] After SMOTE:\")\n",
        "print(f\"  Total: {len(embeddings_balanced_scaled):,} samples\")\n",
        "print(f\"  Original: {n_orig:,}, Synthetic: {n_synthetic:,}\")\n",
        "print(f\"  Class 0: {(y_balanced == 0).sum():,}, Class 1: {(y_balanced == 1).sum():,}\")\n",
        "\n",
        "\n",
        "embeddings_balanced = scaler.inverse_transform(embeddings_balanced_scaled)\n",
        "\n",
        "\n",
        "# Track which samples are synthetic\n",
        "sample_types = np.zeros(len(y_balanced), dtype=np.int8)\n",
        "sample_types[n_orig:] = 1  # 0 = original, 1 = synthetic\n",
        "\n",
        "\n",
        "# Create patient_ids for synthetic samples\n",
        "max_original_patient_id = patient_ids.max()\n",
        "n_synthetic_samples = len(y_balanced) - n_orig\n",
        "\n",
        "synthetic_patient_ids = np.arange(\n",
        "    max_original_patient_id + 1,\n",
        "    max_original_patient_id + 1 + n_synthetic_samples,\n",
        "    dtype=patient_ids.dtype\n",
        ")\n",
        "\n",
        "# Concatenate original patient IDs with synthetic ones\n",
        "patient_ids_balanced = np.concatenate([\n",
        "    patient_ids,\n",
        "    synthetic_patient_ids\n",
        "])\n",
        "\n",
        "\n",
        "print(f\"\\n[OK] Patient ID tracking:\")\n",
        "print(f\"  Original patient IDs: {patient_ids.min()}-{patient_ids.max()} ({len(np.unique(patient_ids)):,} unique)\")\n",
        "print(f\"  Synthetic patient IDs: {synthetic_patient_ids.min()}-{synthetic_patient_ids.max()} ({len(synthetic_patient_ids):,} new)\")\n",
        "print(f\"  Total unique patients: {len(np.unique(patient_ids_balanced)):,}\")\n",
        "\n",
        "\n",
        "del embeddings_scaled, embeddings_balanced_scaled\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# STAGE 4: DECODE IN BATCHES\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STAGE 4: Decoding (Batch Processing)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "\n",
        "def decode_in_batches(embeddings, decoder, batch_size):\n",
        "    n_samples = len(embeddings)\n",
        "    n_batches = (n_samples + batch_size - 1) // batch_size\n",
        "    decoded_list = []\n",
        "\n",
        "    for i in range(n_batches):\n",
        "        start_idx = i * batch_size\n",
        "        end_idx = min((i + 1) * batch_size, n_samples)\n",
        "        batch_emb = embeddings[start_idx:end_idx]\n",
        "        batch_decoded = decoder.predict(batch_emb, batch_size=batch_size, verbose=0)\n",
        "        decoded_list.append(batch_decoded)\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"  Decoded {end_idx:,}/{n_samples:,} samples...\")\n",
        "            gc.collect()\n",
        "\n",
        "    return np.vstack(decoded_list)\n",
        "\n",
        "\n",
        "print(\"Reconstructing sequences...\")\n",
        "X_train_balanced = decode_in_batches(embeddings_balanced, decoder, BATCH_SIZE)\n",
        "print(f\"[OK] Balanced data shape: {X_train_balanced.shape}\")\n",
        "print(f\"[OK] Patient IDs shape: {patient_ids_balanced.shape}\")\n",
        "\n",
        "\n",
        "del embeddings_balanced\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# STAGE 4.5: CLIP EXTREME VALUES\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STAGE 4.5: Clipping Extreme Values\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "\n",
        "lower_bound = np.percentile(X_train_orig, 0.1)\n",
        "upper_bound = np.percentile(X_train_orig, 99.9)\n",
        "\n",
        "\n",
        "print(f\"Original data range: [{X_train_orig.min():.4f}, {X_train_orig.max():.4f}]\")\n",
        "print(f\"Clipping bounds (0.1% - 99.9%): [{lower_bound:.4f}, {upper_bound:.4f}]\")\n",
        "\n",
        "\n",
        "n_inf = np.isinf(X_train_balanced).sum()\n",
        "n_nan = np.isnan(X_train_balanced).sum()\n",
        "n_extreme = ((X_train_balanced < lower_bound) | (X_train_balanced > upper_bound)).sum()\n",
        "\n",
        "\n",
        "if n_inf > 0 or n_nan > 0:\n",
        "    print(f\"[WARNING] Found {n_inf} inf values and {n_nan} NaN values!\")\n",
        "    X_train_balanced = np.nan_to_num(X_train_balanced,\n",
        "                                      nan=0.0,\n",
        "                                      posinf=upper_bound,\n",
        "                                      neginf=lower_bound)\n",
        "    print(f\"[FIX] Replaced inf/NaN values\")\n",
        "\n",
        "\n",
        "if n_extreme > 0:\n",
        "    print(f\"[WARNING] Found {n_extreme} extreme outliers ({n_extreme/(X_train_balanced.size)*100:.2f}% of data)\")\n",
        "    X_train_balanced = np.clip(X_train_balanced, lower_bound, upper_bound)\n",
        "    print(f\"[FIX] Clipped to realistic range\")\n",
        "\n",
        "\n",
        "print(f\"[OK] After clipping: range=[{X_train_balanced.min():.4f}, {X_train_balanced.max():.4f}]\")\n",
        "\n",
        "\n",
        "X_synthetic_clipped = X_train_balanced[n_orig:]\n",
        "X_synthetic_class_1_clipped = X_synthetic_clipped[y_balanced[n_orig:] == 1]\n",
        "print(f\"\\nSynthetic Class 1 AFTER clipping:\")\n",
        "print(f\"  Mean={X_synthetic_class_1_clipped.mean():.4f}, Std={X_synthetic_class_1_clipped.std():.4f}\")\n",
        "print(f\"  Range=[{X_synthetic_class_1_clipped.min():.4f}, {X_synthetic_class_1_clipped.max():.4f}]\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# STAGE 5: QUALITY CHECK & SAVE\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STAGE 5: Quality Check & Saving\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "\n",
        "X_orig_class_1 = X_train_orig[y_train == 1]\n",
        "X_synthetic = X_train_balanced[n_orig:]\n",
        "X_synthetic_class_1 = X_synthetic[y_balanced[n_orig:] == 1]\n",
        "\n",
        "\n",
        "print(f\"\\n[QUALITY METRICS]\")\n",
        "print(f\"Original Class 1 (SEPSIS): Mean={X_orig_class_1.mean():.4f}, Std={X_orig_class_1.std():.4f}\")\n",
        "print(f\"Synthetic Class 1 (SEPSIS): Mean={X_synthetic_class_1.mean():.4f}, Std={X_synthetic_class_1.std():.4f}\")\n",
        "\n",
        "\n",
        "# Save with patient_ids\n",
        "np.savez_compressed(\n",
        "    f'{OUTPUT_DIR}/smoted_train_matrices_weighted_v2_clipped.npz',\n",
        "    X=X_train_balanced.astype(np.float32),\n",
        "    y=y_balanced.astype(np.int8),\n",
        "    patient_ids=patient_ids_balanced.astype(np.int64),\n",
        "    sample_types=sample_types,\n",
        "    n_original=n_orig,\n",
        "    n_synthetic=n_synthetic\n",
        ")\n",
        "\n",
        "\n",
        "import json\n",
        "quality_metrics = {\n",
        "    'n_original': int(n_orig),\n",
        "    'n_synthetic': int(n_synthetic),\n",
        "    'total_samples': int(len(X_train_balanced)),\n",
        "    'total_unique_patients': int(len(np.unique(patient_ids_balanced))),\n",
        "    'original_unique_patients': int(len(np.unique(patient_ids))),\n",
        "    'synthetic_unique_patients': int(len(synthetic_patient_ids)),\n",
        "    'class_0_count': int((y_balanced == 0).sum()),\n",
        "    'class_1_count': int((y_balanced == 1).sum()),\n",
        "    'k_neighbors': int(k_neighbors),\n",
        "    'class_weight_ratio': float(class_ratio),\n",
        "    'autoencoder_final_train_loss': float(final_train_loss),\n",
        "    'autoencoder_final_val_loss': float(final_val_loss),\n",
        "    'weighted_training': True,\n",
        "    'masking_layer_applied': True,  # ⭐ NEW: Document masking\n",
        "    'clipping_applied': True,\n",
        "    'patient_ids_included': True\n",
        "}\n",
        "\n",
        "\n",
        "with open(f'{OUTPUT_DIR}/smote_quality_metrics_weighted_v2_clipped.json', 'w') as f:\n",
        "    json.dump(quality_metrics, f, indent=2)\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"[OK] SMOTE PIPELINE COMPLETE WITH MASKING & PATIENT TRACKING!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Saved: smoted_train_matrices_weighted_v2_clipped.npz\")\n",
        "print(f\"  - X: {X_train_balanced.shape}\")\n",
        "print(f\"  - y: {y_balanced.shape}\")\n",
        "print(f\"  - patient_ids: {patient_ids_balanced.shape}\")\n",
        "print(f\"  - Masking layer: ✓ Applied at encoder input\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "\n",
        "del X_train_orig, X_train_balanced, y_train, y_balanced, patient_ids, patient_ids_balanced\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e35TNI_U2UHR",
        "outputId": "f42a582f-178c-4d2d-a517-b6289bf70f1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "MEMORY-EFFICIENT SMOTE PIPELINE WITH MASKING LAYER\n",
            "============================================================\n",
            "\n",
            "STAGE 0: Loading data...\n",
            "Training data shape: (971516, 4, 21)\n",
            "  Class 0: 955,899, Class 1: 15,617\n",
            "  Class imbalance ratio: 61.21:1\n",
            "\n",
            "============================================================\n",
            "STAGE 1: Training LSTM Autoencoder (WITH MASKING LAYER)\n",
            "============================================================\n",
            "\n",
            "[OK] Encoder architecture:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"encoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m21\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cast_8 (\u001b[38;5;33mCast\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m21\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m21\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ cast_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ masking_4 (\u001b[38;5;33mMasking\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m21\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ any_4 (\u001b[38;5;33mAny\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ not_equal_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m22,016\u001b[0m │ masking_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ any_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ batch_normalizat… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cast_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ cast_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ masking_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ any_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">22,016</span> │ masking_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ any_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ batch_normalizat… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,432\u001b[0m (103.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,432</span> (103.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,304\u001b[0m (102.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,304</span> (102.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SAMPLE WEIGHTING] Applied for class balance:\n",
            "  Class 0 weight: 1.0\n",
            "  Class 1 weight: 61.21\n",
            "  Sample weight shape: (922940,)\n",
            "\n",
            "Training on 922,940 samples (weighted + masked)...\n",
            "Epoch 1/30\n",
            "7211/7211 - 166s - 23ms/step - loss: inf - val_loss: 3.3253 - learning_rate: 1.0000e-03\n",
            "Epoch 2/30\n",
            "7211/7211 - 161s - 22ms/step - loss: 2.8324 - val_loss: 2.8034 - learning_rate: 1.0000e-03\n",
            "Epoch 3/30\n",
            "7211/7211 - 156s - 22ms/step - loss: 2.4764 - val_loss: 2.7641 - learning_rate: 1.0000e-03\n",
            "Epoch 4/30\n",
            "7211/7211 - 205s - 28ms/step - loss: 2.4321 - val_loss: 2.3790 - learning_rate: 1.0000e-03\n",
            "Epoch 5/30\n",
            "7211/7211 - 155s - 22ms/step - loss: 2.4245 - val_loss: 2.3149 - learning_rate: 1.0000e-03\n",
            "Epoch 6/30\n",
            "7211/7211 - 153s - 21ms/step - loss: 2.4234 - val_loss: 2.3130 - learning_rate: 1.0000e-03\n",
            "Epoch 7/30\n",
            "7211/7211 - 154s - 21ms/step - loss: 2.4233 - val_loss: 2.3129 - learning_rate: 1.0000e-03\n",
            "Epoch 8/30\n",
            "7211/7211 - 204s - 28ms/step - loss: 2.4233 - val_loss: 2.3129 - learning_rate: 1.0000e-03\n",
            "Epoch 9/30\n",
            "7211/7211 - 159s - 22ms/step - loss: 2.4233 - val_loss: 2.3129 - learning_rate: 1.0000e-03\n",
            "Epoch 10/30\n",
            "7211/7211 - 159s - 22ms/step - loss: 2.4233 - val_loss: 2.3129 - learning_rate: 1.0000e-03\n",
            "Epoch 11/30\n",
            "7211/7211 - 156s - 22ms/step - loss: 2.4233 - val_loss: 2.3129 - learning_rate: 5.0000e-04\n",
            "Epoch 12/30\n",
            "7211/7211 - 156s - 22ms/step - loss: 2.4233 - val_loss: 2.3129 - learning_rate: 5.0000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[OK] Final training loss: 2.423278\n",
            "[OK] Final validation loss: 2.312937\n",
            "\n",
            "============================================================\n",
            "STAGE 2: Encoding (Batch Processing)\n",
            "============================================================\n",
            "Encoding sequences (with masking)...\n",
            "  Processed 12,800/971,516 samples...\n",
            "  Processed 25,600/971,516 samples...\n",
            "  Processed 38,400/971,516 samples...\n",
            "  Processed 51,200/971,516 samples...\n",
            "  Processed 64,000/971,516 samples...\n",
            "  Processed 76,800/971,516 samples...\n",
            "  Processed 89,600/971,516 samples...\n",
            "  Processed 102,400/971,516 samples...\n",
            "  Processed 115,200/971,516 samples...\n",
            "  Processed 128,000/971,516 samples...\n",
            "  Processed 140,800/971,516 samples...\n",
            "  Processed 153,600/971,516 samples...\n",
            "  Processed 166,400/971,516 samples...\n",
            "  Processed 179,200/971,516 samples...\n",
            "  Processed 192,000/971,516 samples...\n",
            "  Processed 204,800/971,516 samples...\n",
            "  Processed 217,600/971,516 samples...\n",
            "  Processed 230,400/971,516 samples...\n",
            "  Processed 243,200/971,516 samples...\n",
            "  Processed 256,000/971,516 samples...\n",
            "  Processed 268,800/971,516 samples...\n",
            "  Processed 281,600/971,516 samples...\n",
            "  Processed 294,400/971,516 samples...\n",
            "  Processed 307,200/971,516 samples...\n",
            "  Processed 320,000/971,516 samples...\n",
            "  Processed 332,800/971,516 samples...\n",
            "  Processed 345,600/971,516 samples...\n",
            "  Processed 358,400/971,516 samples...\n",
            "  Processed 371,200/971,516 samples...\n",
            "  Processed 384,000/971,516 samples...\n",
            "  Processed 396,800/971,516 samples...\n",
            "  Processed 409,600/971,516 samples...\n",
            "  Processed 422,400/971,516 samples...\n",
            "  Processed 435,200/971,516 samples...\n",
            "  Processed 448,000/971,516 samples...\n",
            "  Processed 460,800/971,516 samples...\n",
            "  Processed 473,600/971,516 samples...\n",
            "  Processed 486,400/971,516 samples...\n",
            "  Processed 499,200/971,516 samples...\n",
            "  Processed 512,000/971,516 samples...\n",
            "  Processed 524,800/971,516 samples...\n",
            "  Processed 537,600/971,516 samples...\n",
            "  Processed 550,400/971,516 samples...\n",
            "  Processed 563,200/971,516 samples...\n",
            "  Processed 576,000/971,516 samples...\n",
            "  Processed 588,800/971,516 samples...\n",
            "  Processed 601,600/971,516 samples...\n",
            "  Processed 614,400/971,516 samples...\n",
            "  Processed 627,200/971,516 samples...\n",
            "  Processed 640,000/971,516 samples...\n",
            "  Processed 652,800/971,516 samples...\n",
            "  Processed 665,600/971,516 samples...\n",
            "  Processed 678,400/971,516 samples...\n",
            "  Processed 691,200/971,516 samples...\n",
            "  Processed 704,000/971,516 samples...\n",
            "  Processed 716,800/971,516 samples...\n",
            "  Processed 729,600/971,516 samples...\n",
            "  Processed 742,400/971,516 samples...\n",
            "  Processed 755,200/971,516 samples...\n",
            "  Processed 768,000/971,516 samples...\n",
            "  Processed 780,800/971,516 samples...\n",
            "  Processed 793,600/971,516 samples...\n",
            "  Processed 806,400/971,516 samples...\n",
            "  Processed 819,200/971,516 samples...\n",
            "  Processed 832,000/971,516 samples...\n",
            "  Processed 844,800/971,516 samples...\n",
            "  Processed 857,600/971,516 samples...\n",
            "  Processed 870,400/971,516 samples...\n",
            "  Processed 883,200/971,516 samples...\n",
            "  Processed 896,000/971,516 samples...\n",
            "  Processed 908,800/971,516 samples...\n",
            "  Processed 921,600/971,516 samples...\n",
            "  Processed 934,400/971,516 samples...\n",
            "  Processed 947,200/971,516 samples...\n",
            "  Processed 960,000/971,516 samples...\n",
            "Embeddings shape: (971516, 64)\n",
            "\n",
            "============================================================\n",
            "STAGE 3: Applying SMOTE (WITH PATIENT ID TRACKING)\n",
            "============================================================\n",
            "Before SMOTE: 955,899 negative, 15,617 positive\n",
            "Applying SMOTE with k_neighbors=5...\n",
            "\n",
            "[OK] After SMOTE:\n",
            "  Total: 1,911,798 samples\n",
            "  Original: 971,516, Synthetic: 940,282\n",
            "  Class 0: 955,899, Class 1: 955,899\n",
            "\n",
            "[OK] Patient ID tracking:\n",
            "  Original patient IDs: 1-120000 (27,064 unique)\n",
            "  Synthetic patient IDs: 120001-1060282 (940,282 new)\n",
            "  Total unique patients: 967,346\n",
            "\n",
            "============================================================\n",
            "STAGE 4: Decoding (Batch Processing)\n",
            "============================================================\n",
            "Reconstructing sequences...\n",
            "  Decoded 12,800/1,911,798 samples...\n",
            "  Decoded 25,600/1,911,798 samples...\n",
            "  Decoded 38,400/1,911,798 samples...\n",
            "  Decoded 51,200/1,911,798 samples...\n",
            "  Decoded 64,000/1,911,798 samples...\n",
            "  Decoded 76,800/1,911,798 samples...\n",
            "  Decoded 89,600/1,911,798 samples...\n",
            "  Decoded 102,400/1,911,798 samples...\n",
            "  Decoded 115,200/1,911,798 samples...\n",
            "  Decoded 128,000/1,911,798 samples...\n",
            "  Decoded 140,800/1,911,798 samples...\n",
            "  Decoded 153,600/1,911,798 samples...\n",
            "  Decoded 166,400/1,911,798 samples...\n",
            "  Decoded 179,200/1,911,798 samples...\n",
            "  Decoded 192,000/1,911,798 samples...\n",
            "  Decoded 204,800/1,911,798 samples...\n",
            "  Decoded 217,600/1,911,798 samples...\n",
            "  Decoded 230,400/1,911,798 samples...\n",
            "  Decoded 243,200/1,911,798 samples...\n",
            "  Decoded 256,000/1,911,798 samples...\n",
            "  Decoded 268,800/1,911,798 samples...\n",
            "  Decoded 281,600/1,911,798 samples...\n",
            "  Decoded 294,400/1,911,798 samples...\n",
            "  Decoded 307,200/1,911,798 samples...\n",
            "  Decoded 320,000/1,911,798 samples...\n",
            "  Decoded 332,800/1,911,798 samples...\n",
            "  Decoded 345,600/1,911,798 samples...\n",
            "  Decoded 358,400/1,911,798 samples...\n",
            "  Decoded 371,200/1,911,798 samples...\n",
            "  Decoded 384,000/1,911,798 samples...\n",
            "  Decoded 396,800/1,911,798 samples...\n",
            "  Decoded 409,600/1,911,798 samples...\n",
            "  Decoded 422,400/1,911,798 samples...\n",
            "  Decoded 435,200/1,911,798 samples...\n",
            "  Decoded 448,000/1,911,798 samples...\n",
            "  Decoded 460,800/1,911,798 samples...\n",
            "  Decoded 473,600/1,911,798 samples...\n",
            "  Decoded 486,400/1,911,798 samples...\n",
            "  Decoded 499,200/1,911,798 samples...\n",
            "  Decoded 512,000/1,911,798 samples...\n",
            "  Decoded 524,800/1,911,798 samples...\n",
            "  Decoded 537,600/1,911,798 samples...\n",
            "  Decoded 550,400/1,911,798 samples...\n",
            "  Decoded 563,200/1,911,798 samples...\n",
            "  Decoded 576,000/1,911,798 samples...\n",
            "  Decoded 588,800/1,911,798 samples...\n",
            "  Decoded 601,600/1,911,798 samples...\n",
            "  Decoded 614,400/1,911,798 samples...\n",
            "  Decoded 627,200/1,911,798 samples...\n",
            "  Decoded 640,000/1,911,798 samples...\n",
            "  Decoded 652,800/1,911,798 samples...\n",
            "  Decoded 665,600/1,911,798 samples...\n",
            "  Decoded 678,400/1,911,798 samples...\n",
            "  Decoded 691,200/1,911,798 samples...\n",
            "  Decoded 704,000/1,911,798 samples...\n",
            "  Decoded 716,800/1,911,798 samples...\n",
            "  Decoded 729,600/1,911,798 samples...\n",
            "  Decoded 742,400/1,911,798 samples...\n",
            "  Decoded 755,200/1,911,798 samples...\n",
            "  Decoded 768,000/1,911,798 samples...\n",
            "  Decoded 780,800/1,911,798 samples...\n",
            "  Decoded 793,600/1,911,798 samples...\n",
            "  Decoded 806,400/1,911,798 samples...\n",
            "  Decoded 819,200/1,911,798 samples...\n",
            "  Decoded 832,000/1,911,798 samples...\n",
            "  Decoded 844,800/1,911,798 samples...\n",
            "  Decoded 857,600/1,911,798 samples...\n",
            "  Decoded 870,400/1,911,798 samples...\n",
            "  Decoded 883,200/1,911,798 samples...\n",
            "  Decoded 896,000/1,911,798 samples...\n",
            "  Decoded 908,800/1,911,798 samples...\n",
            "  Decoded 921,600/1,911,798 samples...\n",
            "  Decoded 934,400/1,911,798 samples...\n",
            "  Decoded 947,200/1,911,798 samples...\n",
            "  Decoded 960,000/1,911,798 samples...\n",
            "  Decoded 972,800/1,911,798 samples...\n",
            "  Decoded 985,600/1,911,798 samples...\n",
            "  Decoded 998,400/1,911,798 samples...\n",
            "  Decoded 1,011,200/1,911,798 samples...\n",
            "  Decoded 1,024,000/1,911,798 samples...\n",
            "  Decoded 1,036,800/1,911,798 samples...\n",
            "  Decoded 1,049,600/1,911,798 samples...\n",
            "  Decoded 1,062,400/1,911,798 samples...\n",
            "  Decoded 1,075,200/1,911,798 samples...\n",
            "  Decoded 1,088,000/1,911,798 samples...\n",
            "  Decoded 1,100,800/1,911,798 samples...\n",
            "  Decoded 1,113,600/1,911,798 samples...\n",
            "  Decoded 1,126,400/1,911,798 samples...\n",
            "  Decoded 1,139,200/1,911,798 samples...\n",
            "  Decoded 1,152,000/1,911,798 samples...\n",
            "  Decoded 1,164,800/1,911,798 samples...\n",
            "  Decoded 1,177,600/1,911,798 samples...\n",
            "  Decoded 1,190,400/1,911,798 samples...\n",
            "  Decoded 1,203,200/1,911,798 samples...\n",
            "  Decoded 1,216,000/1,911,798 samples...\n",
            "  Decoded 1,228,800/1,911,798 samples...\n",
            "  Decoded 1,241,600/1,911,798 samples...\n",
            "  Decoded 1,254,400/1,911,798 samples...\n",
            "  Decoded 1,267,200/1,911,798 samples...\n",
            "  Decoded 1,280,000/1,911,798 samples...\n",
            "  Decoded 1,292,800/1,911,798 samples...\n",
            "  Decoded 1,305,600/1,911,798 samples...\n",
            "  Decoded 1,318,400/1,911,798 samples...\n",
            "  Decoded 1,331,200/1,911,798 samples...\n",
            "  Decoded 1,344,000/1,911,798 samples...\n",
            "  Decoded 1,356,800/1,911,798 samples...\n",
            "  Decoded 1,369,600/1,911,798 samples...\n",
            "  Decoded 1,382,400/1,911,798 samples...\n",
            "  Decoded 1,395,200/1,911,798 samples...\n",
            "  Decoded 1,408,000/1,911,798 samples...\n",
            "  Decoded 1,420,800/1,911,798 samples...\n",
            "  Decoded 1,433,600/1,911,798 samples...\n",
            "  Decoded 1,446,400/1,911,798 samples...\n",
            "  Decoded 1,459,200/1,911,798 samples...\n",
            "  Decoded 1,472,000/1,911,798 samples...\n",
            "  Decoded 1,484,800/1,911,798 samples...\n",
            "  Decoded 1,497,600/1,911,798 samples...\n",
            "  Decoded 1,510,400/1,911,798 samples...\n",
            "  Decoded 1,523,200/1,911,798 samples...\n",
            "  Decoded 1,536,000/1,911,798 samples...\n",
            "  Decoded 1,548,800/1,911,798 samples...\n",
            "  Decoded 1,561,600/1,911,798 samples...\n",
            "  Decoded 1,574,400/1,911,798 samples...\n",
            "  Decoded 1,587,200/1,911,798 samples...\n",
            "  Decoded 1,600,000/1,911,798 samples...\n",
            "  Decoded 1,612,800/1,911,798 samples...\n",
            "  Decoded 1,625,600/1,911,798 samples...\n",
            "  Decoded 1,638,400/1,911,798 samples...\n",
            "  Decoded 1,651,200/1,911,798 samples...\n",
            "  Decoded 1,664,000/1,911,798 samples...\n",
            "  Decoded 1,676,800/1,911,798 samples...\n",
            "  Decoded 1,689,600/1,911,798 samples...\n",
            "  Decoded 1,702,400/1,911,798 samples...\n",
            "  Decoded 1,715,200/1,911,798 samples...\n",
            "  Decoded 1,728,000/1,911,798 samples...\n",
            "  Decoded 1,740,800/1,911,798 samples...\n",
            "  Decoded 1,753,600/1,911,798 samples...\n",
            "  Decoded 1,766,400/1,911,798 samples...\n",
            "  Decoded 1,779,200/1,911,798 samples...\n",
            "  Decoded 1,792,000/1,911,798 samples...\n",
            "  Decoded 1,804,800/1,911,798 samples...\n",
            "  Decoded 1,817,600/1,911,798 samples...\n",
            "  Decoded 1,830,400/1,911,798 samples...\n",
            "  Decoded 1,843,200/1,911,798 samples...\n",
            "  Decoded 1,856,000/1,911,798 samples...\n",
            "  Decoded 1,868,800/1,911,798 samples...\n",
            "  Decoded 1,881,600/1,911,798 samples...\n",
            "  Decoded 1,894,400/1,911,798 samples...\n",
            "  Decoded 1,907,200/1,911,798 samples...\n",
            "[OK] Balanced data shape: (1911798, 4, 21)\n",
            "[OK] Patient IDs shape: (1911798,)\n",
            "\n",
            "============================================================\n",
            "STAGE 4.5: Clipping Extreme Values\n",
            "============================================================\n",
            "Original data range: [-1.0000, 100.0000]\n",
            "Clipping bounds (0.1% - 99.9%): [-1.0000, 88.0000]\n",
            "[WARNING] Found 11057316 extreme outliers (6.89% of data)\n",
            "[FIX] Clipped to realistic range\n",
            "[OK] After clipping: range=[-1.0000, 88.0000]\n",
            "\n",
            "Synthetic Class 1 AFTER clipping:\n",
            "  Mean=4.0853, Std=13.4341\n",
            "  Range=[-1.0000, 88.0000]\n",
            "\n",
            "============================================================\n",
            "STAGE 5: Quality Check & Saving\n",
            "============================================================\n",
            "\n",
            "[QUALITY METRICS]\n",
            "Original Class 1 (SEPSIS): Mean=4.1002, Std=13.5275\n",
            "Synthetic Class 1 (SEPSIS): Mean=4.0853, Std=13.4341\n",
            "\n",
            "============================================================\n",
            "[OK] SMOTE PIPELINE COMPLETE WITH MASKING & PATIENT TRACKING!\n",
            "============================================================\n",
            "Saved: smoted_train_matrices_weighted_v2_clipped.npz\n",
            "  - X: (1911798, 4, 21)\n",
            "  - y: (1911798,)\n",
            "  - patient_ids: (1911798,)\n",
            "  - Masking layer: ✓ Applied at encoder input\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Undersampling"
      ],
      "metadata": {
        "id": "LBDwCzt2JoOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# ============================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================\n",
        "\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/AI_Course_Project/Dataset'\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"UNDERSAMPLING PIPELINE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ============================================================\n",
        "# LOAD ORIGINAL TRAINING DATA\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nLoading original training data...\")\n",
        "data = np.load(f'{OUTPUT_DIR}/baseline_train_matrices.npz')\n",
        "X_train = data['X']  # (971516, 4, 21)\n",
        "y_train = data['y']\n",
        "patient_ids = data['patient_ids']\n",
        "\n",
        "n_total = len(X_train)\n",
        "n_class_0 = (y_train == 0).sum()\n",
        "n_class_1 = (y_train == 1).sum()\n",
        "\n",
        "print(f\"\\nOriginal Training Data:\")\n",
        "print(f\"  Total samples: {n_total:,}\")\n",
        "print(f\"  Class 0 (negative): {n_class_0:,} ({n_class_0/n_total*100:.2f}%)\")\n",
        "print(f\"  Class 1 (positive): {n_class_1:,} ({n_class_1/n_total*100:.2f}%)\")\n",
        "print(f\"  Imbalance ratio: {n_class_0/n_class_1:.1f}:1\")\n",
        "\n",
        "# ============================================================\n",
        "# UNDERSAMPLE MAJORITY CLASS (CLASS 0)\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"UNDERSAMPLING MAJORITY CLASS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get indices for each class\n",
        "idx_class_0 = np.where(y_train == 0)[0]\n",
        "idx_class_1 = np.where(y_train == 1)[0]\n",
        "\n",
        "print(f\"\\nTarget: Balance to {n_class_1:,} samples per class\")\n",
        "\n",
        "# Randomly sample n_class_1 samples from class 0\n",
        "np.random.seed(RANDOM_STATE)\n",
        "idx_class_0_sampled = np.random.choice(idx_class_0, size=n_class_1, replace=False)\n",
        "\n",
        "# Combine sampled class 0 + all class 1\n",
        "idx_undersampled = np.concatenate([idx_class_0_sampled, idx_class_1])\n",
        "\n",
        "# Shuffle to mix classes\n",
        "np.random.shuffle(idx_undersampled)\n",
        "\n",
        "# Create undersampled dataset\n",
        "X_train_undersampled = X_train[idx_undersampled]\n",
        "y_train_undersampled = y_train[idx_undersampled]\n",
        "patient_ids_undersampled = patient_ids[idx_undersampled]\n",
        "\n",
        "print(f\"\\nUndersampled Training Data:\")\n",
        "print(f\"  Total samples: {len(X_train_undersampled):,}\")\n",
        "print(f\"  Class 0: {(y_train_undersampled == 0).sum():,}\")\n",
        "print(f\"  Class 1: {(y_train_undersampled == 1).sum():,}\")\n",
        "print(f\"  Reduction: {n_total:,} → {len(X_train_undersampled):,} ({len(X_train_undersampled)/n_total*100:.1f}% of original)\")\n",
        "\n",
        "# ============================================================\n",
        "# SAVE UNDERSAMPLED DATASET\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SAVING UNDERSAMPLED DATASET\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "np.savez_compressed(\n",
        "    f'{OUTPUT_DIR}/undersampled_train_matrices.npz',\n",
        "    X=X_train_undersampled,\n",
        "    y=y_train_undersampled,\n",
        "    patient_ids=patient_ids_undersampled,\n",
        "    undersampled_from_class_0=n_class_0 - n_class_1,  # How many class 0 samples were removed\n",
        "    n_class_0_original=n_class_0,\n",
        "    n_class_1_original=n_class_1\n",
        ")\n",
        "\n",
        "print(f\"\\n✓ Saved undersampled dataset to:\")\n",
        "print(f\"  {OUTPUT_DIR}/undersampled_train_matrices.npz\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"UNDERSAMPLING COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\n📦 Dataset Summary:\")\n",
        "print(f\"  Original (imbalanced):  baseline_train_matrices.npz    ({n_total:,} samples)\")\n",
        "print(f\"  Oversampled (balanced): smoted_train_matrices.npz      (1,911,798 samples)\")\n",
        "print(f\"  Undersampled (balanced): undersampled_train_matrices.npz ({len(X_train_undersampled):,} samples)\")\n",
        "print(f\"  Validation (unchanged):  baseline_val_matrices.npz      (243,432 samples)\")\n",
        "print(f\"  Test (unchanged):        baseline_test_matrices.npz      (212,844 samples)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ============================================================\n",
        "# VERIFICATION\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n📊 Class Distribution Verification:\")\n",
        "print(f\"  Undersampled dataset is perfectly balanced: {(y_train_undersampled == 0).sum()} vs {(y_train_undersampled == 1).sum()}\")\n",
        "\n",
        "# Check patient diversity\n",
        "unique_patients = len(np.unique(patient_ids_undersampled))\n",
        "print(f\"  Unique patients in undersampled data: {unique_patients:,}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlRrA_KPJpqy",
        "outputId": "76e01e60-f47e-4fa7-f4df-233cdf797fb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "UNDERSAMPLING PIPELINE\n",
            "============================================================\n",
            "\n",
            "Loading original training data...\n",
            "\n",
            "Original Training Data:\n",
            "  Total samples: 971,516\n",
            "  Class 0 (negative): 955,899 (98.39%)\n",
            "  Class 1 (positive): 15,617 (1.61%)\n",
            "  Imbalance ratio: 61.2:1\n",
            "\n",
            "============================================================\n",
            "UNDERSAMPLING MAJORITY CLASS\n",
            "============================================================\n",
            "\n",
            "Target: Balance to 15,617 samples per class\n",
            "\n",
            "Undersampled Training Data:\n",
            "  Total samples: 31,234\n",
            "  Class 0: 15,617\n",
            "  Class 1: 15,617\n",
            "  Reduction: 971,516 → 31,234 (3.2% of original)\n",
            "\n",
            "============================================================\n",
            "SAVING UNDERSAMPLED DATASET\n",
            "============================================================\n",
            "\n",
            "✓ Saved undersampled dataset to:\n",
            "  /content/drive/MyDrive/AI_Fin/undersampled_train_matrices.npz\n",
            "\n",
            "============================================================\n",
            "UNDERSAMPLING COMPLETE!\n",
            "============================================================\n",
            "\n",
            "📦 Dataset Summary:\n",
            "  Original (imbalanced):  baseline_train_matrices.npz    (971,516 samples)\n",
            "  Oversampled (balanced): smoted_train_matrices.npz      (1,911,798 samples)\n",
            "  Undersampled (balanced): undersampled_train_matrices.npz (31,234 samples)\n",
            "  Validation (unchanged):  baseline_val_matrices.npz      (243,432 samples)\n",
            "  Test (unchanged):        baseline_test_matrices.npz      (212,844 samples)\n",
            "============================================================\n",
            "\n",
            "📊 Class Distribution Verification:\n",
            "  Undersampled dataset is perfectly balanced: 15617 vs 15617\n",
            "  Unique patients in undersampled data: 12,157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finding Best combination for all the datasets + Finding the Final Best model for undersampled dataset"
      ],
      "metadata": {
        "id": "m4eZzKDqNJ_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Production-Ready Comprehensive Prototyping Script\n",
        "Memory-efficient with mmap, tf.data, mixed precision, robust error handling\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ============================================================\n",
        "# GPU & MIXED PRECISION SETUP\n",
        "# ============================================================\n",
        "\n",
        "# Enable mixed precision for faster training (GPU only)\n",
        "try:\n",
        "    from tensorflow.keras import mixed_precision\n",
        "    policy = mixed_precision.Policy('mixed_float16')\n",
        "    mixed_precision.set_global_policy(policy)\n",
        "    print(\"✓ Mixed precision (float16) enabled for faster training\")\n",
        "except:\n",
        "    print(\"ℹ Mixed precision not available, using float32\")\n",
        "\n",
        "# GPU memory growth\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    print(f\"✓ GPU memory growth enabled for {len(gpus)} GPU(s)\")\n",
        "\n",
        "# ============================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================\n",
        "\n",
        "BASE_DIR = '/content/drive/MyDrive/AI_Course_Project/Dataset'\n",
        "RESULTS_DIR = os.path.join(BASE_DIR, 'Comprehensive_prototyping')\n",
        "CHECKPOINT_FILE = os.path.join(RESULTS_DIR, 'checkpoint.json')\n",
        "\n",
        "DATASETS = {\n",
        "    'Original': {\n",
        "        'path': f'{BASE_DIR}/baseline_train_matrices.npz',\n",
        "        'use_class_weight': True,\n",
        "        'class_weight': {0: 1.0, 1: 61.0},\n",
        "        'sample_size': 100000\n",
        "    },\n",
        "    'SMOTEv2': {  # CHANGED: Renamed from 'SMOTE'\n",
        "        'path': f'{BASE_DIR}/smoted_train_matrices_weighted_v2_clipped.npz',\n",
        "        'use_class_weight': False,\n",
        "        'class_weight': None,\n",
        "        'sample_size': 200000\n",
        "    },\n",
        "    'Undersampled': {\n",
        "        'path': f'{BASE_DIR}/undersampled_train_matrices.npz',\n",
        "        'use_class_weight': False,\n",
        "        'class_weight': None,\n",
        "        'sample_size': None  # Use all\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "VAL_PATH = f'{BASE_DIR}/baseline_val_matrices.npz'\n",
        "\n",
        "MODELS = ['LSTM', 'RNN', 'GRU', 'LSTM_Attention', 'CNN', 'Transformer']\n",
        "OPTIMIZERS = ['adam', 'rmsprop']\n",
        "ACTIVATIONS = ['relu', 'tanh', 'sigmoid', 'gelu']\n",
        "\n",
        "# Activation mapping for safe GELU handling\n",
        "ACT_MAP = {\n",
        "    'relu': 'relu',\n",
        "    'tanh': 'tanh',\n",
        "    'sigmoid': 'sigmoid',\n",
        "    'gelu': tf.keras.activations.gelu\n",
        "}\n",
        "\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 256\n",
        "UNITS = 128\n",
        "DROPOUT = 0.3\n",
        "LEARNING_RATE = 0.001\n",
        "EARLY_STOPPING_PATIENCE = 5\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "SEQUENCE_LENGTH = 4\n",
        "N_FEATURES = 21\n",
        "\n",
        "# ============================================================\n",
        "# MEMORY-EFFICIENT DATA LOADING\n",
        "# ============================================================\n",
        "\n",
        "def load_npz_memmap(path, key_x='X', key_y='y'):\n",
        "    \"\"\"Load npz with memory mapping for large arrays\"\"\"\n",
        "    npz = np.load(path, mmap_mode='r')\n",
        "    X = npz[key_x]  # Memory-mapped view\n",
        "    y = npz[key_y]\n",
        "    return X, y\n",
        "\n",
        "def stratified_sample_indices(y, n_samples, random_state=42):\n",
        "    \"\"\"Return indices for stratified sample\"\"\"\n",
        "    if n_samples is None or len(y) <= n_samples:\n",
        "        return np.arange(len(y))\n",
        "\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, train_size=n_samples, random_state=random_state)\n",
        "    train_idx, _ = next(sss.split(np.zeros(len(y)), y))\n",
        "    return train_idx\n",
        "\n",
        "def sample_dataset(X, y, max_samples):\n",
        "    \"\"\"Stratified sampling with memory efficiency\"\"\"\n",
        "    if max_samples is None or len(X) <= max_samples:\n",
        "        return X, y\n",
        "\n",
        "    idx = stratified_sample_indices(y, max_samples, random_state=RANDOM_STATE)\n",
        "    return X[idx].astype(np.float32), y[idx]\n",
        "\n",
        "def make_tf_dataset(X, y, batch_size, shuffle=True, buffer_size=10000):\n",
        "    \"\"\"Create tf.data.Dataset for efficient training\"\"\"\n",
        "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size, seed=RANDOM_STATE, reshuffle_each_iteration=True)\n",
        "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "# ============================================================\n",
        "# UTILITY FUNCTIONS\n",
        "# ============================================================\n",
        "\n",
        "def create_directory_structure():\n",
        "    os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "    for dataset in DATASETS.keys():\n",
        "        os.makedirs(os.path.join(RESULTS_DIR, dataset), exist_ok=True)\n",
        "    print(f\"✓ Created directory structure at {RESULTS_DIR}\")\n",
        "\n",
        "def load_checkpoint():\n",
        "    if os.path.exists(CHECKPOINT_FILE):\n",
        "        with open(CHECKPOINT_FILE, 'r') as f:\n",
        "            return json.load(f)\n",
        "    return {'completed': []}\n",
        "\n",
        "def save_checkpoint(checkpoint):\n",
        "    with open(CHECKPOINT_FILE, 'w') as f:\n",
        "        json.dump(checkpoint, f, indent=2)\n",
        "\n",
        "def is_completed(dataset, model, optimizer, activation, checkpoint):\n",
        "    exp_id = f\"{dataset}_{model}_{optimizer}_{activation}\"\n",
        "    return exp_id in checkpoint['completed']\n",
        "\n",
        "def mark_completed(dataset, model, optimizer, activation, checkpoint):\n",
        "    exp_id = f\"{dataset}_{model}_{optimizer}_{activation}\"\n",
        "    checkpoint['completed'].append(exp_id)\n",
        "    save_checkpoint(checkpoint)\n",
        "\n",
        "# ============================================================\n",
        "# MODEL ARCHITECTURES\n",
        "# ============================================================\n",
        "\n",
        "def build_lstm(input_shape, units, dropout, activation):\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Masking(mask_value=-1.0),\n",
        "        layers.LSTM(units, activation=activation, return_sequences=False),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(64, activation=activation),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(1, activation='sigmoid', dtype='float32')  # Force float32 output\n",
        "    ], name='LSTM')\n",
        "    return model\n",
        "\n",
        "def build_rnn(input_shape, units, dropout, activation):\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Masking(mask_value=-1.0),\n",
        "        layers.SimpleRNN(units, activation=activation, return_sequences=False),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(64, activation=activation),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(1, activation='sigmoid', dtype='float32')\n",
        "    ], name='RNN')\n",
        "    return model\n",
        "\n",
        "def build_gru(input_shape, units, dropout, activation):\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Masking(mask_value=-1.0),\n",
        "        layers.GRU(units, activation=activation, return_sequences=False),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(64, activation=activation),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(1, activation='sigmoid', dtype='float32')\n",
        "    ], name='GRU')\n",
        "    return model\n",
        "\n",
        "def build_lstm_attention(input_shape, units, dropout, activation):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    masked = layers.Masking(mask_value=-1.0)(inputs)\n",
        "    lstm_out = layers.LSTM(units, activation=activation, return_sequences=True)(masked)\n",
        "\n",
        "    attention = layers.Dense(1, activation='tanh')(lstm_out)\n",
        "    attention = layers.Flatten()(attention)\n",
        "    attention = layers.Activation('softmax')(attention)\n",
        "    attention = layers.RepeatVector(units)(attention)\n",
        "    attention = layers.Permute([2, 1])(attention)\n",
        "\n",
        "    merged = layers.Multiply()([lstm_out, attention])\n",
        "    merged = layers.Lambda(lambda x: keras.backend.sum(x, axis=1))(merged)\n",
        "\n",
        "    dense = layers.Dense(64, activation=activation)(merged)\n",
        "    dense = layers.Dropout(dropout)(dense)\n",
        "    outputs = layers.Dense(1, activation='sigmoid', dtype='float32')(dense)\n",
        "\n",
        "    return keras.Model(inputs=inputs, outputs=outputs, name='LSTM_Attention')\n",
        "\n",
        "def build_cnn(input_shape, units, dropout, activation):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    masked_input = layers.Lambda(lambda x: tf.where(\n",
        "        tf.equal(x, -1),\n",
        "        tf.zeros_like(x),\n",
        "        x\n",
        "    ))(inputs)\n",
        "\n",
        "    x = layers.Conv1D(filters=64, kernel_size=2, activation=activation, padding='same')(masked_input)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=128, kernel_size=2, activation=activation, padding='same')(x)\n",
        "    x = layers.GlobalMaxPooling1D()(x)\n",
        "\n",
        "    x = layers.Dense(units, activation=activation)(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    outputs = layers.Dense(1, activation='sigmoid', dtype='float32')(x)\n",
        "\n",
        "    return keras.Model(inputs=inputs, outputs=outputs, name='CNN')\n",
        "\n",
        "def build_transformer(input_shape, units, dropout, activation):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    masked = layers.Masking(mask_value=-1.0)(inputs)\n",
        "\n",
        "    positions = tf.range(start=0, limit=input_shape[0], delta=1)\n",
        "    position_embedding = layers.Embedding(input_dim=input_shape[0], output_dim=input_shape[1])(positions)\n",
        "    x = masked + position_embedding\n",
        "\n",
        "    attention_output = layers.MultiHeadAttention(\n",
        "        num_heads=4,\n",
        "        key_dim=input_shape[1]//4,\n",
        "        dropout=dropout\n",
        "    )(x, x)\n",
        "    x = layers.Add()([x, attention_output])\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "    ffn = keras.Sequential([\n",
        "        layers.Dense(units, activation=activation),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(input_shape[1])\n",
        "    ])\n",
        "    ffn_output = ffn(x)\n",
        "    x = layers.Add()([x, ffn_output])\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dense(units, activation=activation)(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    outputs = layers.Dense(1, activation='sigmoid', dtype='float32')(x)\n",
        "\n",
        "    return keras.Model(inputs=inputs, outputs=outputs, name='Transformer')\n",
        "\n",
        "def get_model(model_name, input_shape, units, dropout, activation):\n",
        "    # Map activation string to actual function\n",
        "    act = ACT_MAP.get(activation, activation)\n",
        "\n",
        "    builders = {\n",
        "        'LSTM': build_lstm,\n",
        "        'RNN': build_rnn,\n",
        "        'GRU': build_gru,\n",
        "        'LSTM_Attention': build_lstm_attention,\n",
        "        'CNN': build_cnn,\n",
        "        'Transformer': build_transformer\n",
        "    }\n",
        "    return builders[model_name](input_shape, units, dropout, act)\n",
        "\n",
        "# ============================================================\n",
        "# ROBUST METRICS COMPUTATION\n",
        "# ============================================================\n",
        "\n",
        "def compute_metrics(y_true, y_pred, y_pred_proba):\n",
        "    \"\"\"Compute metrics with robust error handling\"\"\"\n",
        "    try:\n",
        "        cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "\n",
        "        if cm.shape == (2, 2):\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "        else:\n",
        "            # Handle edge case where only one class is present\n",
        "            tn = fp = fn = tp = 0\n",
        "            if cm.shape == (1, 1):\n",
        "                if y_true[0] == 0:\n",
        "                    tn = cm[0, 0]\n",
        "                else:\n",
        "                    tp = cm[0, 0]\n",
        "\n",
        "        # Safe division with zero checks\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "        npv = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n",
        "        f1 = 2 * (precision * sensitivity) / (precision + sensitivity) if (precision + sensitivity) > 0 else 0.0\n",
        "\n",
        "        roc_auc = roc_auc_score(y_true, y_pred_proba) if len(np.unique(y_true)) > 1 else 0.0\n",
        "\n",
        "        if len(np.unique(y_true)) > 1:\n",
        "            precision_curve, recall_curve, _ = precision_recall_curve(y_true, y_pred_proba)\n",
        "            pr_auc = auc(recall_curve, precision_curve)\n",
        "        else:\n",
        "            pr_auc = 0.0\n",
        "\n",
        "        return {\n",
        "            'roc_auc': float(roc_auc),\n",
        "            'pr_auc': float(pr_auc),\n",
        "            'sensitivity': float(sensitivity),\n",
        "            'specificity': float(specificity),\n",
        "            'precision': float(precision),\n",
        "            'npv': float(npv),\n",
        "            'f1_score': float(f1),\n",
        "            'tp': int(tp), 'tn': int(tn), 'fp': int(fp), 'fn': int(fn)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Error computing metrics: {e}\")\n",
        "        return {\n",
        "            'roc_auc': 0.0, 'pr_auc': 0.0, 'sensitivity': 0.0,\n",
        "            'specificity': 0.0, 'precision': 0.0, 'npv': 0.0,\n",
        "            'f1_score': 0.0, 'tp': 0, 'tn': 0, 'fp': 0, 'fn': 0\n",
        "        }\n",
        "\n",
        "# ============================================================\n",
        "# TRAINING\n",
        "# ============================================================\n",
        "\n",
        "def train_and_evaluate(dataset_name, model_name, optimizer_name, activation,\n",
        "                       X_train, y_train, X_val, y_val, class_weight):\n",
        "\n",
        "    input_shape = (SEQUENCE_LENGTH, N_FEATURES)\n",
        "    model = get_model(model_name, input_shape, UNITS, DROPOUT, activation)\n",
        "\n",
        "    if optimizer_name == 'adam':\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "    else:\n",
        "        optimizer = keras.optimizers.RMSprop(learning_rate=LEARNING_RATE)\n",
        "\n",
        "    # Use BinaryCrossentropy for mixed precision compatibility\n",
        "    loss_fn = keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss_fn,\n",
        "        metrics=['accuracy', keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "\n",
        "    exp_name = f\"{dataset_name}_{model_name}_{optimizer_name}_{activation}\"\n",
        "    model_dir = os.path.join(RESULTS_DIR, dataset_name)\n",
        "\n",
        "    callbacks = [\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            patience=EARLY_STOPPING_PATIENCE,\n",
        "            restore_best_weights=True,\n",
        "            monitor='val_auc',\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        ),\n",
        "        keras.callbacks.ReduceLROnPlateau(\n",
        "            factor=0.5,\n",
        "            patience=3,\n",
        "            monitor='val_loss',\n",
        "            min_lr=1e-6,\n",
        "            verbose=1\n",
        "        ),\n",
        "        keras.callbacks.CSVLogger(\n",
        "            os.path.join(model_dir, f'{exp_name}_training_log.csv')\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training: {exp_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Create tf.data.Dataset pipelines\n",
        "    train_ds = make_tf_dataset(X_train, y_train, BATCH_SIZE, shuffle=True)\n",
        "    val_ds = make_tf_dataset(X_val, y_val, BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # Calculate class weights for tf.data\n",
        "    if class_weight:\n",
        "        sample_weights = np.where(y_train == 1, class_weight[1], class_weight[0])\n",
        "        train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train, sample_weights))\n",
        "        train_ds = train_ds.shuffle(10000, seed=RANDOM_STATE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=callbacks,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    epochs_trained = len(history.history['loss'])\n",
        "\n",
        "    # Evaluate\n",
        "    y_val_pred_proba = model.predict(val_ds, verbose=0).flatten()\n",
        "    y_val_pred = (y_val_pred_proba > 0.5).astype(int)\n",
        "\n",
        "    val_metrics = compute_metrics(y_val, y_val_pred, y_val_pred_proba)\n",
        "\n",
        "    model.save(os.path.join(model_dir, f'{exp_name}_model.h5'))\n",
        "\n",
        "    results = {\n",
        "        'dataset': dataset_name,\n",
        "        'model': model_name,\n",
        "        'optimizer': optimizer_name,\n",
        "        'activation': activation,\n",
        "        'train_samples': int(len(X_train)),\n",
        "        'val_samples': int(len(X_val)),\n",
        "        'max_epochs': EPOCHS,\n",
        "        'epochs_trained': int(epochs_trained),\n",
        "        'early_stopped': bool(epochs_trained < EPOCHS),\n",
        "        'final_train_loss': float(history.history['loss'][-1]),\n",
        "        'final_val_loss': float(history.history['val_loss'][-1]),\n",
        "        'final_train_auc': float(history.history['auc'][-1]),\n",
        "        'final_val_auc': float(history.history['val_auc'][-1]),\n",
        "        **val_metrics\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(model_dir, f'{exp_name}_metrics.json'), 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "    print(f\"\\n✓ Completed: {exp_name}\")\n",
        "    print(f\"  Epochs: {epochs_trained}/{EPOCHS}\")\n",
        "    print(f\"  Val ROC-AUC: {val_metrics['roc_auc']:.4f}\")\n",
        "    print(f\"  Val PR-AUC: {val_metrics['pr_auc']:.4f}\")\n",
        "\n",
        "    del model\n",
        "    keras.backend.clear_session()\n",
        "    import gc\n",
        "    gc.collect()\n",
        "\n",
        "    return results\n",
        "\n",
        "# ============================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================\n",
        "\n",
        "def main():\n",
        "    create_directory_structure()\n",
        "    checkpoint = load_checkpoint()\n",
        "\n",
        "    # Load validation data with mmap\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"LOADING VALIDATION DATA\")\n",
        "    print(\"=\"*60)\n",
        "    X_val_full, y_val = load_npz_memmap(VAL_PATH)\n",
        "    X_val = X_val_full[:].astype(np.float32)  # Load into memory (manageable size)\n",
        "    print(f\"✓ Validation: {X_val.shape[0]:,} samples\")\n",
        "\n",
        "    all_results = []\n",
        "    total_experiments = len(DATASETS) * len(MODELS) * len(OPTIMIZERS) * len(ACTIVATIONS)\n",
        "    completed_count = len(checkpoint['completed'])\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"COMPREHENSIVE PROTOTYPING\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Total experiments: {total_experiments}\")\n",
        "    print(f\"Completed: {completed_count}, Remaining: {total_experiments - completed_count}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    experiment_num = 0\n",
        "\n",
        "    for dataset_name, dataset_config in DATASETS.items():\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"LOADING DATASET: {dataset_name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        # Memory-mapped loading\n",
        "        X_full, y_full = load_npz_memmap(dataset_config['path'])\n",
        "\n",
        "        # Stratified sampling\n",
        "        sample_size = dataset_config['sample_size']\n",
        "        idx = stratified_sample_indices(y_full, sample_size, RANDOM_STATE)\n",
        "        X_train = X_full[idx].astype(np.float32)\n",
        "        y_train = y_full[idx]\n",
        "\n",
        "        if sample_size:\n",
        "            print(f\"⚡ Sampled: {len(y_full):,} → {len(X_train):,}\")\n",
        "        else:\n",
        "            print(f\"✓ Using full dataset: {len(X_train):,}\")\n",
        "\n",
        "        print(f\"  Class 0: {(y_train == 0).sum():,}, Class 1: {(y_train == 1).sum():,}\")\n",
        "\n",
        "        class_weight = dataset_config['class_weight'] if dataset_config['use_class_weight'] else None\n",
        "\n",
        "        for model_name in MODELS:\n",
        "            for optimizer_name in OPTIMIZERS:\n",
        "                for activation in ACTIVATIONS:\n",
        "                    experiment_num += 1\n",
        "\n",
        "                    if is_completed(dataset_name, model_name, optimizer_name, activation, checkpoint):\n",
        "                        print(f\"\\n[{experiment_num}/{total_experiments}] SKIPPING: {dataset_name}/{model_name}/{optimizer_name}/{activation}\")\n",
        "                        continue\n",
        "\n",
        "                    print(f\"\\n[{experiment_num}/{total_experiments}] {dataset_name}/{model_name}/{optimizer_name}/{activation}\")\n",
        "\n",
        "                    try:\n",
        "                        results = train_and_evaluate(\n",
        "                            dataset_name, model_name, optimizer_name, activation,\n",
        "                            X_train, y_train, X_val, y_val, class_weight\n",
        "                        )\n",
        "                        all_results.append(results)\n",
        "                        mark_completed(dataset_name, model_name, optimizer_name, activation, checkpoint)\n",
        "                    except Exception as e:\n",
        "                        print(f\"\\n❌ ERROR: {str(e)}\")\n",
        "                        import traceback\n",
        "                        traceback.print_exc()\n",
        "                        continue\n",
        "\n",
        "        del X_train, y_train, X_full, y_full\n",
        "        import gc\n",
        "        gc.collect()\n",
        "\n",
        "    # Save summary\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"SAVING SUMMARY\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    summary_df = pd.DataFrame(all_results)\n",
        "    summary_df.to_csv(os.path.join(RESULTS_DIR, 'comprehensive_summary.csv'), index=False)\n",
        "\n",
        "    for dataset_name in DATASETS.keys():\n",
        "        dataset_results = summary_df[summary_df['dataset'] == dataset_name]\n",
        "        if len(dataset_results) > 0:\n",
        "            best_by_roc = dataset_results.nlargest(5, 'roc_auc')\n",
        "            best_by_roc.to_csv(\n",
        "                os.path.join(RESULTS_DIR, dataset_name, f'{dataset_name}_top5_by_roc_auc.csv'),\n",
        "                index=False\n",
        "            )\n",
        "\n",
        "    print(f\"\\n✓ Complete! Results: {RESULTS_DIR}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR9osFmRNNpx",
        "outputId": "988b358c-fb60-4c1e-de27-2004bba645a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Mixed precision (float16) enabled for faster training\n",
            "✓ GPU memory growth enabled for 1 GPU(s)\n",
            "✓ Created directory structure at /content/drive/MyDrive/AI_Fin/Comprehensive_prototyping\n",
            "\n",
            "============================================================\n",
            "LOADING VALIDATION DATA\n",
            "============================================================\n",
            "✓ Validation: 243,432 samples\n",
            "\n",
            "============================================================\n",
            "COMPREHENSIVE PROTOTYPING\n",
            "============================================================\n",
            "Total experiments: 144\n",
            "Completed: 96, Remaining: 48\n",
            "============================================================\n",
            "\n",
            "\n",
            "============================================================\n",
            "LOADING DATASET: Original\n",
            "============================================================\n",
            "⚡ Sampled: 971,516 → 100,000\n",
            "  Class 0: 98,393, Class 1: 1,607\n",
            "\n",
            "[1/144] SKIPPING: Original/LSTM/adam/relu\n",
            "\n",
            "[2/144] SKIPPING: Original/LSTM/adam/tanh\n",
            "\n",
            "[3/144] SKIPPING: Original/LSTM/adam/sigmoid\n",
            "\n",
            "[4/144] SKIPPING: Original/LSTM/adam/gelu\n",
            "\n",
            "[5/144] SKIPPING: Original/LSTM/rmsprop/relu\n",
            "\n",
            "[6/144] SKIPPING: Original/LSTM/rmsprop/tanh\n",
            "\n",
            "[7/144] SKIPPING: Original/LSTM/rmsprop/sigmoid\n",
            "\n",
            "[8/144] SKIPPING: Original/LSTM/rmsprop/gelu\n",
            "\n",
            "[9/144] SKIPPING: Original/RNN/adam/relu\n",
            "\n",
            "[10/144] SKIPPING: Original/RNN/adam/tanh\n",
            "\n",
            "[11/144] SKIPPING: Original/RNN/adam/sigmoid\n",
            "\n",
            "[12/144] SKIPPING: Original/RNN/adam/gelu\n",
            "\n",
            "[13/144] SKIPPING: Original/RNN/rmsprop/relu\n",
            "\n",
            "[14/144] SKIPPING: Original/RNN/rmsprop/tanh\n",
            "\n",
            "[15/144] SKIPPING: Original/RNN/rmsprop/sigmoid\n",
            "\n",
            "[16/144] SKIPPING: Original/RNN/rmsprop/gelu\n",
            "\n",
            "[17/144] SKIPPING: Original/GRU/adam/relu\n",
            "\n",
            "[18/144] SKIPPING: Original/GRU/adam/tanh\n",
            "\n",
            "[19/144] SKIPPING: Original/GRU/adam/sigmoid\n",
            "\n",
            "[20/144] SKIPPING: Original/GRU/adam/gelu\n",
            "\n",
            "[21/144] SKIPPING: Original/GRU/rmsprop/relu\n",
            "\n",
            "[22/144] SKIPPING: Original/GRU/rmsprop/tanh\n",
            "\n",
            "[23/144] SKIPPING: Original/GRU/rmsprop/sigmoid\n",
            "\n",
            "[24/144] SKIPPING: Original/GRU/rmsprop/gelu\n",
            "\n",
            "[25/144] SKIPPING: Original/LSTM_Attention/adam/relu\n",
            "\n",
            "[26/144] SKIPPING: Original/LSTM_Attention/adam/tanh\n",
            "\n",
            "[27/144] SKIPPING: Original/LSTM_Attention/adam/sigmoid\n",
            "\n",
            "[28/144] SKIPPING: Original/LSTM_Attention/adam/gelu\n",
            "\n",
            "[29/144] SKIPPING: Original/LSTM_Attention/rmsprop/relu\n",
            "\n",
            "[30/144] SKIPPING: Original/LSTM_Attention/rmsprop/tanh\n",
            "\n",
            "[31/144] SKIPPING: Original/LSTM_Attention/rmsprop/sigmoid\n",
            "\n",
            "[32/144] SKIPPING: Original/LSTM_Attention/rmsprop/gelu\n",
            "\n",
            "[33/144] SKIPPING: Original/CNN/adam/relu\n",
            "\n",
            "[34/144] SKIPPING: Original/CNN/adam/tanh\n",
            "\n",
            "[35/144] SKIPPING: Original/CNN/adam/sigmoid\n",
            "\n",
            "[36/144] SKIPPING: Original/CNN/adam/gelu\n",
            "\n",
            "[37/144] SKIPPING: Original/CNN/rmsprop/relu\n",
            "\n",
            "[38/144] SKIPPING: Original/CNN/rmsprop/tanh\n",
            "\n",
            "[39/144] SKIPPING: Original/CNN/rmsprop/sigmoid\n",
            "\n",
            "[40/144] SKIPPING: Original/CNN/rmsprop/gelu\n",
            "\n",
            "[41/144] SKIPPING: Original/Transformer/adam/relu\n",
            "\n",
            "[42/144] SKIPPING: Original/Transformer/adam/tanh\n",
            "\n",
            "[43/144] SKIPPING: Original/Transformer/adam/sigmoid\n",
            "\n",
            "[44/144] SKIPPING: Original/Transformer/adam/gelu\n",
            "\n",
            "[45/144] SKIPPING: Original/Transformer/rmsprop/relu\n",
            "\n",
            "[46/144] SKIPPING: Original/Transformer/rmsprop/tanh\n",
            "\n",
            "[47/144] SKIPPING: Original/Transformer/rmsprop/sigmoid\n",
            "\n",
            "[48/144] SKIPPING: Original/Transformer/rmsprop/gelu\n",
            "\n",
            "============================================================\n",
            "LOADING DATASET: SMOTEv2\n",
            "============================================================\n",
            "⚡ Sampled: 1,911,798 → 200,000\n",
            "  Class 0: 100,000, Class 1: 100,000\n",
            "\n",
            "[49/144] SMOTEv2/LSTM/adam/relu\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_LSTM_adam_relu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 16s - 21ms/step - accuracy: 0.5886 - auc: 0.6259 - loss: 0.6711 - val_accuracy: 0.5064 - val_auc: 0.6625 - val_loss: 0.7247 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6104 - auc: 0.6559 - loss: 0.6543 - val_accuracy: 0.6662 - val_auc: 0.6676 - val_loss: 0.6787 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6181 - auc: 0.6658 - loss: 0.6492 - val_accuracy: 0.6427 - val_auc: 0.6629 - val_loss: 0.7246 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6232 - auc: 0.6716 - loss: 0.6460 - val_accuracy: 0.6489 - val_auc: 0.6528 - val_loss: 0.7682 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6259 - auc: 0.6750 - loss: 0.6444 - val_accuracy: 0.6755 - val_auc: 0.6542 - val_loss: 0.7084 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6298 - auc: 0.6806 - loss: 0.6405 - val_accuracy: 0.6298 - val_auc: 0.6549 - val_loss: 0.7931 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6312 - auc: 0.6821 - loss: 0.6395 - val_accuracy: 0.6617 - val_auc: 0.6472 - val_loss: 0.7979 - learning_rate: 5.0000e-04\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_LSTM_adam_relu\n",
            "  Epochs: 7/50\n",
            "  Val ROC-AUC: 0.6676\n",
            "  Val PR-AUC: 0.0332\n",
            "\n",
            "[50/144] SMOTEv2/LSTM/adam/tanh\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_LSTM_adam_tanh\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 15s - 19ms/step - accuracy: 0.5967 - auc: 0.6367 - loss: 0.6635 - val_accuracy: 0.6427 - val_auc: 0.6670 - val_loss: 0.6368 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 9s - 11ms/step - accuracy: 0.6146 - auc: 0.6604 - loss: 0.6523 - val_accuracy: 0.6619 - val_auc: 0.6712 - val_loss: 0.6347 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 8s - 10ms/step - accuracy: 0.6214 - auc: 0.6686 - loss: 0.6480 - val_accuracy: 0.5890 - val_auc: 0.6648 - val_loss: 0.6779 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 11s - 14ms/step - accuracy: 0.6249 - auc: 0.6730 - loss: 0.6454 - val_accuracy: 0.6722 - val_auc: 0.6618 - val_loss: 0.6226 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 9s - 11ms/step - accuracy: 0.6266 - auc: 0.6755 - loss: 0.6439 - val_accuracy: 0.7204 - val_auc: 0.6546 - val_loss: 0.5794 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "782/782 - 8s - 10ms/step - accuracy: 0.6292 - auc: 0.6793 - loss: 0.6414 - val_accuracy: 0.7238 - val_auc: 0.6571 - val_loss: 0.5688 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "782/782 - 9s - 12ms/step - accuracy: 0.6323 - auc: 0.6822 - loss: 0.6396 - val_accuracy: 0.6400 - val_auc: 0.6534 - val_loss: 0.6449 - learning_rate: 1.0000e-03\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_LSTM_adam_tanh\n",
            "  Epochs: 7/50\n",
            "  Val ROC-AUC: 0.6712\n",
            "  Val PR-AUC: 0.0331\n",
            "\n",
            "[51/144] SMOTEv2/LSTM/adam/sigmoid\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_LSTM_adam_sigmoid\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 15s - 19ms/step - accuracy: 0.5752 - auc: 0.6087 - loss: 0.6751 - val_accuracy: 0.6176 - val_auc: 0.6620 - val_loss: 0.6596 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6036 - auc: 0.6455 - loss: 0.6593 - val_accuracy: 0.6206 - val_auc: 0.6735 - val_loss: 0.6572 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6129 - auc: 0.6580 - loss: 0.6531 - val_accuracy: 0.5775 - val_auc: 0.6776 - val_loss: 0.6963 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6170 - auc: 0.6645 - loss: 0.6497 - val_accuracy: 0.7483 - val_auc: 0.6806 - val_loss: 0.5865 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6197 - auc: 0.6676 - loss: 0.6479 - val_accuracy: 0.7899 - val_auc: 0.6797 - val_loss: 0.5446 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6207 - auc: 0.6701 - loss: 0.6464 - val_accuracy: 0.8107 - val_auc: 0.6757 - val_loss: 0.5184 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "782/782 - 10s - 13ms/step - accuracy: 0.6238 - auc: 0.6726 - loss: 0.6451 - val_accuracy: 0.7017 - val_auc: 0.6766 - val_loss: 0.6110 - learning_rate: 1.0000e-03\n",
            "Epoch 8/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6244 - auc: 0.6744 - loss: 0.6439 - val_accuracy: 0.8334 - val_auc: 0.6729 - val_loss: 0.5031 - learning_rate: 1.0000e-03\n",
            "Epoch 9/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6255 - auc: 0.6756 - loss: 0.6432 - val_accuracy: 0.7850 - val_auc: 0.6702 - val_loss: 0.5293 - learning_rate: 1.0000e-03\n",
            "Epoch 9: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_LSTM_adam_sigmoid\n",
            "  Epochs: 9/50\n",
            "  Val ROC-AUC: 0.6805\n",
            "  Val PR-AUC: 0.0342\n",
            "\n",
            "[52/144] SMOTEv2/LSTM/adam/gelu\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_LSTM_adam_gelu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 16s - 21ms/step - accuracy: 0.5844 - auc: 0.6192 - loss: 0.6863 - val_accuracy: 0.5838 - val_auc: 0.6808 - val_loss: 0.6927 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6108 - auc: 0.6553 - loss: 0.6544 - val_accuracy: 0.6284 - val_auc: 0.6670 - val_loss: 0.7093 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6184 - auc: 0.6642 - loss: 0.6500 - val_accuracy: 0.5986 - val_auc: 0.6548 - val_loss: 0.7466 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6216 - auc: 0.6693 - loss: 0.6470 - val_accuracy: 0.7552 - val_auc: 0.6208 - val_loss: 0.6288 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6241 - auc: 0.6730 - loss: 0.6450 - val_accuracy: 0.7795 - val_auc: 0.6109 - val_loss: 0.5796 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6259 - auc: 0.6761 - loss: 0.6429 - val_accuracy: 0.8026 - val_auc: 0.5829 - val_loss: 0.5173 - learning_rate: 1.0000e-03\n",
            "Epoch 6: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_LSTM_adam_gelu\n",
            "  Epochs: 6/50\n",
            "  Val ROC-AUC: 0.6809\n",
            "  Val PR-AUC: 0.0362\n",
            "\n",
            "[53/144] SMOTEv2/LSTM/rmsprop/relu\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_LSTM_rmsprop_relu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 13s - 17ms/step - accuracy: 0.5817 - auc: 0.6144 - loss: 0.6877 - val_accuracy: 0.7399 - val_auc: 0.6631 - val_loss: 0.6262 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6086 - auc: 0.6521 - loss: 0.6566 - val_accuracy: 0.6778 - val_auc: 0.6766 - val_loss: 0.6132 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6155 - auc: 0.6617 - loss: 0.6518 - val_accuracy: 0.6543 - val_auc: 0.6652 - val_loss: 0.6664 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6191 - auc: 0.6667 - loss: 0.6493 - val_accuracy: 0.7040 - val_auc: 0.6607 - val_loss: 0.6444 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 9s - 12ms/step - accuracy: 0.6226 - auc: 0.6706 - loss: 0.6470 - val_accuracy: 0.6930 - val_auc: 0.6613 - val_loss: 0.6546 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6261 - auc: 0.6771 - loss: 0.6428 - val_accuracy: 0.7096 - val_auc: 0.6592 - val_loss: 0.6214 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "782/782 - 10s - 13ms/step - accuracy: 0.6290 - auc: 0.6795 - loss: 0.6415 - val_accuracy: 0.7308 - val_auc: 0.6636 - val_loss: 0.5970 - learning_rate: 5.0000e-04\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_LSTM_rmsprop_relu\n",
            "  Epochs: 7/50\n",
            "  Val ROC-AUC: 0.6767\n",
            "  Val PR-AUC: 0.0365\n",
            "\n",
            "[54/144] SMOTEv2/LSTM/rmsprop/tanh\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_LSTM_rmsprop_tanh\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 10s - 13ms/step - accuracy: 0.5919 - auc: 0.6275 - loss: 0.6684 - val_accuracy: 0.7936 - val_auc: 0.6668 - val_loss: 0.5492 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 9s - 11ms/step - accuracy: 0.6124 - auc: 0.6566 - loss: 0.6544 - val_accuracy: 0.6285 - val_auc: 0.6724 - val_loss: 0.6438 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 9s - 11ms/step - accuracy: 0.6166 - auc: 0.6636 - loss: 0.6507 - val_accuracy: 0.7270 - val_auc: 0.6707 - val_loss: 0.5838 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 10s - 13ms/step - accuracy: 0.6213 - auc: 0.6691 - loss: 0.6478 - val_accuracy: 0.6559 - val_auc: 0.6630 - val_loss: 0.6345 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 8s - 10ms/step - accuracy: 0.6259 - auc: 0.6756 - loss: 0.6441 - val_accuracy: 0.6907 - val_auc: 0.6646 - val_loss: 0.6004 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "782/782 - 9s - 11ms/step - accuracy: 0.6283 - auc: 0.6781 - loss: 0.6427 - val_accuracy: 0.6468 - val_auc: 0.6588 - val_loss: 0.6364 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "782/782 - 9s - 11ms/step - accuracy: 0.6296 - auc: 0.6795 - loss: 0.6418 - val_accuracy: 0.6619 - val_auc: 0.6576 - val_loss: 0.6236 - learning_rate: 5.0000e-04\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_LSTM_rmsprop_tanh\n",
            "  Epochs: 7/50\n",
            "  Val ROC-AUC: 0.6725\n",
            "  Val PR-AUC: 0.0340\n",
            "\n",
            "[55/144] SMOTEv2/LSTM/rmsprop/sigmoid\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_LSTM_rmsprop_sigmoid\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 13s - 17ms/step - accuracy: 0.5690 - auc: 0.5994 - loss: 0.6776 - val_accuracy: 0.7466 - val_auc: 0.6522 - val_loss: 0.5896 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.5952 - auc: 0.6358 - loss: 0.6638 - val_accuracy: 0.5810 - val_auc: 0.6625 - val_loss: 0.6805 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6002 - auc: 0.6406 - loss: 0.6614 - val_accuracy: 0.6434 - val_auc: 0.6669 - val_loss: 0.6516 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6022 - auc: 0.6434 - loss: 0.6601 - val_accuracy: 0.6334 - val_auc: 0.6697 - val_loss: 0.6680 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6042 - auc: 0.6469 - loss: 0.6582 - val_accuracy: 0.7174 - val_auc: 0.6692 - val_loss: 0.6122 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6052 - auc: 0.6488 - loss: 0.6572 - val_accuracy: 0.7159 - val_auc: 0.6705 - val_loss: 0.6166 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6068 - auc: 0.6499 - loss: 0.6566 - val_accuracy: 0.7312 - val_auc: 0.6721 - val_loss: 0.6018 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6082 - auc: 0.6523 - loss: 0.6555 - val_accuracy: 0.7579 - val_auc: 0.6726 - val_loss: 0.5917 - learning_rate: 2.5000e-04\n",
            "Epoch 9/50\n",
            "782/782 - 10s - 13ms/step - accuracy: 0.6092 - auc: 0.6538 - loss: 0.6546 - val_accuracy: 0.6761 - val_auc: 0.6727 - val_loss: 0.6459 - learning_rate: 2.5000e-04\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6097 - auc: 0.6537 - loss: 0.6548 - val_accuracy: 0.6778 - val_auc: 0.6730 - val_loss: 0.6417 - learning_rate: 2.5000e-04\n",
            "Epoch 11/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6087 - auc: 0.6548 - loss: 0.6540 - val_accuracy: 0.7331 - val_auc: 0.6737 - val_loss: 0.6069 - learning_rate: 1.2500e-04\n",
            "Epoch 12/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6090 - auc: 0.6552 - loss: 0.6539 - val_accuracy: 0.7337 - val_auc: 0.6740 - val_loss: 0.6070 - learning_rate: 1.2500e-04\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6096 - auc: 0.6556 - loss: 0.6537 - val_accuracy: 0.7253 - val_auc: 0.6739 - val_loss: 0.6111 - learning_rate: 1.2500e-04\n",
            "Epoch 14/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6094 - auc: 0.6553 - loss: 0.6539 - val_accuracy: 0.7404 - val_auc: 0.6742 - val_loss: 0.6022 - learning_rate: 6.2500e-05\n",
            "Epoch 15/50\n",
            "782/782 - 9s - 12ms/step - accuracy: 0.6107 - auc: 0.6563 - loss: 0.6533 - val_accuracy: 0.7236 - val_auc: 0.6741 - val_loss: 0.6125 - learning_rate: 6.2500e-05\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6107 - auc: 0.6563 - loss: 0.6534 - val_accuracy: 0.7447 - val_auc: 0.6743 - val_loss: 0.5978 - learning_rate: 6.2500e-05\n",
            "Epoch 17/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6108 - auc: 0.6567 - loss: 0.6533 - val_accuracy: 0.7215 - val_auc: 0.6743 - val_loss: 0.6135 - learning_rate: 3.1250e-05\n",
            "Epoch 18/50\n",
            "782/782 - 8s - 10ms/step - accuracy: 0.6106 - auc: 0.6566 - loss: 0.6533 - val_accuracy: 0.7270 - val_auc: 0.6743 - val_loss: 0.6102 - learning_rate: 3.1250e-05\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6108 - auc: 0.6571 - loss: 0.6531 - val_accuracy: 0.7304 - val_auc: 0.6743 - val_loss: 0.6066 - learning_rate: 3.1250e-05\n",
            "Epoch 20/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6102 - auc: 0.6568 - loss: 0.6531 - val_accuracy: 0.7282 - val_auc: 0.6743 - val_loss: 0.6089 - learning_rate: 1.5625e-05\n",
            "Epoch 21/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6114 - auc: 0.6572 - loss: 0.6530 - val_accuracy: 0.7303 - val_auc: 0.6744 - val_loss: 0.6075 - learning_rate: 1.5625e-05\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6113 - auc: 0.6577 - loss: 0.6528 - val_accuracy: 0.7249 - val_auc: 0.6743 - val_loss: 0.6108 - learning_rate: 1.5625e-05\n",
            "Epoch 23/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6100 - auc: 0.6573 - loss: 0.6529 - val_accuracy: 0.7333 - val_auc: 0.6743 - val_loss: 0.6051 - learning_rate: 7.8125e-06\n",
            "Epoch 24/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6109 - auc: 0.6572 - loss: 0.6529 - val_accuracy: 0.7308 - val_auc: 0.6744 - val_loss: 0.6069 - learning_rate: 7.8125e-06\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6111 - auc: 0.6574 - loss: 0.6529 - val_accuracy: 0.7306 - val_auc: 0.6744 - val_loss: 0.6069 - learning_rate: 7.8125e-06\n",
            "Epoch 26/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6111 - auc: 0.6580 - loss: 0.6526 - val_accuracy: 0.7334 - val_auc: 0.6745 - val_loss: 0.6047 - learning_rate: 3.9063e-06\n",
            "Epoch 27/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6110 - auc: 0.6572 - loss: 0.6530 - val_accuracy: 0.7339 - val_auc: 0.6745 - val_loss: 0.6045 - learning_rate: 3.9063e-06\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6109 - auc: 0.6572 - loss: 0.6529 - val_accuracy: 0.7347 - val_auc: 0.6745 - val_loss: 0.6039 - learning_rate: 3.9063e-06\n",
            "Epoch 29/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6121 - auc: 0.6577 - loss: 0.6526 - val_accuracy: 0.7348 - val_auc: 0.6745 - val_loss: 0.6038 - learning_rate: 1.9531e-06\n",
            "Epoch 30/50\n",
            "782/782 - 8s - 10ms/step - accuracy: 0.6112 - auc: 0.6573 - loss: 0.6529 - val_accuracy: 0.7348 - val_auc: 0.6745 - val_loss: 0.6038 - learning_rate: 1.9531e-06\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6104 - auc: 0.6571 - loss: 0.6530 - val_accuracy: 0.7351 - val_auc: 0.6744 - val_loss: 0.6036 - learning_rate: 1.9531e-06\n",
            "Epoch 32/50\n",
            "782/782 - 8s - 10ms/step - accuracy: 0.6113 - auc: 0.6571 - loss: 0.6531 - val_accuracy: 0.7355 - val_auc: 0.6744 - val_loss: 0.6033 - learning_rate: 1.0000e-06\n",
            "Epoch 33/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6115 - auc: 0.6576 - loss: 0.6527 - val_accuracy: 0.7354 - val_auc: 0.6745 - val_loss: 0.6034 - learning_rate: 1.0000e-06\n",
            "Epoch 33: early stopping\n",
            "Restoring model weights from the end of the best epoch: 28.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_LSTM_rmsprop_sigmoid\n",
            "  Epochs: 33/50\n",
            "  Val ROC-AUC: 0.6744\n",
            "  Val PR-AUC: 0.0357\n",
            "\n",
            "[56/144] SMOTEv2/LSTM/rmsprop/gelu\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_LSTM_rmsprop_gelu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 15s - 20ms/step - accuracy: 0.5867 - auc: 0.6226 - loss: 0.6743 - val_accuracy: 0.7317 - val_auc: 0.6513 - val_loss: 0.6195 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6102 - auc: 0.6543 - loss: 0.6553 - val_accuracy: 0.5717 - val_auc: 0.6700 - val_loss: 0.7057 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6171 - auc: 0.6630 - loss: 0.6508 - val_accuracy: 0.6620 - val_auc: 0.6495 - val_loss: 0.6328 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 10s - 13ms/step - accuracy: 0.6190 - auc: 0.6671 - loss: 0.6487 - val_accuracy: 0.6311 - val_auc: 0.6550 - val_loss: 0.7067 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6249 - auc: 0.6744 - loss: 0.6441 - val_accuracy: 0.6580 - val_auc: 0.6601 - val_loss: 0.6565 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6255 - auc: 0.6762 - loss: 0.6430 - val_accuracy: 0.6206 - val_auc: 0.6549 - val_loss: 0.6764 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6285 - auc: 0.6783 - loss: 0.6417 - val_accuracy: 0.6825 - val_auc: 0.6544 - val_loss: 0.6225 - learning_rate: 5.0000e-04\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_LSTM_rmsprop_gelu\n",
            "  Epochs: 7/50\n",
            "  Val ROC-AUC: 0.6699\n",
            "  Val PR-AUC: 0.0340\n",
            "\n",
            "[57/144] SMOTEv2/RNN/adam/relu\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_RNN_adam_relu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 13s - 17ms/step - accuracy: 0.5713 - auc: 0.5986 - loss: 0.7058 - val_accuracy: 0.6692 - val_auc: 0.6500 - val_loss: 0.6367 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.5994 - auc: 0.6385 - loss: 0.6626 - val_accuracy: 0.6800 - val_auc: 0.6664 - val_loss: 0.6240 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6067 - auc: 0.6496 - loss: 0.6574 - val_accuracy: 0.5537 - val_auc: 0.6648 - val_loss: 0.7031 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6121 - auc: 0.6570 - loss: 0.6538 - val_accuracy: 0.6941 - val_auc: 0.6633 - val_loss: 0.6164 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6164 - auc: 0.6619 - loss: 0.6514 - val_accuracy: 0.7470 - val_auc: 0.6591 - val_loss: 0.5641 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6187 - auc: 0.6660 - loss: 0.6487 - val_accuracy: 0.7659 - val_auc: 0.6545 - val_loss: 0.5657 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "782/782 - 8s - 10ms/step - accuracy: 0.6209 - auc: 0.6693 - loss: 0.6472 - val_accuracy: 0.6758 - val_auc: 0.6587 - val_loss: 0.6284 - learning_rate: 1.0000e-03\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_RNN_adam_relu\n",
            "  Epochs: 7/50\n",
            "  Val ROC-AUC: 0.6663\n",
            "  Val PR-AUC: 0.0349\n",
            "\n",
            "[58/144] SMOTEv2/RNN/adam/tanh\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_RNN_adam_tanh\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 13s - 16ms/step - accuracy: 0.5778 - auc: 0.6069 - loss: 0.6837 - val_accuracy: 0.6690 - val_auc: 0.6644 - val_loss: 0.6280 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6068 - auc: 0.6473 - loss: 0.6593 - val_accuracy: 0.5758 - val_auc: 0.6761 - val_loss: 0.6757 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6180 - auc: 0.6621 - loss: 0.6520 - val_accuracy: 0.5731 - val_auc: 0.6777 - val_loss: 0.6914 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6221 - auc: 0.6683 - loss: 0.6488 - val_accuracy: 0.6321 - val_auc: 0.6728 - val_loss: 0.6473 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6268 - auc: 0.6754 - loss: 0.6447 - val_accuracy: 0.6953 - val_auc: 0.6732 - val_loss: 0.5950 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6288 - auc: 0.6795 - loss: 0.6422 - val_accuracy: 0.6894 - val_auc: 0.6703 - val_loss: 0.6017 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "782/782 - 4s - 6ms/step - accuracy: 0.6313 - auc: 0.6819 - loss: 0.6408 - val_accuracy: 0.6170 - val_auc: 0.6707 - val_loss: 0.6520 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6329 - auc: 0.6842 - loss: 0.6394 - val_accuracy: 0.7044 - val_auc: 0.6666 - val_loss: 0.5775 - learning_rate: 5.0000e-04\n",
            "Epoch 8: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_RNN_adam_tanh\n",
            "  Epochs: 8/50\n",
            "  Val ROC-AUC: 0.6777\n",
            "  Val PR-AUC: 0.0341\n",
            "\n",
            "[59/144] SMOTEv2/RNN/adam/sigmoid\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_RNN_adam_sigmoid\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 13s - 16ms/step - accuracy: 0.5809 - auc: 0.6154 - loss: 0.6719 - val_accuracy: 0.5909 - val_auc: 0.6661 - val_loss: 0.6810 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6045 - auc: 0.6460 - loss: 0.6593 - val_accuracy: 0.6497 - val_auc: 0.6774 - val_loss: 0.6336 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6127 - auc: 0.6577 - loss: 0.6535 - val_accuracy: 0.5657 - val_auc: 0.6814 - val_loss: 0.6909 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6176 - auc: 0.6644 - loss: 0.6499 - val_accuracy: 0.7353 - val_auc: 0.6821 - val_loss: 0.5827 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6205 - auc: 0.6685 - loss: 0.6477 - val_accuracy: 0.7708 - val_auc: 0.6801 - val_loss: 0.5531 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6232 - auc: 0.6721 - loss: 0.6455 - val_accuracy: 0.7916 - val_auc: 0.6787 - val_loss: 0.5152 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6261 - auc: 0.6752 - loss: 0.6439 - val_accuracy: 0.6580 - val_auc: 0.6775 - val_loss: 0.6283 - learning_rate: 1.0000e-03\n",
            "Epoch 8/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6272 - auc: 0.6774 - loss: 0.6424 - val_accuracy: 0.8031 - val_auc: 0.6705 - val_loss: 0.5095 - learning_rate: 1.0000e-03\n",
            "Epoch 9/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6289 - auc: 0.6798 - loss: 0.6411 - val_accuracy: 0.6834 - val_auc: 0.6736 - val_loss: 0.5949 - learning_rate: 1.0000e-03\n",
            "Epoch 9: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_RNN_adam_sigmoid\n",
            "  Epochs: 9/50\n",
            "  Val ROC-AUC: 0.6821\n",
            "  Val PR-AUC: 0.0352\n",
            "\n",
            "[60/144] SMOTEv2/RNN/adam/gelu\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_RNN_adam_gelu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 14s - 17ms/step - accuracy: 0.5613 - auc: 0.5832 - loss: 0.7322 - val_accuracy: 0.7847 - val_auc: 0.6598 - val_loss: 0.6046 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6005 - auc: 0.6409 - loss: 0.6618 - val_accuracy: 0.5752 - val_auc: 0.6674 - val_loss: 0.6947 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6103 - auc: 0.6546 - loss: 0.6554 - val_accuracy: 0.5470 - val_auc: 0.6622 - val_loss: 0.7478 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6181 - auc: 0.6647 - loss: 0.6502 - val_accuracy: 0.5785 - val_auc: 0.6482 - val_loss: 0.7347 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6261 - auc: 0.6754 - loss: 0.6442 - val_accuracy: 0.6400 - val_auc: 0.6461 - val_loss: 0.6824 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6286 - auc: 0.6784 - loss: 0.6420 - val_accuracy: 0.6028 - val_auc: 0.6393 - val_loss: 0.7377 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6314 - auc: 0.6817 - loss: 0.6402 - val_accuracy: 0.5611 - val_auc: 0.6464 - val_loss: 0.7433 - learning_rate: 5.0000e-04\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_RNN_adam_gelu\n",
            "  Epochs: 7/50\n",
            "  Val ROC-AUC: 0.6674\n",
            "  Val PR-AUC: 0.0353\n",
            "\n",
            "[61/144] SMOTEv2/RNN/rmsprop/relu\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_RNN_rmsprop_relu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 12s - 16ms/step - accuracy: 0.5726 - auc: 0.5993 - loss: 0.7034 - val_accuracy: 0.7721 - val_auc: 0.6532 - val_loss: 0.6021 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 4s - 6ms/step - accuracy: 0.6052 - auc: 0.6458 - loss: 0.6603 - val_accuracy: 0.7486 - val_auc: 0.6668 - val_loss: 0.6006 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6127 - auc: 0.6563 - loss: 0.6548 - val_accuracy: 0.6540 - val_auc: 0.6688 - val_loss: 0.6367 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6153 - auc: 0.6627 - loss: 0.6512 - val_accuracy: 0.6729 - val_auc: 0.6584 - val_loss: 0.6724 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6190 - auc: 0.6669 - loss: 0.6487 - val_accuracy: 0.7716 - val_auc: 0.6495 - val_loss: 0.5907 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6222 - auc: 0.6706 - loss: 0.6467 - val_accuracy: 0.6243 - val_auc: 0.6516 - val_loss: 0.6983 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "782/782 - 4s - 6ms/step - accuracy: 0.6240 - auc: 0.6726 - loss: 0.6456 - val_accuracy: 0.6832 - val_auc: 0.6548 - val_loss: 0.6533 - learning_rate: 1.0000e-03\n",
            "Epoch 8/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6254 - auc: 0.6754 - loss: 0.6438 - val_accuracy: 0.7681 - val_auc: 0.6462 - val_loss: 0.5866 - learning_rate: 1.0000e-03\n",
            "Epoch 8: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_RNN_rmsprop_relu\n",
            "  Epochs: 8/50\n",
            "  Val ROC-AUC: 0.6689\n",
            "  Val PR-AUC: 0.0341\n",
            "\n",
            "[62/144] SMOTEv2/RNN/rmsprop/tanh\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_RNN_rmsprop_tanh\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 12s - 16ms/step - accuracy: 0.5717 - auc: 0.5961 - loss: 0.6927 - val_accuracy: 0.7594 - val_auc: 0.6585 - val_loss: 0.5682 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6074 - auc: 0.6483 - loss: 0.6588 - val_accuracy: 0.6221 - val_auc: 0.6717 - val_loss: 0.6481 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6154 - auc: 0.6612 - loss: 0.6523 - val_accuracy: 0.5751 - val_auc: 0.6675 - val_loss: 0.6844 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6210 - auc: 0.6693 - loss: 0.6479 - val_accuracy: 0.5516 - val_auc: 0.6685 - val_loss: 0.7110 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6290 - auc: 0.6796 - loss: 0.6420 - val_accuracy: 0.6330 - val_auc: 0.6640 - val_loss: 0.6439 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6322 - auc: 0.6838 - loss: 0.6396 - val_accuracy: 0.5874 - val_auc: 0.6643 - val_loss: 0.6779 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6340 - auc: 0.6865 - loss: 0.6379 - val_accuracy: 0.6396 - val_auc: 0.6617 - val_loss: 0.6301 - learning_rate: 5.0000e-04\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_RNN_rmsprop_tanh\n",
            "  Epochs: 7/50\n",
            "  Val ROC-AUC: 0.6717\n",
            "  Val PR-AUC: 0.0341\n",
            "\n",
            "[63/144] SMOTEv2/RNN/rmsprop/sigmoid\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_RNN_rmsprop_sigmoid\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 12s - 15ms/step - accuracy: 0.5638 - auc: 0.5928 - loss: 0.6806 - val_accuracy: 0.6964 - val_auc: 0.6495 - val_loss: 0.6130 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.5946 - auc: 0.6344 - loss: 0.6645 - val_accuracy: 0.5169 - val_auc: 0.6611 - val_loss: 0.7093 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.5994 - auc: 0.6396 - loss: 0.6623 - val_accuracy: 0.6198 - val_auc: 0.6669 - val_loss: 0.6590 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 8s - 10ms/step - accuracy: 0.6022 - auc: 0.6442 - loss: 0.6598 - val_accuracy: 0.6185 - val_auc: 0.6721 - val_loss: 0.6607 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.6057 - auc: 0.6496 - loss: 0.6573 - val_accuracy: 0.6807 - val_auc: 0.6712 - val_loss: 0.6181 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6087 - auc: 0.6520 - loss: 0.6562 - val_accuracy: 0.6858 - val_auc: 0.6742 - val_loss: 0.6170 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6098 - auc: 0.6542 - loss: 0.6551 - val_accuracy: 0.7319 - val_auc: 0.6762 - val_loss: 0.5831 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6117 - auc: 0.6559 - loss: 0.6542 - val_accuracy: 0.7795 - val_auc: 0.6765 - val_loss: 0.5492 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6133 - auc: 0.6585 - loss: 0.6530 - val_accuracy: 0.6214 - val_auc: 0.6780 - val_loss: 0.6608 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "782/782 - 4s - 6ms/step - accuracy: 0.6148 - auc: 0.6611 - loss: 0.6516 - val_accuracy: 0.6428 - val_auc: 0.6776 - val_loss: 0.6462 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6163 - auc: 0.6626 - loss: 0.6510 - val_accuracy: 0.7560 - val_auc: 0.6782 - val_loss: 0.5688 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "782/782 - 9s - 12ms/step - accuracy: 0.6181 - auc: 0.6654 - loss: 0.6494 - val_accuracy: 0.7375 - val_auc: 0.6780 - val_loss: 0.5793 - learning_rate: 2.5000e-04\n",
            "Epoch 13/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6172 - auc: 0.6653 - loss: 0.6494 - val_accuracy: 0.7045 - val_auc: 0.6787 - val_loss: 0.6014 - learning_rate: 2.5000e-04\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6192 - auc: 0.6664 - loss: 0.6488 - val_accuracy: 0.7289 - val_auc: 0.6791 - val_loss: 0.5862 - learning_rate: 2.5000e-04\n",
            "Epoch 15/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6201 - auc: 0.6678 - loss: 0.6480 - val_accuracy: 0.7143 - val_auc: 0.6789 - val_loss: 0.5946 - learning_rate: 1.2500e-04\n",
            "Epoch 16/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6208 - auc: 0.6683 - loss: 0.6478 - val_accuracy: 0.7340 - val_auc: 0.6794 - val_loss: 0.5791 - learning_rate: 1.2500e-04\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "782/782 - 4s - 6ms/step - accuracy: 0.6200 - auc: 0.6678 - loss: 0.6481 - val_accuracy: 0.6861 - val_auc: 0.6793 - val_loss: 0.6171 - learning_rate: 1.2500e-04\n",
            "Epoch 18/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6215 - auc: 0.6690 - loss: 0.6475 - val_accuracy: 0.7296 - val_auc: 0.6792 - val_loss: 0.5805 - learning_rate: 6.2500e-05\n",
            "Epoch 19/50\n",
            "782/782 - 9s - 12ms/step - accuracy: 0.6212 - auc: 0.6696 - loss: 0.6471 - val_accuracy: 0.7238 - val_auc: 0.6793 - val_loss: 0.5849 - learning_rate: 6.2500e-05\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6217 - auc: 0.6688 - loss: 0.6475 - val_accuracy: 0.7219 - val_auc: 0.6792 - val_loss: 0.5879 - learning_rate: 6.2500e-05\n",
            "Epoch 21/50\n",
            "782/782 - 4s - 6ms/step - accuracy: 0.6212 - auc: 0.6692 - loss: 0.6472 - val_accuracy: 0.7262 - val_auc: 0.6790 - val_loss: 0.5848 - learning_rate: 3.1250e-05\n",
            "Epoch 21: early stopping\n",
            "Restoring model weights from the end of the best epoch: 16.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_RNN_rmsprop_sigmoid\n",
            "  Epochs: 21/50\n",
            "  Val ROC-AUC: 0.6794\n",
            "  Val PR-AUC: 0.0359\n",
            "\n",
            "[64/144] SMOTEv2/RNN/rmsprop/gelu\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_RNN_rmsprop_gelu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 13s - 17ms/step - accuracy: 0.5625 - auc: 0.5871 - loss: 0.7001 - val_accuracy: 0.8074 - val_auc: 0.6477 - val_loss: 0.6029 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.5958 - auc: 0.6355 - loss: 0.6646 - val_accuracy: 0.7781 - val_auc: 0.6666 - val_loss: 0.5722 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6107 - auc: 0.6533 - loss: 0.6565 - val_accuracy: 0.5621 - val_auc: 0.6663 - val_loss: 0.6925 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 8s - 10ms/step - accuracy: 0.6178 - auc: 0.6639 - loss: 0.6510 - val_accuracy: 0.5719 - val_auc: 0.6708 - val_loss: 0.7226 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6212 - auc: 0.6688 - loss: 0.6483 - val_accuracy: 0.6469 - val_auc: 0.6585 - val_loss: 0.6435 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6278 - auc: 0.6790 - loss: 0.6420 - val_accuracy: 0.5843 - val_auc: 0.6564 - val_loss: 0.7150 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6305 - auc: 0.6823 - loss: 0.6398 - val_accuracy: 0.5657 - val_auc: 0.6572 - val_loss: 0.7114 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6325 - auc: 0.6860 - loss: 0.6374 - val_accuracy: 0.5788 - val_auc: 0.6531 - val_loss: 0.7167 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6361 - auc: 0.6909 - loss: 0.6339 - val_accuracy: 0.5258 - val_auc: 0.6548 - val_loss: 0.7971 - learning_rate: 2.5000e-04\n",
            "Epoch 9: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_RNN_rmsprop_gelu\n",
            "  Epochs: 9/50\n",
            "  Val ROC-AUC: 0.6708\n",
            "  Val PR-AUC: 0.0339\n",
            "\n",
            "[65/144] SMOTEv2/GRU/adam/relu\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_GRU_adam_relu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 15s - 19ms/step - accuracy: 0.5686 - auc: 0.5950 - loss: 0.6978 - val_accuracy: 0.7239 - val_auc: 0.6646 - val_loss: 0.6095 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6053 - auc: 0.6473 - loss: 0.6582 - val_accuracy: 0.7533 - val_auc: 0.6784 - val_loss: 0.5919 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6150 - auc: 0.6603 - loss: 0.6523 - val_accuracy: 0.7296 - val_auc: 0.6829 - val_loss: 0.6124 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6184 - auc: 0.6666 - loss: 0.6490 - val_accuracy: 0.7817 - val_auc: 0.6835 - val_loss: 0.5732 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6221 - auc: 0.6698 - loss: 0.6473 - val_accuracy: 0.7661 - val_auc: 0.6787 - val_loss: 0.5719 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6240 - auc: 0.6727 - loss: 0.6454 - val_accuracy: 0.7899 - val_auc: 0.6779 - val_loss: 0.5546 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6267 - auc: 0.6756 - loss: 0.6438 - val_accuracy: 0.6984 - val_auc: 0.6726 - val_loss: 0.5950 - learning_rate: 1.0000e-03\n",
            "Epoch 8/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6285 - auc: 0.6793 - loss: 0.6416 - val_accuracy: 0.8275 - val_auc: 0.6620 - val_loss: 0.5011 - learning_rate: 1.0000e-03\n",
            "Epoch 9/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6298 - auc: 0.6818 - loss: 0.6397 - val_accuracy: 0.6894 - val_auc: 0.6608 - val_loss: 0.5945 - learning_rate: 1.0000e-03\n",
            "Epoch 9: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_GRU_adam_relu\n",
            "  Epochs: 9/50\n",
            "  Val ROC-AUC: 0.6836\n",
            "  Val PR-AUC: 0.0344\n",
            "\n",
            "[66/144] SMOTEv2/GRU/adam/tanh\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_GRU_adam_tanh\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 11s - 14ms/step - accuracy: 0.5806 - auc: 0.6132 - loss: 0.6781 - val_accuracy: 0.6386 - val_auc: 0.6665 - val_loss: 0.6274 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 10s - 12ms/step - accuracy: 0.6097 - auc: 0.6531 - loss: 0.6561 - val_accuracy: 0.6446 - val_auc: 0.6722 - val_loss: 0.6335 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 10s - 12ms/step - accuracy: 0.6200 - auc: 0.6664 - loss: 0.6495 - val_accuracy: 0.5822 - val_auc: 0.6701 - val_loss: 0.6810 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 9s - 11ms/step - accuracy: 0.6259 - auc: 0.6734 - loss: 0.6456 - val_accuracy: 0.6602 - val_auc: 0.6568 - val_loss: 0.6290 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 10s - 13ms/step - accuracy: 0.6306 - auc: 0.6796 - loss: 0.6420 - val_accuracy: 0.6667 - val_auc: 0.6540 - val_loss: 0.6262 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "782/782 - 9s - 12ms/step - accuracy: 0.6313 - auc: 0.6825 - loss: 0.6402 - val_accuracy: 0.6724 - val_auc: 0.6512 - val_loss: 0.6156 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "782/782 - 8s - 10ms/step - accuracy: 0.6336 - auc: 0.6846 - loss: 0.6389 - val_accuracy: 0.6092 - val_auc: 0.6523 - val_loss: 0.6801 - learning_rate: 5.0000e-04\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_GRU_adam_tanh\n",
            "  Epochs: 7/50\n",
            "  Val ROC-AUC: 0.6722\n",
            "  Val PR-AUC: 0.0326\n",
            "\n",
            "[67/144] SMOTEv2/GRU/adam/sigmoid\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_GRU_adam_sigmoid\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 14s - 18ms/step - accuracy: 0.5809 - auc: 0.6164 - loss: 0.6715 - val_accuracy: 0.5829 - val_auc: 0.6686 - val_loss: 0.6777 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6098 - auc: 0.6532 - loss: 0.6554 - val_accuracy: 0.7039 - val_auc: 0.6832 - val_loss: 0.6051 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6174 - auc: 0.6649 - loss: 0.6496 - val_accuracy: 0.6756 - val_auc: 0.6851 - val_loss: 0.6357 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 10s - 12ms/step - accuracy: 0.6209 - auc: 0.6698 - loss: 0.6468 - val_accuracy: 0.7962 - val_auc: 0.6853 - val_loss: 0.5486 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 10s - 12ms/step - accuracy: 0.6234 - auc: 0.6727 - loss: 0.6452 - val_accuracy: 0.7694 - val_auc: 0.6812 - val_loss: 0.5583 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6256 - auc: 0.6756 - loss: 0.6434 - val_accuracy: 0.8144 - val_auc: 0.6817 - val_loss: 0.5082 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6283 - auc: 0.6784 - loss: 0.6417 - val_accuracy: 0.7151 - val_auc: 0.6832 - val_loss: 0.5912 - learning_rate: 1.0000e-03\n",
            "Epoch 8/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6303 - auc: 0.6814 - loss: 0.6398 - val_accuracy: 0.8282 - val_auc: 0.6798 - val_loss: 0.4909 - learning_rate: 1.0000e-03\n",
            "Epoch 9/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6313 - auc: 0.6835 - loss: 0.6384 - val_accuracy: 0.7371 - val_auc: 0.6806 - val_loss: 0.5594 - learning_rate: 1.0000e-03\n",
            "Epoch 9: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_GRU_adam_sigmoid\n",
            "  Epochs: 9/50\n",
            "  Val ROC-AUC: 0.6853\n",
            "  Val PR-AUC: 0.0347\n",
            "\n",
            "[68/144] SMOTEv2/GRU/adam/gelu\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_GRU_adam_gelu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 16s - 20ms/step - accuracy: 0.5890 - auc: 0.6230 - loss: 0.6811 - val_accuracy: 0.6568 - val_auc: 0.6737 - val_loss: 0.6561 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6163 - auc: 0.6621 - loss: 0.6513 - val_accuracy: 0.6636 - val_auc: 0.6709 - val_loss: 0.6541 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6226 - auc: 0.6705 - loss: 0.6467 - val_accuracy: 0.6348 - val_auc: 0.6658 - val_loss: 0.6754 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6260 - auc: 0.6753 - loss: 0.6436 - val_accuracy: 0.7371 - val_auc: 0.6511 - val_loss: 0.6219 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6288 - auc: 0.6788 - loss: 0.6415 - val_accuracy: 0.7320 - val_auc: 0.6535 - val_loss: 0.6011 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6306 - auc: 0.6829 - loss: 0.6387 - val_accuracy: 0.6700 - val_auc: 0.6444 - val_loss: 0.6606 - learning_rate: 1.0000e-03\n",
            "Epoch 6: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_GRU_adam_gelu\n",
            "  Epochs: 6/50\n",
            "  Val ROC-AUC: 0.6738\n",
            "  Val PR-AUC: 0.0341\n",
            "\n",
            "[69/144] SMOTEv2/GRU/rmsprop/relu\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_GRU_rmsprop_relu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 14s - 18ms/step - accuracy: 0.5820 - auc: 0.6151 - loss: 0.6769 - val_accuracy: 0.8019 - val_auc: 0.6656 - val_loss: 0.5879 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 14s - 17ms/step - accuracy: 0.6080 - auc: 0.6517 - loss: 0.6565 - val_accuracy: 0.7067 - val_auc: 0.6785 - val_loss: 0.6405 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6149 - auc: 0.6615 - loss: 0.6518 - val_accuracy: 0.7264 - val_auc: 0.6718 - val_loss: 0.5852 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6201 - auc: 0.6685 - loss: 0.6480 - val_accuracy: 0.6078 - val_auc: 0.6596 - val_loss: 0.7007 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6226 - auc: 0.6712 - loss: 0.6465 - val_accuracy: 0.7033 - val_auc: 0.6671 - val_loss: 0.6107 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6255 - auc: 0.6754 - loss: 0.6441 - val_accuracy: 0.7000 - val_auc: 0.6577 - val_loss: 0.6137 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6314 - auc: 0.6819 - loss: 0.6398 - val_accuracy: 0.7003 - val_auc: 0.6631 - val_loss: 0.5988 - learning_rate: 5.0000e-04\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_GRU_rmsprop_relu\n",
            "  Epochs: 7/50\n",
            "  Val ROC-AUC: 0.6785\n",
            "  Val PR-AUC: 0.0341\n",
            "\n",
            "[70/144] SMOTEv2/GRU/rmsprop/tanh\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_GRU_rmsprop_tanh\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 10s - 12ms/step - accuracy: 0.5798 - auc: 0.6127 - loss: 0.6762 - val_accuracy: 0.7150 - val_auc: 0.6646 - val_loss: 0.5855 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 11s - 14ms/step - accuracy: 0.6076 - auc: 0.6507 - loss: 0.6574 - val_accuracy: 0.5436 - val_auc: 0.6797 - val_loss: 0.6892 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 9s - 11ms/step - accuracy: 0.6176 - auc: 0.6635 - loss: 0.6510 - val_accuracy: 0.6268 - val_auc: 0.6767 - val_loss: 0.6456 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 8s - 10ms/step - accuracy: 0.6225 - auc: 0.6705 - loss: 0.6473 - val_accuracy: 0.6056 - val_auc: 0.6660 - val_loss: 0.6620 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 10s - 13ms/step - accuracy: 0.6281 - auc: 0.6773 - loss: 0.6436 - val_accuracy: 0.6308 - val_auc: 0.6575 - val_loss: 0.6482 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "782/782 - 9s - 11ms/step - accuracy: 0.6295 - auc: 0.6800 - loss: 0.6418 - val_accuracy: 0.6292 - val_auc: 0.6583 - val_loss: 0.6466 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "782/782 - 8s - 10ms/step - accuracy: 0.6320 - auc: 0.6815 - loss: 0.6410 - val_accuracy: 0.6248 - val_auc: 0.6636 - val_loss: 0.6486 - learning_rate: 5.0000e-04\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_GRU_rmsprop_tanh\n",
            "  Epochs: 7/50\n",
            "  Val ROC-AUC: 0.6798\n",
            "  Val PR-AUC: 0.0350\n",
            "\n",
            "[71/144] SMOTEv2/GRU/rmsprop/sigmoid\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_GRU_rmsprop_sigmoid\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 14s - 18ms/step - accuracy: 0.5686 - auc: 0.5977 - loss: 0.6782 - val_accuracy: 0.6985 - val_auc: 0.6595 - val_loss: 0.6016 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.5959 - auc: 0.6353 - loss: 0.6639 - val_accuracy: 0.5982 - val_auc: 0.6685 - val_loss: 0.6611 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.5996 - auc: 0.6414 - loss: 0.6609 - val_accuracy: 0.6292 - val_auc: 0.6721 - val_loss: 0.6438 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6046 - auc: 0.6473 - loss: 0.6582 - val_accuracy: 0.6243 - val_auc: 0.6760 - val_loss: 0.6598 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6069 - auc: 0.6510 - loss: 0.6563 - val_accuracy: 0.6714 - val_auc: 0.6750 - val_loss: 0.6270 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6096 - auc: 0.6553 - loss: 0.6542 - val_accuracy: 0.6989 - val_auc: 0.6762 - val_loss: 0.6100 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6121 - auc: 0.6567 - loss: 0.6536 - val_accuracy: 0.7193 - val_auc: 0.6782 - val_loss: 0.5901 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6135 - auc: 0.6596 - loss: 0.6521 - val_accuracy: 0.7994 - val_auc: 0.6775 - val_loss: 0.5361 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6149 - auc: 0.6618 - loss: 0.6509 - val_accuracy: 0.6383 - val_auc: 0.6797 - val_loss: 0.6545 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "782/782 - 8s - 10ms/step - accuracy: 0.6165 - auc: 0.6634 - loss: 0.6503 - val_accuracy: 0.6486 - val_auc: 0.6796 - val_loss: 0.6484 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6183 - auc: 0.6658 - loss: 0.6491 - val_accuracy: 0.7489 - val_auc: 0.6799 - val_loss: 0.5750 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6193 - auc: 0.6678 - loss: 0.6478 - val_accuracy: 0.7322 - val_auc: 0.6797 - val_loss: 0.5833 - learning_rate: 2.5000e-04\n",
            "Epoch 13/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6194 - auc: 0.6688 - loss: 0.6474 - val_accuracy: 0.7059 - val_auc: 0.6800 - val_loss: 0.6045 - learning_rate: 2.5000e-04\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6211 - auc: 0.6692 - loss: 0.6471 - val_accuracy: 0.7308 - val_auc: 0.6796 - val_loss: 0.5863 - learning_rate: 2.5000e-04\n",
            "Epoch 15/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6207 - auc: 0.6703 - loss: 0.6465 - val_accuracy: 0.7251 - val_auc: 0.6800 - val_loss: 0.5889 - learning_rate: 1.2500e-04\n",
            "Epoch 16/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6216 - auc: 0.6704 - loss: 0.6464 - val_accuracy: 0.7342 - val_auc: 0.6802 - val_loss: 0.5820 - learning_rate: 1.2500e-04\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6228 - auc: 0.6718 - loss: 0.6457 - val_accuracy: 0.6862 - val_auc: 0.6802 - val_loss: 0.6175 - learning_rate: 1.2500e-04\n",
            "Epoch 18/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6213 - auc: 0.6712 - loss: 0.6462 - val_accuracy: 0.7266 - val_auc: 0.6804 - val_loss: 0.5864 - learning_rate: 6.2500e-05\n",
            "Epoch 19/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6223 - auc: 0.6717 - loss: 0.6458 - val_accuracy: 0.7243 - val_auc: 0.6803 - val_loss: 0.5879 - learning_rate: 6.2500e-05\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6220 - auc: 0.6720 - loss: 0.6456 - val_accuracy: 0.7220 - val_auc: 0.6806 - val_loss: 0.5909 - learning_rate: 6.2500e-05\n",
            "Epoch 21/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6224 - auc: 0.6719 - loss: 0.6455 - val_accuracy: 0.7245 - val_auc: 0.6803 - val_loss: 0.5895 - learning_rate: 3.1250e-05\n",
            "Epoch 22/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6219 - auc: 0.6713 - loss: 0.6458 - val_accuracy: 0.7172 - val_auc: 0.6804 - val_loss: 0.5955 - learning_rate: 3.1250e-05\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6226 - auc: 0.6719 - loss: 0.6456 - val_accuracy: 0.7267 - val_auc: 0.6802 - val_loss: 0.5874 - learning_rate: 3.1250e-05\n",
            "Epoch 24/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6223 - auc: 0.6722 - loss: 0.6453 - val_accuracy: 0.7235 - val_auc: 0.6803 - val_loss: 0.5896 - learning_rate: 1.5625e-05\n",
            "Epoch 25/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6223 - auc: 0.6721 - loss: 0.6456 - val_accuracy: 0.7239 - val_auc: 0.6802 - val_loss: 0.5891 - learning_rate: 1.5625e-05\n",
            "Epoch 25: early stopping\n",
            "Restoring model weights from the end of the best epoch: 20.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_GRU_rmsprop_sigmoid\n",
            "  Epochs: 25/50\n",
            "  Val ROC-AUC: 0.6806\n",
            "  Val PR-AUC: 0.0356\n",
            "\n",
            "[72/144] SMOTEv2/GRU/rmsprop/gelu\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_GRU_rmsprop_gelu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 15s - 19ms/step - accuracy: 0.5812 - auc: 0.6124 - loss: 0.6869 - val_accuracy: 0.7952 - val_auc: 0.6541 - val_loss: 0.5861 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6099 - auc: 0.6531 - loss: 0.6560 - val_accuracy: 0.7465 - val_auc: 0.6633 - val_loss: 0.5821 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6162 - auc: 0.6631 - loss: 0.6509 - val_accuracy: 0.6738 - val_auc: 0.6619 - val_loss: 0.6295 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6208 - auc: 0.6694 - loss: 0.6475 - val_accuracy: 0.7304 - val_auc: 0.6553 - val_loss: 0.6173 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6249 - auc: 0.6729 - loss: 0.6457 - val_accuracy: 0.7400 - val_auc: 0.6580 - val_loss: 0.5821 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6286 - auc: 0.6800 - loss: 0.6409 - val_accuracy: 0.6439 - val_auc: 0.6583 - val_loss: 0.6372 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6307 - auc: 0.6823 - loss: 0.6397 - val_accuracy: 0.7107 - val_auc: 0.6661 - val_loss: 0.5895 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6320 - auc: 0.6843 - loss: 0.6384 - val_accuracy: 0.7189 - val_auc: 0.6622 - val_loss: 0.5884 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "782/782 - 8s - 10ms/step - accuracy: 0.6346 - auc: 0.6877 - loss: 0.6358 - val_accuracy: 0.6530 - val_auc: 0.6648 - val_loss: 0.6423 - learning_rate: 2.5000e-04\n",
            "Epoch 10/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6356 - auc: 0.6890 - loss: 0.6353 - val_accuracy: 0.6367 - val_auc: 0.6627 - val_loss: 0.6442 - learning_rate: 2.5000e-04\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6361 - auc: 0.6901 - loss: 0.6346 - val_accuracy: 0.7124 - val_auc: 0.6582 - val_loss: 0.5993 - learning_rate: 2.5000e-04\n",
            "Epoch 12/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6375 - auc: 0.6920 - loss: 0.6333 - val_accuracy: 0.6814 - val_auc: 0.6582 - val_loss: 0.6222 - learning_rate: 1.2500e-04\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_GRU_rmsprop_gelu\n",
            "  Epochs: 12/50\n",
            "  Val ROC-AUC: 0.6661\n",
            "  Val PR-AUC: 0.0322\n",
            "\n",
            "[73/144] SMOTEv2/LSTM_Attention/adam/relu\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_LSTM_Attention_adam_relu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 15s - 19ms/step - accuracy: 0.5985 - auc: 0.6380 - loss: 0.6639 - val_accuracy: 0.7181 - val_auc: 0.6754 - val_loss: 0.6073 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6177 - auc: 0.6650 - loss: 0.6494 - val_accuracy: 0.6695 - val_auc: 0.6682 - val_loss: 0.6532 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6221 - auc: 0.6707 - loss: 0.6461 - val_accuracy: 0.5946 - val_auc: 0.6717 - val_loss: 0.7003 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6249 - auc: 0.6746 - loss: 0.6440 - val_accuracy: 0.6782 - val_auc: 0.6613 - val_loss: 0.6485 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 10s - 12ms/step - accuracy: 0.6290 - auc: 0.6794 - loss: 0.6412 - val_accuracy: 0.6445 - val_auc: 0.6577 - val_loss: 0.6561 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6304 - auc: 0.6820 - loss: 0.6395 - val_accuracy: 0.6597 - val_auc: 0.6627 - val_loss: 0.6517 - learning_rate: 5.0000e-04\n",
            "Epoch 6: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_LSTM_Attention_adam_relu\n",
            "  Epochs: 6/50\n",
            "  Val ROC-AUC: 0.6753\n",
            "  Val PR-AUC: 0.0336\n",
            "\n",
            "[74/144] SMOTEv2/LSTM_Attention/adam/tanh\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_LSTM_Attention_adam_tanh\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 12s - 16ms/step - accuracy: 0.5992 - auc: 0.6415 - loss: 0.6608 - val_accuracy: 0.6814 - val_auc: 0.6705 - val_loss: 0.6063 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 10s - 13ms/step - accuracy: 0.6177 - auc: 0.6652 - loss: 0.6495 - val_accuracy: 0.6000 - val_auc: 0.6777 - val_loss: 0.6758 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 10s - 13ms/step - accuracy: 0.6245 - auc: 0.6739 - loss: 0.6448 - val_accuracy: 0.6355 - val_auc: 0.6790 - val_loss: 0.6540 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 9s - 11ms/step - accuracy: 0.6284 - auc: 0.6787 - loss: 0.6421 - val_accuracy: 0.6748 - val_auc: 0.6753 - val_loss: 0.6236 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 10s - 13ms/step - accuracy: 0.6332 - auc: 0.6836 - loss: 0.6390 - val_accuracy: 0.7244 - val_auc: 0.6714 - val_loss: 0.5901 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "782/782 - 10s - 12ms/step - accuracy: 0.6341 - auc: 0.6862 - loss: 0.6373 - val_accuracy: 0.7439 - val_auc: 0.6696 - val_loss: 0.5666 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "782/782 - 9s - 12ms/step - accuracy: 0.6368 - auc: 0.6883 - loss: 0.6361 - val_accuracy: 0.6280 - val_auc: 0.6735 - val_loss: 0.6711 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "782/782 - 9s - 12ms/step - accuracy: 0.6372 - auc: 0.6903 - loss: 0.6345 - val_accuracy: 0.7725 - val_auc: 0.6685 - val_loss: 0.5290 - learning_rate: 5.0000e-04\n",
            "Epoch 8: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_LSTM_Attention_adam_tanh\n",
            "  Epochs: 8/50\n",
            "  Val ROC-AUC: 0.6790\n",
            "  Val PR-AUC: 0.0359\n",
            "\n",
            "[75/144] SMOTEv2/LSTM_Attention/adam/sigmoid\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_LSTM_Attention_adam_sigmoid\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 15s - 19ms/step - accuracy: 0.5749 - auc: 0.6082 - loss: 0.6755 - val_accuracy: 0.5807 - val_auc: 0.6652 - val_loss: 0.6683 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6090 - auc: 0.6534 - loss: 0.6552 - val_accuracy: 0.6455 - val_auc: 0.6772 - val_loss: 0.6397 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6178 - auc: 0.6655 - loss: 0.6492 - val_accuracy: 0.6056 - val_auc: 0.6797 - val_loss: 0.6712 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6205 - auc: 0.6699 - loss: 0.6466 - val_accuracy: 0.7423 - val_auc: 0.6796 - val_loss: 0.5749 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6221 - auc: 0.6720 - loss: 0.6452 - val_accuracy: 0.7482 - val_auc: 0.6773 - val_loss: 0.5600 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6236 - auc: 0.6746 - loss: 0.6437 - val_accuracy: 0.7891 - val_auc: 0.6760 - val_loss: 0.5225 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6272 - auc: 0.6776 - loss: 0.6421 - val_accuracy: 0.6400 - val_auc: 0.6779 - val_loss: 0.6503 - learning_rate: 1.0000e-03\n",
            "Epoch 8/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6276 - auc: 0.6795 - loss: 0.6408 - val_accuracy: 0.7816 - val_auc: 0.6739 - val_loss: 0.5219 - learning_rate: 1.0000e-03\n",
            "Epoch 8: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_LSTM_Attention_adam_sigmoid\n",
            "  Epochs: 8/50\n",
            "  Val ROC-AUC: 0.6797\n",
            "  Val PR-AUC: 0.0354\n",
            "\n",
            "[76/144] SMOTEv2/LSTM_Attention/adam/gelu\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_LSTM_Attention_adam_gelu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 16s - 21ms/step - accuracy: 0.5988 - auc: 0.6395 - loss: 0.6655 - val_accuracy: 0.6861 - val_auc: 0.6765 - val_loss: 0.6185 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6164 - auc: 0.6648 - loss: 0.6496 - val_accuracy: 0.6966 - val_auc: 0.6760 - val_loss: 0.6262 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 8s - 10ms/step - accuracy: 0.6217 - auc: 0.6708 - loss: 0.6460 - val_accuracy: 0.5786 - val_auc: 0.6729 - val_loss: 0.7236 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6268 - auc: 0.6757 - loss: 0.6431 - val_accuracy: 0.6665 - val_auc: 0.6727 - val_loss: 0.6586 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6307 - auc: 0.6820 - loss: 0.6391 - val_accuracy: 0.6739 - val_auc: 0.6628 - val_loss: 0.6494 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "782/782 - 9s - 12ms/step - accuracy: 0.6321 - auc: 0.6847 - loss: 0.6371 - val_accuracy: 0.7313 - val_auc: 0.6642 - val_loss: 0.6018 - learning_rate: 5.0000e-04\n",
            "Epoch 6: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_LSTM_Attention_adam_gelu\n",
            "  Epochs: 6/50\n",
            "  Val ROC-AUC: 0.6766\n",
            "  Val PR-AUC: 0.0343\n",
            "\n",
            "[77/144] SMOTEv2/LSTM_Attention/rmsprop/relu\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_LSTM_Attention_rmsprop_relu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 14s - 18ms/step - accuracy: 0.5904 - auc: 0.6279 - loss: 0.6680 - val_accuracy: 0.6964 - val_auc: 0.6584 - val_loss: 0.6659 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6117 - auc: 0.6558 - loss: 0.6546 - val_accuracy: 0.6546 - val_auc: 0.6799 - val_loss: 0.6440 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6182 - auc: 0.6651 - loss: 0.6498 - val_accuracy: 0.6148 - val_auc: 0.6772 - val_loss: 0.6795 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6226 - auc: 0.6708 - loss: 0.6468 - val_accuracy: 0.6468 - val_auc: 0.6754 - val_loss: 0.6830 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 8s - 10ms/step - accuracy: 0.6255 - auc: 0.6748 - loss: 0.6444 - val_accuracy: 0.7446 - val_auc: 0.6667 - val_loss: 0.6058 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6285 - auc: 0.6780 - loss: 0.6427 - val_accuracy: 0.7173 - val_auc: 0.6535 - val_loss: 0.6151 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6303 - auc: 0.6796 - loss: 0.6415 - val_accuracy: 0.7506 - val_auc: 0.6552 - val_loss: 0.5782 - learning_rate: 1.0000e-03\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_LSTM_Attention_rmsprop_relu\n",
            "  Epochs: 7/50\n",
            "  Val ROC-AUC: 0.6799\n",
            "  Val PR-AUC: 0.0339\n",
            "\n",
            "[78/144] SMOTEv2/LSTM_Attention/rmsprop/tanh\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_LSTM_Attention_rmsprop_tanh\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 11s - 14ms/step - accuracy: 0.5869 - auc: 0.6237 - loss: 0.6690 - val_accuracy: 0.7032 - val_auc: 0.6625 - val_loss: 0.5895 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 8s - 11ms/step - accuracy: 0.6114 - auc: 0.6558 - loss: 0.6546 - val_accuracy: 0.7184 - val_auc: 0.6723 - val_loss: 0.5790 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 9s - 12ms/step - accuracy: 0.6193 - auc: 0.6665 - loss: 0.6489 - val_accuracy: 0.6703 - val_auc: 0.6654 - val_loss: 0.6124 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 10s - 13ms/step - accuracy: 0.6224 - auc: 0.6720 - loss: 0.6458 - val_accuracy: 0.6926 - val_auc: 0.6683 - val_loss: 0.6116 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 9s - 12ms/step - accuracy: 0.6255 - auc: 0.6748 - loss: 0.6443 - val_accuracy: 0.7511 - val_auc: 0.6622 - val_loss: 0.5529 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "782/782 - 8s - 10ms/step - accuracy: 0.6270 - auc: 0.6776 - loss: 0.6427 - val_accuracy: 0.7624 - val_auc: 0.6578 - val_loss: 0.5498 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "782/782 - 9s - 12ms/step - accuracy: 0.6292 - auc: 0.6794 - loss: 0.6417 - val_accuracy: 0.8208 - val_auc: 0.6670 - val_loss: 0.4981 - learning_rate: 1.0000e-03\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_LSTM_Attention_rmsprop_tanh\n",
            "  Epochs: 7/50\n",
            "  Val ROC-AUC: 0.6722\n",
            "  Val PR-AUC: 0.0335\n",
            "\n",
            "[79/144] SMOTEv2/LSTM_Attention/rmsprop/sigmoid\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_LSTM_Attention_rmsprop_sigmoid\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 14s - 18ms/step - accuracy: 0.5654 - auc: 0.5973 - loss: 0.6777 - val_accuracy: 0.6595 - val_auc: 0.6553 - val_loss: 0.6027 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.5963 - auc: 0.6365 - loss: 0.6632 - val_accuracy: 0.5589 - val_auc: 0.6628 - val_loss: 0.6714 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.5999 - auc: 0.6424 - loss: 0.6601 - val_accuracy: 0.5794 - val_auc: 0.6667 - val_loss: 0.6723 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6040 - auc: 0.6472 - loss: 0.6579 - val_accuracy: 0.5918 - val_auc: 0.6712 - val_loss: 0.6710 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6069 - auc: 0.6516 - loss: 0.6557 - val_accuracy: 0.6763 - val_auc: 0.6703 - val_loss: 0.6171 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6093 - auc: 0.6543 - loss: 0.6543 - val_accuracy: 0.6974 - val_auc: 0.6727 - val_loss: 0.6047 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6106 - auc: 0.6562 - loss: 0.6535 - val_accuracy: 0.7088 - val_auc: 0.6749 - val_loss: 0.5952 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6139 - auc: 0.6590 - loss: 0.6522 - val_accuracy: 0.7808 - val_auc: 0.6761 - val_loss: 0.5422 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6143 - auc: 0.6609 - loss: 0.6512 - val_accuracy: 0.6195 - val_auc: 0.6767 - val_loss: 0.6731 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6145 - auc: 0.6624 - loss: 0.6506 - val_accuracy: 0.6456 - val_auc: 0.6768 - val_loss: 0.6538 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6155 - auc: 0.6646 - loss: 0.6493 - val_accuracy: 0.7782 - val_auc: 0.6783 - val_loss: 0.5470 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6175 - auc: 0.6670 - loss: 0.6481 - val_accuracy: 0.7276 - val_auc: 0.6780 - val_loss: 0.5879 - learning_rate: 2.5000e-04\n",
            "Epoch 13/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6179 - auc: 0.6676 - loss: 0.6477 - val_accuracy: 0.6916 - val_auc: 0.6783 - val_loss: 0.6183 - learning_rate: 2.5000e-04\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6182 - auc: 0.6681 - loss: 0.6473 - val_accuracy: 0.7395 - val_auc: 0.6787 - val_loss: 0.5788 - learning_rate: 2.5000e-04\n",
            "Epoch 15/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6195 - auc: 0.6695 - loss: 0.6466 - val_accuracy: 0.7161 - val_auc: 0.6787 - val_loss: 0.5962 - learning_rate: 1.2500e-04\n",
            "Epoch 16/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6200 - auc: 0.6697 - loss: 0.6465 - val_accuracy: 0.7425 - val_auc: 0.6789 - val_loss: 0.5744 - learning_rate: 1.2500e-04\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "782/782 - 10s - 12ms/step - accuracy: 0.6199 - auc: 0.6699 - loss: 0.6463 - val_accuracy: 0.6885 - val_auc: 0.6790 - val_loss: 0.6217 - learning_rate: 1.2500e-04\n",
            "Epoch 18/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6204 - auc: 0.6703 - loss: 0.6461 - val_accuracy: 0.7341 - val_auc: 0.6789 - val_loss: 0.5818 - learning_rate: 6.2500e-05\n",
            "Epoch 19/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6200 - auc: 0.6705 - loss: 0.6460 - val_accuracy: 0.7261 - val_auc: 0.6789 - val_loss: 0.5885 - learning_rate: 6.2500e-05\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6201 - auc: 0.6711 - loss: 0.6457 - val_accuracy: 0.7289 - val_auc: 0.6789 - val_loss: 0.5880 - learning_rate: 6.2500e-05\n",
            "Epoch 21/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6207 - auc: 0.6712 - loss: 0.6457 - val_accuracy: 0.7338 - val_auc: 0.6789 - val_loss: 0.5835 - learning_rate: 3.1250e-05\n",
            "Epoch 22/50\n",
            "782/782 - 11s - 14ms/step - accuracy: 0.6204 - auc: 0.6711 - loss: 0.6457 - val_accuracy: 0.7175 - val_auc: 0.6792 - val_loss: 0.5978 - learning_rate: 3.1250e-05\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6207 - auc: 0.6713 - loss: 0.6455 - val_accuracy: 0.7371 - val_auc: 0.6788 - val_loss: 0.5801 - learning_rate: 3.1250e-05\n",
            "Epoch 24/50\n",
            "782/782 - 8s - 10ms/step - accuracy: 0.6208 - auc: 0.6717 - loss: 0.6454 - val_accuracy: 0.7313 - val_auc: 0.6790 - val_loss: 0.5856 - learning_rate: 1.5625e-05\n",
            "Epoch 25/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6206 - auc: 0.6714 - loss: 0.6455 - val_accuracy: 0.7334 - val_auc: 0.6788 - val_loss: 0.5838 - learning_rate: 1.5625e-05\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6211 - auc: 0.6717 - loss: 0.6454 - val_accuracy: 0.7296 - val_auc: 0.6789 - val_loss: 0.5873 - learning_rate: 1.5625e-05\n",
            "Epoch 27/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6214 - auc: 0.6717 - loss: 0.6454 - val_accuracy: 0.7341 - val_auc: 0.6788 - val_loss: 0.5831 - learning_rate: 7.8125e-06\n",
            "Epoch 27: early stopping\n",
            "Restoring model weights from the end of the best epoch: 22.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_LSTM_Attention_rmsprop_sigmoid\n",
            "  Epochs: 27/50\n",
            "  Val ROC-AUC: 0.6791\n",
            "  Val PR-AUC: 0.0357\n",
            "\n",
            "[80/144] SMOTEv2/LSTM_Attention/rmsprop/gelu\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_LSTM_Attention_rmsprop_gelu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 15s - 19ms/step - accuracy: 0.5900 - auc: 0.6246 - loss: 0.6717 - val_accuracy: 0.7700 - val_auc: 0.6517 - val_loss: 0.5899 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6107 - auc: 0.6552 - loss: 0.6549 - val_accuracy: 0.6102 - val_auc: 0.6617 - val_loss: 0.6511 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6167 - auc: 0.6641 - loss: 0.6501 - val_accuracy: 0.5810 - val_auc: 0.6538 - val_loss: 0.6945 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6208 - auc: 0.6698 - loss: 0.6469 - val_accuracy: 0.6342 - val_auc: 0.6666 - val_loss: 0.7121 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6278 - auc: 0.6786 - loss: 0.6417 - val_accuracy: 0.6568 - val_auc: 0.6637 - val_loss: 0.6918 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6299 - auc: 0.6813 - loss: 0.6399 - val_accuracy: 0.6782 - val_auc: 0.6595 - val_loss: 0.6859 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6318 - auc: 0.6838 - loss: 0.6385 - val_accuracy: 0.6826 - val_auc: 0.6606 - val_loss: 0.6935 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6350 - auc: 0.6882 - loss: 0.6356 - val_accuracy: 0.7094 - val_auc: 0.6628 - val_loss: 0.6813 - learning_rate: 2.5000e-04\n",
            "Epoch 9/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6366 - auc: 0.6895 - loss: 0.6348 - val_accuracy: 0.6395 - val_auc: 0.6654 - val_loss: 0.7824 - learning_rate: 2.5000e-04\n",
            "Epoch 9: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_LSTM_Attention_rmsprop_gelu\n",
            "  Epochs: 9/50\n",
            "  Val ROC-AUC: 0.6667\n",
            "  Val PR-AUC: 0.0313\n",
            "\n",
            "[81/144] SMOTEv2/CNN/adam/relu\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_CNN_adam_relu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 13s - 17ms/step - accuracy: 0.5529 - auc: 0.5730 - loss: 0.7117 - val_accuracy: 0.3106 - val_auc: 0.6448 - val_loss: 0.7980 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.5983 - auc: 0.6369 - loss: 0.6634 - val_accuracy: 0.4308 - val_auc: 0.6516 - val_loss: 0.7709 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6102 - auc: 0.6512 - loss: 0.6573 - val_accuracy: 0.5442 - val_auc: 0.6541 - val_loss: 0.7216 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6152 - auc: 0.6595 - loss: 0.6529 - val_accuracy: 0.6163 - val_auc: 0.6497 - val_loss: 0.6797 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6199 - auc: 0.6653 - loss: 0.6498 - val_accuracy: 0.6650 - val_auc: 0.6468 - val_loss: 0.6857 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6220 - auc: 0.6698 - loss: 0.6472 - val_accuracy: 0.7058 - val_auc: 0.6435 - val_loss: 0.6502 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "782/782 - 4s - 6ms/step - accuracy: 0.6252 - auc: 0.6733 - loss: 0.6452 - val_accuracy: 0.5106 - val_auc: 0.6467 - val_loss: 0.7690 - learning_rate: 1.0000e-03\n",
            "Epoch 8/50\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6277 - auc: 0.6774 - loss: 0.6428 - val_accuracy: 0.6510 - val_auc: 0.6461 - val_loss: 0.6551 - learning_rate: 1.0000e-03\n",
            "Epoch 8: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_CNN_adam_relu\n",
            "  Epochs: 8/50\n",
            "  Val ROC-AUC: 0.6540\n",
            "  Val PR-AUC: 0.0317\n",
            "\n",
            "[82/144] SMOTEv2/CNN/adam/tanh\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_CNN_adam_tanh\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 12s - 15ms/step - accuracy: 0.5808 - auc: 0.6132 - loss: 0.6760 - val_accuracy: 0.4987 - val_auc: 0.6512 - val_loss: 0.7444 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6027 - auc: 0.6443 - loss: 0.6605 - val_accuracy: 0.3946 - val_auc: 0.6559 - val_loss: 0.8253 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 4s - 6ms/step - accuracy: 0.6114 - auc: 0.6551 - loss: 0.6552 - val_accuracy: 0.3402 - val_auc: 0.6563 - val_loss: 0.8771 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6151 - auc: 0.6609 - loss: 0.6522 - val_accuracy: 0.3886 - val_auc: 0.6577 - val_loss: 0.8412 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6203 - auc: 0.6675 - loss: 0.6486 - val_accuracy: 0.4851 - val_auc: 0.6558 - val_loss: 0.7592 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6218 - auc: 0.6692 - loss: 0.6478 - val_accuracy: 0.5318 - val_auc: 0.6526 - val_loss: 0.7330 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6236 - auc: 0.6720 - loss: 0.6463 - val_accuracy: 0.3624 - val_auc: 0.6513 - val_loss: 0.8587 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6241 - auc: 0.6732 - loss: 0.6454 - val_accuracy: 0.5452 - val_auc: 0.6499 - val_loss: 0.7229 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6247 - auc: 0.6743 - loss: 0.6447 - val_accuracy: 0.4526 - val_auc: 0.6511 - val_loss: 0.8081 - learning_rate: 5.0000e-04\n",
            "Epoch 9: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_CNN_adam_tanh\n",
            "  Epochs: 9/50\n",
            "  Val ROC-AUC: 0.6576\n",
            "  Val PR-AUC: 0.0304\n",
            "\n",
            "[83/144] SMOTEv2/CNN/adam/sigmoid\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_CNN_adam_sigmoid\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 12s - 15ms/step - accuracy: 0.5736 - auc: 0.6057 - loss: 0.6758 - val_accuracy: 0.3206 - val_auc: 0.6442 - val_loss: 0.8604 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6037 - auc: 0.6464 - loss: 0.6590 - val_accuracy: 0.3616 - val_auc: 0.6508 - val_loss: 0.8616 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6107 - auc: 0.6558 - loss: 0.6545 - val_accuracy: 0.3365 - val_auc: 0.6517 - val_loss: 0.9012 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6134 - auc: 0.6605 - loss: 0.6521 - val_accuracy: 0.4673 - val_auc: 0.6525 - val_loss: 0.7930 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6163 - auc: 0.6633 - loss: 0.6508 - val_accuracy: 0.5670 - val_auc: 0.6537 - val_loss: 0.7106 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6191 - auc: 0.6663 - loss: 0.6490 - val_accuracy: 0.5900 - val_auc: 0.6534 - val_loss: 0.6948 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6209 - auc: 0.6686 - loss: 0.6480 - val_accuracy: 0.4407 - val_auc: 0.6548 - val_loss: 0.8284 - learning_rate: 1.0000e-03\n",
            "Epoch 8/50\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6223 - auc: 0.6708 - loss: 0.6469 - val_accuracy: 0.6364 - val_auc: 0.6542 - val_loss: 0.6664 - learning_rate: 1.0000e-03\n",
            "Epoch 9/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6223 - auc: 0.6707 - loss: 0.6464 - val_accuracy: 0.5338 - val_auc: 0.6528 - val_loss: 0.7465 - learning_rate: 1.0000e-03\n",
            "Epoch 10/50\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6237 - auc: 0.6729 - loss: 0.6453 - val_accuracy: 0.5445 - val_auc: 0.6516 - val_loss: 0.7566 - learning_rate: 1.0000e-03\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6257 - auc: 0.6740 - loss: 0.6447 - val_accuracy: 0.5195 - val_auc: 0.6493 - val_loss: 0.7671 - learning_rate: 1.0000e-03\n",
            "Epoch 12/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6276 - auc: 0.6770 - loss: 0.6428 - val_accuracy: 0.5720 - val_auc: 0.6483 - val_loss: 0.7185 - learning_rate: 5.0000e-04\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_CNN_adam_sigmoid\n",
            "  Epochs: 12/50\n",
            "  Val ROC-AUC: 0.6548\n",
            "  Val PR-AUC: 0.0308\n",
            "\n",
            "[84/144] SMOTEv2/CNN/adam/gelu\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_CNN_adam_gelu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 13s - 16ms/step - accuracy: 0.5468 - auc: 0.5676 - loss: 0.7105 - val_accuracy: 0.4788 - val_auc: 0.6460 - val_loss: 0.7392 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 4s - 6ms/step - accuracy: 0.6022 - auc: 0.6424 - loss: 0.6615 - val_accuracy: 0.4276 - val_auc: 0.6658 - val_loss: 0.7878 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6158 - auc: 0.6603 - loss: 0.6530 - val_accuracy: 0.4057 - val_auc: 0.6659 - val_loss: 0.8363 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 4s - 6ms/step - accuracy: 0.6209 - auc: 0.6675 - loss: 0.6489 - val_accuracy: 0.5364 - val_auc: 0.6672 - val_loss: 0.7462 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6254 - auc: 0.6744 - loss: 0.6451 - val_accuracy: 0.5091 - val_auc: 0.6633 - val_loss: 0.7673 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6273 - auc: 0.6772 - loss: 0.6434 - val_accuracy: 0.4592 - val_auc: 0.6631 - val_loss: 0.8122 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "782/782 - 4s - 6ms/step - accuracy: 0.6297 - auc: 0.6800 - loss: 0.6415 - val_accuracy: 0.4654 - val_auc: 0.6624 - val_loss: 0.7912 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6327 - auc: 0.6838 - loss: 0.6392 - val_accuracy: 0.4897 - val_auc: 0.6579 - val_loss: 0.7800 - learning_rate: 2.5000e-04\n",
            "Epoch 9/50\n",
            "782/782 - 4s - 6ms/step - accuracy: 0.6335 - auc: 0.6855 - loss: 0.6378 - val_accuracy: 0.5087 - val_auc: 0.6569 - val_loss: 0.7511 - learning_rate: 2.5000e-04\n",
            "Epoch 9: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_CNN_adam_gelu\n",
            "  Epochs: 9/50\n",
            "  Val ROC-AUC: 0.6672\n",
            "  Val PR-AUC: 0.0335\n",
            "\n",
            "[85/144] SMOTEv2/CNN/rmsprop/relu\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_CNN_rmsprop_relu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 11s - 15ms/step - accuracy: 0.5638 - auc: 0.5904 - loss: 0.7133 - val_accuracy: 0.4375 - val_auc: 0.6483 - val_loss: 0.7441 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6031 - auc: 0.6452 - loss: 0.6597 - val_accuracy: 0.5121 - val_auc: 0.6548 - val_loss: 0.7616 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6134 - auc: 0.6588 - loss: 0.6532 - val_accuracy: 0.3971 - val_auc: 0.6579 - val_loss: 0.8020 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6176 - auc: 0.6656 - loss: 0.6497 - val_accuracy: 0.4809 - val_auc: 0.6396 - val_loss: 0.7725 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.6253 - auc: 0.6746 - loss: 0.6445 - val_accuracy: 0.4738 - val_auc: 0.6519 - val_loss: 0.7816 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6261 - auc: 0.6769 - loss: 0.6428 - val_accuracy: 0.4963 - val_auc: 0.6474 - val_loss: 0.7504 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "782/782 - 4s - 6ms/step - accuracy: 0.6298 - auc: 0.6800 - loss: 0.6412 - val_accuracy: 0.4583 - val_auc: 0.6547 - val_loss: 0.7965 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6316 - auc: 0.6836 - loss: 0.6387 - val_accuracy: 0.5059 - val_auc: 0.6526 - val_loss: 0.7583 - learning_rate: 2.5000e-04\n",
            "Epoch 8: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_CNN_rmsprop_relu\n",
            "  Epochs: 8/50\n",
            "  Val ROC-AUC: 0.6580\n",
            "  Val PR-AUC: 0.0333\n",
            "\n",
            "[86/144] SMOTEv2/CNN/rmsprop/tanh\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_CNN_rmsprop_tanh\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 11s - 15ms/step - accuracy: 0.5707 - auc: 0.5975 - loss: 0.6863 - val_accuracy: 0.5231 - val_auc: 0.6485 - val_loss: 0.6976 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6003 - auc: 0.6404 - loss: 0.6624 - val_accuracy: 0.5006 - val_auc: 0.6535 - val_loss: 0.7308 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6102 - auc: 0.6532 - loss: 0.6563 - val_accuracy: 0.4039 - val_auc: 0.6496 - val_loss: 0.8211 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6153 - auc: 0.6613 - loss: 0.6522 - val_accuracy: 0.4561 - val_auc: 0.6436 - val_loss: 0.7688 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6235 - auc: 0.6712 - loss: 0.6469 - val_accuracy: 0.4954 - val_auc: 0.6458 - val_loss: 0.7795 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6247 - auc: 0.6736 - loss: 0.6454 - val_accuracy: 0.5190 - val_auc: 0.6452 - val_loss: 0.7541 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6276 - auc: 0.6756 - loss: 0.6443 - val_accuracy: 0.5606 - val_auc: 0.6485 - val_loss: 0.7281 - learning_rate: 5.0000e-04\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_CNN_rmsprop_tanh\n",
            "  Epochs: 7/50\n",
            "  Val ROC-AUC: 0.6536\n",
            "  Val PR-AUC: 0.0310\n",
            "\n",
            "[87/144] SMOTEv2/CNN/rmsprop/sigmoid\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_CNN_rmsprop_sigmoid\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 11s - 14ms/step - accuracy: 0.5465 - auc: 0.5675 - loss: 0.6865 - val_accuracy: 0.3691 - val_auc: 0.6474 - val_loss: 0.7589 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.5943 - auc: 0.6310 - loss: 0.6662 - val_accuracy: 0.3583 - val_auc: 0.6494 - val_loss: 0.8137 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.5995 - auc: 0.6399 - loss: 0.6621 - val_accuracy: 0.4229 - val_auc: 0.6515 - val_loss: 0.7978 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6036 - auc: 0.6461 - loss: 0.6592 - val_accuracy: 0.3492 - val_auc: 0.6516 - val_loss: 0.8698 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6070 - auc: 0.6516 - loss: 0.6564 - val_accuracy: 0.4741 - val_auc: 0.6526 - val_loss: 0.8009 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6089 - auc: 0.6538 - loss: 0.6554 - val_accuracy: 0.5058 - val_auc: 0.6540 - val_loss: 0.7678 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "782/782 - 4s - 6ms/step - accuracy: 0.6103 - auc: 0.6561 - loss: 0.6545 - val_accuracy: 0.5186 - val_auc: 0.6551 - val_loss: 0.7618 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6115 - auc: 0.6581 - loss: 0.6533 - val_accuracy: 0.5509 - val_auc: 0.6545 - val_loss: 0.7311 - learning_rate: 2.5000e-04\n",
            "Epoch 9/50\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6121 - auc: 0.6591 - loss: 0.6528 - val_accuracy: 0.4365 - val_auc: 0.6543 - val_loss: 0.8381 - learning_rate: 2.5000e-04\n",
            "Epoch 10/50\n",
            "782/782 - 7s - 9ms/step - accuracy: 0.6139 - auc: 0.6602 - loss: 0.6523 - val_accuracy: 0.4295 - val_auc: 0.6539 - val_loss: 0.8531 - learning_rate: 2.5000e-04\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6147 - auc: 0.6614 - loss: 0.6518 - val_accuracy: 0.5220 - val_auc: 0.6538 - val_loss: 0.7555 - learning_rate: 2.5000e-04\n",
            "Epoch 12/50\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6149 - auc: 0.6620 - loss: 0.6514 - val_accuracy: 0.5100 - val_auc: 0.6544 - val_loss: 0.7658 - learning_rate: 1.2500e-04\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_CNN_rmsprop_sigmoid\n",
            "  Epochs: 12/50\n",
            "  Val ROC-AUC: 0.6550\n",
            "  Val PR-AUC: 0.0325\n",
            "\n",
            "[88/144] SMOTEv2/CNN/rmsprop/gelu\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_CNN_rmsprop_gelu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 12s - 16ms/step - accuracy: 0.5638 - auc: 0.5890 - loss: 0.7208 - val_accuracy: 0.7592 - val_auc: 0.6602 - val_loss: 0.6407 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6013 - auc: 0.6421 - loss: 0.6608 - val_accuracy: 0.5166 - val_auc: 0.6630 - val_loss: 0.7406 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 4s - 6ms/step - accuracy: 0.6124 - auc: 0.6583 - loss: 0.6535 - val_accuracy: 0.4539 - val_auc: 0.6649 - val_loss: 0.7826 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6189 - auc: 0.6671 - loss: 0.6491 - val_accuracy: 0.3499 - val_auc: 0.6628 - val_loss: 0.8402 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6257 - auc: 0.6751 - loss: 0.6444 - val_accuracy: 0.4530 - val_auc: 0.6603 - val_loss: 0.7870 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6270 - auc: 0.6784 - loss: 0.6423 - val_accuracy: 0.3935 - val_auc: 0.6624 - val_loss: 0.8181 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6293 - auc: 0.6802 - loss: 0.6414 - val_accuracy: 0.4339 - val_auc: 0.6657 - val_loss: 0.7793 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6321 - auc: 0.6841 - loss: 0.6388 - val_accuracy: 0.4430 - val_auc: 0.6580 - val_loss: 0.7784 - learning_rate: 2.5000e-04\n",
            "Epoch 9/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6329 - auc: 0.6853 - loss: 0.6380 - val_accuracy: 0.3766 - val_auc: 0.6616 - val_loss: 0.8654 - learning_rate: 2.5000e-04\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "782/782 - 4s - 6ms/step - accuracy: 0.6332 - auc: 0.6862 - loss: 0.6374 - val_accuracy: 0.3796 - val_auc: 0.6631 - val_loss: 0.8536 - learning_rate: 2.5000e-04\n",
            "Epoch 11/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6346 - auc: 0.6878 - loss: 0.6363 - val_accuracy: 0.4116 - val_auc: 0.6606 - val_loss: 0.8111 - learning_rate: 1.2500e-04\n",
            "Epoch 12/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6356 - auc: 0.6888 - loss: 0.6356 - val_accuracy: 0.4133 - val_auc: 0.6600 - val_loss: 0.8146 - learning_rate: 1.2500e-04\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_CNN_rmsprop_gelu\n",
            "  Epochs: 12/50\n",
            "  Val ROC-AUC: 0.6657\n",
            "  Val PR-AUC: 0.0347\n",
            "\n",
            "[89/144] SMOTEv2/Transformer/adam/relu\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_Transformer_adam_relu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 20s - 25ms/step - accuracy: 0.5816 - auc: 0.6179 - loss: 0.6702 - val_accuracy: 0.6672 - val_auc: 0.6263 - val_loss: 0.6575 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6052 - auc: 0.6473 - loss: 0.6583 - val_accuracy: 0.6474 - val_auc: 0.6264 - val_loss: 0.6836 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6114 - auc: 0.6556 - loss: 0.6540 - val_accuracy: 0.5765 - val_auc: 0.6272 - val_loss: 0.7515 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6165 - auc: 0.6627 - loss: 0.6508 - val_accuracy: 0.6368 - val_auc: 0.6294 - val_loss: 0.6816 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6228 - auc: 0.6713 - loss: 0.6461 - val_accuracy: 0.6307 - val_auc: 0.6314 - val_loss: 0.6893 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6257 - auc: 0.6757 - loss: 0.6435 - val_accuracy: 0.6307 - val_auc: 0.6279 - val_loss: 0.7156 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6277 - auc: 0.6785 - loss: 0.6419 - val_accuracy: 0.6461 - val_auc: 0.6281 - val_loss: 0.6862 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6297 - auc: 0.6817 - loss: 0.6396 - val_accuracy: 0.6595 - val_auc: 0.6264 - val_loss: 0.6765 - learning_rate: 2.5000e-04\n",
            "Epoch 9/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6309 - auc: 0.6833 - loss: 0.6387 - val_accuracy: 0.6429 - val_auc: 0.6241 - val_loss: 0.7059 - learning_rate: 2.5000e-04\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6310 - auc: 0.6838 - loss: 0.6384 - val_accuracy: 0.6552 - val_auc: 0.6258 - val_loss: 0.6782 - learning_rate: 2.5000e-04\n",
            "Epoch 10: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_Transformer_adam_relu\n",
            "  Epochs: 10/50\n",
            "  Val ROC-AUC: 0.6314\n",
            "  Val PR-AUC: 0.0271\n",
            "\n",
            "[90/144] SMOTEv2/Transformer/adam/tanh\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_Transformer_adam_tanh\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 18s - 23ms/step - accuracy: 0.5774 - auc: 0.6128 - loss: 0.6730 - val_accuracy: 0.6155 - val_auc: 0.6186 - val_loss: 0.7155 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.5995 - auc: 0.6409 - loss: 0.6613 - val_accuracy: 0.5752 - val_auc: 0.6144 - val_loss: 0.7946 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6032 - auc: 0.6455 - loss: 0.6592 - val_accuracy: 0.5620 - val_auc: 0.6184 - val_loss: 0.7886 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6045 - auc: 0.6477 - loss: 0.6581 - val_accuracy: 0.6645 - val_auc: 0.6160 - val_loss: 0.6824 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6064 - auc: 0.6490 - loss: 0.6576 - val_accuracy: 0.6972 - val_auc: 0.6134 - val_loss: 0.6379 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "782/782 - 9s - 12ms/step - accuracy: 0.6073 - auc: 0.6515 - loss: 0.6564 - val_accuracy: 0.7206 - val_auc: 0.6064 - val_loss: 0.6128 - learning_rate: 1.0000e-03\n",
            "Epoch 6: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_Transformer_adam_tanh\n",
            "  Epochs: 6/50\n",
            "  Val ROC-AUC: 0.6186\n",
            "  Val PR-AUC: 0.0237\n",
            "\n",
            "[91/144] SMOTEv2/Transformer/adam/sigmoid\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_Transformer_adam_sigmoid\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 18s - 23ms/step - accuracy: 0.5687 - auc: 0.5989 - loss: 0.6790 - val_accuracy: 0.6665 - val_auc: 0.6201 - val_loss: 0.6404 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.5995 - auc: 0.6401 - loss: 0.6619 - val_accuracy: 0.6651 - val_auc: 0.6155 - val_loss: 0.6834 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6031 - auc: 0.6451 - loss: 0.6593 - val_accuracy: 0.6001 - val_auc: 0.6114 - val_loss: 0.7730 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6044 - auc: 0.6473 - loss: 0.6581 - val_accuracy: 0.6637 - val_auc: 0.6165 - val_loss: 0.6841 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6052 - auc: 0.6493 - loss: 0.6568 - val_accuracy: 0.6533 - val_auc: 0.6183 - val_loss: 0.7100 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6056 - auc: 0.6502 - loss: 0.6563 - val_accuracy: 0.6172 - val_auc: 0.6189 - val_loss: 0.7474 - learning_rate: 5.0000e-04\n",
            "Epoch 6: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_Transformer_adam_sigmoid\n",
            "  Epochs: 6/50\n",
            "  Val ROC-AUC: 0.6201\n",
            "  Val PR-AUC: 0.0249\n",
            "\n",
            "[92/144] SMOTEv2/Transformer/adam/gelu\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_Transformer_adam_gelu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 18s - 24ms/step - accuracy: 0.5833 - auc: 0.6205 - loss: 0.6694 - val_accuracy: 0.6060 - val_auc: 0.6195 - val_loss: 0.7078 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6023 - auc: 0.6450 - loss: 0.6594 - val_accuracy: 0.5842 - val_auc: 0.6240 - val_loss: 0.7488 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6132 - auc: 0.6581 - loss: 0.6535 - val_accuracy: 0.5821 - val_auc: 0.6338 - val_loss: 0.7050 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6181 - auc: 0.6648 - loss: 0.6499 - val_accuracy: 0.7013 - val_auc: 0.6360 - val_loss: 0.6044 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6209 - auc: 0.6681 - loss: 0.6482 - val_accuracy: 0.7004 - val_auc: 0.6371 - val_loss: 0.5995 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6222 - auc: 0.6710 - loss: 0.6463 - val_accuracy: 0.7257 - val_auc: 0.6407 - val_loss: 0.5646 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6240 - auc: 0.6738 - loss: 0.6447 - val_accuracy: 0.6497 - val_auc: 0.6408 - val_loss: 0.6637 - learning_rate: 1.0000e-03\n",
            "Epoch 8/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6265 - auc: 0.6769 - loss: 0.6428 - val_accuracy: 0.7219 - val_auc: 0.6441 - val_loss: 0.5868 - learning_rate: 1.0000e-03\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6280 - auc: 0.6788 - loss: 0.6416 - val_accuracy: 0.6551 - val_auc: 0.6438 - val_loss: 0.6823 - learning_rate: 1.0000e-03\n",
            "Epoch 10/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6318 - auc: 0.6837 - loss: 0.6389 - val_accuracy: 0.6669 - val_auc: 0.6489 - val_loss: 0.6554 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6313 - auc: 0.6848 - loss: 0.6379 - val_accuracy: 0.6720 - val_auc: 0.6448 - val_loss: 0.6552 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6329 - auc: 0.6862 - loss: 0.6370 - val_accuracy: 0.6460 - val_auc: 0.6486 - val_loss: 0.6888 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6346 - auc: 0.6886 - loss: 0.6357 - val_accuracy: 0.6410 - val_auc: 0.6468 - val_loss: 0.6966 - learning_rate: 2.5000e-04\n",
            "Epoch 14/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6357 - auc: 0.6889 - loss: 0.6355 - val_accuracy: 0.6321 - val_auc: 0.6457 - val_loss: 0.7161 - learning_rate: 2.5000e-04\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6370 - auc: 0.6904 - loss: 0.6346 - val_accuracy: 0.5964 - val_auc: 0.6451 - val_loss: 0.7583 - learning_rate: 2.5000e-04\n",
            "Epoch 15: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_Transformer_adam_gelu\n",
            "  Epochs: 15/50\n",
            "  Val ROC-AUC: 0.6490\n",
            "  Val PR-AUC: 0.0285\n",
            "\n",
            "[93/144] SMOTEv2/Transformer/rmsprop/relu\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_Transformer_rmsprop_relu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 16s - 21ms/step - accuracy: 0.5745 - auc: 0.6100 - loss: 0.6730 - val_accuracy: 0.6692 - val_auc: 0.6276 - val_loss: 0.6362 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6049 - auc: 0.6467 - loss: 0.6584 - val_accuracy: 0.6904 - val_auc: 0.6450 - val_loss: 0.6119 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6144 - auc: 0.6598 - loss: 0.6522 - val_accuracy: 0.6970 - val_auc: 0.6418 - val_loss: 0.5965 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6187 - auc: 0.6664 - loss: 0.6487 - val_accuracy: 0.7043 - val_auc: 0.6372 - val_loss: 0.6358 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6214 - auc: 0.6701 - loss: 0.6467 - val_accuracy: 0.7523 - val_auc: 0.6231 - val_loss: 0.5507 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6247 - auc: 0.6742 - loss: 0.6444 - val_accuracy: 0.7058 - val_auc: 0.6268 - val_loss: 0.5884 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6263 - auc: 0.6764 - loss: 0.6431 - val_accuracy: 0.6893 - val_auc: 0.6268 - val_loss: 0.5804 - learning_rate: 1.0000e-03\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_Transformer_rmsprop_relu\n",
            "  Epochs: 7/50\n",
            "  Val ROC-AUC: 0.6450\n",
            "  Val PR-AUC: 0.0291\n",
            "\n",
            "[94/144] SMOTEv2/Transformer/rmsprop/tanh\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_Transformer_rmsprop_tanh\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 16s - 21ms/step - accuracy: 0.5642 - auc: 0.5940 - loss: 0.6794 - val_accuracy: 0.7271 - val_auc: 0.6284 - val_loss: 0.5904 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.5948 - auc: 0.6346 - loss: 0.6644 - val_accuracy: 0.7600 - val_auc: 0.6261 - val_loss: 0.5725 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6004 - auc: 0.6404 - loss: 0.6618 - val_accuracy: 0.6694 - val_auc: 0.6173 - val_loss: 0.6568 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6021 - auc: 0.6439 - loss: 0.6602 - val_accuracy: 0.6851 - val_auc: 0.6182 - val_loss: 0.6473 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "782/782 - 9s - 12ms/step - accuracy: 0.6034 - auc: 0.6456 - loss: 0.6594 - val_accuracy: 0.6915 - val_auc: 0.6172 - val_loss: 0.6512 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6064 - auc: 0.6501 - loss: 0.6573 - val_accuracy: 0.7203 - val_auc: 0.6182 - val_loss: 0.6251 - learning_rate: 5.0000e-04\n",
            "Epoch 6: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_Transformer_rmsprop_tanh\n",
            "  Epochs: 6/50\n",
            "  Val ROC-AUC: 0.6284\n",
            "  Val PR-AUC: 0.0262\n",
            "\n",
            "[95/144] SMOTEv2/Transformer/rmsprop/sigmoid\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_Transformer_rmsprop_sigmoid\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 18s - 23ms/step - accuracy: 0.5568 - auc: 0.5839 - loss: 0.6839 - val_accuracy: 0.6354 - val_auc: 0.6289 - val_loss: 0.6686 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.5930 - auc: 0.6321 - loss: 0.6653 - val_accuracy: 0.6815 - val_auc: 0.6345 - val_loss: 0.6321 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.5978 - auc: 0.6391 - loss: 0.6621 - val_accuracy: 0.6611 - val_auc: 0.6290 - val_loss: 0.6704 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6003 - auc: 0.6423 - loss: 0.6604 - val_accuracy: 0.6828 - val_auc: 0.6267 - val_loss: 0.6585 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 10s - 12ms/step - accuracy: 0.6013 - auc: 0.6440 - loss: 0.6595 - val_accuracy: 0.7319 - val_auc: 0.6267 - val_loss: 0.6036 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6029 - auc: 0.6461 - loss: 0.6583 - val_accuracy: 0.7832 - val_auc: 0.6250 - val_loss: 0.5497 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6035 - auc: 0.6467 - loss: 0.6581 - val_accuracy: 0.7622 - val_auc: 0.6238 - val_loss: 0.5637 - learning_rate: 1.0000e-03\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_Transformer_rmsprop_sigmoid\n",
            "  Epochs: 7/50\n",
            "  Val ROC-AUC: 0.6346\n",
            "  Val PR-AUC: 0.0265\n",
            "\n",
            "[96/144] SMOTEv2/Transformer/rmsprop/gelu\n",
            "\n",
            "============================================================\n",
            "Training: SMOTEv2_Transformer_rmsprop_gelu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "782/782 - 17s - 22ms/step - accuracy: 0.5762 - auc: 0.6120 - loss: 0.6726 - val_accuracy: 0.6927 - val_auc: 0.6211 - val_loss: 0.6241 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.5990 - auc: 0.6401 - loss: 0.6617 - val_accuracy: 0.6284 - val_auc: 0.6170 - val_loss: 0.6800 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6098 - auc: 0.6534 - loss: 0.6556 - val_accuracy: 0.6730 - val_auc: 0.6408 - val_loss: 0.6242 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6166 - auc: 0.6626 - loss: 0.6514 - val_accuracy: 0.7062 - val_auc: 0.6233 - val_loss: 0.6167 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "782/782 - 6s - 8ms/step - accuracy: 0.6203 - auc: 0.6669 - loss: 0.6490 - val_accuracy: 0.7293 - val_auc: 0.6313 - val_loss: 0.5831 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "782/782 - 9s - 12ms/step - accuracy: 0.6223 - auc: 0.6706 - loss: 0.6467 - val_accuracy: 0.7295 - val_auc: 0.6257 - val_loss: 0.5901 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "782/782 - 6s - 7ms/step - accuracy: 0.6251 - auc: 0.6728 - loss: 0.6456 - val_accuracy: 0.7214 - val_auc: 0.6245 - val_loss: 0.6029 - learning_rate: 1.0000e-03\n",
            "Epoch 8/50\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6259 - auc: 0.6748 - loss: 0.6441 - val_accuracy: 0.7673 - val_auc: 0.6225 - val_loss: 0.5645 - learning_rate: 1.0000e-03\n",
            "Epoch 8: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: SMOTEv2_Transformer_rmsprop_gelu\n",
            "  Epochs: 8/50\n",
            "  Val ROC-AUC: 0.6409\n",
            "  Val PR-AUC: 0.0301\n",
            "\n",
            "============================================================\n",
            "LOADING DATASET: Undersampled\n",
            "============================================================\n",
            "✓ Using full dataset: 31,234\n",
            "  Class 0: 15,617, Class 1: 15,617\n",
            "\n",
            "[97/144] SKIPPING: Undersampled/LSTM/adam/relu\n",
            "\n",
            "[98/144] SKIPPING: Undersampled/LSTM/adam/tanh\n",
            "\n",
            "[99/144] SKIPPING: Undersampled/LSTM/adam/sigmoid\n",
            "\n",
            "[100/144] SKIPPING: Undersampled/LSTM/adam/gelu\n",
            "\n",
            "[101/144] SKIPPING: Undersampled/LSTM/rmsprop/relu\n",
            "\n",
            "[102/144] SKIPPING: Undersampled/LSTM/rmsprop/tanh\n",
            "\n",
            "[103/144] SKIPPING: Undersampled/LSTM/rmsprop/sigmoid\n",
            "\n",
            "[104/144] SKIPPING: Undersampled/LSTM/rmsprop/gelu\n",
            "\n",
            "[105/144] SKIPPING: Undersampled/RNN/adam/relu\n",
            "\n",
            "[106/144] SKIPPING: Undersampled/RNN/adam/tanh\n",
            "\n",
            "[107/144] SKIPPING: Undersampled/RNN/adam/sigmoid\n",
            "\n",
            "[108/144] SKIPPING: Undersampled/RNN/adam/gelu\n",
            "\n",
            "[109/144] SKIPPING: Undersampled/RNN/rmsprop/relu\n",
            "\n",
            "[110/144] SKIPPING: Undersampled/RNN/rmsprop/tanh\n",
            "\n",
            "[111/144] SKIPPING: Undersampled/RNN/rmsprop/sigmoid\n",
            "\n",
            "[112/144] SKIPPING: Undersampled/RNN/rmsprop/gelu\n",
            "\n",
            "[113/144] SKIPPING: Undersampled/GRU/adam/relu\n",
            "\n",
            "[114/144] SKIPPING: Undersampled/GRU/adam/tanh\n",
            "\n",
            "[115/144] SKIPPING: Undersampled/GRU/adam/sigmoid\n",
            "\n",
            "[116/144] SKIPPING: Undersampled/GRU/adam/gelu\n",
            "\n",
            "[117/144] SKIPPING: Undersampled/GRU/rmsprop/relu\n",
            "\n",
            "[118/144] SKIPPING: Undersampled/GRU/rmsprop/tanh\n",
            "\n",
            "[119/144] SKIPPING: Undersampled/GRU/rmsprop/sigmoid\n",
            "\n",
            "[120/144] SKIPPING: Undersampled/GRU/rmsprop/gelu\n",
            "\n",
            "[121/144] SKIPPING: Undersampled/LSTM_Attention/adam/relu\n",
            "\n",
            "[122/144] SKIPPING: Undersampled/LSTM_Attention/adam/tanh\n",
            "\n",
            "[123/144] SKIPPING: Undersampled/LSTM_Attention/adam/sigmoid\n",
            "\n",
            "[124/144] SKIPPING: Undersampled/LSTM_Attention/adam/gelu\n",
            "\n",
            "[125/144] SKIPPING: Undersampled/LSTM_Attention/rmsprop/relu\n",
            "\n",
            "[126/144] SKIPPING: Undersampled/LSTM_Attention/rmsprop/tanh\n",
            "\n",
            "[127/144] SKIPPING: Undersampled/LSTM_Attention/rmsprop/sigmoid\n",
            "\n",
            "[128/144] SKIPPING: Undersampled/LSTM_Attention/rmsprop/gelu\n",
            "\n",
            "[129/144] SKIPPING: Undersampled/CNN/adam/relu\n",
            "\n",
            "[130/144] SKIPPING: Undersampled/CNN/adam/tanh\n",
            "\n",
            "[131/144] SKIPPING: Undersampled/CNN/adam/sigmoid\n",
            "\n",
            "[132/144] SKIPPING: Undersampled/CNN/adam/gelu\n",
            "\n",
            "[133/144] SKIPPING: Undersampled/CNN/rmsprop/relu\n",
            "\n",
            "[134/144] SKIPPING: Undersampled/CNN/rmsprop/tanh\n",
            "\n",
            "[135/144] SKIPPING: Undersampled/CNN/rmsprop/sigmoid\n",
            "\n",
            "[136/144] SKIPPING: Undersampled/CNN/rmsprop/gelu\n",
            "\n",
            "[137/144] SKIPPING: Undersampled/Transformer/adam/relu\n",
            "\n",
            "[138/144] SKIPPING: Undersampled/Transformer/adam/tanh\n",
            "\n",
            "[139/144] SKIPPING: Undersampled/Transformer/adam/sigmoid\n",
            "\n",
            "[140/144] SKIPPING: Undersampled/Transformer/adam/gelu\n",
            "\n",
            "[141/144] SKIPPING: Undersampled/Transformer/rmsprop/relu\n",
            "\n",
            "[142/144] SKIPPING: Undersampled/Transformer/rmsprop/tanh\n",
            "\n",
            "[143/144] SKIPPING: Undersampled/Transformer/rmsprop/sigmoid\n",
            "\n",
            "[144/144] SKIPPING: Undersampled/Transformer/rmsprop/gelu\n",
            "\n",
            "============================================================\n",
            "SAVING SUMMARY\n",
            "============================================================\n",
            "\n",
            "✓ Complete! Results: /content/drive/MyDrive/AI_Fin/Comprehensive_prototyping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regeerate the summary"
      ],
      "metadata": {
        "id": "sbdeWXlaGsAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Regenerate comprehensive_summary_complete.csv from all metrics JSON files\n",
        "Automatically detects all dataset directories\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "\n",
        "BASE_DIR = '/content/drive/MyDrive/AI_Course_Project/Dataset'\n",
        "\n",
        "# ============================================================\n",
        "# AUTO-DETECT ALL DATASET DIRECTORIES\n",
        "# ============================================================\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"REGENERATING COMPREHENSIVE SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Find all subdirectories that contain metrics files\n",
        "all_subdirs = [d for d in os.listdir(BASE_DIR)\n",
        "               if os.path.isdir(os.path.join(BASE_DIR, d))]\n",
        "\n",
        "# Filter to only dataset directories (those with _metrics.json files)\n",
        "datasets = []\n",
        "for subdir in all_subdirs:\n",
        "    dataset_dir = os.path.join(BASE_DIR, subdir)\n",
        "    json_files = glob.glob(os.path.join(dataset_dir, '*_metrics.json'))\n",
        "    if len(json_files) > 0:\n",
        "        datasets.append(subdir)\n",
        "\n",
        "datasets = sorted(datasets)  # Sort alphabetically for consistent ordering\n",
        "\n",
        "print(f\"\\n[OK] Detected {len(datasets)} dataset(s): {datasets}\")\n",
        "\n",
        "# ============================================================\n",
        "# COLLECT ALL METRICS FROM JSON FILES\n",
        "# ============================================================\n",
        "\n",
        "all_results = []\n",
        "\n",
        "for dataset in datasets:\n",
        "    dataset_dir = os.path.join(BASE_DIR, dataset)\n",
        "    json_files = glob.glob(os.path.join(dataset_dir, '*_metrics.json'))\n",
        "\n",
        "    print(f\"\\nProcessing {dataset}: {len(json_files)} files\")\n",
        "\n",
        "    for json_file in json_files:\n",
        "        try:\n",
        "            with open(json_file, 'r') as f:\n",
        "                metrics = json.load(f)\n",
        "                all_results.append(metrics)\n",
        "        except Exception as e:\n",
        "            print(f\"  [ERROR] Failed to read {os.path.basename(json_file)}: {e}\")\n",
        "\n",
        "# ============================================================\n",
        "# CREATE DATAFRAME AND SAVE\n",
        "# ============================================================\n",
        "\n",
        "if len(all_results) == 0:\n",
        "    print(\"\\n[ERROR] No metrics found! Check that experiments have completed.\")\n",
        "    exit(1)\n",
        "\n",
        "summary_df = pd.DataFrame(all_results)\n",
        "\n",
        "# Sort by dataset and ROC-AUC for better readability\n",
        "summary_df = summary_df.sort_values(['dataset', 'roc_auc'], ascending=[True, False])\n",
        "\n",
        "summary_df.to_csv(os.path.join(BASE_DIR, 'comprehensive_summary_complete.csv'), index=False)\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"[OK] Regenerated comprehensive summary with {len(summary_df)} records\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "print(f\"\\nBreakdown by dataset:\")\n",
        "dataset_counts = summary_df['dataset'].value_counts()\n",
        "for dataset in sorted(dataset_counts.index):\n",
        "    count = dataset_counts[dataset]\n",
        "    print(f\"  {dataset:15s}: {count:3d} experiments\")\n",
        "\n",
        "print(f\"\\n[OK] Saved to: {BASE_DIR}/comprehensive_summary_complete.csv\")\n",
        "\n",
        "# ============================================================\n",
        "# GENERATE TOP 5 PER DATASET\n",
        "# ============================================================\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"GENERATING TOP 5 BY ROC-AUC PER DATASET\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "for dataset_name in datasets:\n",
        "    dataset_results = summary_df[summary_df['dataset'] == dataset_name]\n",
        "\n",
        "    if len(dataset_results) > 0:\n",
        "        best_by_roc = dataset_results.nlargest(5, 'roc_auc')\n",
        "        output_path = os.path.join(BASE_DIR, dataset_name, f'{dataset_name}_top5_by_roc_auc.csv')\n",
        "        best_by_roc.to_csv(output_path, index=False)\n",
        "\n",
        "        print(f\"\\n{dataset_name}:\")\n",
        "        for idx, row in enumerate(best_by_roc.iterrows(), 1):\n",
        "            _, r = row\n",
        "            print(f\"  {idx}. {r['model']:15s} {r['optimizer']:8s}-{r['activation']:8s} | ROC: {r['roc_auc']:.4f}\")\n",
        "\n",
        "        print(f\"  [OK] Saved to: {dataset_name}_top5_by_roc_auc.csv\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"[OK] ALL DONE!\")\n",
        "print(f\"{'='*80}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmQUYyZzGuqh",
        "outputId": "a39b5892-fe4a-4bd2-c199-6ec80bcf5899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "REGENERATING COMPREHENSIVE SUMMARY\n",
            "================================================================================\n",
            "\n",
            "[OK] Detected 4 dataset(s): ['Original', 'SMOTE', 'SMOTEv2', 'Undersampled']\n",
            "\n",
            "Processing Original: 48 files\n",
            "\n",
            "Processing SMOTE: 48 files\n",
            "\n",
            "Processing SMOTEv2: 48 files\n",
            "\n",
            "Processing Undersampled: 48 files\n",
            "\n",
            "================================================================================\n",
            "[OK] Regenerated comprehensive summary with 192 records\n",
            "================================================================================\n",
            "\n",
            "Breakdown by dataset:\n",
            "  Original       :  48 experiments\n",
            "  SMOTE          :  48 experiments\n",
            "  SMOTEv2        :  48 experiments\n",
            "  Undersampled   :  48 experiments\n",
            "\n",
            "[OK] Saved to: /content/drive/MyDrive/AI_Fin/Comprehensive_prototyping/comprehensive_summary_complete.csv\n",
            "\n",
            "================================================================================\n",
            "GENERATING TOP 5 BY ROC-AUC PER DATASET\n",
            "================================================================================\n",
            "\n",
            "Original:\n",
            "  1. GRU             adam    -gelu     | ROC: 0.7270\n",
            "  2. LSTM_Attention  adam    -tanh     | ROC: 0.7259\n",
            "  3. LSTM_Attention  adam    -gelu     | ROC: 0.7246\n",
            "  4. LSTM            adam    -gelu     | ROC: 0.7242\n",
            "  5. LSTM_Attention  rmsprop -tanh     | ROC: 0.7224\n",
            "  [OK] Saved to: Original_top5_by_roc_auc.csv\n",
            "\n",
            "SMOTE:\n",
            "  1. LSTM            adam    -tanh     | ROC: 0.7039\n",
            "  2. RNN             rmsprop -sigmoid  | ROC: 0.6991\n",
            "  3. RNN             adam    -sigmoid  | ROC: 0.6990\n",
            "  4. LSTM            adam    -sigmoid  | ROC: 0.6988\n",
            "  5. Transformer     adam    -relu     | ROC: 0.6985\n",
            "  [OK] Saved to: SMOTE_top5_by_roc_auc.csv\n",
            "\n",
            "SMOTEv2:\n",
            "  1. GRU             adam    -sigmoid  | ROC: 0.6853\n",
            "  2. GRU             adam    -relu     | ROC: 0.6836\n",
            "  3. RNN             adam    -sigmoid  | ROC: 0.6821\n",
            "  4. LSTM            adam    -gelu     | ROC: 0.6809\n",
            "  5. GRU             rmsprop -sigmoid  | ROC: 0.6806\n",
            "  [OK] Saved to: SMOTEv2_top5_by_roc_auc.csv\n",
            "\n",
            "Undersampled:\n",
            "  1. LSTM            rmsprop -gelu     | ROC: 0.7425\n",
            "  2. GRU             rmsprop -gelu     | ROC: 0.7392\n",
            "  3. LSTM_Attention  rmsprop -tanh     | ROC: 0.7383\n",
            "  4. LSTM_Attention  rmsprop -gelu     | ROC: 0.7377\n",
            "  5. LSTM            adam    -gelu     | ROC: 0.7376\n",
            "  [OK] Saved to: Undersampled_top5_by_roc_auc.csv\n",
            "\n",
            "================================================================================\n",
            "[OK] ALL DONE!\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Combination for each model"
      ],
      "metadata": {
        "id": "LM0bjhtmLbRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Extract Best Combinations for Each Model Across All Datasets\n",
        "Saves results to best_combinations.csv and detailed markdown report\n",
        "Supports: Original, SMOTE, SMOTEv2, Undersampled\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# ============================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================\n",
        "\n",
        "BASE_DIR = '/content/drive/MyDrive/AI_Course_Project/Dataset/Comprehensive_prototyping'\n",
        "INPUT_FILE = os.path.join(BASE_DIR, 'comprehensive_summary_complete.csv')\n",
        "OUTPUT_CSV = os.path.join(BASE_DIR, 'best_combinations.csv')\n",
        "OUTPUT_MARKDOWN = os.path.join(BASE_DIR, 'best_combinations_report.md')\n",
        "\n",
        "# ============================================================\n",
        "# LOAD DATA\n",
        "# ============================================================\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"EXTRACTING BEST COMBINATIONS PER MODEL PER DATASET\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "df = pd.read_csv(INPUT_FILE)\n",
        "\n",
        "print(f\"\\n[OK] Loaded {len(df)} experiments from comprehensive summary\")\n",
        "print(f\"  Datasets: {df['dataset'].unique().tolist()}\")\n",
        "print(f\"  Models: {df['model'].unique().tolist()}\")\n",
        "\n",
        "# ============================================================\n",
        "# EXTRACT BEST COMBINATIONS\n",
        "# ============================================================\n",
        "\n",
        "best_combinations = []\n",
        "\n",
        "# CHANGED: Automatically detect all unique datasets instead of hardcoding\n",
        "datasets = sorted(df['dataset'].unique())\n",
        "\n",
        "for dataset in datasets:\n",
        "    dataset_df = df[df['dataset'] == dataset].copy()\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Processing: {dataset} Dataset\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    for model in df['model'].unique():\n",
        "        model_df = dataset_df[dataset_df['model'] == model].copy()\n",
        "\n",
        "        if len(model_df) > 0:\n",
        "            # Get best by ROC-AUC\n",
        "            best_idx = model_df['roc_auc'].idxmax()\n",
        "            best = model_df.loc[best_idx]\n",
        "\n",
        "            best_combinations.append({\n",
        "                'dataset': dataset,\n",
        "                'model': model,\n",
        "                'optimizer': best['optimizer'],\n",
        "                'activation': best['activation'],\n",
        "                'combination': f\"{best['optimizer']}-{best['activation']}\",\n",
        "                'roc_auc': best['roc_auc'],\n",
        "                'pr_auc': best['pr_auc'],\n",
        "                'sensitivity': best['sensitivity'],\n",
        "                'specificity': best['specificity'],\n",
        "                'precision': best['precision'],\n",
        "                'f1_score': best['f1_score'],\n",
        "                'epochs_trained': best['epochs_trained'],\n",
        "                'train_samples': best['train_samples'],\n",
        "                'val_samples': best['val_samples']\n",
        "            })\n",
        "\n",
        "            print(f\"  {model:20s} | {best['optimizer']:8s}-{best['activation']:8s} | ROC: {best['roc_auc']:.4f}\")\n",
        "\n",
        "# ============================================================\n",
        "# CREATE DATAFRAME AND SAVE CSV\n",
        "# ============================================================\n",
        "\n",
        "best_df = pd.DataFrame(best_combinations)\n",
        "\n",
        "# Sort by dataset and ROC-AUC\n",
        "best_df = best_df.sort_values(['dataset', 'roc_auc'], ascending=[True, False])\n",
        "\n",
        "# Save to CSV\n",
        "best_df.to_csv(OUTPUT_CSV, index=False)\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"[OK] Saved to CSV: {OUTPUT_CSV}\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "# ============================================================\n",
        "# CREATE DETAILED MARKDOWN REPORT\n",
        "# ============================================================\n",
        "\n",
        "markdown_content = f\"\"\"# Best Combinations Report\n",
        "## Comprehensive Prototyping Results - Stage 1\n",
        "\n",
        "**Generated from**: {INPUT_FILE}\n",
        "**Total Experiments**: {len(df)}\n",
        "**Datasets Analyzed**: {', '.join(datasets)}\n",
        "**Date**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n",
        "---\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# CHANGED: Iterate through detected datasets dynamically\n",
        "for dataset in datasets:\n",
        "    dataset_best = best_df[best_df['dataset'] == dataset].copy()\n",
        "\n",
        "    if len(dataset_best) == 0:\n",
        "        continue\n",
        "\n",
        "    markdown_content += f\"\"\"## {dataset} Dataset\n",
        "\n",
        "**Training Samples**: {dataset_best.iloc[0]['train_samples']:,}\n",
        "**Validation Samples**: {dataset_best.iloc[0]['val_samples']:,}\n",
        "\n",
        "| Rank | Model | Optimizer | Activation | ROC-AUC | PR-AUC | Sensitivity | Specificity | F1-Score | Epochs |\n",
        "|------|-------|-----------|------------|---------|--------|-------------|-------------|----------|--------|\n",
        "\"\"\"\n",
        "\n",
        "    for idx, row in enumerate(dataset_best.iterrows(), 1):\n",
        "        _, r = row\n",
        "        markdown_content += f\"| {idx} | {r['model']} | {r['optimizer']} | {r['activation']} | {r['roc_auc']:.4f} | {r['pr_auc']:.4f} | {r['sensitivity']:.2%} | {r['specificity']:.2%} | {r['f1_score']:.4f} | {r['epochs_trained']} |\\n\"\n",
        "\n",
        "    # Add winner\n",
        "    winner = dataset_best.iloc[0]\n",
        "    markdown_content += f\"\"\"\n",
        "### Winner: {winner['model']}\n",
        "- **Combination**: {winner['optimizer']}-{winner['activation']}\n",
        "- **ROC-AUC**: {winner['roc_auc']:.4f}\n",
        "- **PR-AUC**: {winner['pr_auc']:.4f}\n",
        "- **Sensitivity**: {winner['sensitivity']:.2%}\n",
        "- **Specificity**: {winner['specificity']:.2%}\n",
        "\n",
        "---\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Add overall comparison\n",
        "markdown_content += \"\"\"## Cross-Dataset Comparison\n",
        "\n",
        "| Rank | Dataset | Best Model | Combination | ROC-AUC | PR-AUC | Train Samples |\n",
        "|------|---------|------------|-------------|---------|--------|---------------|\n",
        "\"\"\"\n",
        "\n",
        "overall_best = []\n",
        "for dataset in datasets:\n",
        "    dataset_best = best_df[best_df['dataset'] == dataset].copy()\n",
        "    if len(dataset_best) > 0:\n",
        "        winner = dataset_best.iloc[0]\n",
        "        overall_best.append(winner)\n",
        "\n",
        "overall_best_sorted = sorted(overall_best, key=lambda x: x['roc_auc'], reverse=True)\n",
        "\n",
        "for rank, winner in enumerate(overall_best_sorted, 1):\n",
        "    markdown_content += f\"| {rank} | {winner['dataset']} | {winner['model']} | {winner['combination']} | {winner['roc_auc']:.4f} | {winner['pr_auc']:.4f} | {winner['train_samples']:,} |\\n\"\n",
        "\n",
        "markdown_content += f\"\"\"\n",
        "---\n",
        "\n",
        "## Stage 2 Training Recommendations\n",
        "\n",
        "### Datasets to Train on Full Data:\n",
        "\"\"\"\n",
        "\n",
        "# CHANGED: Identify sampled datasets (exclude Undersampled which is already full)\n",
        "sampled_datasets = [d for d in datasets if d != 'Undersampled']\n",
        "\n",
        "for dataset in sampled_datasets:\n",
        "    dataset_best = best_df[best_df['dataset'] == dataset].copy()\n",
        "    if len(dataset_best) > 0:\n",
        "        markdown_content += f\"\"\"\n",
        "#### {dataset} Dataset (Full Data Required)\n",
        "\"\"\"\n",
        "        for idx, row in enumerate(dataset_best.iterrows(), 1):\n",
        "            _, r = row\n",
        "            markdown_content += f\"{idx}. {r['model']} - {r['optimizer']} + {r['activation']} (ROC: {r['roc_auc']:.4f})\\n\"\n",
        "\n",
        "# Add note about Undersampled if it exists\n",
        "if 'Undersampled' in datasets:\n",
        "    markdown_content += \"\"\"\n",
        "#### Undersampled Dataset\n",
        "Already trained on 100% data in Stage 1 - No Stage 2 needed\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Add note about SMOTE comparison if both exist\n",
        "if 'SMOTE' in datasets and 'SMOTEv2' in datasets:\n",
        "    smote_old = best_df[best_df['dataset'] == 'SMOTE'].iloc[0]\n",
        "    smote_v2 = best_df[best_df['dataset'] == 'SMOTEv2'].iloc[0]\n",
        "    markdown_content += f\"\"\"\n",
        "#### SMOTE Version Comparison\n",
        "- **SMOTE (original)**: {smote_old['model']} - ROC-AUC {smote_old['roc_auc']:.4f}\n",
        "- **SMOTEv2 (weighted+clipped)**: {smote_v2['model']} - ROC-AUC {smote_v2['roc_auc']:.4f}\n",
        "- **Improvement**: {((smote_v2['roc_auc'] - smote_old['roc_auc']) / smote_old['roc_auc'] * 100):+.2f}%\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "markdown_content += \"\"\"\n",
        "---\n",
        "\n",
        "## Key Insights\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Calculate insights\n",
        "overall_winner = max(overall_best, key=lambda x: x['roc_auc'])\n",
        "markdown_content += f\"\"\"\n",
        "1. **Overall Winner**: {overall_winner['dataset']} - {overall_winner['model']} ({overall_winner['combination']})\n",
        "   - ROC-AUC: {overall_winner['roc_auc']:.4f}\n",
        "   - This model achieved the best performance across all experiments\n",
        "\n",
        "2. **Dataset Performance**:\n",
        "\"\"\"\n",
        "\n",
        "for rank, winner in enumerate(overall_best_sorted, 1):\n",
        "    markdown_content += f\"   - #{rank}: {winner['dataset']} (ROC-AUC: {winner['roc_auc']:.4f})\\n\"\n",
        "\n",
        "markdown_content += \"\"\"\n",
        "3. **Recommended Focus for Stage 3 Hyperparameter Tuning**:\n",
        "\"\"\"\n",
        "markdown_content += f\"   - Primary: {overall_best_sorted[0]['dataset']} {overall_best_sorted[0]['model']} ({overall_best_sorted[0]['combination']})\\n\"\n",
        "if len(overall_best_sorted) > 1:\n",
        "    markdown_content += f\"   - Secondary: {overall_best_sorted[1]['dataset']} {overall_best_sorted[1]['model']} ({overall_best_sorted[1]['combination']})\\n\"\n",
        "\n",
        "# Save markdown\n",
        "with open(OUTPUT_MARKDOWN, 'w') as f:\n",
        "    f.write(markdown_content)\n",
        "\n",
        "print(f\"[OK] Saved to Markdown: {OUTPUT_MARKDOWN}\")\n",
        "\n",
        "# ============================================================\n",
        "# DISPLAY SUMMARY\n",
        "# ============================================================\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"SUMMARY\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"\\nTotal best combinations extracted: {len(best_df)}\")\n",
        "print(f\"\\nBreakdown:\")\n",
        "for dataset in datasets:\n",
        "    count = len(best_df[best_df['dataset'] == dataset])\n",
        "    print(f\"  {dataset:15s}: {count} models\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"TOP 3 OVERALL\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "top3 = best_df.nlargest(3, 'roc_auc')\n",
        "for idx, row in enumerate(top3.iterrows(), 1):\n",
        "    _, r = row\n",
        "    print(f\"{idx}. {r['dataset']:15s} | {r['model']:20s} | {r['combination']:15s} | ROC: {r['roc_auc']:.4f}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"FILES CREATED\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"1. CSV file: {OUTPUT_CSV}\")\n",
        "print(f\"2. Markdown report: {OUTPUT_MARKDOWN}\")\n",
        "print(f\"\\n[OK] All done!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRHTWrMmLfF4",
        "outputId": "b293b287-c848-40f3-ef19-857b86b011b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "EXTRACTING BEST COMBINATIONS PER MODEL PER DATASET\n",
            "================================================================================\n",
            "\n",
            "[OK] Loaded 192 experiments from comprehensive summary\n",
            "  Datasets: ['Original', 'SMOTE', 'SMOTEv2', 'Undersampled']\n",
            "  Models: ['GRU', 'LSTM_Attention', 'LSTM', 'CNN', 'RNN', 'Transformer']\n",
            "\n",
            "================================================================================\n",
            "Processing: Original Dataset\n",
            "================================================================================\n",
            "  GRU                  | adam    -gelu     | ROC: 0.7270\n",
            "  LSTM_Attention       | adam    -tanh     | ROC: 0.7259\n",
            "  LSTM                 | adam    -gelu     | ROC: 0.7242\n",
            "  CNN                  | adam    -gelu     | ROC: 0.7223\n",
            "  RNN                  | adam    -gelu     | ROC: 0.7127\n",
            "  Transformer          | adam    -tanh     | ROC: 0.7096\n",
            "\n",
            "================================================================================\n",
            "Processing: SMOTE Dataset\n",
            "================================================================================\n",
            "  GRU                  | rmsprop -sigmoid  | ROC: 0.6974\n",
            "  LSTM_Attention       | adam    -tanh     | ROC: 0.6918\n",
            "  LSTM                 | adam    -tanh     | ROC: 0.7039\n",
            "  CNN                  | rmsprop -relu     | ROC: 0.6874\n",
            "  RNN                  | rmsprop -sigmoid  | ROC: 0.6991\n",
            "  Transformer          | adam    -relu     | ROC: 0.6985\n",
            "\n",
            "================================================================================\n",
            "Processing: SMOTEv2 Dataset\n",
            "================================================================================\n",
            "  GRU                  | adam    -sigmoid  | ROC: 0.6853\n",
            "  LSTM_Attention       | rmsprop -relu     | ROC: 0.6799\n",
            "  LSTM                 | adam    -gelu     | ROC: 0.6809\n",
            "  CNN                  | adam    -gelu     | ROC: 0.6672\n",
            "  RNN                  | adam    -sigmoid  | ROC: 0.6821\n",
            "  Transformer          | adam    -gelu     | ROC: 0.6490\n",
            "\n",
            "================================================================================\n",
            "Processing: Undersampled Dataset\n",
            "================================================================================\n",
            "  GRU                  | rmsprop -gelu     | ROC: 0.7392\n",
            "  LSTM_Attention       | rmsprop -tanh     | ROC: 0.7383\n",
            "  LSTM                 | rmsprop -gelu     | ROC: 0.7425\n",
            "  CNN                  | adam    -gelu     | ROC: 0.7250\n",
            "  RNN                  | rmsprop -tanh     | ROC: 0.7281\n",
            "  Transformer          | rmsprop -gelu     | ROC: 0.7345\n",
            "\n",
            "================================================================================\n",
            "[OK] Saved to CSV: /content/drive/MyDrive/AI_Fin/Comprehensive_prototyping/best_combinations.csv\n",
            "================================================================================\n",
            "[OK] Saved to Markdown: /content/drive/MyDrive/AI_Fin/Comprehensive_prototyping/best_combinations_report.md\n",
            "\n",
            "================================================================================\n",
            "SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Total best combinations extracted: 24\n",
            "\n",
            "Breakdown:\n",
            "  Original       : 6 models\n",
            "  SMOTE          : 6 models\n",
            "  SMOTEv2        : 6 models\n",
            "  Undersampled   : 6 models\n",
            "\n",
            "================================================================================\n",
            "TOP 3 OVERALL\n",
            "================================================================================\n",
            "1. Undersampled    | LSTM                 | rmsprop-gelu    | ROC: 0.7425\n",
            "2. Undersampled    | GRU                  | rmsprop-gelu    | ROC: 0.7392\n",
            "3. Undersampled    | LSTM_Attention       | rmsprop-tanh    | ROC: 0.7383\n",
            "\n",
            "================================================================================\n",
            "FILES CREATED\n",
            "================================================================================\n",
            "1. CSV file: /content/drive/MyDrive/AI_Fin/Comprehensive_prototyping/best_combinations.csv\n",
            "2. Markdown report: /content/drive/MyDrive/AI_Fin/Comprehensive_prototyping/best_combinations_report.md\n",
            "\n",
            "[OK] All done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building for Original dataset."
      ],
      "metadata": {
        "id": "8Ae3NoE7Z3d7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " LSTM"
      ],
      "metadata": {
        "id": "IFt9II_Jcmfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Stage 2 Baseline Training: Original LSTM (adam-gelu) - PRODUCTION RUN SCRIPT v2\n",
        "Enhanced with:\n",
        "- Complete TF reproducibility (tf.random.set_seed)\n",
        "- Youden J statistic for optimal threshold selection\n",
        "- Patient-level aggregation and metrics\n",
        "- Mixed precision and GPU memory growth\n",
        "- Class weighting for Original dataset imbalance\n",
        "- PR-AUC metric tracking (curve='PR')\n",
        "- Robust error handling with all required keys\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import math\n",
        "import json\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import mixed_precision\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, confusion_matrix, roc_curve\n",
        "\n",
        "# -------------------------------\n",
        "# Configurable parameters\n",
        "# -------------------------------\n",
        "BASE_DIR = '/content/drive/MyDrive/AI_Course_Project/Dataset'\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, 'Stage2_Baseline')\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Original dataset paths\n",
        "TRAIN_PATH = os.path.join(BASE_DIR, 'baseline_train_matrices.npz')\n",
        "VAL_PATH   = os.path.join(BASE_DIR, 'baseline_val_matrices.npz')\n",
        "TEST_PATH  = os.path.join(BASE_DIR, 'baseline_test_matrices.npz')\n",
        "\n",
        "# Best combo for Original LSTM\n",
        "MODEL_NAME     = 'Original_LSTM_adam_gelu'\n",
        "OPTIMIZER_NAME = 'adam'\n",
        "ACTIVATION     = tf.nn.gelu  # callable GELU for robustness\n",
        "\n",
        "# Class weights for Original dataset (heavily imbalanced)\n",
        "CLASS_WEIGHT = {0: 1.0, 1: 61.0}\n",
        "\n",
        "# Hyperparameters\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 256\n",
        "UNITS = 128\n",
        "DROPOUT = 0.3\n",
        "LEARNING_RATE = 0.001\n",
        "PATIENCE = 5\n",
        "\n",
        "SEQUENCE_LENGTH = 4\n",
        "N_FEATURES = 21\n",
        "\n",
        "# Reproducibility - COMPLETE SEEDING\n",
        "RANDOM_STATE = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(RANDOM_STATE)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "np.random.seed(RANDOM_STATE)\n",
        "tf.random.set_seed(RANDOM_STATE)\n",
        "random.seed(RANDOM_STATE)\n",
        "\n",
        "# -------------------------------\n",
        "# Utility functions\n",
        "# -------------------------------\n",
        "def set_gpu_and_mixed_precision():\n",
        "    \"\"\"Enable memory growth and mixed precision if available.\"\"\"\n",
        "    try:\n",
        "        policy = mixed_precision.Policy('mixed_float16')\n",
        "        mixed_precision.set_global_policy(policy)\n",
        "        print(\"[OK] Mixed precision (float16) policy enabled\")\n",
        "    except Exception:\n",
        "        print(\"[INFO] Mixed precision not available\")\n",
        "\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        for gpu in gpus:\n",
        "            try:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "            except Exception:\n",
        "                pass\n",
        "        print(f\"[OK] GPU memory growth enabled for {len(gpus)} GPU(s)\")\n",
        "\n",
        "def load_data_memmap_with_ids(path):\n",
        "    \"\"\"Load X (memmap), y (numpy), and optional patient_ids from .npz using mmap.\"\"\"\n",
        "    npz = np.load(path, mmap_mode='r')\n",
        "    X = npz['X']\n",
        "    y = np.array(npz['y'])\n",
        "    patient_ids = None\n",
        "    if 'patient_ids' in npz.files:\n",
        "        patient_ids = np.array(npz['patient_ids'])\n",
        "    return X, y, patient_ids\n",
        "\n",
        "def create_memmap_dataset(X_mmap, y, batch_size, shuffle=False, buffer_size=10000, sample_weights=None):\n",
        "    \"\"\"\n",
        "    Create a tf.data.Dataset that loads samples from a memmap by index.\n",
        "    If sample_weights is provided, yields (x, y, w) for weighted training.\n",
        "    Casts input to current mixed-precision compute dtype if enabled.\n",
        "    \"\"\"\n",
        "    n_samples = len(y)\n",
        "    indices = np.arange(n_samples, dtype=np.int64)\n",
        "    labels = y.copy().astype(np.int32)\n",
        "\n",
        "    if sample_weights is not None:\n",
        "        weights = np.array(sample_weights, dtype=np.float32)\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((indices, labels, weights))\n",
        "    else:\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((indices, labels))\n",
        "\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=buffer_size, seed=RANDOM_STATE, reshuffle_each_iteration=True)\n",
        "\n",
        "    def load_sample(*args):\n",
        "        if sample_weights is not None:\n",
        "            idx, label, weight = args\n",
        "        else:\n",
        "            idx, label = args\n",
        "\n",
        "        def _load(idx_val):\n",
        "            return X_mmap[int(idx_val)].astype(np.float32)\n",
        "\n",
        "        x = tf.numpy_function(_load, [idx], tf.float32)\n",
        "\n",
        "        # safe cast to mixed-precision compute dtype (float16 if policy set)\n",
        "        try:\n",
        "            compute_dtype = mixed_precision.global_policy().compute_dtype\n",
        "        except Exception:\n",
        "            compute_dtype = 'float32'\n",
        "        x = tf.cast(x, compute_dtype)\n",
        "\n",
        "        x.set_shape((SEQUENCE_LENGTH, N_FEATURES))\n",
        "\n",
        "        if sample_weights is not None:\n",
        "            return x, label, weight\n",
        "        else:\n",
        "            return x, label\n",
        "\n",
        "    dataset = dataset.map(load_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=False)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "def build_lstm(input_shape, units, dropout, activation):\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Masking(mask_value=-1.0),\n",
        "        layers.LSTM(units, activation=activation, return_sequences=False),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(64, activation=activation),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(1, activation='sigmoid', dtype='float32')\n",
        "    ], name='LSTM')\n",
        "    return model\n",
        "\n",
        "def find_optimal_threshold_youden(y_true, y_pred_proba):\n",
        "    \"\"\"Find optimal threshold using Youden's J statistic (maximizes sensitivity + specificity - 1).\"\"\"\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
        "    j_scores = tpr - fpr  # Youden's J statistic\n",
        "    optimal_idx = np.argmax(j_scores)\n",
        "    optimal_threshold = thresholds[optimal_idx]\n",
        "    return float(optimal_threshold), float(j_scores[optimal_idx])\n",
        "\n",
        "def compute_metrics(y_true, y_pred, y_pred_proba, threshold=0.5):\n",
        "    \"\"\"Compute comprehensive metrics with robust error handling.\"\"\"\n",
        "    try:\n",
        "        cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "        if cm.size == 4:\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "        else:\n",
        "            tn = fp = fn = tp = 0\n",
        "\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "        precision_val = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "        npv = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n",
        "        f1 = 2 * (precision_val * sensitivity) / (precision_val + sensitivity) if (precision_val + sensitivity) > 0 else 0.0\n",
        "\n",
        "        roc_auc = roc_auc_score(y_true, y_pred_proba) if len(np.unique(y_true)) > 1 else 0.0\n",
        "\n",
        "        if len(np.unique(y_true)) > 1:\n",
        "            precision_curve, recall_curve, _ = precision_recall_curve(y_true, y_pred_proba)\n",
        "            pr_auc = auc(recall_curve, precision_curve)\n",
        "        else:\n",
        "            pr_auc = 0.0\n",
        "\n",
        "        return {\n",
        "            'threshold': float(threshold),\n",
        "            'roc_auc': float(roc_auc),\n",
        "            'pr_auc': float(pr_auc),\n",
        "            'sensitivity': float(sensitivity),\n",
        "            'specificity': float(specificity),\n",
        "            'precision': float(precision_val),\n",
        "            'npv': float(npv),\n",
        "            'f1_score': float(f1),\n",
        "            'tp': int(tp), 'tn': int(tn), 'fp': int(fp), 'fn': int(fn)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f'Warning: Error computing metrics: {e}')\n",
        "        return {\n",
        "            'threshold': float(threshold),\n",
        "            'roc_auc': 0.0, 'pr_auc': 0.0,\n",
        "            'sensitivity': 0.0, 'specificity': 0.0,\n",
        "            'precision': 0.0, 'npv': 0.0, 'f1_score': 0.0,\n",
        "            'tp': 0, 'tn': 0, 'fp': 0, 'fn': 0\n",
        "        }\n",
        "\n",
        "def compute_patient_level_metrics(pred_df):\n",
        "    \"\"\"\n",
        "    Patient-level aggregation and metrics.\n",
        "    - y_true: max across windows\n",
        "    - y_pred_proba: max across windows\n",
        "    \"\"\"\n",
        "    if 'patient_id' not in pred_df.columns or pred_df['patient_id'].isna().all():\n",
        "        print(\"[WARNING] No patient IDs available for patient-level aggregation\")\n",
        "        return None\n",
        "\n",
        "    patient_agg = pred_df.groupby('patient_id').agg({\n",
        "        'y_true': 'max',\n",
        "        'y_pred_proba': 'max'\n",
        "    }).reset_index()\n",
        "\n",
        "    unique_labels = patient_agg['y_true'].unique()\n",
        "    if len(unique_labels) < 2:\n",
        "        print(f\"[WARNING] Only {len(unique_labels)} class(es) in patient-level data. Metrics may be invalid.\")\n",
        "\n",
        "    try:\n",
        "        optimal_threshold, j_stat = find_optimal_threshold_youden(\n",
        "            patient_agg['y_true'].values,\n",
        "            patient_agg['y_pred_proba'].values\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"[WARNING] Could not compute optimal threshold: {e}. Using 0.5.\")\n",
        "        optimal_threshold = 0.5\n",
        "        j_stat = 0.0\n",
        "\n",
        "    patient_agg['y_pred_optimal'] = (patient_agg['y_pred_proba'] >= optimal_threshold).astype(int)\n",
        "\n",
        "    metrics_optimal = compute_metrics(\n",
        "        patient_agg['y_true'].values,\n",
        "        patient_agg['y_pred_optimal'].values,\n",
        "        patient_agg['y_pred_proba'].values,\n",
        "        threshold=optimal_threshold\n",
        "    )\n",
        "\n",
        "    patient_agg['y_pred_0.5'] = (patient_agg['y_pred_proba'] >= 0.5).astype(int)\n",
        "    metrics_0_5 = compute_metrics(\n",
        "        patient_agg['y_true'].values,\n",
        "        patient_agg['y_pred_0.5'].values,\n",
        "        patient_agg['y_pred_proba'].values,\n",
        "        threshold=0.5\n",
        "    )\n",
        "\n",
        "    print(f\"[OK] Patient-level aggregation: {len(patient_agg)} patients\")\n",
        "    print(f\"  Positive patients: {patient_agg['y_true'].sum()}\")\n",
        "    print(f\"  Negative patients: {(patient_agg['y_true'] == 0).sum()}\")\n",
        "\n",
        "    return {\n",
        "        'patient_aggregation': patient_agg,\n",
        "        'n_patients': len(patient_agg),\n",
        "        'n_positive_patients': int(patient_agg['y_true'].sum()),\n",
        "        'n_negative_patients': int((patient_agg['y_true'] == 0).sum()),\n",
        "        'optimal_threshold': optimal_threshold,\n",
        "        'youden_j_statistic': j_stat,\n",
        "        'metrics_at_optimal_threshold': metrics_optimal,\n",
        "        'metrics_at_0.5_threshold': metrics_0_5\n",
        "    }\n",
        "\n",
        "# -------------------------------\n",
        "# Main run\n",
        "# -------------------------------\n",
        "def main(dry_run_max_samples=None):\n",
        "    set_gpu_and_mixed_precision()\n",
        "\n",
        "    print('\\nLoading memmap datasets...')\n",
        "    X_train_mmap, y_train, patient_ids_train = load_data_memmap_with_ids(TRAIN_PATH)\n",
        "    X_val_mmap,   y_val,   patient_ids_val   = load_data_memmap_with_ids(VAL_PATH)\n",
        "    X_test_mmap,  y_test,  patient_ids_test  = load_data_memmap_with_ids(TEST_PATH)\n",
        "\n",
        "    # Optional quick dry run\n",
        "    if dry_run_max_samples is not None:\n",
        "        print(f'[FAST] DRY RUN: limiting datasets to {dry_run_max_samples} samples (stratified sample)')\n",
        "\n",
        "        def sample_mmap(X_mmap, y, patient_ids, n):\n",
        "            if len(y) <= n:\n",
        "                return X_mmap, y, patient_ids\n",
        "            idx0 = np.where(y == 0)[0]\n",
        "            idx1 = np.where(y == 1)[0]\n",
        "            ratio = len(idx1) / max(len(y), 1)\n",
        "            n1 = max(2, int(round(n * ratio)))\n",
        "            n0 = max(2, n - n1)\n",
        "            chosen0 = np.random.choice(idx0, size=min(n0, len(idx0)), replace=False)\n",
        "            chosen1 = np.random.choice(idx1, size=min(n1, len(idx1)), replace=False)\n",
        "            chosen = np.concatenate([chosen0, chosen1])\n",
        "            np.random.shuffle(chosen)\n",
        "            X_small = np.stack([X_mmap[i].astype(np.float32) for i in chosen])\n",
        "            y_small = y[chosen]\n",
        "            p_small = patient_ids[chosen] if patient_ids is not None else None\n",
        "            return X_small, y_small, p_small\n",
        "\n",
        "        X_train_mmap, y_train, patient_ids_train = sample_mmap(X_train_mmap, y_train, patient_ids_train, dry_run_max_samples)\n",
        "        X_val_mmap,   y_val,   patient_ids_val   = sample_mmap(X_val_mmap,   y_val,   patient_ids_val,   min(max(dry_run_max_samples // 10, 1000), len(y_val)))\n",
        "        X_test_mmap,  y_test,  patient_ids_test  = sample_mmap(X_test_mmap,  y_test,  patient_ids_test,  min(max(dry_run_max_samples // 10, 1000), len(y_test)))\n",
        "\n",
        "    n_train = len(y_train)\n",
        "    n_val   = len(y_val)\n",
        "    n_test  = len(y_test)\n",
        "\n",
        "    print(f'\\n[OK] Training samples: {n_train:,}')\n",
        "    print(f'  Class 0: {(y_train == 0).sum():,} | Class 1: {(y_train == 1).sum():,}')\n",
        "    print(f'[OK] Validation: {n_val:,}, Test: {n_test:,}')\n",
        "\n",
        "    # Sample weights for class imbalance (Original dataset)\n",
        "    train_sample_weights = np.where(y_train == 1, CLASS_WEIGHT[1], CLASS_WEIGHT[0]).astype(np.float32)\n",
        "\n",
        "    # Datasets: training uses weights; val/test do not\n",
        "    train_ds = create_memmap_dataset(X_train_mmap, y_train, batch_size=BATCH_SIZE, shuffle=True, sample_weights=train_sample_weights)\n",
        "    val_ds   = create_memmap_dataset(X_val_mmap,   y_val,   batch_size=BATCH_SIZE, shuffle=False)\n",
        "    test_ds  = create_memmap_dataset(X_test_mmap,  y_test,  batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    steps_per_epoch = math.ceil(n_train / BATCH_SIZE)\n",
        "\n",
        "    # Model\n",
        "    model = build_lstm((SEQUENCE_LENGTH, N_FEATURES), UNITS, DROPOUT, ACTIVATION)\n",
        "\n",
        "    # Optimizer (with optional loss scaling under mixed precision)\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "    try:\n",
        "        from tensorflow.keras.mixed_precision import LossScaleOptimizer\n",
        "        if tf.keras.mixed_precision.global_policy().name == 'mixed_float16':\n",
        "            optimizer = LossScaleOptimizer(optimizer)\n",
        "            print('[OK] Optimizer wrapped with LossScaleOptimizer')\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    loss_fn = keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss_fn,\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            keras.metrics.AUC(name='auc'),                 # ROC-AUC\n",
        "            keras.metrics.AUC(name='pr_auc', curve='PR'),  # PR-AUC\n",
        "            keras.metrics.Precision(name='precision'),\n",
        "            keras.metrics.Recall(name='recall')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    checkpoint_path = os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_best.weights.h5')\n",
        "    callbacks = [\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            patience=PATIENCE,\n",
        "            restore_best_weights=True,\n",
        "            monitor='val_auc',\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        ),\n",
        "        keras.callbacks.ReduceLROnPlateau(\n",
        "            factor=0.5,\n",
        "            patience=3,\n",
        "            monitor='val_loss',\n",
        "            min_lr=1e-6,\n",
        "            verbose=1\n",
        "        ),\n",
        "        keras.callbacks.ModelCheckpoint(\n",
        "            filepath=checkpoint_path,\n",
        "            monitor='val_auc',\n",
        "            mode='max',\n",
        "            save_best_only=True,\n",
        "            save_weights_only=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        keras.callbacks.CSVLogger(\n",
        "            os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_training_log.csv')\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    print('\\nTRAINING:')\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=EPOCHS,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        callbacks=callbacks,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    epochs_trained = len(history.history['loss'])\n",
        "    print(f'\\n[OK] Training complete: {epochs_trained}/{EPOCHS} epochs')\n",
        "\n",
        "    # Save history\n",
        "    try:\n",
        "        history_serializable = {k: [float(v) for v in vals] for k, vals in history.history.items()}\n",
        "        with open(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_history.json'), 'w') as f:\n",
        "            json.dump(history_serializable, f, indent=2)\n",
        "    except Exception as e:\n",
        "        print('Warning: failed to save history:', e)\n",
        "\n",
        "    # VALIDATION EVALUATION WITH OPTIMAL THRESHOLD\n",
        "    print('\\nEVALUATING: Validation Predictions...')\n",
        "    y_val_pred_proba = model.predict(val_ds, verbose=1).flatten()\n",
        "    if len(y_val_pred_proba) != len(y_val):\n",
        "        y_val_pred_proba = y_val_pred_proba[:len(y_val)]\n",
        "\n",
        "    val_optimal_threshold, val_j_stat = find_optimal_threshold_youden(y_val, y_val_pred_proba)\n",
        "    print(f\"[OK] Optimal threshold (Youden's J): {val_optimal_threshold:.4f} (J={val_j_stat:.4f})\")\n",
        "\n",
        "    y_val_pred_optimal = (y_val_pred_proba >= val_optimal_threshold).astype(int)\n",
        "    y_val_pred_0_5     = (y_val_pred_proba > 0.5).astype(int)\n",
        "\n",
        "    val_metrics_optimal = compute_metrics(y_val, y_val_pred_optimal, y_val_pred_proba, val_optimal_threshold)\n",
        "    val_metrics_0_5     = compute_metrics(y_val, y_val_pred_0_5,     y_val_pred_proba, 0.5)\n",
        "\n",
        "    val_df = pd.DataFrame({\n",
        "        'y_true': y_val,\n",
        "        'y_pred_0.5': y_val_pred_0_5,\n",
        "        'y_pred_optimal': y_val_pred_optimal,\n",
        "        'y_pred_proba': y_val_pred_proba\n",
        "    })\n",
        "    if patient_ids_val is not None:\n",
        "        val_df.insert(0, 'patient_id', patient_ids_val[:len(y_val)])\n",
        "    val_df.to_csv(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_val_predictions.csv'), index=False)\n",
        "    print(f'[OK] Saved validation window-level predictions ({len(val_df)} rows)')\n",
        "\n",
        "    val_patient_metrics = compute_patient_level_metrics(val_df)\n",
        "    if val_patient_metrics:\n",
        "        val_patient_metrics['patient_aggregation'].to_csv(\n",
        "            os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_val_patient_predictions.csv'),\n",
        "            index=False\n",
        "        )\n",
        "        print(f\"[OK] Saved validation patient-level predictions ({val_patient_metrics['n_patients']} patients)\")\n",
        "\n",
        "    # TEST EVALUATION (using validation optimal threshold)\n",
        "    print('\\nEVALUATING: Test Predictions...')\n",
        "    y_test_pred_proba = model.predict(test_ds, verbose=1).flatten()\n",
        "    if len(y_test_pred_proba) != len(y_test):\n",
        "        y_test_pred_proba = y_test_pred_proba[:len(y_test)]\n",
        "\n",
        "    y_test_pred_optimal = (y_test_pred_proba >= val_optimal_threshold).astype(int)\n",
        "    y_test_pred_0_5     = (y_test_pred_proba > 0.5).astype(int)\n",
        "\n",
        "    test_metrics_optimal = compute_metrics(y_test, y_test_pred_optimal, y_test_pred_proba, val_optimal_threshold)\n",
        "    test_metrics_0_5     = compute_metrics(y_test, y_test_pred_0_5,     y_test_pred_proba, 0.5)\n",
        "\n",
        "    test_df = pd.DataFrame({\n",
        "        'y_true': y_test,\n",
        "        'y_pred_0.5': y_test_pred_0_5,\n",
        "        'y_pred_optimal': y_test_pred_optimal,\n",
        "        'y_pred_proba': y_test_pred_proba\n",
        "    })\n",
        "    if patient_ids_test is not None:\n",
        "        test_df.insert(0, 'patient_id', patient_ids_test[:len(y_test)])\n",
        "    test_df.to_csv(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_test_predictions.csv'), index=False)\n",
        "    print(f'[OK] Saved test window-level predictions ({len(test_df)} rows)')\n",
        "\n",
        "    test_patient_metrics = compute_patient_level_metrics(test_df)\n",
        "    if test_patient_metrics:\n",
        "        test_patient_metrics['patient_aggregation'].to_csv(\n",
        "            os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_test_patient_predictions.csv'),\n",
        "            index=False\n",
        "        )\n",
        "        print(f\"[OK] Saved test patient-level predictions ({test_patient_metrics['n_patients']} patients)\")\n",
        "\n",
        "    # Save comprehensive results\n",
        "    results = {\n",
        "        'model_name': MODEL_NAME,\n",
        "        'dataset': 'Original',\n",
        "        'model_type': 'LSTM',\n",
        "        'optimizer': OPTIMIZER_NAME,\n",
        "        'activation': 'gelu',\n",
        "        'train_samples': int(n_train),\n",
        "        'val_samples': int(n_val),\n",
        "        'test_samples': int(n_test),\n",
        "        'max_epochs': EPOCHS,\n",
        "        'epochs_trained': int(epochs_trained),\n",
        "        'early_stopped': bool(epochs_trained < EPOCHS),\n",
        "        'steps_per_epoch': steps_per_epoch,\n",
        "        'units': UNITS,\n",
        "        'dropout': DROPOUT,\n",
        "        'learning_rate': LEARNING_RATE,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'random_state': RANDOM_STATE,\n",
        "        'class_weight': CLASS_WEIGHT,\n",
        "        'optimal_threshold': val_optimal_threshold,\n",
        "        'youden_j_statistic': val_j_stat,\n",
        "        'validation_metrics': {\n",
        "            'window_level_0.5_threshold': val_metrics_0_5,\n",
        "            'window_level_optimal_threshold': val_metrics_optimal,\n",
        "            'patient_level': val_patient_metrics if val_patient_metrics else None\n",
        "        },\n",
        "        'test_metrics': {\n",
        "            'window_level_0.5_threshold': test_metrics_0_5,\n",
        "            'window_level_optimal_threshold': test_metrics_optimal,\n",
        "            'patient_level': test_patient_metrics if test_patient_metrics else None\n",
        "        }\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_results.json'), 'w') as f:\n",
        "        json.dump(results, f, indent=2, default=str)\n",
        "\n",
        "    # Save final model\n",
        "    final_model_path = os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_final.h5')\n",
        "    try:\n",
        "        model.save(final_model_path)\n",
        "        print(f'[OK] Model saved: {final_model_path}')\n",
        "    except Exception as e:\n",
        "        print('Warning: full model.save failed, saving weights only. Error:', e)\n",
        "        try:\n",
        "            model.save_weights(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_final_weights.h5'))\n",
        "            print('[OK] Weights saved as fallback')\n",
        "        except Exception as e2:\n",
        "            print('ERROR: failed to save weights as well:', e2)\n",
        "\n",
        "    print('\\nTRAINING SUMMARY')\n",
        "    print('='*80)\n",
        "    print(f\"Dataset: Original (train samples: {n_train:,})\")\n",
        "    print(f\"Epochs trained: {epochs_trained}/{EPOCHS}\")\n",
        "    print(f\"\\nOptimal threshold (Youden's J): {val_optimal_threshold:.4f}\")\n",
        "    print('\\nValidation metrics (window-level at optimal threshold):')\n",
        "    for k, v in val_metrics_optimal.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "    print('\\nTest metrics (window-level at optimal threshold):')\n",
        "    for k, v in test_metrics_optimal.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    DRY_RUN = False\n",
        "    DRY_RUN_SAMPLES = 1000\n",
        "\n",
        "    if DRY_RUN:\n",
        "        MODEL_NAME = MODEL_NAME + '_DRY_RUN'\n",
        "        print(\"=\"*80)\n",
        "        print(\"[TEST] DRY RUN MODE: Quick validation with small sample\")\n",
        "        print(f\"   Using {DRY_RUN_SAMPLES:,} training samples\")\n",
        "        print(f\"   Files will be saved with suffix: _DRY_RUN\")\n",
        "        print(\"=\"*80)\n",
        "        main(dry_run_max_samples=DRY_RUN_SAMPLES)\n",
        "    else:\n",
        "        print(\"=\"*80)\n",
        "        print(\"[FULL] FULL TRAINING MODE: Complete dataset\")\n",
        "        print(\"   Using all available training samples\")\n",
        "        print(\"=\"*80)\n",
        "        main(dry_run_max_samples=None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G40QHkjFZ9HL",
        "outputId": "1c6aaa50-79b0-44c5-9650-f97ee38f8d10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "[TEST] DRY RUN MODE: Quick validation with small sample\n",
            "   Using 1,000 training samples\n",
            "   Files will be saved with suffix: _DRY_RUN\n",
            "================================================================================\n",
            "[OK] Mixed precision (float16) policy enabled\n",
            "\n",
            "Loading memmap datasets...\n",
            "[FAST] DRY RUN: limiting datasets to 1000 samples (stratified sample)\n",
            "\n",
            "[OK] Training samples: 1,000\n",
            "  Class 0: 984 | Class 1: 16\n",
            "[OK] Validation: 1,000, Test: 1,000\n",
            "[OK] Optimizer wrapped with LossScaleOptimizer\n",
            "\n",
            "TRAINING:\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 1: val_auc improved from -inf to 0.67419, saving model to /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Original_LSTM_adam_gelu_DRY_RUN_best.weights.h5\n",
            "4/4 - 8s - 2s/step - accuracy: 0.3140 - auc: 0.4663 - loss: 3.9237 - pr_auc: 0.0151 - precision: 0.0159 - recall: 0.6875 - val_accuracy: 0.0580 - val_auc: 0.6742 - val_loss: 1.3287 - val_pr_auc: 0.0277 - val_precision: 0.0157 - val_recall: 0.9375 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 2: val_auc did not improve from 0.67419\n",
            "4/4 - 1s - 239ms/step - accuracy: 0.5340 - auc: 0.5192 - loss: 3.3168 - pr_auc: 0.0178 - precision: 0.0151 - recall: 0.4375 - val_accuracy: 0.9840 - val_auc: 0.5240 - val_loss: 0.1800 - val_pr_auc: 0.0228 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 3: val_auc did not improve from 0.67419\n",
            "4/4 - 1s - 242ms/step - accuracy: 0.5900 - auc: 0.4616 - loss: 2.8442 - pr_auc: 0.0140 - precision: 0.0075 - recall: 0.1875 - val_accuracy: 0.4170 - val_auc: 0.6430 - val_loss: 0.7627 - val_pr_auc: 0.0280 - val_precision: 0.0203 - val_recall: 0.7500 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: val_auc did not improve from 0.67419\n",
            "4/4 - 1s - 309ms/step - accuracy: 0.4260 - auc: 0.6166 - loss: 2.1755 - pr_auc: 0.0205 - precision: 0.0206 - recall: 0.7500 - val_accuracy: 0.2120 - val_auc: 0.6220 - val_loss: 0.9169 - val_pr_auc: 0.0242 - val_precision: 0.0175 - val_recall: 0.8750 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 5: val_auc did not improve from 0.67419\n",
            "4/4 - 1s - 241ms/step - accuracy: 0.4510 - auc: 0.5231 - loss: 2.3435 - pr_auc: 0.0209 - precision: 0.0146 - recall: 0.5000 - val_accuracy: 0.7940 - val_auc: 0.6392 - val_loss: 0.6039 - val_pr_auc: 0.0266 - val_precision: 0.0388 - val_recall: 0.5000 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 6: val_auc did not improve from 0.67419\n",
            "4/4 - 1s - 245ms/step - accuracy: 0.5170 - auc: 0.5254 - loss: 2.0198 - pr_auc: 0.0174 - precision: 0.0125 - recall: 0.3750 - val_accuracy: 0.9720 - val_auc: 0.6631 - val_loss: 0.5110 - val_pr_auc: 0.0301 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 6: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "\n",
            "[OK] Training complete: 6/50 epochs\n",
            "\n",
            "EVALUATING: Validation Predictions...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step\n",
            "[OK] Optimal threshold (Youden's J): 0.7812 (J=0.3664)\n",
            "[OK] Saved validation window-level predictions (1000 rows)\n",
            "[OK] Patient-level aggregation: 897 patients\n",
            "  Positive patients: 16\n",
            "  Negative patients: 881\n",
            "[OK] Saved validation patient-level predictions (897 patients)\n",
            "\n",
            "EVALUATING: Test Predictions...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Saved test window-level predictions (1000 rows)\n",
            "[OK] Patient-level aggregation: 888 patients\n",
            "  Positive patients: 17\n",
            "  Negative patients: 871\n",
            "[OK] Saved test patient-level predictions (888 patients)\n",
            "[OK] Model saved: /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Original_LSTM_adam_gelu_DRY_RUN_final.h5\n",
            "\n",
            "TRAINING SUMMARY\n",
            "================================================================================\n",
            "Dataset: Original (train samples: 1,000)\n",
            "Epochs trained: 6/50\n",
            "\n",
            "Optimal threshold (Youden's J): 0.7812\n",
            "\n",
            "Validation metrics (window-level at optimal threshold):\n",
            "  threshold: 0.7812365889549255\n",
            "  roc_auc: 0.6762576219512195\n",
            "  pr_auc: 0.02818455419556939\n",
            "  sensitivity: 0.6875\n",
            "  specificity: 0.6788617886178862\n",
            "  precision: 0.03363914373088685\n",
            "  npv: 0.9925705794947994\n",
            "  f1_score: 0.0641399416909621\n",
            "  tp: 11\n",
            "  tn: 668\n",
            "  fp: 316\n",
            "  fn: 5\n",
            "\n",
            "Test metrics (window-level at optimal threshold):\n",
            "  threshold: 0.7812365889549255\n",
            "  roc_auc: 0.747651247681168\n",
            "  pr_auc: 0.040695101247107686\n",
            "  sensitivity: 0.6470588235294118\n",
            "  specificity: 0.7009155645981688\n",
            "  precision: 0.036065573770491806\n",
            "  npv: 0.9913669064748202\n",
            "  f1_score: 0.06832298136645963\n",
            "  tp: 11\n",
            "  tn: 689\n",
            "  fp: 294\n",
            "  fn: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " RNN"
      ],
      "metadata": {
        "id": "I1bbfsBjcoVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Stage 2 Baseline Training: Original RNN (adam-gelu) - PRODUCTION RUN SCRIPT v2\n",
        "Enhanced with:\n",
        "- Complete TF reproducibility (tf.random.set_seed)\n",
        "- Youden J statistic for optimal threshold selection\n",
        "- Patient-level aggregation and metrics\n",
        "- Mixed precision and GPU memory growth\n",
        "- Class weighting for Original dataset imbalance\n",
        "- PR-AUC metric tracking (curve='PR')\n",
        "- Robust error handling with all required keys\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import math\n",
        "import json\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import mixed_precision\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, confusion_matrix, roc_curve\n",
        "\n",
        "# -------------------------------\n",
        "# Configurable parameters\n",
        "# -------------------------------\n",
        "BASE_DIR = '/content/drive/MyDrive/AI_Course_Project/Dataset'\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, 'Stage2_Baseline')\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Original dataset paths\n",
        "TRAIN_PATH = os.path.join(BASE_DIR, 'baseline_train_matrices.npz')\n",
        "VAL_PATH   = os.path.join(BASE_DIR, 'baseline_val_matrices.npz')\n",
        "TEST_PATH  = os.path.join(BASE_DIR, 'baseline_test_matrices.npz')\n",
        "\n",
        "# Best combo for Original RNN\n",
        "MODEL_NAME     = 'Original_RNN_adam_gelu'\n",
        "OPTIMIZER_NAME = 'adam'\n",
        "ACTIVATION     = tf.nn.gelu  # callable GELU for robustness\n",
        "\n",
        "# Class weights for Original dataset (heavily imbalanced)\n",
        "CLASS_WEIGHT = {0: 1.0, 1: 61.0}\n",
        "\n",
        "# Hyperparameters\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 256\n",
        "UNITS = 128\n",
        "DROPOUT = 0.3\n",
        "LEARNING_RATE = 0.001\n",
        "PATIENCE = 5\n",
        "\n",
        "SEQUENCE_LENGTH = 4\n",
        "N_FEATURES = 21\n",
        "\n",
        "# Reproducibility - COMPLETE SEEDING\n",
        "RANDOM_STATE = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(RANDOM_STATE)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "np.random.seed(RANDOM_STATE)\n",
        "tf.random.set_seed(RANDOM_STATE)\n",
        "random.seed(RANDOM_STATE)\n",
        "\n",
        "# -------------------------------\n",
        "# Utility functions\n",
        "# -------------------------------\n",
        "def set_gpu_and_mixed_precision():\n",
        "    \"\"\"Enable memory growth and mixed precision if available.\"\"\"\n",
        "    try:\n",
        "        policy = mixed_precision.Policy('mixed_float16')\n",
        "        mixed_precision.set_global_policy(policy)\n",
        "        print(\"[OK] Mixed precision (float16) policy enabled\")\n",
        "    except Exception:\n",
        "        print(\"[INFO] Mixed precision not available\")\n",
        "\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        for gpu in gpus:\n",
        "            try:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "            except Exception:\n",
        "                pass\n",
        "        print(f\"[OK] GPU memory growth enabled for {len(gpus)} GPU(s)\")\n",
        "\n",
        "def load_data_memmap_with_ids(path):\n",
        "    \"\"\"Load X (memmap), y (numpy), and optional patient_ids from .npz using mmap.\"\"\"\n",
        "    npz = np.load(path, mmap_mode='r')\n",
        "    X = npz['X']\n",
        "    y = np.array(npz['y'])\n",
        "    patient_ids = None\n",
        "    if 'patient_ids' in npz.files:\n",
        "        patient_ids = np.array(npz['patient_ids'])\n",
        "    return X, y, patient_ids\n",
        "\n",
        "def create_memmap_dataset(X_mmap, y, batch_size, shuffle=False, buffer_size=10000, sample_weights=None):\n",
        "    \"\"\"\n",
        "    Create a tf.data.Dataset that loads samples from a memmap by index.\n",
        "    If sample_weights is provided, yields (x, y, w) for weighted training.\n",
        "    Casts input to current mixed-precision compute dtype if enabled.\n",
        "    \"\"\"\n",
        "    n_samples = len(y)\n",
        "    indices = np.arange(n_samples, dtype=np.int64)\n",
        "    labels = y.copy().astype(np.int32)\n",
        "\n",
        "    if sample_weights is not None:\n",
        "        weights = np.array(sample_weights, dtype=np.float32)\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((indices, labels, weights))\n",
        "    else:\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((indices, labels))\n",
        "\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=buffer_size, seed=RANDOM_STATE, reshuffle_each_iteration=True)\n",
        "\n",
        "    def load_sample(*args):\n",
        "        if sample_weights is not None:\n",
        "            idx, label, weight = args\n",
        "        else:\n",
        "            idx, label = args\n",
        "\n",
        "        def _load(idx_val):\n",
        "            return X_mmap[int(idx_val)].astype(np.float32)\n",
        "\n",
        "        x = tf.numpy_function(_load, [idx], tf.float32)\n",
        "\n",
        "        # safe cast to mixed-precision compute dtype (float16 if policy set)\n",
        "        try:\n",
        "            compute_dtype = mixed_precision.global_policy().compute_dtype\n",
        "        except Exception:\n",
        "            compute_dtype = 'float32'\n",
        "        x = tf.cast(x, compute_dtype)\n",
        "\n",
        "        x.set_shape((SEQUENCE_LENGTH, N_FEATURES))\n",
        "\n",
        "        if sample_weights is not None:\n",
        "            return x, label, weight\n",
        "        else:\n",
        "            return x, label\n",
        "\n",
        "    dataset = dataset.map(load_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=False)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "def build_rnn(input_shape, units, dropout, activation):\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Masking(mask_value=-1.0),\n",
        "        layers.SimpleRNN(units, activation=activation, return_sequences=False),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(64, activation=activation),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(1, activation='sigmoid', dtype='float32')\n",
        "    ], name='RNN')\n",
        "    return model\n",
        "\n",
        "def find_optimal_threshold_youden(y_true, y_pred_proba):\n",
        "    \"\"\"Find optimal threshold using Youden's J statistic (maximizes sensitivity + specificity - 1).\"\"\"\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
        "    j_scores = tpr - fpr  # Youden's J statistic\n",
        "    optimal_idx = np.argmax(j_scores)\n",
        "    optimal_threshold = thresholds[optimal_idx]\n",
        "    return float(optimal_threshold), float(j_scores[optimal_idx])\n",
        "\n",
        "def compute_metrics(y_true, y_pred, y_pred_proba, threshold=0.5):\n",
        "    \"\"\"Compute comprehensive metrics with robust error handling.\"\"\"\n",
        "    try:\n",
        "        cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "        if cm.size == 4:\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "        else:\n",
        "            tn = fp = fn = tp = 0\n",
        "\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "        precision_val = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "        npv = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n",
        "        f1 = 2 * (precision_val * sensitivity) / (precision_val + sensitivity) if (precision_val + sensitivity) > 0 else 0.0\n",
        "\n",
        "        roc_auc = roc_auc_score(y_true, y_pred_proba) if len(np.unique(y_true)) > 1 else 0.0\n",
        "\n",
        "        if len(np.unique(y_true)) > 1:\n",
        "            precision_curve, recall_curve, _ = precision_recall_curve(y_true, y_pred_proba)\n",
        "            pr_auc = auc(recall_curve, precision_curve)\n",
        "        else:\n",
        "            pr_auc = 0.0\n",
        "\n",
        "        return {\n",
        "            'threshold': float(threshold),\n",
        "            'roc_auc': float(roc_auc),\n",
        "            'pr_auc': float(pr_auc),\n",
        "            'sensitivity': float(sensitivity),\n",
        "            'specificity': float(specificity),\n",
        "            'precision': float(precision_val),\n",
        "            'npv': float(npv),\n",
        "            'f1_score': float(f1),\n",
        "            'tp': int(tp), 'tn': int(tn), 'fp': int(fp), 'fn': int(fn)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f'Warning: Error computing metrics: {e}')\n",
        "        return {\n",
        "            'threshold': float(threshold),\n",
        "            'roc_auc': 0.0, 'pr_auc': 0.0,\n",
        "            'sensitivity': 0.0, 'specificity': 0.0,\n",
        "            'precision': 0.0, 'npv': 0.0, 'f1_score': 0.0,\n",
        "            'tp': 0, 'tn': 0, 'fp': 0, 'fn': 0\n",
        "        }\n",
        "\n",
        "def compute_patient_level_metrics(pred_df):\n",
        "    \"\"\"\n",
        "    Patient-level aggregation and metrics.\n",
        "    - y_true: max across windows\n",
        "    - y_pred_proba: max across windows\n",
        "    \"\"\"\n",
        "    if 'patient_id' not in pred_df.columns or pred_df['patient_id'].isna().all():\n",
        "        print(\"[WARNING] No patient IDs available for patient-level aggregation\")\n",
        "        return None\n",
        "\n",
        "    patient_agg = pred_df.groupby('patient_id').agg({\n",
        "        'y_true': 'max',\n",
        "        'y_pred_proba': 'max'\n",
        "    }).reset_index()\n",
        "\n",
        "    unique_labels = patient_agg['y_true'].unique()\n",
        "    if len(unique_labels) < 2:\n",
        "        print(f\"[WARNING] Only {len(unique_labels)} class(es) in patient-level data. Metrics may be invalid.\")\n",
        "\n",
        "    try:\n",
        "        optimal_threshold, j_stat = find_optimal_threshold_youden(\n",
        "            patient_agg['y_true'].values,\n",
        "            patient_agg['y_pred_proba'].values\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"[WARNING] Could not compute optimal threshold: {e}. Using 0.5.\")\n",
        "        optimal_threshold = 0.5\n",
        "        j_stat = 0.0\n",
        "\n",
        "    patient_agg['y_pred_optimal'] = (patient_agg['y_pred_proba'] >= optimal_threshold).astype(int)\n",
        "\n",
        "    metrics_optimal = compute_metrics(\n",
        "        patient_agg['y_true'].values,\n",
        "        patient_agg['y_pred_optimal'].values,\n",
        "        patient_agg['y_pred_proba'].values,\n",
        "        threshold=optimal_threshold\n",
        "    )\n",
        "\n",
        "    patient_agg['y_pred_0.5'] = (patient_agg['y_pred_proba'] >= 0.5).astype(int)\n",
        "    metrics_0_5 = compute_metrics(\n",
        "        patient_agg['y_true'].values,\n",
        "        patient_agg['y_pred_0.5'].values,\n",
        "        patient_agg['y_pred_proba'].values,\n",
        "        threshold=0.5\n",
        "    )\n",
        "\n",
        "    print(f\"[OK] Patient-level aggregation: {len(patient_agg)} patients\")\n",
        "    print(f\"  Positive patients: {patient_agg['y_true'].sum()}\")\n",
        "    print(f\"  Negative patients: {(patient_agg['y_true'] == 0).sum()}\")\n",
        "\n",
        "    return {\n",
        "        'patient_aggregation': patient_agg,\n",
        "        'n_patients': len(patient_agg),\n",
        "        'n_positive_patients': int(patient_agg['y_true'].sum()),\n",
        "        'n_negative_patients': int((patient_agg['y_true'] == 0).sum()),\n",
        "        'optimal_threshold': optimal_threshold,\n",
        "        'youden_j_statistic': j_stat,\n",
        "        'metrics_at_optimal_threshold': metrics_optimal,\n",
        "        'metrics_at_0.5_threshold': metrics_0_5\n",
        "    }\n",
        "\n",
        "# -------------------------------\n",
        "# Main run\n",
        "# -------------------------------\n",
        "def main(dry_run_max_samples=None):\n",
        "    set_gpu_and_mixed_precision()\n",
        "\n",
        "    print('\\nLoading memmap datasets...')\n",
        "    X_train_mmap, y_train, patient_ids_train = load_data_memmap_with_ids(TRAIN_PATH)\n",
        "    X_val_mmap,   y_val,   patient_ids_val   = load_data_memmap_with_ids(VAL_PATH)\n",
        "    X_test_mmap,  y_test,  patient_ids_test  = load_data_memmap_with_ids(TEST_PATH)\n",
        "\n",
        "    # Optional quick dry run\n",
        "    if dry_run_max_samples is not None:\n",
        "        print(f'[FAST] DRY RUN: limiting datasets to {dry_run_max_samples} samples (stratified sample)')\n",
        "\n",
        "        def sample_mmap(X_mmap, y, patient_ids, n):\n",
        "            if len(y) <= n:\n",
        "                return X_mmap, y, patient_ids\n",
        "            idx0 = np.where(y == 0)[0]\n",
        "            idx1 = np.where(y == 1)[0]\n",
        "            ratio = len(idx1) / max(len(y), 1)\n",
        "            n1 = max(2, int(round(n * ratio)))\n",
        "            n0 = max(2, n - n1)\n",
        "            chosen0 = np.random.choice(idx0, size=min(n0, len(idx0)), replace=False)\n",
        "            chosen1 = np.random.choice(idx1, size=min(n1, len(idx1)), replace=False)\n",
        "            chosen = np.concatenate([chosen0, chosen1])\n",
        "            np.random.shuffle(chosen)\n",
        "            X_small = np.stack([X_mmap[i].astype(np.float32) for i in chosen])\n",
        "            y_small = y[chosen]\n",
        "            p_small = patient_ids[chosen] if patient_ids is not None else None\n",
        "            return X_small, y_small, p_small\n",
        "\n",
        "        X_train_mmap, y_train, patient_ids_train = sample_mmap(X_train_mmap, y_train, patient_ids_train, dry_run_max_samples)\n",
        "        X_val_mmap,   y_val,   patient_ids_val   = sample_mmap(X_val_mmap,   y_val,   patient_ids_val,   min(max(dry_run_max_samples // 10, 1000), len(y_val)))\n",
        "        X_test_mmap,  y_test,  patient_ids_test  = sample_mmap(X_test_mmap,  y_test,  patient_ids_test,  min(max(dry_run_max_samples // 10, 1000), len(y_test)))\n",
        "\n",
        "    n_train = len(y_train)\n",
        "    n_val   = len(y_val)\n",
        "    n_test  = len(y_test)\n",
        "\n",
        "    print(f'\\n[OK] Training samples: {n_train:,}')\n",
        "    print(f'  Class 0: {(y_train == 0).sum():,} | Class 1: {(y_train == 1).sum():,}')\n",
        "    print(f'[OK] Validation: {n_val:,}, Test: {n_test:,}')\n",
        "\n",
        "    # Sample weights for class imbalance (Original dataset)\n",
        "    train_sample_weights = np.where(y_train == 1, CLASS_WEIGHT[1], CLASS_WEIGHT[0]).astype(np.float32)\n",
        "\n",
        "    # Datasets: training uses weights; val/test do not\n",
        "    train_ds = create_memmap_dataset(X_train_mmap, y_train, batch_size=BATCH_SIZE, shuffle=True, sample_weights=train_sample_weights)\n",
        "    val_ds   = create_memmap_dataset(X_val_mmap,   y_val,   batch_size=BATCH_SIZE, shuffle=False)\n",
        "    test_ds  = create_memmap_dataset(X_test_mmap,  y_test,  batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    steps_per_epoch = math.ceil(n_train / BATCH_SIZE)\n",
        "\n",
        "\n",
        "    # Correct the call (no keyword ACTIVITY):\n",
        "    model = build_rnn((SEQUENCE_LENGTH, N_FEATURES), UNITS, DROPOUT, ACTIVATION)\n",
        "\n",
        "    # Optimizer (with optional loss scaling under mixed precision)\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "    try:\n",
        "        from tensorflow.keras.mixed_precision import LossScaleOptimizer\n",
        "        if tf.keras.mixed_precision.global_policy().name == 'mixed_float16':\n",
        "            optimizer = LossScaleOptimizer(optimizer)\n",
        "            print('[OK] Optimizer wrapped with LossScaleOptimizer')\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    loss_fn = keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss_fn,\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            keras.metrics.AUC(name='auc'),                 # ROC-AUC\n",
        "            keras.metrics.AUC(name='pr_auc', curve='PR'),  # PR-AUC\n",
        "            keras.metrics.Precision(name='precision'),\n",
        "            keras.metrics.Recall(name='recall')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    checkpoint_path = os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_best.weights.h5')\n",
        "    callbacks = [\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            patience=PATIENCE,\n",
        "            restore_best_weights=True,\n",
        "            monitor='val_auc',\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        ),\n",
        "        keras.callbacks.ReduceLROnPlateau(\n",
        "            factor=0.5,\n",
        "            patience=3,\n",
        "            monitor='val_loss',\n",
        "            min_lr=1e-6,\n",
        "            verbose=1\n",
        "        ),\n",
        "        keras.callbacks.ModelCheckpoint(\n",
        "            filepath=checkpoint_path,\n",
        "            monitor='val_auc',\n",
        "            mode='max',\n",
        "            save_best_only=True,\n",
        "            save_weights_only=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        keras.callbacks.CSVLogger(\n",
        "            os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_training_log.csv')\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    print('\\nTRAINING:')\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=EPOCHS,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        callbacks=callbacks,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    epochs_trained = len(history.history['loss'])\n",
        "    print(f'\\n[OK] Training complete: {epochs_trained}/{EPOCHS} epochs')\n",
        "\n",
        "    # Save history\n",
        "    try:\n",
        "        history_serializable = {k: [float(v) for v in vals] for k, vals in history.history.items()}\n",
        "        with open(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_history.json'), 'w') as f:\n",
        "            json.dump(history_serializable, f, indent=2)\n",
        "    except Exception as e:\n",
        "        print('Warning: failed to save history:', e)\n",
        "\n",
        "    # VALIDATION EVALUATION WITH OPTIMAL THRESHOLD\n",
        "    print('\\nEVALUATING: Validation Predictions...')\n",
        "    y_val_pred_proba = model.predict(val_ds, verbose=1).flatten()\n",
        "    if len(y_val_pred_proba) != len(y_val):\n",
        "        y_val_pred_proba = y_val_pred_proba[:len(y_val)]\n",
        "\n",
        "    val_optimal_threshold, val_j_stat = find_optimal_threshold_youden(y_val, y_val_pred_proba)\n",
        "    print(f\"[OK] Optimal threshold (Youden's J): {val_optimal_threshold:.4f} (J={val_j_stat:.4f})\")\n",
        "\n",
        "    y_val_pred_optimal = (y_val_pred_proba >= val_optimal_threshold).astype(int)\n",
        "    y_val_pred_0_5     = (y_val_pred_proba > 0.5).astype(int)\n",
        "\n",
        "    val_metrics_optimal = compute_metrics(y_val, y_val_pred_optimal, y_val_pred_proba, val_optimal_threshold)\n",
        "    val_metrics_0_5     = compute_metrics(y_val, y_val_pred_0_5,     y_val_pred_proba, 0.5)\n",
        "\n",
        "    val_df = pd.DataFrame({\n",
        "        'y_true': y_val,\n",
        "        'y_pred_0.5': y_val_pred_0_5,\n",
        "        'y_pred_optimal': y_val_pred_optimal,\n",
        "        'y_pred_proba': y_val_pred_proba\n",
        "    })\n",
        "    if patient_ids_val is not None:\n",
        "        val_df.insert(0, 'patient_id', patient_ids_val[:len(y_val)])\n",
        "    val_df.to_csv(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_val_predictions.csv'), index=False)\n",
        "    print(f'[OK] Saved validation window-level predictions ({len(val_df)} rows)')\n",
        "\n",
        "    val_patient_metrics = compute_patient_level_metrics(val_df)\n",
        "    if val_patient_metrics:\n",
        "        val_patient_metrics['patient_aggregation'].to_csv(\n",
        "            os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_val_patient_predictions.csv'),\n",
        "            index=False\n",
        "        )\n",
        "        print(f\"[OK] Saved validation patient-level predictions ({val_patient_metrics['n_patients']} patients)\")\n",
        "\n",
        "    # TEST EVALUATION (using validation optimal threshold)\n",
        "    print('\\nEVALUATING: Test Predictions...')\n",
        "    y_test_pred_proba = model.predict(test_ds, verbose=1).flatten()\n",
        "    if len(y_test_pred_proba) != len(y_test):\n",
        "        y_test_pred_proba = y_test_pred_proba[:len(y_test)]\n",
        "\n",
        "    y_test_pred_optimal = (y_test_pred_proba >= val_optimal_threshold).astype(int)\n",
        "\n",
        "    # Correct line:\n",
        "    y_test_pred_0_5     = (y_test_pred_proba > 0.5).astype(int)\n",
        "\n",
        "    test_metrics_optimal = compute_metrics(y_test, y_test_pred_optimal, y_test_pred_proba, val_optimal_threshold)\n",
        "    test_metrics_0_5     = compute_metrics(y_test, y_test_pred_0_5,     y_test_pred_proba, 0.5)\n",
        "\n",
        "    test_df = pd.DataFrame({\n",
        "        'y_true': y_test,\n",
        "        'y_pred_0.5': y_test_pred_0_5,\n",
        "        'y_pred_optimal': y_test_pred_optimal,\n",
        "        'y_pred_proba': y_test_pred_proba\n",
        "    })\n",
        "    if patient_ids_test is not None:\n",
        "        test_df.insert(0, 'patient_id', patient_ids_test[:len(y_test)])\n",
        "    test_df.to_csv(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_test_predictions.csv'), index=False)\n",
        "    print(f'[OK] Saved test window-level predictions ({len(test_df)} rows)')\n",
        "\n",
        "    test_patient_metrics = compute_patient_level_metrics(test_df)\n",
        "    if test_patient_metrics:\n",
        "        test_patient_metrics['patient_aggregation'].to_csv(\n",
        "            os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_test_patient_predictions.csv'),\n",
        "            index=False\n",
        "        )\n",
        "        print(f\"[OK] Saved test patient-level predictions ({test_patient_metrics['n_patients']} patients)\")\n",
        "\n",
        "    # Save comprehensive results\n",
        "    results = {\n",
        "        'model_name': MODEL_NAME,\n",
        "        'dataset': 'Original',\n",
        "        'model_type': 'RNN',\n",
        "        'optimizer': OPTIMIZER_NAME,\n",
        "        'activation': 'gelu',\n",
        "        'train_samples': int(n_train),\n",
        "        'val_samples': int(n_val),\n",
        "        'test_samples': int(n_test),\n",
        "        'max_epochs': EPOCHS,\n",
        "        'epochs_trained': int(epochs_trained),\n",
        "        'early_stopped': bool(epochs_trained < EPOCHS),\n",
        "        'steps_per_epoch': steps_per_epoch,\n",
        "        'units': UNITS,\n",
        "        'dropout': DROPOUT,\n",
        "        'learning_rate': LEARNING_RATE,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'random_state': RANDOM_STATE,\n",
        "        'class_weight': CLASS_WEIGHT,\n",
        "        'optimal_threshold': val_optimal_threshold,\n",
        "        'youden_j_statistic': val_j_stat,\n",
        "        'validation_metrics': {\n",
        "            'window_level_0.5_threshold': val_metrics_0_5,\n",
        "            'window_level_optimal_threshold': val_metrics_optimal,\n",
        "            'patient_level': val_patient_metrics if val_patient_metrics else None\n",
        "        },\n",
        "        'test_metrics': {\n",
        "            'window_level_0.5_threshold': test_metrics_0_5,\n",
        "            'window_level_optimal_threshold': test_metrics_optimal,\n",
        "            'patient_level': test_patient_metrics if test_patient_metrics else None\n",
        "        }\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_results.json'), 'w') as f:\n",
        "        json.dump(results, f, indent=2, default=str)\n",
        "\n",
        "    # Save final model\n",
        "    final_model_path = os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_final.h5')\n",
        "    try:\n",
        "        model.save(final_model_path)\n",
        "        print(f'[OK] Model saved: {final_model_path}')\n",
        "    except Exception as e:\n",
        "        print('Warning: full model.save failed, saving weights only. Error:', e)\n",
        "        try:\n",
        "            model.save_weights(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_final_weights.h5'))\n",
        "            print('[OK] Weights saved as fallback')\n",
        "        except Exception as e2:\n",
        "            print('ERROR: failed to save weights as well:', e2)\n",
        "\n",
        "    print('\\nTRAINING SUMMARY')\n",
        "    print('='*80)\n",
        "    print(f\"Dataset: Original (train samples: {n_train:,})\")\n",
        "    print(f\"Epochs trained: {epochs_trained}/{EPOCHS}\")\n",
        "    print(f\"\\nOptimal threshold (Youden's J): {val_optimal_threshold:.4f}\")\n",
        "    print('\\nValidation metrics (window-level at optimal threshold):')\n",
        "    for k, v in val_metrics_optimal.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "    print('\\nTest metrics (window-level at optimal threshold):')\n",
        "    for k, v in test_metrics_optimal.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    DRY_RUN = False\n",
        "    DRY_RUN_SAMPLES = 1000\n",
        "\n",
        "    if DRY_RUN:\n",
        "        MODEL_NAME = MODEL_NAME + '_DRY_RUN'\n",
        "        print(\"=\"*80)\n",
        "        print(\"[TEST] DRY RUN MODE: Quick validation with small sample\")\n",
        "        print(f\"   Using {DRY_RUN_SAMPLES:,} training samples\")\n",
        "        print(f\"   Files will be saved with suffix: _DRY_RUN\")\n",
        "        print(\"=\"*80)\n",
        "        main(dry_run_max_samples=DRY_RUN_SAMPLES)\n",
        "    else:\n",
        "        print(\"=\"*80)\n",
        "        print(\"[FULL] FULL TRAINING MODE: Complete dataset\")\n",
        "        print(\"   Using all available training samples\")\n",
        "        print(\"=\"*80)\n",
        "        main(dry_run_max_samples=None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl4S_wAwelQv",
        "outputId": "37cab04e-cc4d-4548-f4dd-a30ddb505439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "[TEST] DRY RUN MODE: Quick validation with small sample\n",
            "   Using 1,000 training samples\n",
            "   Files will be saved with suffix: _DRY_RUN\n",
            "================================================================================\n",
            "[OK] Mixed precision (float16) policy enabled\n",
            "\n",
            "Loading memmap datasets...\n",
            "[FAST] DRY RUN: limiting datasets to 1000 samples (stratified sample)\n",
            "\n",
            "[OK] Training samples: 1,000\n",
            "  Class 0: 984 | Class 1: 16\n",
            "[OK] Validation: 1,000, Test: 1,000\n",
            "[OK] Optimizer wrapped with LossScaleOptimizer\n",
            "\n",
            "TRAINING:\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 1: val_auc improved from -inf to 0.57215, saving model to /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Original_RNN_adam_gelu_DRY_RUN_best.weights.h5\n",
            "4/4 - 10s - 2s/step - accuracy: 0.1110 - auc: 0.5100 - loss: 10.7631 - pr_auc: 0.0168 - precision: 0.0145 - recall: 0.8125 - val_accuracy: 0.0530 - val_auc: 0.5722 - val_loss: 2.3656 - val_pr_auc: 0.0291 - val_precision: 0.0146 - val_recall: 0.8750 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 2: val_auc did not improve from 0.57215\n",
            "4/4 - 1s - 199ms/step - accuracy: 0.6330 - auc: 0.4409 - loss: 9.4232 - pr_auc: 0.0161 - precision: 0.0165 - recall: 0.3750 - val_accuracy: 0.9840 - val_auc: 0.4579 - val_loss: 0.1246 - val_pr_auc: 0.0141 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 3: val_auc did not improve from 0.57215\n",
            "4/4 - 1s - 193ms/step - accuracy: 0.7850 - auc: 0.4457 - loss: 6.4722 - pr_auc: 0.0132 - precision: 0.0050 - recall: 0.0625 - val_accuracy: 0.9740 - val_auc: 0.3659 - val_loss: 0.2944 - val_pr_auc: 0.0113 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: val_auc did not improve from 0.57215\n",
            "4/4 - 1s - 184ms/step - accuracy: 0.4190 - auc: 0.4852 - loss: 4.7051 - pr_auc: 0.0186 - precision: 0.0121 - recall: 0.4375 - val_accuracy: 0.0200 - val_auc: 0.5022 - val_loss: 2.8432 - val_pr_auc: 0.0149 - val_precision: 0.0151 - val_recall: 0.9375 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 5: val_auc did not improve from 0.57215\n",
            "4/4 - 1s - 182ms/step - accuracy: 0.3080 - auc: 0.5061 - loss: 4.2704 - pr_auc: 0.0162 - precision: 0.0185 - recall: 0.8125 - val_accuracy: 0.1210 - val_auc: 0.4058 - val_loss: 1.0729 - val_pr_auc: 0.0121 - val_precision: 0.0157 - val_recall: 0.8750 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 6: val_auc did not improve from 0.57215\n",
            "4/4 - 1s - 316ms/step - accuracy: 0.4220 - auc: 0.3831 - loss: 3.6636 - pr_auc: 0.0138 - precision: 0.0070 - recall: 0.2500 - val_accuracy: 0.9340 - val_auc: 0.3268 - val_loss: 0.4281 - val_pr_auc: 0.0111 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 6: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "\n",
            "[OK] Training complete: 6/50 epochs\n",
            "\n",
            "EVALUATING: Validation Predictions...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step\n",
            "[OK] Optimal threshold (Youden's J): 0.9166 (J=0.1819)\n",
            "[OK] Saved validation window-level predictions (1000 rows)\n",
            "[OK] Patient-level aggregation: 897 patients\n",
            "  Positive patients: 16\n",
            "  Negative patients: 881\n",
            "[OK] Saved validation patient-level predictions (897 patients)\n",
            "\n",
            "EVALUATING: Test Predictions...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Saved test window-level predictions (1000 rows)\n",
            "[OK] Patient-level aggregation: 888 patients\n",
            "  Positive patients: 17\n",
            "  Negative patients: 871\n",
            "[OK] Saved test patient-level predictions (888 patients)\n",
            "[OK] Model saved: /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Original_RNN_adam_gelu_DRY_RUN_final.h5\n",
            "\n",
            "TRAINING SUMMARY\n",
            "================================================================================\n",
            "Dataset: Original (train samples: 1,000)\n",
            "Epochs trained: 6/50\n",
            "\n",
            "Optimal threshold (Youden's J): 0.9166\n",
            "\n",
            "Validation metrics (window-level at optimal threshold):\n",
            "  threshold: 0.9165747761726379\n",
            "  roc_auc: 0.5708206300813008\n",
            "  pr_auc: 0.029489578367166105\n",
            "  sensitivity: 0.625\n",
            "  specificity: 0.556910569105691\n",
            "  precision: 0.02242152466367713\n",
            "  npv: 0.9891696750902527\n",
            "  f1_score: 0.04329004329004329\n",
            "  tp: 10\n",
            "  tn: 548\n",
            "  fp: 436\n",
            "  fn: 6\n",
            "\n",
            "Test metrics (window-level at optimal threshold):\n",
            "  threshold: 0.9165747761726379\n",
            "  roc_auc: 0.5916462210520017\n",
            "  pr_auc: 0.024566808122580087\n",
            "  sensitivity: 0.5882352941176471\n",
            "  specificity: 0.5401831129196337\n",
            "  precision: 0.021645021645021644\n",
            "  npv: 0.9869888475836431\n",
            "  f1_score: 0.04175365344467641\n",
            "  tp: 10\n",
            "  tn: 531\n",
            "  fp: 452\n",
            "  fn: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " GRU"
      ],
      "metadata": {
        "id": "IciMzHJIerQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Stage 2 Baseline Training: Original GRU (adam-gelu) - PRODUCTION RUN SCRIPT v2\n",
        "Enhanced with:\n",
        "- Complete TF reproducibility (tf.random.set_seed)\n",
        "- Youden J statistic for optimal threshold selection\n",
        "- Patient-level aggregation and metrics\n",
        "- Mixed precision and GPU memory growth\n",
        "- Class weighting for Original dataset imbalance\n",
        "- PR-AUC metric tracking (curve='PR')\n",
        "- Robust error handling with all required keys\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import math\n",
        "import json\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import mixed_precision\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, confusion_matrix, roc_curve\n",
        "\n",
        "# -------------------------------\n",
        "# Configurable parameters\n",
        "# -------------------------------\n",
        "BASE_DIR = '/content/drive/MyDrive/AI_Course_Project/Dataset'\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, 'Stage2_Baseline')\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Original dataset paths\n",
        "TRAIN_PATH = os.path.join(BASE_DIR, 'baseline_train_matrices.npz')\n",
        "VAL_PATH   = os.path.join(BASE_DIR, 'baseline_val_matrices.npz')\n",
        "TEST_PATH  = os.path.join(BASE_DIR, 'baseline_test_matrices.npz')\n",
        "\n",
        "# Best combo for Original GRU (highest ROC-AUC: 0.727)\n",
        "MODEL_NAME     = 'Original_GRU_adam_gelu'\n",
        "OPTIMIZER_NAME = 'adam'\n",
        "ACTIVATION     = tf.nn.gelu  # callable GELU for robustness\n",
        "\n",
        "# Class weights for Original dataset (heavily imbalanced)\n",
        "CLASS_WEIGHT = {0: 1.0, 1: 61.0}\n",
        "\n",
        "# Hyperparameters\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 256\n",
        "UNITS = 128\n",
        "DROPOUT = 0.3\n",
        "LEARNING_RATE = 0.001\n",
        "PATIENCE = 5\n",
        "\n",
        "SEQUENCE_LENGTH = 4\n",
        "N_FEATURES = 21\n",
        "\n",
        "# Reproducibility - COMPLETE SEEDING\n",
        "RANDOM_STATE = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(RANDOM_STATE)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "np.random.seed(RANDOM_STATE)\n",
        "tf.random.set_seed(RANDOM_STATE)\n",
        "random.seed(RANDOM_STATE)\n",
        "\n",
        "# -------------------------------\n",
        "# Utility functions\n",
        "# -------------------------------\n",
        "def set_gpu_and_mixed_precision():\n",
        "    \"\"\"Enable memory growth and mixed precision if available.\"\"\"\n",
        "    try:\n",
        "        policy = mixed_precision.Policy('mixed_float16')\n",
        "        mixed_precision.set_global_policy(policy)\n",
        "        print(\"[OK] Mixed precision (float16) policy enabled\")\n",
        "    except Exception:\n",
        "        print(\"[INFO] Mixed precision not available\")\n",
        "\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        for gpu in gpus:\n",
        "            try:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "            except Exception:\n",
        "                pass\n",
        "        print(f\"[OK] GPU memory growth enabled for {len(gpus)} GPU(s)\")\n",
        "\n",
        "def load_data_memmap_with_ids(path):\n",
        "    \"\"\"Load X (memmap), y (numpy), and optional patient_ids from .npz using mmap.\"\"\"\n",
        "    npz = np.load(path, mmap_mode='r')\n",
        "    X = npz['X']\n",
        "    y = np.array(npz['y'])\n",
        "    patient_ids = None\n",
        "    if 'patient_ids' in npz.files:\n",
        "        patient_ids = np.array(npz['patient_ids'])\n",
        "    return X, y, patient_ids\n",
        "\n",
        "def create_memmap_dataset(X_mmap, y, batch_size, shuffle=False, buffer_size=10000, sample_weights=None):\n",
        "    \"\"\"\n",
        "    Create a tf.data.Dataset that loads samples from a memmap by index.\n",
        "    If sample_weights is provided, yields (x, y, w) for weighted training.\n",
        "    Casts input to current mixed-precision compute dtype if enabled.\n",
        "    \"\"\"\n",
        "    n_samples = len(y)\n",
        "    indices = np.arange(n_samples, dtype=np.int64)\n",
        "    labels = y.copy().astype(np.int32)\n",
        "\n",
        "    if sample_weights is not None:\n",
        "        weights = np.array(sample_weights, dtype=np.float32)\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((indices, labels, weights))\n",
        "    else:\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((indices, labels))\n",
        "\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=buffer_size, seed=RANDOM_STATE, reshuffle_each_iteration=True)\n",
        "\n",
        "    def load_sample(*args):\n",
        "        if sample_weights is not None:\n",
        "            idx, label, weight = args\n",
        "        else:\n",
        "            idx, label = args\n",
        "\n",
        "        def _load(idx_val):\n",
        "            return X_mmap[int(idx_val)].astype(np.float32)\n",
        "\n",
        "        x = tf.numpy_function(_load, [idx], tf.float32)\n",
        "\n",
        "        # safe cast to mixed-precision compute dtype (float16 if policy set)\n",
        "        try:\n",
        "            compute_dtype = mixed_precision.global_policy().compute_dtype\n",
        "        except Exception:\n",
        "            compute_dtype = 'float32'\n",
        "        x = tf.cast(x, compute_dtype)\n",
        "\n",
        "        x.set_shape((SEQUENCE_LENGTH, N_FEATURES))\n",
        "\n",
        "        if sample_weights is not None:\n",
        "            return x, label, weight\n",
        "        else:\n",
        "            return x, label\n",
        "\n",
        "    dataset = dataset.map(load_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=False)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "def build_gru(input_shape, units, dropout, activation):\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Masking(mask_value=-1.0),\n",
        "        layers.GRU(units, activation=activation, return_sequences=False),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(64, activation=activation),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(1, activation='sigmoid', dtype='float32')\n",
        "    ], name='GRU')\n",
        "    return model\n",
        "\n",
        "def find_optimal_threshold_youden(y_true, y_pred_proba):\n",
        "    \"\"\"Find optimal threshold using Youden's J statistic (maximizes sensitivity + specificity - 1).\"\"\"\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
        "    j_scores = tpr - fpr  # Youden's J statistic\n",
        "    optimal_idx = np.argmax(j_scores)\n",
        "    optimal_threshold = thresholds[optimal_idx]\n",
        "    return float(optimal_threshold), float(j_scores[optimal_idx])\n",
        "\n",
        "def compute_metrics(y_true, y_pred, y_pred_proba, threshold=0.5):\n",
        "    \"\"\"Compute comprehensive metrics with robust error handling.\"\"\"\n",
        "    try:\n",
        "        cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "        if cm.size == 4:\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "        else:\n",
        "            tn = fp = fn = tp = 0\n",
        "\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "        precision_val = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "        npv = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n",
        "        f1 = 2 * (precision_val * sensitivity) / (precision_val + sensitivity) if (precision_val + sensitivity) > 0 else 0.0\n",
        "\n",
        "        roc_auc = roc_auc_score(y_true, y_pred_proba) if len(np.unique(y_true)) > 1 else 0.0\n",
        "\n",
        "        if len(np.unique(y_true)) > 1:\n",
        "            precision_curve, recall_curve, _ = precision_recall_curve(y_true, y_pred_proba)\n",
        "            pr_auc = auc(recall_curve, precision_curve)\n",
        "        else:\n",
        "            pr_auc = 0.0\n",
        "\n",
        "        return {\n",
        "            'threshold': float(threshold),\n",
        "            'roc_auc': float(roc_auc),\n",
        "            'pr_auc': float(pr_auc),\n",
        "            'sensitivity': float(sensitivity),\n",
        "            'specificity': float(specificity),\n",
        "            'precision': float(precision_val),\n",
        "            'npv': float(npv),\n",
        "            'f1_score': float(f1),\n",
        "            'tp': int(tp), 'tn': int(tn), 'fp': int(fp), 'fn': int(fn)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f'Warning: Error computing metrics: {e}')\n",
        "        return {\n",
        "            'threshold': float(threshold),\n",
        "            'roc_auc': 0.0, 'pr_auc': 0.0,\n",
        "            'sensitivity': 0.0, 'specificity': 0.0,\n",
        "            'precision': 0.0, 'npv': 0.0, 'f1_score': 0.0,\n",
        "            'tp': 0, 'tn': 0, 'fp': 0, 'fn': 0\n",
        "        }\n",
        "\n",
        "def compute_patient_level_metrics(pred_df):\n",
        "    \"\"\"\n",
        "    Patient-level aggregation and metrics.\n",
        "    - y_true: max across windows\n",
        "    - y_pred_proba: max across windows\n",
        "    \"\"\"\n",
        "    if 'patient_id' not in pred_df.columns or pred_df['patient_id'].isna().all():\n",
        "        print(\"[WARNING] No patient IDs available for patient-level aggregation\")\n",
        "        return None\n",
        "\n",
        "    patient_agg = pred_df.groupby('patient_id').agg({\n",
        "        'y_true': 'max',\n",
        "        'y_pred_proba': 'max'\n",
        "    }).reset_index()\n",
        "\n",
        "    unique_labels = patient_agg['y_true'].unique()\n",
        "    if len(unique_labels) < 2:\n",
        "        print(f\"[WARNING] Only {len(unique_labels)} class(es) in patient-level data. Metrics may be invalid.\")\n",
        "\n",
        "    try:\n",
        "        optimal_threshold, j_stat = find_optimal_threshold_youden(\n",
        "            patient_agg['y_true'].values,\n",
        "            patient_agg['y_pred_proba'].values\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"[WARNING] Could not compute optimal threshold: {e}. Using 0.5.\")\n",
        "        optimal_threshold = 0.5\n",
        "        j_stat = 0.0\n",
        "\n",
        "    patient_agg['y_pred_optimal'] = (patient_agg['y_pred_proba'] >= optimal_threshold).astype(int)\n",
        "\n",
        "    metrics_optimal = compute_metrics(\n",
        "        patient_agg['y_true'].values,\n",
        "        patient_agg['y_pred_optimal'].values,\n",
        "        patient_agg['y_pred_proba'].values,\n",
        "        threshold=optimal_threshold\n",
        "    )\n",
        "\n",
        "    patient_agg['y_pred_0.5'] = (patient_agg['y_pred_proba'] >= 0.5).astype(int)\n",
        "    metrics_0_5 = compute_metrics(\n",
        "        patient_agg['y_true'].values,\n",
        "        patient_agg['y_pred_0.5'].values,\n",
        "        patient_agg['y_pred_proba'].values,\n",
        "        threshold=0.5\n",
        "    )\n",
        "\n",
        "    print(f\"[OK] Patient-level aggregation: {len(patient_agg)} patients\")\n",
        "    print(f\"  Positive patients: {patient_agg['y_true'].sum()}\")\n",
        "    print(f\"  Negative patients: {(patient_agg['y_true'] == 0).sum()}\")\n",
        "\n",
        "    return {\n",
        "        'patient_aggregation': patient_agg,\n",
        "        'n_patients': len(patient_agg),\n",
        "        'n_positive_patients': int(patient_agg['y_true'].sum()),\n",
        "        'n_negative_patients': int((patient_agg['y_true'] == 0).sum()),\n",
        "        'optimal_threshold': optimal_threshold,\n",
        "        'youden_j_statistic': j_stat,\n",
        "        'metrics_at_optimal_threshold': metrics_optimal,\n",
        "        'metrics_at_0.5_threshold': metrics_0_5\n",
        "    }\n",
        "\n",
        "# -------------------------------\n",
        "# Main run\n",
        "# -------------------------------\n",
        "def main(dry_run_max_samples=None):\n",
        "    set_gpu_and_mixed_precision()\n",
        "\n",
        "    print('\\nLoading memmap datasets...')\n",
        "    X_train_mmap, y_train, patient_ids_train = load_data_memmap_with_ids(TRAIN_PATH)\n",
        "    X_val_mmap,   y_val,   patient_ids_val   = load_data_memmap_with_ids(VAL_PATH)\n",
        "    X_test_mmap,  y_test,  patient_ids_test  = load_data_memmap_with_ids(TEST_PATH)\n",
        "\n",
        "    # Optional quick dry run\n",
        "    if dry_run_max_samples is not None:\n",
        "        print(f'[FAST] DRY RUN: limiting datasets to {dry_run_max_samples} samples (stratified sample)')\n",
        "\n",
        "        def sample_mmap(X_mmap, y, patient_ids, n):\n",
        "            if len(y) <= n:\n",
        "                return X_mmap, y, patient_ids\n",
        "            idx0 = np.where(y == 0)[0]\n",
        "            idx1 = np.where(y == 1)[0]\n",
        "            ratio = len(idx1) / max(len(y), 1)\n",
        "            n1 = max(2, int(round(n * ratio)))\n",
        "            n0 = max(2, n - n1)\n",
        "            chosen0 = np.random.choice(idx0, size=min(n0, len(idx0)), replace=False)\n",
        "            chosen1 = np.random.choice(idx1, size=min(n1, len(idx1)), replace=False)\n",
        "            chosen = np.concatenate([chosen0, chosen1])\n",
        "            np.random.shuffle(chosen)\n",
        "            X_small = np.stack([X_mmap[i].astype(np.float32) for i in chosen])\n",
        "            y_small = y[chosen]\n",
        "            p_small = patient_ids[chosen] if patient_ids is not None else None\n",
        "            return X_small, y_small, p_small\n",
        "\n",
        "        X_train_mmap, y_train, patient_ids_train = sample_mmap(X_train_mmap, y_train, patient_ids_train, dry_run_max_samples)\n",
        "        X_val_mmap,   y_val,   patient_ids_val   = sample_mmap(X_val_mmap,   y_val,   patient_ids_val,   min(max(dry_run_max_samples // 10, 1000), len(y_val)))\n",
        "        X_test_mmap,  y_test,  patient_ids_test  = sample_mmap(X_test_mmap,  y_test,  patient_ids_test,  min(max(dry_run_max_samples // 10, 1000), len(y_test)))\n",
        "\n",
        "    n_train = len(y_train)\n",
        "    n_val   = len(y_val)\n",
        "    n_test  = len(y_test)\n",
        "\n",
        "    print(f'\\n[OK] Training samples: {n_train:,}')\n",
        "    print(f'  Class 0: {(y_train == 0).sum():,} | Class 1: {(y_train == 1).sum():,}')\n",
        "    print(f'[OK] Validation: {n_val:,}, Test: {n_test:,}')\n",
        "\n",
        "    # Sample weights for class imbalance (Original dataset)\n",
        "    train_sample_weights = np.where(y_train == 1, CLASS_WEIGHT[1], CLASS_WEIGHT[0]).astype(np.float32)\n",
        "\n",
        "    # Datasets: training uses weights; val/test do not\n",
        "    train_ds = create_memmap_dataset(X_train_mmap, y_train, batch_size=BATCH_SIZE, shuffle=True, sample_weights=train_sample_weights)\n",
        "    val_ds   = create_memmap_dataset(X_val_mmap,   y_val,   batch_size=BATCH_SIZE, shuffle=False)\n",
        "    test_ds  = create_memmap_dataset(X_test_mmap,  y_test,  batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    steps_per_epoch = math.ceil(n_train / BATCH_SIZE)\n",
        "\n",
        "    # Model\n",
        "    model = build_gru((SEQUENCE_LENGTH, N_FEATURES), UNITS, DROPOUT, ACTIVATION)\n",
        "\n",
        "    # Optimizer (with optional loss scaling under mixed precision)\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "    try:\n",
        "        from tensorflow.keras.mixed_precision import LossScaleOptimizer\n",
        "        if tf.keras.mixed_precision.global_policy().name == 'mixed_float16':\n",
        "            optimizer = LossScaleOptimizer(optimizer)\n",
        "            print('[OK] Optimizer wrapped with LossScaleOptimizer')\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    loss_fn = keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss_fn,\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            keras.metrics.AUC(name='auc'),                 # ROC-AUC\n",
        "            keras.metrics.AUC(name='pr_auc', curve='PR'),  # PR-AUC\n",
        "            keras.metrics.Precision(name='precision'),\n",
        "            keras.metrics.Recall(name='recall')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    checkpoint_path = os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_best.weights.h5')\n",
        "    callbacks = [\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            patience=PATIENCE,\n",
        "            restore_best_weights=True,\n",
        "            monitor='val_auc',\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        ),\n",
        "        keras.callbacks.ReduceLROnPlateau(\n",
        "            factor=0.5,\n",
        "            patience=3,\n",
        "            monitor='val_loss',\n",
        "            min_lr=1e-6,\n",
        "            verbose=1\n",
        "        ),\n",
        "        keras.callbacks.ModelCheckpoint(\n",
        "            filepath=checkpoint_path,\n",
        "            monitor='val_auc',\n",
        "            mode='max',\n",
        "            save_best_only=True,\n",
        "            save_weights_only=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        keras.callbacks.CSVLogger(\n",
        "            os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_training_log.csv')\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    print('\\nTRAINING:')\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=EPOCHS,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        callbacks=callbacks,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    epochs_trained = len(history.history['loss'])\n",
        "    print(f'\\n[OK] Training complete: {epochs_trained}/{EPOCHS} epochs')\n",
        "\n",
        "    # Save history\n",
        "    try:\n",
        "        history_serializable = {k: [float(v) for v in vals] for k, vals in history.history.items()}\n",
        "        with open(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_history.json'), 'w') as f:\n",
        "            json.dump(history_serializable, f, indent=2)\n",
        "    except Exception as e:\n",
        "        print('Warning: failed to save history:', e)\n",
        "\n",
        "    # VALIDATION EVALUATION WITH OPTIMAL THRESHOLD\n",
        "    print('\\nEVALUATING: Validation Predictions...')\n",
        "    y_val_pred_proba = model.predict(val_ds, verbose=1).flatten()\n",
        "    if len(y_val_pred_proba) != len(y_val):\n",
        "        y_val_pred_proba = y_val_pred_proba[:len(y_val)]\n",
        "\n",
        "    val_optimal_threshold, val_j_stat = find_optimal_threshold_youden(y_val, y_val_pred_proba)\n",
        "    print(f\"[OK] Optimal threshold (Youden's J): {val_optimal_threshold:.4f} (J={val_j_stat:.4f})\")\n",
        "\n",
        "    y_val_pred_optimal = (y_val_pred_proba >= val_optimal_threshold).astype(int)\n",
        "    y_val_pred_0_5     = (y_val_pred_proba > 0.5).astype(int)\n",
        "\n",
        "    val_metrics_optimal = compute_metrics(y_val, y_val_pred_optimal, y_val_pred_proba, val_optimal_threshold)\n",
        "    val_metrics_0_5     = compute_metrics(y_val, y_val_pred_0_5,     y_val_pred_proba, 0.5)\n",
        "\n",
        "    val_df = pd.DataFrame({\n",
        "        'y_true': y_val,\n",
        "        'y_pred_0.5': y_val_pred_0_5,\n",
        "        'y_pred_optimal': y_val_pred_optimal,\n",
        "        'y_pred_proba': y_val_pred_proba\n",
        "    })\n",
        "    if patient_ids_val is not None:\n",
        "        val_df.insert(0, 'patient_id', patient_ids_val[:len(y_val)])\n",
        "    val_df.to_csv(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_val_predictions.csv'), index=False)\n",
        "    print(f'[OK] Saved validation window-level predictions ({len(val_df)} rows)')\n",
        "\n",
        "    val_patient_metrics = compute_patient_level_metrics(val_df)\n",
        "    if val_patient_metrics:\n",
        "        val_patient_metrics['patient_aggregation'].to_csv(\n",
        "            os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_val_patient_predictions.csv'),\n",
        "            index=False\n",
        "        )\n",
        "        print(f\"[OK] Saved validation patient-level predictions ({val_patient_metrics['n_patients']} patients)\")\n",
        "\n",
        "    # TEST EVALUATION (using validation optimal threshold)\n",
        "    print('\\nEVALUATING: Test Predictions...')\n",
        "    y_test_pred_proba = model.predict(test_ds, verbose=1).flatten()\n",
        "    if len(y_test_pred_proba) != len(y_test):\n",
        "        y_test_pred_proba = y_test_pred_proba[:len(y_test)]\n",
        "\n",
        "    y_test_pred_optimal = (y_test_pred_proba >= val_optimal_threshold).astype(int)\n",
        "    y_test_pred_0_5     = (y_test_pred_proba > 0.5).astype(int)\n",
        "\n",
        "    test_metrics_optimal = compute_metrics(y_test, y_test_pred_optimal, y_test_pred_proba, val_optimal_threshold)\n",
        "    test_metrics_0_5     = compute_metrics(y_test, y_test_pred_0_5,     y_test_pred_proba, 0.5)\n",
        "\n",
        "    test_df = pd.DataFrame({\n",
        "        'y_true': y_test,\n",
        "        'y_pred_0.5': y_test_pred_0_5,\n",
        "        'y_pred_optimal': y_test_pred_optimal,\n",
        "        'y_pred_proba': y_test_pred_proba\n",
        "    })\n",
        "    if patient_ids_test is not None:\n",
        "        test_df.insert(0, 'patient_id', patient_ids_test[:len(y_test)])\n",
        "    test_df.to_csv(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_test_predictions.csv'), index=False)\n",
        "    print(f'[OK] Saved test window-level predictions ({len(test_df)} rows)')\n",
        "\n",
        "    test_patient_metrics = compute_patient_level_metrics(test_df)\n",
        "    if test_patient_metrics:\n",
        "        test_patient_metrics['patient_aggregation'].to_csv(\n",
        "            os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_test_patient_predictions.csv'),\n",
        "            index=False\n",
        "        )\n",
        "        print(f\"[OK] Saved test patient-level predictions ({test_patient_metrics['n_patients']} patients)\")\n",
        "\n",
        "    # Save comprehensive results\n",
        "    results = {\n",
        "        'model_name': MODEL_NAME,\n",
        "        'dataset': 'Original',\n",
        "        'model_type': 'GRU',\n",
        "        'optimizer': OPTIMIZER_NAME,\n",
        "        'activation': 'gelu',\n",
        "        'train_samples': int(n_train),\n",
        "        'val_samples': int(n_val),\n",
        "        'test_samples': int(n_test),\n",
        "        'max_epochs': EPOCHS,\n",
        "        'epochs_trained': int(epochs_trained),\n",
        "        'early_stopped': bool(epochs_trained < EPOCHS),\n",
        "        'steps_per_epoch': steps_per_epoch,\n",
        "        'units': UNITS,\n",
        "        'dropout': DROPOUT,\n",
        "        'learning_rate': LEARNING_RATE,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'random_state': RANDOM_STATE,\n",
        "        'class_weight': CLASS_WEIGHT,\n",
        "        'optimal_threshold': val_optimal_threshold,\n",
        "        'youden_j_statistic': val_j_stat,\n",
        "        'validation_metrics': {\n",
        "            'window_level_0.5_threshold': val_metrics_0_5,\n",
        "            'window_level_optimal_threshold': val_metrics_optimal,\n",
        "            'patient_level': val_patient_metrics if val_patient_metrics else None\n",
        "        },\n",
        "        'test_metrics': {\n",
        "            'window_level_0.5_threshold': test_metrics_0_5,\n",
        "            'window_level_optimal_threshold': test_metrics_optimal,\n",
        "            'patient_level': test_patient_metrics if test_patient_metrics else None\n",
        "        }\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_results.json'), 'w') as f:\n",
        "        json.dump(results, f, indent=2, default=str)\n",
        "\n",
        "    # Save final model\n",
        "    final_model_path = os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_final.h5')\n",
        "    try:\n",
        "        model.save(final_model_path)\n",
        "        print(f'[OK] Model saved: {final_model_path}')\n",
        "    except Exception as e:\n",
        "        print('Warning: full model.save failed, saving weights only. Error:', e)\n",
        "        try:\n",
        "            model.save_weights(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_final_weights.h5'))\n",
        "            print('[OK] Weights saved as fallback')\n",
        "        except Exception as e2:\n",
        "            print('ERROR: failed to save weights as well:', e2)\n",
        "\n",
        "    print('\\nTRAINING SUMMARY')\n",
        "    print('='*80)\n",
        "    print(f\"Dataset: Original (train samples: {n_train:,})\")\n",
        "    print(f\"Epochs trained: {epochs_trained}/{EPOCHS}\")\n",
        "    print(f\"\\nOptimal threshold (Youden's J): {val_optimal_threshold:.4f}\")\n",
        "    print('\\nValidation metrics (window-level at optimal threshold):')\n",
        "    for k, v in val_metrics_optimal.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "    print('\\nTest metrics (window-level at optimal threshold):')\n",
        "    for k, v in test_metrics_optimal.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    DRY_RUN = False\n",
        "    DRY_RUN_SAMPLES = 1000\n",
        "\n",
        "    if DRY_RUN:\n",
        "        MODEL_NAME = MODEL_NAME + '_DRY_RUN'\n",
        "        print(\"=\"*80)\n",
        "        print(\"[TEST] DRY RUN MODE: Quick validation with small sample\")\n",
        "        print(f\"   Using {DRY_RUN_SAMPLES:,} training samples\")\n",
        "        print(f\"   Files will be saved with suffix: _DRY_RUN\")\n",
        "        print(\"=\"*80)\n",
        "        main(dry_run_max_samples=DRY_RUN_SAMPLES)\n",
        "    else:\n",
        "        print(\"=\"*80)\n",
        "        print(\"[FULL] FULL TRAINING MODE: Complete dataset\")\n",
        "        print(\"   Using all available training samples\")\n",
        "        print(\"=\"*80)\n",
        "        main(dry_run_max_samples=None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXqAl7OpesSH",
        "outputId": "7e07ece2-cc4e-4b36-ecee-411481fcc9e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "[TEST] DRY RUN MODE: Quick validation with small sample\n",
            "   Using 1,000 training samples\n",
            "   Files will be saved with suffix: _DRY_RUN\n",
            "================================================================================\n",
            "[OK] Mixed precision (float16) policy enabled\n",
            "\n",
            "Loading memmap datasets...\n",
            "[FAST] DRY RUN: limiting datasets to 1000 samples (stratified sample)\n",
            "\n",
            "[OK] Training samples: 1,000\n",
            "  Class 0: 984 | Class 1: 16\n",
            "[OK] Validation: 1,000, Test: 1,000\n",
            "[OK] Optimizer wrapped with LossScaleOptimizer\n",
            "\n",
            "TRAINING:\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 1: val_auc improved from -inf to 0.65098, saving model to /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Original_GRU_adam_gelu_DRY_RUN_best.weights.h5\n",
            "4/4 - 12s - 3s/step - accuracy: 0.2450 - auc: 0.4110 - loss: 3.0715 - pr_auc: 0.0132 - precision: 0.0132 - recall: 0.6250 - val_accuracy: 0.0910 - val_auc: 0.6510 - val_loss: 1.1308 - val_pr_auc: 0.0495 - val_precision: 0.0152 - val_recall: 0.8750 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 2: val_auc did not improve from 0.65098\n",
            "4/4 - 3s - 626ms/step - accuracy: 0.5050 - auc: 0.4982 - loss: 1.9402 - pr_auc: 0.0148 - precision: 0.0142 - recall: 0.4375 - val_accuracy: 0.9840 - val_auc: 0.5928 - val_loss: 0.3620 - val_pr_auc: 0.0364 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 3: val_auc did not improve from 0.65098\n",
            "4/4 - 1s - 228ms/step - accuracy: 0.6980 - auc: 0.5747 - loss: 1.7897 - pr_auc: 0.0820 - precision: 0.0201 - recall: 0.3750 - val_accuracy: 0.9840 - val_auc: 0.6232 - val_loss: 0.3337 - val_pr_auc: 0.0323 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: val_auc improved from 0.65098 to 0.69788, saving model to /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Original_GRU_adam_gelu_DRY_RUN_best.weights.h5\n",
            "4/4 - 1s - 248ms/step - accuracy: 0.6120 - auc: 0.5210 - loss: 1.7164 - pr_auc: 0.0155 - precision: 0.0156 - recall: 0.3750 - val_accuracy: 0.7210 - val_auc: 0.6979 - val_loss: 0.6383 - val_pr_auc: 0.0421 - val_precision: 0.0287 - val_recall: 0.5000 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 5: val_auc did not improve from 0.69788\n",
            "4/4 - 1s - 226ms/step - accuracy: 0.4540 - auc: 0.4729 - loss: 1.8224 - pr_auc: 0.0164 - precision: 0.0164 - recall: 0.5625 - val_accuracy: 0.3400 - val_auc: 0.6961 - val_loss: 0.7450 - val_pr_auc: 0.0409 - val_precision: 0.0208 - val_recall: 0.8750 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 6: val_auc did not improve from 0.69788\n",
            "4/4 - 1s - 229ms/step - accuracy: 0.4470 - auc: 0.4670 - loss: 1.7358 - pr_auc: 0.0191 - precision: 0.0145 - recall: 0.5000 - val_accuracy: 0.7200 - val_auc: 0.6822 - val_loss: 0.6493 - val_pr_auc: 0.0377 - val_precision: 0.0286 - val_recall: 0.5000 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 7: val_auc did not improve from 0.69788\n",
            "4/4 - 1s - 221ms/step - accuracy: 0.4800 - auc: 0.5551 - loss: 1.4953 - pr_auc: 0.0371 - precision: 0.0172 - recall: 0.5625 - val_accuracy: 0.8430 - val_auc: 0.6811 - val_loss: 0.6135 - val_pr_auc: 0.0369 - val_precision: 0.0452 - val_recall: 0.4375 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 8: val_auc did not improve from 0.69788\n",
            "4/4 - 1s - 231ms/step - accuracy: 0.5330 - auc: 0.6588 - loss: 1.3096 - pr_auc: 0.0258 - precision: 0.0253 - recall: 0.7500 - val_accuracy: 0.9320 - val_auc: 0.6860 - val_loss: 0.5721 - val_pr_auc: 0.0372 - val_precision: 0.0357 - val_recall: 0.1250 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 9: val_auc did not improve from 0.69788\n",
            "4/4 - 1s - 261ms/step - accuracy: 0.5340 - auc: 0.4588 - loss: 1.7001 - pr_auc: 0.0168 - precision: 0.0151 - recall: 0.4375 - val_accuracy: 0.9460 - val_auc: 0.6657 - val_loss: 0.5559 - val_pr_auc: 0.0361 - val_precision: 0.0250 - val_recall: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 9: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "\n",
            "[OK] Training complete: 9/50 epochs\n",
            "\n",
            "EVALUATING: Validation Predictions...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 238ms/step\n",
            "[OK] Optimal threshold (Youden's J): 0.4669 (J=0.3440)\n",
            "[OK] Saved validation window-level predictions (1000 rows)\n",
            "[OK] Patient-level aggregation: 897 patients\n",
            "  Positive patients: 16\n",
            "  Negative patients: 881\n",
            "[OK] Saved validation patient-level predictions (897 patients)\n",
            "\n",
            "EVALUATING: Test Predictions...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Saved test window-level predictions (1000 rows)\n",
            "[OK] Patient-level aggregation: 888 patients\n",
            "  Positive patients: 17\n",
            "  Negative patients: 871\n",
            "[OK] Saved test patient-level predictions (888 patients)\n",
            "[OK] Model saved: /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Original_GRU_adam_gelu_DRY_RUN_final.h5\n",
            "\n",
            "TRAINING SUMMARY\n",
            "================================================================================\n",
            "Dataset: Original (train samples: 1,000)\n",
            "Epochs trained: 9/50\n",
            "\n",
            "Optimal threshold (Youden's J): 0.4669\n",
            "\n",
            "Validation metrics (window-level at optimal threshold):\n",
            "  threshold: 0.4668651819229126\n",
            "  roc_auc: 0.6989964430894309\n",
            "  pr_auc: 0.04266080813581652\n",
            "  sensitivity: 0.8125\n",
            "  specificity: 0.5315040650406504\n",
            "  precision: 0.027426160337552744\n",
            "  npv: 0.9942965779467681\n",
            "  f1_score: 0.05306122448979592\n",
            "  tp: 13\n",
            "  tn: 523\n",
            "  fp: 461\n",
            "  fn: 3\n",
            "\n",
            "Test metrics (window-level at optimal threshold):\n",
            "  threshold: 0.4668651819229126\n",
            "  roc_auc: 0.6085811740769553\n",
            "  pr_auc: 0.024087180688898306\n",
            "  sensitivity: 0.6470588235294118\n",
            "  specificity: 0.5239064089521872\n",
            "  precision: 0.022964509394572025\n",
            "  npv: 0.9884836852207294\n",
            "  f1_score: 0.044354838709677415\n",
            "  tp: 11\n",
            "  tn: 515\n",
            "  fp: 468\n",
            "  fn: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " LSTM with attention"
      ],
      "metadata": {
        "id": "HlUPC9w-ewKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Stage 2 Baseline Training: Original LSTM_Attention (adam-tanh) - PRODUCTION RUN SCRIPT v2\n",
        "Enhanced with:\n",
        "- Complete TF reproducibility (tf.random.set_seed)\n",
        "- Youden J statistic for optimal threshold selection\n",
        "- Patient-level aggregation and metrics\n",
        "- Mixed precision and GPU memory growth\n",
        "- Class weighting for Original dataset imbalance\n",
        "- PR-AUC metric tracking (curve='PR')\n",
        "- Attention mechanism for temporal weighting\n",
        "- Robust error handling with all required keys\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import math\n",
        "import json\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import mixed_precision\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, confusion_matrix, roc_curve\n",
        "\n",
        "# -------------------------------\n",
        "# Configurable parameters\n",
        "# -------------------------------\n",
        "BASE_DIR = '/content/drive/MyDrive/AI_Course_Project/Dataset'\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, 'Stage2_Baseline')\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Original dataset paths\n",
        "TRAIN_PATH = os.path.join(BASE_DIR, 'baseline_train_matrices.npz')\n",
        "VAL_PATH   = os.path.join(BASE_DIR, 'baseline_val_matrices.npz')\n",
        "TEST_PATH  = os.path.join(BASE_DIR, 'baseline_test_matrices.npz')\n",
        "\n",
        "# Best combo for Original LSTM_Attention\n",
        "MODEL_NAME     = 'Original_LSTM_Attention_adam_tanh'\n",
        "OPTIMIZER_NAME = 'adam'\n",
        "ACTIVATION     = 'tanh'  # tanh activation for LSTM_Attention\n",
        "\n",
        "# Class weights for Original dataset (heavily imbalanced)\n",
        "CLASS_WEIGHT = {0: 1.0, 1: 61.0}\n",
        "\n",
        "# Hyperparameters\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 256\n",
        "UNITS = 128\n",
        "DROPOUT = 0.3\n",
        "LEARNING_RATE = 0.001\n",
        "PATIENCE = 5\n",
        "\n",
        "SEQUENCE_LENGTH = 4\n",
        "N_FEATURES = 21\n",
        "\n",
        "# Reproducibility - COMPLETE SEEDING\n",
        "RANDOM_STATE = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(RANDOM_STATE)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "np.random.seed(RANDOM_STATE)\n",
        "tf.random.set_seed(RANDOM_STATE)\n",
        "random.seed(RANDOM_STATE)\n",
        "\n",
        "# -------------------------------\n",
        "# Utility functions\n",
        "# -------------------------------\n",
        "def set_gpu_and_mixed_precision():\n",
        "    \"\"\"Enable memory growth and mixed precision if available.\"\"\"\n",
        "    try:\n",
        "        policy = mixed_precision.Policy('mixed_float16')\n",
        "        mixed_precision.set_global_policy(policy)\n",
        "        print(\"[OK] Mixed precision (float16) policy enabled\")\n",
        "    except Exception:\n",
        "        print(\"[INFO] Mixed precision not available\")\n",
        "\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        for gpu in gpus:\n",
        "            try:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "            except Exception:\n",
        "                pass\n",
        "        print(f\"[OK] GPU memory growth enabled for {len(gpus)} GPU(s)\")\n",
        "\n",
        "def load_data_memmap_with_ids(path):\n",
        "    \"\"\"Load X (memmap), y (numpy), and optional patient_ids from .npz using mmap.\"\"\"\n",
        "    npz = np.load(path, mmap_mode='r')\n",
        "    X = npz['X']\n",
        "    y = np.array(npz['y'])\n",
        "    patient_ids = None\n",
        "    if 'patient_ids' in npz.files:\n",
        "        patient_ids = np.array(npz['patient_ids'])\n",
        "    return X, y, patient_ids\n",
        "\n",
        "def create_memmap_dataset(X_mmap, y, batch_size, shuffle=False, buffer_size=10000, sample_weights=None):\n",
        "    \"\"\"\n",
        "    Create a tf.data.Dataset that loads samples from a memmap by index.\n",
        "    If sample_weights is provided, yields (x, y, w) for weighted training.\n",
        "    Casts input to current mixed-precision compute dtype if enabled.\n",
        "    \"\"\"\n",
        "    n_samples = len(y)\n",
        "    indices = np.arange(n_samples, dtype=np.int64)\n",
        "    labels = y.copy().astype(np.int32)\n",
        "\n",
        "    if sample_weights is not None:\n",
        "        weights = np.array(sample_weights, dtype=np.float32)\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((indices, labels, weights))\n",
        "    else:\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((indices, labels))\n",
        "\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=buffer_size, seed=RANDOM_STATE, reshuffle_each_iteration=True)\n",
        "\n",
        "    def load_sample(*args):\n",
        "        if sample_weights is not None:\n",
        "            idx, label, weight = args\n",
        "        else:\n",
        "            idx, label = args\n",
        "\n",
        "        def _load(idx_val):\n",
        "            return X_mmap[int(idx_val)].astype(np.float32)\n",
        "\n",
        "        x = tf.numpy_function(_load, [idx], tf.float32)\n",
        "\n",
        "        # safe cast to mixed-precision compute dtype (float16 if policy set)\n",
        "        try:\n",
        "            compute_dtype = mixed_precision.global_policy().compute_dtype\n",
        "        except Exception:\n",
        "            compute_dtype = 'float32'\n",
        "        x = tf.cast(x, compute_dtype)\n",
        "\n",
        "        x.set_shape((SEQUENCE_LENGTH, N_FEATURES))\n",
        "\n",
        "        if sample_weights is not None:\n",
        "            return x, label, weight\n",
        "        else:\n",
        "            return x, label\n",
        "\n",
        "    dataset = dataset.map(load_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=False)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "def build_lstm_attention(input_shape, units, dropout, activation):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    masked = layers.Masking(mask_value=-1.0)(inputs)\n",
        "    lstm_out = layers.LSTM(units, activation=activation, return_sequences=True)(masked)\n",
        "\n",
        "    # Attention mechanism\n",
        "    attention = layers.Dense(1, activation='tanh')(lstm_out)\n",
        "    attention = layers.Flatten()(attention)\n",
        "    attention = layers.Activation('softmax')(attention)\n",
        "    attention = layers.RepeatVector(units)(attention)\n",
        "    attention = layers.Permute([2, 1])(attention)\n",
        "\n",
        "    # Apply attention weights\n",
        "    merged = layers.Multiply()([lstm_out, attention])\n",
        "    merged = layers.Lambda(lambda x: keras.backend.sum(x, axis=1))(merged)\n",
        "\n",
        "    # Dense layers\n",
        "    dense = layers.Dense(64, activation=activation)(merged)\n",
        "    dense = layers.Dropout(dropout)(dense)\n",
        "    outputs = layers.Dense(1, activation='sigmoid', dtype='float32')(dense)\n",
        "\n",
        "    return keras.Model(inputs=inputs, outputs=outputs, name='LSTM_Attention')\n",
        "\n",
        "def find_optimal_threshold_youden(y_true, y_pred_proba):\n",
        "    \"\"\"Find optimal threshold using Youden's J statistic (maximizes sensitivity + specificity - 1).\"\"\"\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
        "    j_scores = tpr - fpr  # Youden's J statistic\n",
        "    optimal_idx = np.argmax(j_scores)\n",
        "    optimal_threshold = thresholds[optimal_idx]\n",
        "    return float(optimal_threshold), float(j_scores[optimal_idx])\n",
        "\n",
        "def compute_metrics(y_true, y_pred, y_pred_proba, threshold=0.5):\n",
        "    \"\"\"Compute comprehensive metrics with robust error handling.\"\"\"\n",
        "    try:\n",
        "        cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "        if cm.size == 4:\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "        else:\n",
        "            tn = fp = fn = tp = 0\n",
        "\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "        precision_val = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "        npv = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n",
        "        f1 = 2 * (precision_val * sensitivity) / (precision_val + sensitivity) if (precision_val + sensitivity) > 0 else 0.0\n",
        "\n",
        "        roc_auc = roc_auc_score(y_true, y_pred_proba) if len(np.unique(y_true)) > 1 else 0.0\n",
        "\n",
        "        if len(np.unique(y_true)) > 1:\n",
        "            precision_curve, recall_curve, _ = precision_recall_curve(y_true, y_pred_proba)\n",
        "            pr_auc = auc(recall_curve, precision_curve)\n",
        "        else:\n",
        "            pr_auc = 0.0\n",
        "\n",
        "        return {\n",
        "            'threshold': float(threshold),\n",
        "            'roc_auc': float(roc_auc),\n",
        "            'pr_auc': float(pr_auc),\n",
        "            'sensitivity': float(sensitivity),\n",
        "            'specificity': float(specificity),\n",
        "            'precision': float(precision_val),\n",
        "            'npv': float(npv),\n",
        "            'f1_score': float(f1),\n",
        "            'tp': int(tp), 'tn': int(tn), 'fp': int(fp), 'fn': int(fn)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f'Warning: Error computing metrics: {e}')\n",
        "        return {\n",
        "            'threshold': float(threshold),\n",
        "            'roc_auc': 0.0, 'pr_auc': 0.0,\n",
        "            'sensitivity': 0.0, 'specificity': 0.0,\n",
        "            'precision': 0.0, 'npv': 0.0, 'f1_score': 0.0,\n",
        "            'tp': 0, 'tn': 0, 'fp': 0, 'fn': 0\n",
        "        }\n",
        "\n",
        "def compute_patient_level_metrics(pred_df):\n",
        "    \"\"\"\n",
        "    Patient-level aggregation and metrics.\n",
        "    - y_true: max across windows\n",
        "    - y_pred_proba: max across windows\n",
        "    \"\"\"\n",
        "    if 'patient_id' not in pred_df.columns or pred_df['patient_id'].isna().all():\n",
        "        print(\"[WARNING] No patient IDs available for patient-level aggregation\")\n",
        "        return None\n",
        "\n",
        "    patient_agg = pred_df.groupby('patient_id').agg({\n",
        "        'y_true': 'max',\n",
        "        'y_pred_proba': 'max'\n",
        "    }).reset_index()\n",
        "\n",
        "    unique_labels = patient_agg['y_true'].unique()\n",
        "    if len(unique_labels) < 2:\n",
        "        print(f\"[WARNING] Only {len(unique_labels)} class(es) in patient-level data. Metrics may be invalid.\")\n",
        "\n",
        "    try:\n",
        "        optimal_threshold, j_stat = find_optimal_threshold_youden(\n",
        "            patient_agg['y_true'].values,\n",
        "            patient_agg['y_pred_proba'].values\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"[WARNING] Could not compute optimal threshold: {e}. Using 0.5.\")\n",
        "        optimal_threshold = 0.5\n",
        "        j_stat = 0.0\n",
        "\n",
        "    patient_agg['y_pred_optimal'] = (patient_agg['y_pred_proba'] >= optimal_threshold).astype(int)\n",
        "\n",
        "    metrics_optimal = compute_metrics(\n",
        "        patient_agg['y_true'].values,\n",
        "        patient_agg['y_pred_optimal'].values,\n",
        "        patient_agg['y_pred_proba'].values,\n",
        "        threshold=optimal_threshold\n",
        "    )\n",
        "\n",
        "    patient_agg['y_pred_0.5'] = (patient_agg['y_pred_proba'] >= 0.5).astype(int)\n",
        "    metrics_0_5 = compute_metrics(\n",
        "        patient_agg['y_true'].values,\n",
        "        patient_agg['y_pred_0.5'].values,\n",
        "        patient_agg['y_pred_proba'].values,\n",
        "        threshold=0.5\n",
        "    )\n",
        "\n",
        "    print(f\"[OK] Patient-level aggregation: {len(patient_agg)} patients\")\n",
        "    print(f\"  Positive patients: {patient_agg['y_true'].sum()}\")\n",
        "    print(f\"  Negative patients: {(patient_agg['y_true'] == 0).sum()}\")\n",
        "\n",
        "    return {\n",
        "        'patient_aggregation': patient_agg,\n",
        "        'n_patients': len(patient_agg),\n",
        "        'n_positive_patients': int(patient_agg['y_true'].sum()),\n",
        "        'n_negative_patients': int((patient_agg['y_true'] == 0).sum()),\n",
        "        'optimal_threshold': optimal_threshold,\n",
        "        'youden_j_statistic': j_stat,\n",
        "        'metrics_at_optimal_threshold': metrics_optimal,\n",
        "        'metrics_at_0.5_threshold': metrics_0_5\n",
        "    }\n",
        "\n",
        "# -------------------------------\n",
        "# Main run\n",
        "# -------------------------------\n",
        "def main(dry_run_max_samples=None):\n",
        "    set_gpu_and_mixed_precision()\n",
        "\n",
        "    print('\\nLoading memmap datasets...')\n",
        "    X_train_mmap, y_train, patient_ids_train = load_data_memmap_with_ids(TRAIN_PATH)\n",
        "    X_val_mmap,   y_val,   patient_ids_val   = load_data_memmap_with_ids(VAL_PATH)\n",
        "    X_test_mmap,  y_test,  patient_ids_test  = load_data_memmap_with_ids(TEST_PATH)\n",
        "\n",
        "    # Optional quick dry run\n",
        "    if dry_run_max_samples is not None:\n",
        "        print(f'[FAST] DRY RUN: limiting datasets to {dry_run_max_samples} samples (stratified sample)')\n",
        "\n",
        "        def sample_mmap(X_mmap, y, patient_ids, n):\n",
        "            if len(y) <= n:\n",
        "                return X_mmap, y, patient_ids\n",
        "            idx0 = np.where(y == 0)[0]\n",
        "            idx1 = np.where(y == 1)[0]\n",
        "            ratio = len(idx1) / max(len(y), 1)\n",
        "            n1 = max(2, int(round(n * ratio)))\n",
        "            n0 = max(2, n - n1)\n",
        "            chosen0 = np.random.choice(idx0, size=min(n0, len(idx0)), replace=False)\n",
        "            chosen1 = np.random.choice(idx1, size=min(n1, len(idx1)), replace=False)\n",
        "            chosen = np.concatenate([chosen0, chosen1])\n",
        "            np.random.shuffle(chosen)\n",
        "            X_small = np.stack([X_mmap[i].astype(np.float32) for i in chosen])\n",
        "            y_small = y[chosen]\n",
        "            p_small = patient_ids[chosen] if patient_ids is not None else None\n",
        "            return X_small, y_small, p_small\n",
        "\n",
        "        X_train_mmap, y_train, patient_ids_train = sample_mmap(X_train_mmap, y_train, patient_ids_train, dry_run_max_samples)\n",
        "        X_val_mmap,   y_val,   patient_ids_val   = sample_mmap(X_val_mmap,   y_val,   patient_ids_val,   min(max(dry_run_max_samples // 10, 1000), len(y_val)))\n",
        "        X_test_mmap,  y_test,  patient_ids_test  = sample_mmap(X_test_mmap,  y_test,  patient_ids_test,  min(max(dry_run_max_samples // 10, 1000), len(y_test)))\n",
        "\n",
        "    n_train = len(y_train)\n",
        "    n_val   = len(y_val)\n",
        "    n_test  = len(y_test)\n",
        "\n",
        "    print(f'\\n[OK] Training samples: {n_train:,}')\n",
        "    print(f'  Class 0: {(y_train == 0).sum():,} | Class 1: {(y_train == 1).sum():,}')\n",
        "    print(f'[OK] Validation: {n_val:,}, Test: {n_test:,}')\n",
        "\n",
        "    # Sample weights for class imbalance (Original dataset)\n",
        "    train_sample_weights = np.where(y_train == 1, CLASS_WEIGHT[1], CLASS_WEIGHT[0]).astype(np.float32)\n",
        "\n",
        "    # Datasets: training uses weights; val/test do not\n",
        "    train_ds = create_memmap_dataset(X_train_mmap, y_train, batch_size=BATCH_SIZE, shuffle=True, sample_weights=train_sample_weights)\n",
        "    val_ds   = create_memmap_dataset(X_val_mmap,   y_val,   batch_size=BATCH_SIZE, shuffle=False)\n",
        "    test_ds  = create_memmap_dataset(X_test_mmap,  y_test,  batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    steps_per_epoch = math.ceil(n_train / BATCH_SIZE)\n",
        "\n",
        "    # Model\n",
        "    model = build_lstm_attention((SEQUENCE_LENGTH, N_FEATURES), UNITS, DROPOUT, ACTIVATION)\n",
        "\n",
        "    # Optimizer (with optional loss scaling under mixed precision)\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "    try:\n",
        "        from tensorflow.keras.mixed_precision import LossScaleOptimizer\n",
        "        if tf.keras.mixed_precision.global_policy().name == 'mixed_float16':\n",
        "            optimizer = LossScaleOptimizer(optimizer)\n",
        "            print('[OK] Optimizer wrapped with LossScaleOptimizer')\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    loss_fn = keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss_fn,\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            keras.metrics.AUC(name='auc'),                 # ROC-AUC\n",
        "            keras.metrics.AUC(name='pr_auc', curve='PR'),  # PR-AUC\n",
        "            keras.metrics.Precision(name='precision'),\n",
        "            keras.metrics.Recall(name='recall')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    checkpoint_path = os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_best.weights.h5')\n",
        "    callbacks = [\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            patience=PATIENCE,\n",
        "            restore_best_weights=True,\n",
        "            monitor='val_auc',\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        ),\n",
        "        keras.callbacks.ReduceLROnPlateau(\n",
        "            factor=0.5,\n",
        "            patience=3,\n",
        "            monitor='val_loss',\n",
        "            min_lr=1e-6,\n",
        "            verbose=1\n",
        "        ),\n",
        "        keras.callbacks.ModelCheckpoint(\n",
        "            filepath=checkpoint_path,\n",
        "            monitor='val_auc',\n",
        "            mode='max',\n",
        "            save_best_only=True,\n",
        "            save_weights_only=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        keras.callbacks.CSVLogger(\n",
        "            os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_training_log.csv')\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    print('\\nTRAINING:')\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=EPOCHS,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        callbacks=callbacks,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    epochs_trained = len(history.history['loss'])\n",
        "    print(f'\\n[OK] Training complete: {epochs_trained}/{EPOCHS} epochs')\n",
        "\n",
        "    # Save history\n",
        "    try:\n",
        "        history_serializable = {k: [float(v) for v in vals] for k, vals in history.history.items()}\n",
        "        with open(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_history.json'), 'w') as f:\n",
        "            json.dump(history_serializable, f, indent=2)\n",
        "    except Exception as e:\n",
        "        print('Warning: failed to save history:', e)\n",
        "\n",
        "    # VALIDATION EVALUATION WITH OPTIMAL THRESHOLD\n",
        "    print('\\nEVALUATING: Validation Predictions...')\n",
        "    y_val_pred_proba = model.predict(val_ds, verbose=1).flatten()\n",
        "    if len(y_val_pred_proba) != len(y_val):\n",
        "        y_val_pred_proba = y_val_pred_proba[:len(y_val)]\n",
        "\n",
        "    val_optimal_threshold, val_j_stat = find_optimal_threshold_youden(y_val, y_val_pred_proba)\n",
        "    print(f\"[OK] Optimal threshold (Youden's J): {val_optimal_threshold:.4f} (J={val_j_stat:.4f})\")\n",
        "\n",
        "    y_val_pred_optimal = (y_val_pred_proba >= val_optimal_threshold).astype(int)\n",
        "    y_val_pred_0_5     = (y_val_pred_proba > 0.5).astype(int)\n",
        "\n",
        "    val_metrics_optimal = compute_metrics(y_val, y_val_pred_optimal, y_val_pred_proba, val_optimal_threshold)\n",
        "    val_metrics_0_5     = compute_metrics(y_val, y_val_pred_0_5,     y_val_pred_proba, 0.5)\n",
        "\n",
        "    val_df = pd.DataFrame({\n",
        "        'y_true': y_val,\n",
        "        'y_pred_0.5': y_val_pred_0_5,\n",
        "        'y_pred_optimal': y_val_pred_optimal,\n",
        "        'y_pred_proba': y_val_pred_proba\n",
        "    })\n",
        "    if patient_ids_val is not None:\n",
        "        val_df.insert(0, 'patient_id', patient_ids_val[:len(y_val)])\n",
        "    val_df.to_csv(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_val_predictions.csv'), index=False)\n",
        "    print(f'[OK] Saved validation window-level predictions ({len(val_df)} rows)')\n",
        "\n",
        "    val_patient_metrics = compute_patient_level_metrics(val_df)\n",
        "    if val_patient_metrics:\n",
        "        val_patient_metrics['patient_aggregation'].to_csv(\n",
        "            os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_val_patient_predictions.csv'),\n",
        "            index=False\n",
        "        )\n",
        "        print(f\"[OK] Saved validation patient-level predictions ({val_patient_metrics['n_patients']} patients)\")\n",
        "\n",
        "    # TEST EVALUATION (using validation optimal threshold)\n",
        "    print('\\nEVALUATING: Test Predictions...')\n",
        "    y_test_pred_proba = model.predict(test_ds, verbose=1).flatten()\n",
        "    if len(y_test_pred_proba) != len(y_test):\n",
        "        y_test_pred_proba = y_test_pred_proba[:len(y_test)]\n",
        "\n",
        "    y_test_pred_optimal = (y_test_pred_proba >= val_optimal_threshold).astype(int)\n",
        "    y_test_pred_0_5     = (y_test_pred_proba > 0.5).astype(int)\n",
        "\n",
        "    test_metrics_optimal = compute_metrics(y_test, y_test_pred_optimal, y_test_pred_proba, val_optimal_threshold)\n",
        "    test_metrics_0_5     = compute_metrics(y_test, y_test_pred_0_5,     y_test_pred_proba, 0.5)\n",
        "\n",
        "    test_df = pd.DataFrame({\n",
        "        'y_true': y_test,\n",
        "        'y_pred_0.5': y_test_pred_0_5,\n",
        "        'y_pred_optimal': y_test_pred_optimal,\n",
        "        'y_pred_proba': y_test_pred_proba\n",
        "    })\n",
        "    if patient_ids_test is not None:\n",
        "        test_df.insert(0, 'patient_id', patient_ids_test[:len(y_test)])\n",
        "    test_df.to_csv(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_test_predictions.csv'), index=False)\n",
        "    print(f'[OK] Saved test window-level predictions ({len(test_df)} rows)')\n",
        "\n",
        "    test_patient_metrics = compute_patient_level_metrics(test_df)\n",
        "    if test_patient_metrics:\n",
        "        test_patient_metrics['patient_aggregation'].to_csv(\n",
        "            os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_test_patient_predictions.csv'),\n",
        "            index=False\n",
        "        )\n",
        "        print(f\"[OK] Saved test patient-level predictions ({test_patient_metrics['n_patients']} patients)\")\n",
        "\n",
        "    # Save comprehensive results\n",
        "    results = {\n",
        "        'model_name': MODEL_NAME,\n",
        "        'dataset': 'Original',\n",
        "        'model_type': 'LSTM_Attention',\n",
        "        'optimizer': OPTIMIZER_NAME,\n",
        "        'activation': 'tanh',\n",
        "        'train_samples': int(n_train),\n",
        "        'val_samples': int(n_val),\n",
        "        'test_samples': int(n_test),\n",
        "        'max_epochs': EPOCHS,\n",
        "        'epochs_trained': int(epochs_trained),\n",
        "        'early_stopped': bool(epochs_trained < EPOCHS),\n",
        "        'steps_per_epoch': steps_per_epoch,\n",
        "        'units': UNITS,\n",
        "        'dropout': DROPOUT,\n",
        "        'learning_rate': LEARNING_RATE,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'random_state': RANDOM_STATE,\n",
        "        'class_weight': CLASS_WEIGHT,\n",
        "        'optimal_threshold': val_optimal_threshold,\n",
        "        'youden_j_statistic': val_j_stat,\n",
        "        'validation_metrics': {\n",
        "            'window_level_0.5_threshold': val_metrics_0_5,\n",
        "            'window_level_optimal_threshold': val_metrics_optimal,\n",
        "            'patient_level': val_patient_metrics if val_patient_metrics else None\n",
        "        },\n",
        "        'test_metrics': {\n",
        "            'window_level_0.5_threshold': test_metrics_0_5,\n",
        "            'window_level_optimal_threshold': test_metrics_optimal,\n",
        "            'patient_level': test_patient_metrics if test_patient_metrics else None\n",
        "        }\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_results.json'), 'w') as f:\n",
        "        json.dump(results, f, indent=2, default=str)\n",
        "\n",
        "    # Save final model\n",
        "    final_model_path = os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_final.h5')\n",
        "    try:\n",
        "        model.save(final_model_path)\n",
        "        print(f'[OK] Model saved: {final_model_path}')\n",
        "    except Exception as e:\n",
        "        print('Warning: full model.save failed, saving weights only. Error:', e)\n",
        "        try:\n",
        "            model.save_weights(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_final_weights.h5'))\n",
        "            print('[OK] Weights saved as fallback')\n",
        "        except Exception as e2:\n",
        "            print('ERROR: failed to save weights as well:', e2)\n",
        "\n",
        "    print('\\nTRAINING SUMMARY')\n",
        "    print('='*80)\n",
        "    print(f\"Dataset: Original (train samples: {n_train:,})\")\n",
        "    print(f\"Epochs trained: {epochs_trained}/{EPOCHS}\")\n",
        "    print(f\"\\nOptimal threshold (Youden's J): {val_optimal_threshold:.4f}\")\n",
        "    print('\\nValidation metrics (window-level at optimal threshold):')\n",
        "    for k, v in val_metrics_optimal.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "    print('\\nTest metrics (window-level at optimal threshold):')\n",
        "    for k, v in test_metrics_optimal.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    DRY_RUN = False\n",
        "    DRY_RUN_SAMPLES = 1000\n",
        "\n",
        "    if DRY_RUN:\n",
        "        MODEL_NAME = MODEL_NAME + '_DRY_RUN'\n",
        "        print(\"=\"*80)\n",
        "        print(\"[TEST] DRY RUN MODE: Quick validation with small sample\")\n",
        "        print(f\"   Using {DRY_RUN_SAMPLES:,} training samples\")\n",
        "        print(f\"   Files will be saved with suffix: _DRY_RUN\")\n",
        "        print(\"=\"*80)\n",
        "        main(dry_run_max_samples=DRY_RUN_SAMPLES)\n",
        "    else:\n",
        "        print(\"=\"*80)\n",
        "        print(\"[FULL] FULL TRAINING MODE: Complete dataset\")\n",
        "        print(\"   Using all available training samples\")\n",
        "        print(\"=\"*80)\n",
        "        main(dry_run_max_samples=None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4Cwxk93e1CF",
        "outputId": "662c3c5a-8efe-48d0-9d21-c16cdb14f399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "[TEST] DRY RUN MODE: Quick validation with small sample\n",
            "   Using 1,000 training samples\n",
            "   Files will be saved with suffix: _DRY_RUN\n",
            "================================================================================\n",
            "[OK] Mixed precision (float16) policy enabled\n",
            "\n",
            "Loading memmap datasets...\n",
            "[FAST] DRY RUN: limiting datasets to 1000 samples (stratified sample)\n",
            "\n",
            "[OK] Training samples: 1,000\n",
            "  Class 0: 984 | Class 1: 16\n",
            "[OK] Validation: 1,000, Test: 1,000\n",
            "[OK] Optimizer wrapped with LossScaleOptimizer\n",
            "\n",
            "TRAINING:\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 1: val_auc improved from -inf to 0.64009, saving model to /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Original_LSTM_Attention_adam_tanh_DRY_RUN_best.weights.h5\n",
            "4/4 - 12s - 3s/step - accuracy: 0.3120 - auc: 0.5943 - loss: 1.3649 - pr_auc: 0.0184 - precision: 0.0200 - recall: 0.8750 - val_accuracy: 0.9840 - val_auc: 0.6401 - val_loss: 0.6188 - val_pr_auc: 0.0372 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 2: val_auc improved from 0.64009 to 0.70821, saving model to /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Original_LSTM_Attention_adam_tanh_DRY_RUN_best.weights.h5\n",
            "4/4 - 1s - 255ms/step - accuracy: 0.8050 - auc: 0.4287 - loss: 1.4911 - pr_auc: 0.0138 - precision: 0.0109 - recall: 0.1250 - val_accuracy: 0.9840 - val_auc: 0.7082 - val_loss: 0.4738 - val_pr_auc: 0.0707 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 3: val_auc did not improve from 0.70821\n",
            "4/4 - 1s - 292ms/step - accuracy: 0.7850 - auc: 0.5344 - loss: 1.4024 - pr_auc: 0.0159 - precision: 0.0146 - recall: 0.1875 - val_accuracy: 0.6750 - val_auc: 0.7028 - val_loss: 0.6774 - val_pr_auc: 0.0898 - val_precision: 0.0332 - val_recall: 0.6875 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: val_auc did not improve from 0.70821\n",
            "4/4 - 1s - 246ms/step - accuracy: 0.4130 - auc: 0.6231 - loss: 1.3599 - pr_auc: 0.0201 - precision: 0.0250 - recall: 0.9375 - val_accuracy: 0.0400 - val_auc: 0.6991 - val_loss: 0.8134 - val_pr_auc: 0.0710 - val_precision: 0.0154 - val_recall: 0.9375 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 5: val_auc did not improve from 0.70821\n",
            "4/4 - 1s - 273ms/step - accuracy: 0.3170 - auc: 0.6551 - loss: 1.3055 - pr_auc: 0.0351 - precision: 0.0215 - recall: 0.9375 - val_accuracy: 0.0650 - val_auc: 0.6996 - val_loss: 0.7872 - val_pr_auc: 0.0774 - val_precision: 0.0158 - val_recall: 0.9375 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 6: val_auc did not improve from 0.70821\n",
            "4/4 - 1s - 278ms/step - accuracy: 0.3450 - auc: 0.4741 - loss: 1.4238 - pr_auc: 0.0148 - precision: 0.0152 - recall: 0.6250 - val_accuracy: 0.1440 - val_auc: 0.6981 - val_loss: 0.7320 - val_pr_auc: 0.0865 - val_precision: 0.0172 - val_recall: 0.9375 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 7: val_auc did not improve from 0.70821\n",
            "4/4 - 1s - 326ms/step - accuracy: 0.4640 - auc: 0.5640 - loss: 1.3505 - pr_auc: 0.0218 - precision: 0.0185 - recall: 0.6250 - val_accuracy: 0.4730 - val_auc: 0.6965 - val_loss: 0.6861 - val_pr_auc: 0.0779 - val_precision: 0.0242 - val_recall: 0.8125 - learning_rate: 5.0000e-04\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "\n",
            "[OK] Training complete: 7/50 epochs\n",
            "\n",
            "EVALUATING: Validation Predictions...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 181ms/step\n",
            "[OK] Optimal threshold (Youden's J): 0.3746 (J=0.3440)\n",
            "[OK] Saved validation window-level predictions (1000 rows)\n",
            "[OK] Patient-level aggregation: 897 patients\n",
            "  Positive patients: 16\n",
            "  Negative patients: 881\n",
            "[OK] Saved validation patient-level predictions (897 patients)\n",
            "\n",
            "EVALUATING: Test Predictions...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Saved test window-level predictions (1000 rows)\n",
            "[OK] Patient-level aggregation: 888 patients\n",
            "  Positive patients: 17\n",
            "  Negative patients: 871\n",
            "[OK] Saved test patient-level predictions (888 patients)\n",
            "[OK] Model saved: /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Original_LSTM_Attention_adam_tanh_DRY_RUN_final.h5\n",
            "\n",
            "TRAINING SUMMARY\n",
            "================================================================================\n",
            "Dataset: Original (train samples: 1,000)\n",
            "Epochs trained: 7/50\n",
            "\n",
            "Optimal threshold (Youden's J): 0.3746\n",
            "\n",
            "Validation metrics (window-level at optimal threshold):\n",
            "  threshold: 0.37461355328559875\n",
            "  roc_auc: 0.701854674796748\n",
            "  pr_auc: 0.06155503934422764\n",
            "  sensitivity: 0.8125\n",
            "  specificity: 0.5315040650406504\n",
            "  precision: 0.027426160337552744\n",
            "  npv: 0.9942965779467681\n",
            "  f1_score: 0.05306122448979592\n",
            "  tp: 13\n",
            "  tn: 523\n",
            "  fp: 461\n",
            "  fn: 3\n",
            "\n",
            "Test metrics (window-level at optimal threshold):\n",
            "  threshold: 0.37461355328559875\n",
            "  roc_auc: 0.6460415295314463\n",
            "  pr_auc: 0.024038890911608435\n",
            "  sensitivity: 0.7058823529411765\n",
            "  specificity: 0.5473041709053916\n",
            "  precision: 0.0262582056892779\n",
            "  npv: 0.990791896869245\n",
            "  f1_score: 0.05063291139240506\n",
            "  tp: 12\n",
            "  tn: 538\n",
            "  fp: 445\n",
            "  fn: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " CNN"
      ],
      "metadata": {
        "id": "Cl74RscgeyFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Stage 2 Baseline Training: Original CNN (adam-gelu) - PRODUCTION RUN SCRIPT v2\n",
        "Enhanced with:\n",
        "- Complete TF reproducibility (tf.random.set_seed)\n",
        "- Youden J statistic for optimal threshold selection\n",
        "- Patient-level aggregation and metrics\n",
        "- Mixed precision and GPU memory growth\n",
        "- Class weighting for Original dataset imbalance\n",
        "- PR-AUC metric tracking (curve='PR')\n",
        "- Advanced CNN masking with missingness indicator channel\n",
        "- Robust error handling with all required keys\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import math\n",
        "import json\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import mixed_precision\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, confusion_matrix, roc_curve\n",
        "\n",
        "# -------------------------------\n",
        "# Configurable parameters\n",
        "# -------------------------------\n",
        "BASE_DIR = '/content/drive/MyDrive/AI_Course_Project/Dataset'\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, 'Stage2_Baseline')\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Original dataset paths\n",
        "TRAIN_PATH = os.path.join(BASE_DIR, 'baseline_train_matrices.npz')\n",
        "VAL_PATH   = os.path.join(BASE_DIR, 'baseline_val_matrices.npz')\n",
        "TEST_PATH  = os.path.join(BASE_DIR, 'baseline_test_matrices.npz')\n",
        "\n",
        "# Best combo for Original CNN\n",
        "MODEL_NAME     = 'Original_CNN_adam_gelu'\n",
        "OPTIMIZER_NAME = 'adam'\n",
        "ACTIVATION     = 'gelu'\n",
        "\n",
        "# Class weights for Original dataset (heavily imbalanced)\n",
        "CLASS_WEIGHT = {0: 1.0, 1: 61.0}\n",
        "\n",
        "# Hyperparameters\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 256\n",
        "FILTERS = 128\n",
        "KERNEL_SIZE = 2\n",
        "DROPOUT = 0.3\n",
        "LEARNING_RATE = 0.001\n",
        "PATIENCE = 5\n",
        "\n",
        "SEQUENCE_LENGTH = 4\n",
        "N_FEATURES = 21\n",
        "\n",
        "# Reproducibility - COMPLETE SEEDING\n",
        "RANDOM_STATE = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(RANDOM_STATE)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "np.random.seed(RANDOM_STATE)\n",
        "tf.random.set_seed(RANDOM_STATE)\n",
        "random.seed(RANDOM_STATE)\n",
        "\n",
        "# -------------------------------\n",
        "# Utility functions\n",
        "# -------------------------------\n",
        "def set_gpu_and_mixed_precision():\n",
        "    \"\"\"Enable memory growth and mixed precision if available.\"\"\"\n",
        "    try:\n",
        "        policy = mixed_precision.Policy('mixed_float16')\n",
        "        mixed_precision.set_global_policy(policy)\n",
        "        print(\"[OK] Mixed precision (float16) policy enabled\")\n",
        "    except Exception:\n",
        "        print(\"[INFO] Mixed precision not available\")\n",
        "\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        for gpu in gpus:\n",
        "            try:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "            except Exception:\n",
        "                pass\n",
        "        print(f\"[OK] GPU memory growth enabled for {len(gpus)} GPU(s)\")\n",
        "\n",
        "def load_data_memmap_with_ids(path):\n",
        "    \"\"\"Load X (memmap), y (numpy), and optional patient_ids from .npz using mmap.\"\"\"\n",
        "    npz = np.load(path, mmap_mode='r')\n",
        "    X = npz['X']\n",
        "    y = np.array(npz['y'])\n",
        "    patient_ids = None\n",
        "    if 'patient_ids' in npz.files:\n",
        "        patient_ids = np.array(npz['patient_ids'])\n",
        "    return X, y, patient_ids\n",
        "\n",
        "def create_memmap_dataset(X_mmap, y, batch_size, shuffle=False, buffer_size=10000, sample_weights=None):\n",
        "    \"\"\"\n",
        "    Create a tf.data.Dataset that loads samples from a memmap by index.\n",
        "    If sample_weights is provided, yields (x, y, w) for weighted training.\n",
        "    Casts input to current mixed-precision compute dtype if enabled.\n",
        "    \"\"\"\n",
        "    n_samples = len(y)\n",
        "    indices = np.arange(n_samples, dtype=np.int64)\n",
        "    labels = y.copy().astype(np.int32)\n",
        "\n",
        "    if sample_weights is not None:\n",
        "        weights = np.array(sample_weights, dtype=np.float32)\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((indices, labels, weights))\n",
        "    else:\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((indices, labels))\n",
        "\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=buffer_size, seed=RANDOM_STATE, reshuffle_each_iteration=True)\n",
        "\n",
        "    def load_sample(*args):\n",
        "        if sample_weights is not None:\n",
        "            idx, label, weight = args\n",
        "        else:\n",
        "            idx, label = args\n",
        "\n",
        "        def _load(idx_val):\n",
        "            return X_mmap[int(idx_val)].astype(np.float32)\n",
        "\n",
        "        x = tf.numpy_function(_load, [idx], tf.float32)\n",
        "\n",
        "        # safe cast to mixed-precision compute dtype (float16 if policy set)\n",
        "        try:\n",
        "            compute_dtype = mixed_precision.global_policy().compute_dtype\n",
        "        except Exception:\n",
        "            compute_dtype = 'float32'\n",
        "        x = tf.cast(x, compute_dtype)\n",
        "\n",
        "        x.set_shape((SEQUENCE_LENGTH, N_FEATURES))\n",
        "\n",
        "        if sample_weights is not None:\n",
        "            return x, label, weight\n",
        "        else:\n",
        "            return x, label\n",
        "\n",
        "    dataset = dataset.map(load_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=False)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "class CNNMaskingLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Mixed-precision safe masking layer:\n",
        "    - Replaces mask_value with 0 (using inputs.dtype)\n",
        "    - Adds a missingness indicator channel (same dtype as inputs)\n",
        "    \"\"\"\n",
        "    def __init__(self, mask_value=-1.0, **kwargs):\n",
        "        super(CNNMaskingLayer, self).__init__(**kwargs)\n",
        "        self.mask_value = mask_value\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Ensure mask_value has same dtype as inputs\n",
        "        mask_val = tf.cast(self.mask_value, inputs.dtype)\n",
        "        mask = tf.equal(inputs, mask_val)              # boolean mask (True where missing)\n",
        "\n",
        "        # Replace masked entries with zeros of same dtype\n",
        "        outputs = tf.where(mask, tf.zeros_like(inputs), inputs)\n",
        "\n",
        "        # Missingness flag as same dtype (0/1)\n",
        "        missing_flag = tf.cast(mask, inputs.dtype)\n",
        "\n",
        "        # Concatenate along feature axis -> doubles the feature dimension\n",
        "        return tf.concat([outputs, missing_flag], axis=-1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        # input_shape: (batch, time, features) or (None, time, features)\n",
        "        if input_shape is None:\n",
        "            return None\n",
        "        batch, time, features = input_shape\n",
        "        return (batch, time, features * 2)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(CNNMaskingLayer, self).get_config()\n",
        "        config.update({'mask_value': self.mask_value})\n",
        "        return config\n",
        "\n",
        "def build_cnn(input_shape, filters, kernel_size, dropout, activation):\n",
        "    \"\"\"\n",
        "    Build CNN with advanced masking layer.\n",
        "\n",
        "    Note: Input shape is (SEQUENCE_LENGTH, N_FEATURES),\n",
        "    but after CNNMaskingLayer, it becomes (SEQUENCE_LENGTH, N_FEATURES*2)\n",
        "    due to the missingness indicator channel.\n",
        "    \"\"\"\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        CNNMaskingLayer(mask_value=-1.0),  # Outputs shape: (SEQUENCE_LENGTH, N_FEATURES*2)\n",
        "        layers.Conv1D(filters=filters, kernel_size=kernel_size, activation=activation, padding='same'),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Conv1D(filters=filters//2, kernel_size=kernel_size, activation=activation, padding='same'),\n",
        "        layers.GlobalMaxPooling1D(),\n",
        "        layers.Dense(64, activation=activation),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(1, activation='sigmoid', dtype='float32')\n",
        "    ], name='CNN')\n",
        "    return model\n",
        "\n",
        "def find_optimal_threshold_youden(y_true, y_pred_proba):\n",
        "    \"\"\"Find optimal threshold using Youden's J statistic (maximizes sensitivity + specificity - 1).\"\"\"\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
        "    j_scores = tpr - fpr  # Youden's J statistic\n",
        "    optimal_idx = np.argmax(j_scores)\n",
        "    optimal_threshold = thresholds[optimal_idx]\n",
        "    return float(optimal_threshold), float(j_scores[optimal_idx])\n",
        "\n",
        "def compute_metrics(y_true, y_pred, y_pred_proba, threshold=0.5):\n",
        "    \"\"\"Compute comprehensive metrics with robust error handling.\"\"\"\n",
        "    try:\n",
        "        cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "        if cm.size == 4:\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "        else:\n",
        "            tn = fp = fn = tp = 0\n",
        "\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "        precision_val = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "        npv = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n",
        "        f1 = 2 * (precision_val * sensitivity) / (precision_val + sensitivity) if (precision_val + sensitivity) > 0 else 0.0\n",
        "\n",
        "        roc_auc = roc_auc_score(y_true, y_pred_proba) if len(np.unique(y_true)) > 1 else 0.0\n",
        "\n",
        "        if len(np.unique(y_true)) > 1:\n",
        "            precision_curve, recall_curve, _ = precision_recall_curve(y_true, y_pred_proba)\n",
        "            pr_auc = auc(recall_curve, precision_curve)\n",
        "        else:\n",
        "            pr_auc = 0.0\n",
        "\n",
        "        return {\n",
        "            'threshold': float(threshold),\n",
        "            'roc_auc': float(roc_auc),\n",
        "            'pr_auc': float(pr_auc),\n",
        "            'sensitivity': float(sensitivity),\n",
        "            'specificity': float(specificity),\n",
        "            'precision': float(precision_val),\n",
        "            'npv': float(npv),\n",
        "            'f1_score': float(f1),\n",
        "            'tp': int(tp), 'tn': int(tn), 'fp': int(fp), 'fn': int(fn)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f'Warning: Error computing metrics: {e}')\n",
        "        return {\n",
        "            'threshold': float(threshold),\n",
        "            'roc_auc': 0.0, 'pr_auc': 0.0,\n",
        "            'sensitivity': 0.0, 'specificity': 0.0,\n",
        "            'precision': 0.0, 'npv': 0.0, 'f1_score': 0.0,\n",
        "            'tp': 0, 'tn': 0, 'fp': 0, 'fn': 0\n",
        "        }\n",
        "\n",
        "def compute_patient_level_metrics(pred_df):\n",
        "    \"\"\"\n",
        "    Patient-level aggregation and metrics.\n",
        "    - y_true: max across windows\n",
        "    - y_pred_proba: max across windows\n",
        "    \"\"\"\n",
        "    if 'patient_id' not in pred_df.columns or pred_df['patient_id'].isna().all():\n",
        "        print(\"[WARNING] No patient IDs available for patient-level aggregation\")\n",
        "        return None\n",
        "\n",
        "    patient_agg = pred_df.groupby('patient_id').agg({\n",
        "        'y_true': 'max',\n",
        "        'y_pred_proba': 'max'\n",
        "    }).reset_index()\n",
        "\n",
        "    unique_labels = patient_agg['y_true'].unique()\n",
        "    if len(unique_labels) < 2:\n",
        "        print(f\"[WARNING] Only {len(unique_labels)} class(es) in patient-level data. Metrics may be invalid.\")\n",
        "\n",
        "    try:\n",
        "        optimal_threshold, j_stat = find_optimal_threshold_youden(\n",
        "            patient_agg['y_true'].values,\n",
        "            patient_agg['y_pred_proba'].values\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"[WARNING] Could not compute optimal threshold: {e}. Using 0.5.\")\n",
        "        optimal_threshold = 0.5\n",
        "        j_stat = 0.0\n",
        "\n",
        "    patient_agg['y_pred_optimal'] = (patient_agg['y_pred_proba'] >= optimal_threshold).astype(int)\n",
        "\n",
        "    metrics_optimal = compute_metrics(\n",
        "        patient_agg['y_true'].values,\n",
        "        patient_agg['y_pred_optimal'].values,\n",
        "        patient_agg['y_pred_proba'].values,\n",
        "        threshold=optimal_threshold\n",
        "    )\n",
        "\n",
        "    patient_agg['y_pred_0.5'] = (patient_agg['y_pred_proba'] >= 0.5).astype(int)\n",
        "    metrics_0_5 = compute_metrics(\n",
        "        patient_agg['y_true'].values,\n",
        "        patient_agg['y_pred_0.5'].values,\n",
        "        patient_agg['y_pred_proba'].values,\n",
        "        threshold=0.5\n",
        "    )\n",
        "\n",
        "    print(f\"[OK] Patient-level aggregation: {len(patient_agg)} patients\")\n",
        "    print(f\"  Positive patients: {patient_agg['y_true'].sum()}\")\n",
        "    print(f\"  Negative patients: {(patient_agg['y_true'] == 0).sum()}\")\n",
        "\n",
        "    return {\n",
        "        'patient_aggregation': patient_agg,\n",
        "        'n_patients': len(patient_agg),\n",
        "        'n_positive_patients': int(patient_agg['y_true'].sum()),\n",
        "        'n_negative_patients': int((patient_agg['y_true'] == 0).sum()),\n",
        "        'optimal_threshold': optimal_threshold,\n",
        "        'youden_j_statistic': j_stat,\n",
        "        'metrics_at_optimal_threshold': metrics_optimal,\n",
        "        'metrics_at_0.5_threshold': metrics_0_5\n",
        "    }\n",
        "\n",
        "# -------------------------------\n",
        "# Main run\n",
        "# -------------------------------\n",
        "def main(dry_run_max_samples=None):\n",
        "    set_gpu_and_mixed_precision()\n",
        "\n",
        "    print('\\nLoading memmap datasets...')\n",
        "    X_train_mmap, y_train, patient_ids_train = load_data_memmap_with_ids(TRAIN_PATH)\n",
        "    X_val_mmap,   y_val,   patient_ids_val   = load_data_memmap_with_ids(VAL_PATH)\n",
        "    X_test_mmap,  y_test,  patient_ids_test  = load_data_memmap_with_ids(TEST_PATH)\n",
        "\n",
        "    # Optional quick dry run\n",
        "    if dry_run_max_samples is not None:\n",
        "        print(f'[FAST] DRY RUN: limiting datasets to {dry_run_max_samples} samples (stratified sample)')\n",
        "\n",
        "        def sample_mmap(X_mmap, y, patient_ids, n):\n",
        "            if len(y) <= n:\n",
        "                return X_mmap, y, patient_ids\n",
        "            idx0 = np.where(y == 0)[0]\n",
        "            idx1 = np.where(y == 1)[0]\n",
        "            ratio = len(idx1) / max(len(y), 1)\n",
        "            n1 = max(2, int(round(n * ratio)))\n",
        "            n0 = max(2, n - n1)\n",
        "            chosen0 = np.random.choice(idx0, size=min(n0, len(idx0)), replace=False)\n",
        "            chosen1 = np.random.choice(idx1, size=min(n1, len(idx1)), replace=False)\n",
        "            chosen = np.concatenate([chosen0, chosen1])\n",
        "            np.random.shuffle(chosen)\n",
        "            X_small = np.stack([X_mmap[i].astype(np.float32) for i in chosen])\n",
        "            y_small = y[chosen]\n",
        "            p_small = patient_ids[chosen] if patient_ids is not None else None\n",
        "            return X_small, y_small, p_small\n",
        "\n",
        "        X_train_mmap, y_train, patient_ids_train = sample_mmap(X_train_mmap, y_train, patient_ids_train, dry_run_max_samples)\n",
        "        X_val_mmap,   y_val,   patient_ids_val   = sample_mmap(X_val_mmap,   y_val,   patient_ids_val,   min(max(dry_run_max_samples // 10, 1000), len(y_val)))\n",
        "        X_test_mmap,  y_test,  patient_ids_test  = sample_mmap(X_test_mmap,  y_test,  patient_ids_test,  min(max(dry_run_max_samples // 10, 1000), len(y_test)))\n",
        "\n",
        "    n_train = len(y_train)\n",
        "    n_val   = len(y_val)\n",
        "    n_test  = len(y_test)\n",
        "\n",
        "    print(f'\\n[OK] Training samples: {n_train:,}')\n",
        "    print(f'  Class 0: {(y_train == 0).sum():,} | Class 1: {(y_train == 1).sum():,}')\n",
        "    print(f'[OK] Validation: {n_val:,}, Test: {n_test:,}')\n",
        "\n",
        "    # Sample weights for class imbalance (Original dataset)\n",
        "    train_sample_weights = np.where(y_train == 1, CLASS_WEIGHT[1], CLASS_WEIGHT[0]).astype(np.float32)\n",
        "\n",
        "    # Datasets: training uses weights; val/test do not\n",
        "    train_ds = create_memmap_dataset(X_train_mmap, y_train, batch_size=BATCH_SIZE, shuffle=True, sample_weights=train_sample_weights)\n",
        "    val_ds   = create_memmap_dataset(X_val_mmap,   y_val,   batch_size=BATCH_SIZE, shuffle=False)\n",
        "    test_ds  = create_memmap_dataset(X_test_mmap,  y_test,  batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    steps_per_epoch = math.ceil(n_train / BATCH_SIZE)\n",
        "\n",
        "    # Model\n",
        "    model = build_cnn((SEQUENCE_LENGTH, N_FEATURES), FILTERS, KERNEL_SIZE, DROPOUT, ACTIVATION)\n",
        "\n",
        "    # Optimizer (with optional loss scaling under mixed precision)\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "    try:\n",
        "        from tensorflow.keras.mixed_precision import LossScaleOptimizer\n",
        "        if tf.keras.mixed_precision.global_policy().name == 'mixed_float16':\n",
        "            optimizer = LossScaleOptimizer(optimizer)\n",
        "            print('[OK] Optimizer wrapped with LossScaleOptimizer')\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    loss_fn = keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss_fn,\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            keras.metrics.AUC(name='auc'),                 # ROC-AUC\n",
        "            keras.metrics.AUC(name='pr_auc', curve='PR'),  # PR-AUC\n",
        "            keras.metrics.Precision(name='precision'),\n",
        "            keras.metrics.Recall(name='recall')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    checkpoint_path = os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_best.weights.h5')\n",
        "    callbacks = [\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            patience=PATIENCE,\n",
        "            restore_best_weights=True,\n",
        "            monitor='val_auc',\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        ),\n",
        "        keras.callbacks.ReduceLROnPlateau(\n",
        "            factor=0.5,\n",
        "            patience=3,\n",
        "            monitor='val_loss',\n",
        "            min_lr=1e-6,\n",
        "            verbose=1\n",
        "        ),\n",
        "        keras.callbacks.ModelCheckpoint(\n",
        "            filepath=checkpoint_path,\n",
        "            monitor='val_auc',\n",
        "            mode='max',\n",
        "            save_best_only=True,\n",
        "            save_weights_only=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        keras.callbacks.CSVLogger(\n",
        "            os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_training_log.csv')\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    print('\\nTRAINING:')\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=EPOCHS,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        callbacks=callbacks,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    epochs_trained = len(history.history['loss'])\n",
        "    print(f'\\n[OK] Training complete: {epochs_trained}/{EPOCHS} epochs')\n",
        "\n",
        "    # Save history\n",
        "    try:\n",
        "        history_serializable = {k: [float(v) for v in vals] for k, vals in history.history.items()}\n",
        "        with open(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_history.json'), 'w') as f:\n",
        "            json.dump(history_serializable, f, indent=2)\n",
        "    except Exception as e:\n",
        "        print('Warning: failed to save history:', e)\n",
        "\n",
        "    # VALIDATION EVALUATION WITH OPTIMAL THRESHOLD\n",
        "    print('\\nEVALUATING: Validation Predictions...')\n",
        "    y_val_pred_proba = model.predict(val_ds, verbose=1).flatten()\n",
        "    if len(y_val_pred_proba) != len(y_val):\n",
        "        y_val_pred_proba = y_val_pred_proba[:len(y_val)]\n",
        "\n",
        "    val_optimal_threshold, val_j_stat = find_optimal_threshold_youden(y_val, y_val_pred_proba)\n",
        "    print(f\"[OK] Optimal threshold (Youden's J): {val_optimal_threshold:.4f} (J={val_j_stat:.4f})\")\n",
        "\n",
        "    y_val_pred_optimal = (y_val_pred_proba >= val_optimal_threshold).astype(int)\n",
        "    y_val_pred_0_5     = (y_val_pred_proba > 0.5).astype(int)\n",
        "\n",
        "    val_metrics_optimal = compute_metrics(y_val, y_val_pred_optimal, y_val_pred_proba, val_optimal_threshold)\n",
        "    val_metrics_0_5     = compute_metrics(y_val, y_val_pred_0_5,     y_val_pred_proba, 0.5)\n",
        "\n",
        "    val_df = pd.DataFrame({\n",
        "        'y_true': y_val,\n",
        "        'y_pred_0.5': y_val_pred_0_5,\n",
        "        'y_pred_optimal': y_val_pred_optimal,\n",
        "        'y_pred_proba': y_val_pred_proba\n",
        "    })\n",
        "    if patient_ids_val is not None:\n",
        "        val_df.insert(0, 'patient_id', patient_ids_val[:len(y_val)])\n",
        "    val_df.to_csv(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_val_predictions.csv'), index=False)\n",
        "    print(f'[OK] Saved validation window-level predictions ({len(val_df)} rows)')\n",
        "\n",
        "    val_patient_metrics = compute_patient_level_metrics(val_df)\n",
        "    if val_patient_metrics:\n",
        "        val_patient_metrics['patient_aggregation'].to_csv(\n",
        "            os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_val_patient_predictions.csv'),\n",
        "            index=False\n",
        "        )\n",
        "        print(f\"[OK] Saved validation patient-level predictions ({val_patient_metrics['n_patients']} patients)\")\n",
        "\n",
        "    # TEST EVALUATION (using validation optimal threshold)\n",
        "    print('\\nEVALUATING: Test Predictions...')\n",
        "    y_test_pred_proba = model.predict(test_ds, verbose=1).flatten()\n",
        "    if len(y_test_pred_proba) != len(y_test):\n",
        "        y_test_pred_proba = y_test_pred_proba[:len(y_test)]\n",
        "\n",
        "    y_test_pred_optimal = (y_test_pred_proba >= val_optimal_threshold).astype(int)\n",
        "    y_test_pred_0_5     = (y_test_pred_proba > 0.5).astype(int)\n",
        "\n",
        "    test_metrics_optimal = compute_metrics(y_test, y_test_pred_optimal, y_test_pred_proba, val_optimal_threshold)\n",
        "    test_metrics_0_5     = compute_metrics(y_test, y_test_pred_0_5,     y_test_pred_proba, 0.5)\n",
        "\n",
        "    test_df = pd.DataFrame({\n",
        "        'y_true': y_test,\n",
        "        'y_pred_0.5': y_test_pred_0_5,\n",
        "        'y_pred_optimal': y_test_pred_optimal,\n",
        "        'y_pred_proba': y_test_pred_proba\n",
        "    })\n",
        "    if patient_ids_test is not None:\n",
        "        test_df.insert(0, 'patient_id', patient_ids_test[:len(y_test)])\n",
        "    test_df.to_csv(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_test_predictions.csv'), index=False)\n",
        "    print(f'[OK] Saved test window-level predictions ({len(test_df)} rows)')\n",
        "\n",
        "    test_patient_metrics = compute_patient_level_metrics(test_df)\n",
        "    if test_patient_metrics:\n",
        "        test_patient_metrics['patient_aggregation'].to_csv(\n",
        "            os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_test_patient_predictions.csv'),\n",
        "            index=False\n",
        "        )\n",
        "        print(f\"[OK] Saved test patient-level predictions ({test_patient_metrics['n_patients']} patients)\")\n",
        "\n",
        "    # Save comprehensive results\n",
        "    results = {\n",
        "        'model_name': MODEL_NAME,\n",
        "        'dataset': 'Original',\n",
        "        'model_type': 'CNN',\n",
        "        'optimizer': OPTIMIZER_NAME,\n",
        "        'activation': ACTIVATION,\n",
        "        'train_samples': int(n_train),\n",
        "        'val_samples': int(n_val),\n",
        "        'test_samples': int(n_test),\n",
        "        'max_epochs': EPOCHS,\n",
        "        'epochs_trained': int(epochs_trained),\n",
        "        'early_stopped': bool(epochs_trained < EPOCHS),\n",
        "        'steps_per_epoch': steps_per_epoch,\n",
        "        'filters': FILTERS,\n",
        "        'kernel_size': KERNEL_SIZE,\n",
        "        'dropout': DROPOUT,\n",
        "        'learning_rate': LEARNING_RATE,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'random_state': RANDOM_STATE,\n",
        "        'class_weight': CLASS_WEIGHT,\n",
        "        'optimal_threshold': val_optimal_threshold,\n",
        "        'youden_j_statistic': val_j_stat,\n",
        "        'validation_metrics': {\n",
        "            'window_level_0.5_threshold': val_metrics_0_5,\n",
        "            'window_level_optimal_threshold': val_metrics_optimal,\n",
        "            'patient_level': val_patient_metrics if val_patient_metrics else None\n",
        "        },\n",
        "        'test_metrics': {\n",
        "            'window_level_0.5_threshold': test_metrics_0_5,\n",
        "            'window_level_optimal_threshold': test_metrics_optimal,\n",
        "            'patient_level': test_patient_metrics if test_patient_metrics else None\n",
        "        }\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_results.json'), 'w') as f:\n",
        "        json.dump(results, f, indent=2, default=str)\n",
        "\n",
        "    # Save final model\n",
        "    final_model_path = os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_final.h5')\n",
        "    try:\n",
        "        model.save(final_model_path)\n",
        "        print(f'[OK] Model saved: {final_model_path}')\n",
        "    except Exception as e:\n",
        "        print('Warning: full model.save failed, saving weights only. Error:', e)\n",
        "        try:\n",
        "            model.save_weights(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_final_weights.h5'))\n",
        "            print('[OK] Weights saved as fallback')\n",
        "        except Exception as e2:\n",
        "            print('ERROR: failed to save weights as well:', e2)\n",
        "\n",
        "    print('\\nTRAINING SUMMARY')\n",
        "    print('='*80)\n",
        "    print(f\"Dataset: Original (train samples: {n_train:,})\")\n",
        "    print(f\"Epochs trained: {epochs_trained}/{EPOCHS}\")\n",
        "    print(f\"\\nOptimal threshold (Youden's J): {val_optimal_threshold:.4f}\")\n",
        "    print('\\nValidation metrics (window-level at optimal threshold):')\n",
        "    for k, v in val_metrics_optimal.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "    print('\\nTest metrics (window-level at optimal threshold):')\n",
        "    for k, v in test_metrics_optimal.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "\n",
        "    if test_patient_metrics:\n",
        "        print('\\nTest metrics (patient-level at optimal threshold):')\n",
        "        for k, v in test_patient_metrics['metrics_at_optimal_threshold'].items():\n",
        "            print(f\"  {k}: {v}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    DRY_RUN = False\n",
        "    DRY_RUN_SAMPLES = 1000\n",
        "\n",
        "    if DRY_RUN:\n",
        "        MODEL_NAME = MODEL_NAME + '_DRY_RUN'\n",
        "        print(\"=\"*80)\n",
        "        print(\"[TEST] DRY RUN MODE: Quick validation with small sample\")\n",
        "        print(f\"   Using {DRY_RUN_SAMPLES:,} training samples\")\n",
        "        print(f\"   Files will be saved with suffix: _DRY_RUN\")\n",
        "        print(\"=\"*80)\n",
        "        main(dry_run_max_samples=DRY_RUN_SAMPLES)\n",
        "    else:\n",
        "        print(\"=\"*80)\n",
        "        print(\"[FULL] FULL TRAINING MODE: Complete dataset\")\n",
        "        print(\"   Using all available training samples\")\n",
        "        print(\"=\"*80)\n",
        "        main(dry_run_max_samples=None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n08ok8jHe1bX",
        "outputId": "fdfd2671-8512-4451-b66d-4793afc106a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "[TEST] DRY RUN MODE: Quick validation with small sample\n",
            "   Using 1,000 training samples\n",
            "   Files will be saved with suffix: _DRY_RUN\n",
            "================================================================================\n",
            "[OK] Mixed precision (float16) policy enabled\n",
            "\n",
            "Loading memmap datasets...\n",
            "[FAST] DRY RUN: limiting datasets to 1000 samples (stratified sample)\n",
            "\n",
            "[OK] Training samples: 1,000\n",
            "  Class 0: 984 | Class 1: 16\n",
            "[OK] Validation: 1,000, Test: 1,000\n",
            "[OK] Optimizer wrapped with LossScaleOptimizer\n",
            "\n",
            "TRAINING:\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 1: val_auc improved from -inf to 0.46907, saving model to /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Original_CNN_adam_gelu_DRY_RUN_best.weights.h5\n",
            "4/4 - 14s - 3s/step - accuracy: 0.1510 - auc: 0.4520 - loss: 5.7454 - pr_auc: 0.0139 - precision: 0.0151 - recall: 0.8125 - val_accuracy: 0.9840 - val_auc: 0.4691 - val_loss: 0.1350 - val_pr_auc: 0.0207 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 2: val_auc improved from 0.46907 to 0.54770, saving model to /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Original_CNN_adam_gelu_DRY_RUN_best.weights.h5\n",
            "4/4 - 2s - 444ms/step - accuracy: 0.6700 - auc: 0.4227 - loss: 4.1941 - pr_auc: 0.0135 - precision: 0.0094 - recall: 0.1875 - val_accuracy: 0.9760 - val_auc: 0.5477 - val_loss: 0.4787 - val_pr_auc: 0.0166 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 3: val_auc improved from 0.54770 to 0.56225, saving model to /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Original_CNN_adam_gelu_DRY_RUN_best.weights.h5\n",
            "4/4 - 2s - 417ms/step - accuracy: 0.3210 - auc: 0.5014 - loss: 3.1959 - pr_auc: 0.0148 - precision: 0.0161 - recall: 0.6875 - val_accuracy: 0.0220 - val_auc: 0.5622 - val_loss: 1.5545 - val_pr_auc: 0.0268 - val_precision: 0.0161 - val_recall: 1.0000 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 4: val_auc did not improve from 0.56225\n",
            "4/4 - 2s - 495ms/step - accuracy: 0.2980 - auc: 0.5662 - loss: 3.0048 - pr_auc: 0.0192 - precision: 0.0183 - recall: 0.8125 - val_accuracy: 0.7900 - val_auc: 0.4615 - val_loss: 0.6181 - val_pr_auc: 0.0271 - val_precision: 0.0101 - val_recall: 0.1250 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 5: val_auc did not improve from 0.56225\n",
            "4/4 - 4s - 914ms/step - accuracy: 0.6700 - auc: 0.4413 - loss: 2.7593 - pr_auc: 0.0173 - precision: 0.0154 - recall: 0.3125 - val_accuracy: 0.9830 - val_auc: 0.4676 - val_loss: 0.4780 - val_pr_auc: 0.0153 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 6: val_auc did not improve from 0.56225\n",
            "4/4 - 4s - 1s/step - accuracy: 0.6750 - auc: 0.4381 - loss: 2.7816 - pr_auc: 0.0147 - precision: 0.0157 - recall: 0.3125 - val_accuracy: 0.9640 - val_auc: 0.4830 - val_loss: 0.5572 - val_pr_auc: 0.0173 - val_precision: 0.0455 - val_recall: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 7: val_auc did not improve from 0.56225\n",
            "4/4 - 3s - 782ms/step - accuracy: 0.5810 - auc: 0.3957 - loss: 2.4281 - pr_auc: 0.0119 - precision: 0.0097 - recall: 0.2500 - val_accuracy: 0.1010 - val_auc: 0.5042 - val_loss: 0.8293 - val_pr_auc: 0.0783 - val_precision: 0.0154 - val_recall: 0.8750 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 8: val_auc did not improve from 0.56225\n",
            "4/4 - 6s - 2s/step - accuracy: 0.4280 - auc: 0.4666 - loss: 1.9713 - pr_auc: 0.0155 - precision: 0.0174 - recall: 0.6250 - val_accuracy: 0.0830 - val_auc: 0.5241 - val_loss: 0.8870 - val_pr_auc: 0.0790 - val_precision: 0.0161 - val_recall: 0.9375 - learning_rate: 2.5000e-04\n",
            "Epoch 8: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "\n",
            "[OK] Training complete: 8/50 epochs\n",
            "\n",
            "EVALUATING: Validation Predictions...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 200ms/step\n",
            "[OK] Optimal threshold (Youden's J): 0.8012 (J=0.2099)\n",
            "[OK] Saved validation window-level predictions (1000 rows)\n",
            "[OK] Patient-level aggregation: 897 patients\n",
            "  Positive patients: 16\n",
            "  Negative patients: 881\n",
            "[OK] Saved validation patient-level predictions (897 patients)\n",
            "\n",
            "EVALUATING: Test Predictions...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Saved test window-level predictions (1000 rows)\n",
            "[OK] Patient-level aggregation: 888 patients\n",
            "  Positive patients: 17\n",
            "  Negative patients: 871\n",
            "[OK] Saved test patient-level predictions (888 patients)\n",
            "[OK] Model saved: /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Original_CNN_adam_gelu_DRY_RUN_final.h5\n",
            "\n",
            "TRAINING SUMMARY\n",
            "================================================================================\n",
            "Dataset: Original (train samples: 1,000)\n",
            "Epochs trained: 8/50\n",
            "\n",
            "Optimal threshold (Youden's J): 0.8012\n",
            "\n",
            "Validation metrics (window-level at optimal threshold):\n",
            "  threshold: 0.8012427091598511\n",
            "  roc_auc: 0.5625635162601627\n",
            "  pr_auc: 0.027637106604483465\n",
            "  sensitivity: 0.6875\n",
            "  specificity: 0.5223577235772358\n",
            "  precision: 0.02286902286902287\n",
            "  npv: 0.9903660886319846\n",
            "  f1_score: 0.04426559356136821\n",
            "  tp: 11\n",
            "  tn: 514\n",
            "  fp: 470\n",
            "  fn: 5\n",
            "\n",
            "Test metrics (window-level at optimal threshold):\n",
            "  threshold: 0.8012427091598511\n",
            "  roc_auc: 0.45927831966967864\n",
            "  pr_auc: 0.01407358729261864\n",
            "  sensitivity: 0.35294117647058826\n",
            "  specificity: 0.5462868769074263\n",
            "  precision: 0.01327433628318584\n",
            "  npv: 0.9799270072992701\n",
            "  f1_score: 0.025586353944562896\n",
            "  tp: 6\n",
            "  tn: 537\n",
            "  fp: 446\n",
            "  fn: 11\n",
            "\n",
            "Test metrics (patient-level at optimal threshold):\n",
            "  threshold: 0.7077004313468933\n",
            "  roc_auc: 0.4828797190517998\n",
            "  pr_auc: 0.016619574709614462\n",
            "  sensitivity: 1.0\n",
            "  specificity: 0.208955223880597\n",
            "  precision: 0.024079320113314446\n",
            "  npv: 1.0\n",
            "  f1_score: 0.04702627939142461\n",
            "  tp: 17\n",
            "  tn: 182\n",
            "  fp: 689\n",
            "  fn: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer"
      ],
      "metadata": {
        "id": "0enQOJkFezB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Stage 2 Baseline Training: Original Transformer (adam-tanh) - PRODUCTION RUN SCRIPT v2\n",
        "Enhanced with:\n",
        "- Complete TF reproducibility (tf.random.set_seed)\n",
        "- Youden J statistic for optimal threshold selection\n",
        "- Patient-level aggregation and metrics\n",
        "- Mixed precision and GPU memory growth\n",
        "- Class weighting for Original dataset imbalance\n",
        "- PR-AUC metric tracking (curve='PR')\n",
        "- Multi-head attention with positional embeddings\n",
        "- Robust error handling with all required keys\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import math\n",
        "import json\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import mixed_precision\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, confusion_matrix, roc_curve\n",
        "\n",
        "# -------------------------------\n",
        "# Configurable parameters\n",
        "# -------------------------------\n",
        "BASE_DIR = '/content/drive/MyDrive/AI_Course_Project/Dataset'\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, 'Stage2_Baseline')\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Original dataset paths\n",
        "TRAIN_PATH = os.path.join(BASE_DIR, 'baseline_train_matrices.npz')\n",
        "VAL_PATH   = os.path.join(BASE_DIR, 'baseline_val_matrices.npz')\n",
        "TEST_PATH  = os.path.join(BASE_DIR, 'baseline_test_matrices.npz')\n",
        "\n",
        "# Best combo for Original Transformer\n",
        "MODEL_NAME     = 'Original_Transformer_adam_tanh'\n",
        "OPTIMIZER_NAME = 'adam'\n",
        "ACTIVATION     = 'tanh'\n",
        "\n",
        "# Class weights for Original dataset (heavily imbalanced)\n",
        "CLASS_WEIGHT = {0: 1.0, 1: 61.0}\n",
        "\n",
        "# Hyperparameters\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 256\n",
        "UNITS = 128\n",
        "DROPOUT = 0.3\n",
        "LEARNING_RATE = 0.001\n",
        "PATIENCE = 5\n",
        "NUM_HEADS = 4\n",
        "\n",
        "SEQUENCE_LENGTH = 4\n",
        "N_FEATURES = 21\n",
        "\n",
        "# Reproducibility - COMPLETE SEEDING\n",
        "RANDOM_STATE = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(RANDOM_STATE)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "np.random.seed(RANDOM_STATE)\n",
        "tf.random.set_seed(RANDOM_STATE)\n",
        "random.seed(RANDOM_STATE)\n",
        "\n",
        "# -------------------------------\n",
        "# Utility functions\n",
        "# -------------------------------\n",
        "def set_gpu_and_mixed_precision():\n",
        "    \"\"\"Enable memory growth and mixed precision if available.\"\"\"\n",
        "    try:\n",
        "        policy = mixed_precision.Policy('mixed_float16')\n",
        "        mixed_precision.set_global_policy(policy)\n",
        "        print(\"[OK] Mixed precision (float16) policy enabled\")\n",
        "    except Exception:\n",
        "        print(\"[INFO] Mixed precision not available\")\n",
        "\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        for gpu in gpus:\n",
        "            try:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "            except Exception:\n",
        "                pass\n",
        "        print(f\"[OK] GPU memory growth enabled for {len(gpus)} GPU(s)\")\n",
        "\n",
        "def load_data_memmap_with_ids(path):\n",
        "    \"\"\"Load X (memmap), y (numpy), and optional patient_ids from .npz using mmap.\"\"\"\n",
        "    npz = np.load(path, mmap_mode='r')\n",
        "    X = npz['X']\n",
        "    y = np.array(npz['y'])\n",
        "    patient_ids = None\n",
        "    if 'patient_ids' in npz.files:\n",
        "        patient_ids = np.array(npz['patient_ids'])\n",
        "    return X, y, patient_ids\n",
        "\n",
        "def create_memmap_dataset(X_mmap, y, batch_size, shuffle=False, buffer_size=10000, sample_weights=None):\n",
        "    \"\"\"\n",
        "    Create a tf.data.Dataset that loads samples from a memmap by index.\n",
        "    If sample_weights is provided, yields (x, y, w) for weighted training.\n",
        "    Casts input to current mixed-precision compute dtype if enabled.\n",
        "    \"\"\"\n",
        "    n_samples = len(y)\n",
        "    indices = np.arange(n_samples, dtype=np.int64)\n",
        "    labels = y.copy().astype(np.int32)\n",
        "\n",
        "    if sample_weights is not None:\n",
        "        weights = np.array(sample_weights, dtype=np.float32)\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((indices, labels, weights))\n",
        "    else:\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((indices, labels))\n",
        "\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=buffer_size, seed=RANDOM_STATE, reshuffle_each_iteration=True)\n",
        "\n",
        "    def load_sample(*args):\n",
        "        if sample_weights is not None:\n",
        "            idx, label, weight = args\n",
        "        else:\n",
        "            idx, label = args\n",
        "\n",
        "        def _load(idx_val):\n",
        "            return X_mmap[int(idx_val)].astype(np.float32)\n",
        "\n",
        "        x = tf.numpy_function(_load, [idx], tf.float32)\n",
        "\n",
        "        # safe cast to mixed-precision compute dtype (float16 if policy set)\n",
        "        try:\n",
        "            compute_dtype = mixed_precision.global_policy().compute_dtype\n",
        "        except Exception:\n",
        "            compute_dtype = 'float32'\n",
        "        x = tf.cast(x, compute_dtype)\n",
        "\n",
        "        x.set_shape((SEQUENCE_LENGTH, N_FEATURES))\n",
        "\n",
        "        if sample_weights is not None:\n",
        "            return x, label, weight\n",
        "        else:\n",
        "            return x, label\n",
        "\n",
        "    dataset = dataset.map(load_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=False)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "def build_transformer(input_shape, units, dropout, activation, num_heads=4):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    masked = layers.Masking(mask_value=-1.0)(inputs)\n",
        "\n",
        "    # Positional embeddings\n",
        "    positions = tf.range(start=0, limit=input_shape[0], delta=1)\n",
        "    position_embedding = layers.Embedding(input_dim=input_shape[0], output_dim=input_shape[1])(positions)\n",
        "    x = masked + position_embedding\n",
        "\n",
        "    # Multi-head attention\n",
        "    attention_output = layers.MultiHeadAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=input_shape[1]//num_heads,\n",
        "        dropout=dropout\n",
        "    )(x, x)\n",
        "    x = layers.Add()([x, attention_output])\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "    # Feed-forward network\n",
        "    ffn = keras.Sequential([\n",
        "        layers.Dense(units, activation=activation),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(input_shape[1])\n",
        "    ])\n",
        "    ffn_output = ffn(x)\n",
        "    x = layers.Add()([x, ffn_output])\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "    # Classification head\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dense(units, activation=activation)(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    outputs = layers.Dense(1, activation='sigmoid', dtype='float32')(x)\n",
        "\n",
        "    return keras.Model(inputs=inputs, outputs=outputs, name='Transformer')\n",
        "\n",
        "def find_optimal_threshold_youden(y_true, y_pred_proba):\n",
        "    \"\"\"Find optimal threshold using Youden's J statistic (maximizes sensitivity + specificity - 1).\"\"\"\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
        "    j_scores = tpr - fpr  # Youden's J statistic\n",
        "    optimal_idx = np.argmax(j_scores)\n",
        "    optimal_threshold = thresholds[optimal_idx]\n",
        "    return float(optimal_threshold), float(j_scores[optimal_idx])\n",
        "\n",
        "def compute_metrics(y_true, y_pred, y_pred_proba, threshold=0.5):\n",
        "    \"\"\"Compute comprehensive metrics with robust error handling.\"\"\"\n",
        "    try:\n",
        "        cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "        if cm.size == 4:\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "        else:\n",
        "            tn = fp = fn = tp = 0\n",
        "\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "        precision_val = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "        npv = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n",
        "        f1 = 2 * (precision_val * sensitivity) / (precision_val + sensitivity) if (precision_val + sensitivity) > 0 else 0.0\n",
        "\n",
        "        roc_auc = roc_auc_score(y_true, y_pred_proba) if len(np.unique(y_true)) > 1 else 0.0\n",
        "\n",
        "        if len(np.unique(y_true)) > 1:\n",
        "            precision_curve, recall_curve, _ = precision_recall_curve(y_true, y_pred_proba)\n",
        "            pr_auc = auc(recall_curve, precision_curve)\n",
        "        else:\n",
        "            pr_auc = 0.0\n",
        "\n",
        "        return {\n",
        "            'threshold': float(threshold),\n",
        "            'roc_auc': float(roc_auc),\n",
        "            'pr_auc': float(pr_auc),\n",
        "            'sensitivity': float(sensitivity),\n",
        "            'specificity': float(specificity),\n",
        "            'precision': float(precision_val),\n",
        "            'npv': float(npv),\n",
        "            'f1_score': float(f1),\n",
        "            'tp': int(tp), 'tn': int(tn), 'fp': int(fp), 'fn': int(fn)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f'Warning: Error computing metrics: {e}')\n",
        "        return {\n",
        "            'threshold': float(threshold),\n",
        "            'roc_auc': 0.0, 'pr_auc': 0.0,\n",
        "            'sensitivity': 0.0, 'specificity': 0.0,\n",
        "            'precision': 0.0, 'npv': 0.0, 'f1_score': 0.0,\n",
        "            'tp': 0, 'tn': 0, 'fp': 0, 'fn': 0\n",
        "        }\n",
        "\n",
        "def compute_patient_level_metrics(pred_df):\n",
        "    \"\"\"\n",
        "    Patient-level aggregation and metrics.\n",
        "    - y_true: max across windows\n",
        "    - y_pred_proba: max across windows\n",
        "    \"\"\"\n",
        "    if 'patient_id' not in pred_df.columns or pred_df['patient_id'].isna().all():\n",
        "        print(\"[WARNING] No patient IDs available for patient-level aggregation\")\n",
        "        return None\n",
        "\n",
        "    patient_agg = pred_df.groupby('patient_id').agg({\n",
        "        'y_true': 'max',\n",
        "        'y_pred_proba': 'max'\n",
        "    }).reset_index()\n",
        "\n",
        "    unique_labels = patient_agg['y_true'].unique()\n",
        "    if len(unique_labels) < 2:\n",
        "        print(f\"[WARNING] Only {len(unique_labels)} class(es) in patient-level data. Metrics may be invalid.\")\n",
        "\n",
        "    try:\n",
        "        optimal_threshold, j_stat = find_optimal_threshold_youden(\n",
        "            patient_agg['y_true'].values,\n",
        "            patient_agg['y_pred_proba'].values\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"[WARNING] Could not compute optimal threshold: {e}. Using 0.5.\")\n",
        "        optimal_threshold = 0.5\n",
        "        j_stat = 0.0\n",
        "\n",
        "    patient_agg['y_pred_optimal'] = (patient_agg['y_pred_proba'] >= optimal_threshold).astype(int)\n",
        "\n",
        "    metrics_optimal = compute_metrics(\n",
        "        patient_agg['y_true'].values,\n",
        "        patient_agg['y_pred_optimal'].values,\n",
        "        patient_agg['y_pred_proba'].values,\n",
        "        threshold=optimal_threshold\n",
        "    )\n",
        "\n",
        "    patient_agg['y_pred_0.5'] = (patient_agg['y_pred_proba'] >= 0.5).astype(int)\n",
        "    metrics_0_5 = compute_metrics(\n",
        "        patient_agg['y_true'].values,\n",
        "        patient_agg['y_pred_0.5'].values,\n",
        "        patient_agg['y_pred_proba'].values,\n",
        "        threshold=0.5\n",
        "    )\n",
        "\n",
        "    print(f\"[OK] Patient-level aggregation: {len(patient_agg)} patients\")\n",
        "    print(f\"  Positive patients: {patient_agg['y_true'].sum()}\")\n",
        "    print(f\"  Negative patients: {(patient_agg['y_true'] == 0).sum()}\")\n",
        "\n",
        "    return {\n",
        "        'patient_aggregation': patient_agg,\n",
        "        'n_patients': len(patient_agg),\n",
        "        'n_positive_patients': int(patient_agg['y_true'].sum()),\n",
        "        'n_negative_patients': int((patient_agg['y_true'] == 0).sum()),\n",
        "        'optimal_threshold': optimal_threshold,\n",
        "        'youden_j_statistic': j_stat,\n",
        "        'metrics_at_optimal_threshold': metrics_optimal,\n",
        "        'metrics_at_0.5_threshold': metrics_0_5\n",
        "    }\n",
        "\n",
        "# -------------------------------\n",
        "# Main run\n",
        "# -------------------------------\n",
        "def main(dry_run_max_samples=None):\n",
        "    set_gpu_and_mixed_precision()\n",
        "\n",
        "    print('\\nLoading memmap datasets...')\n",
        "    X_train_mmap, y_train, patient_ids_train = load_data_memmap_with_ids(TRAIN_PATH)\n",
        "    X_val_mmap,   y_val,   patient_ids_val   = load_data_memmap_with_ids(VAL_PATH)\n",
        "    X_test_mmap,  y_test,  patient_ids_test  = load_data_memmap_with_ids(TEST_PATH)\n",
        "\n",
        "    # Optional quick dry run\n",
        "    if dry_run_max_samples is not None:\n",
        "        print(f'[FAST] DRY RUN: limiting datasets to {dry_run_max_samples} samples (stratified sample)')\n",
        "\n",
        "        def sample_mmap(X_mmap, y, patient_ids, n):\n",
        "            if len(y) <= n:\n",
        "                return X_mmap, y, patient_ids\n",
        "            idx0 = np.where(y == 0)[0]\n",
        "            idx1 = np.where(y == 1)[0]\n",
        "            ratio = len(idx1) / max(len(y), 1)\n",
        "            n1 = max(2, int(round(n * ratio)))\n",
        "            n0 = max(2, n - n1)\n",
        "            chosen0 = np.random.choice(idx0, size=min(n0, len(idx0)), replace=False)\n",
        "            chosen1 = np.random.choice(idx1, size=min(n1, len(idx1)), replace=False)\n",
        "            chosen = np.concatenate([chosen0, chosen1])\n",
        "            np.random.shuffle(chosen)\n",
        "            X_small = np.stack([X_mmap[i].astype(np.float32) for i in chosen])\n",
        "            y_small = y[chosen]\n",
        "            p_small = patient_ids[chosen] if patient_ids is not None else None\n",
        "            return X_small, y_small, p_small\n",
        "\n",
        "        X_train_mmap, y_train, patient_ids_train = sample_mmap(X_train_mmap, y_train, patient_ids_train, dry_run_max_samples)\n",
        "        X_val_mmap,   y_val,   patient_ids_val   = sample_mmap(X_val_mmap,   y_val,   patient_ids_val,   min(max(dry_run_max_samples // 10, 1000), len(y_val)))\n",
        "        X_test_mmap,  y_test,  patient_ids_test  = sample_mmap(X_test_mmap,  y_test,  patient_ids_test,  min(max(dry_run_max_samples // 10, 1000), len(y_test)))\n",
        "\n",
        "    n_train = len(y_train)\n",
        "    n_val   = len(y_val)\n",
        "    n_test  = len(y_test)\n",
        "\n",
        "    print(f'\\n[OK] Training samples: {n_train:,}')\n",
        "    print(f'  Class 0: {(y_train == 0).sum():,} | Class 1: {(y_train == 1).sum():,}')\n",
        "    print(f'[OK] Validation: {n_val:,}, Test: {n_test:,}')\n",
        "\n",
        "    # Sample weights for class imbalance (Original dataset)\n",
        "    train_sample_weights = np.where(y_train == 1, CLASS_WEIGHT[1], CLASS_WEIGHT[0]).astype(np.float32)\n",
        "\n",
        "    # Datasets: training uses weights; val/test do not\n",
        "    train_ds = create_memmap_dataset(X_train_mmap, y_train, batch_size=BATCH_SIZE, shuffle=True, sample_weights=train_sample_weights)\n",
        "    val_ds   = create_memmap_dataset(X_val_mmap,   y_val,   batch_size=BATCH_SIZE, shuffle=False)\n",
        "    test_ds  = create_memmap_dataset(X_test_mmap,  y_test,  batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    steps_per_epoch = math.ceil(n_train / BATCH_SIZE)\n",
        "\n",
        "    # Model\n",
        "    model = build_transformer((SEQUENCE_LENGTH, N_FEATURES), UNITS, DROPOUT, ACTIVATION, NUM_HEADS)\n",
        "\n",
        "    # Optimizer (with optional loss scaling under mixed precision)\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "    try:\n",
        "        from tensorflow.keras.mixed_precision import LossScaleOptimizer\n",
        "        if tf.keras.mixed_precision.global_policy().name == 'mixed_float16':\n",
        "            optimizer = LossScaleOptimizer(optimizer)\n",
        "            print('[OK] Optimizer wrapped with LossScaleOptimizer')\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    loss_fn = keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss_fn,\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            keras.metrics.AUC(name='auc'),                 # ROC-AUC\n",
        "            keras.metrics.AUC(name='pr_auc', curve='PR'),  # PR-AUC\n",
        "            keras.metrics.Precision(name='precision'),\n",
        "            keras.metrics.Recall(name='recall')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    checkpoint_path = os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_best.weights.h5')\n",
        "    callbacks = [\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            patience=PATIENCE,\n",
        "            restore_best_weights=True,\n",
        "            monitor='val_auc',\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        ),\n",
        "        keras.callbacks.ReduceLROnPlateau(\n",
        "            factor=0.5,\n",
        "            patience=3,\n",
        "            monitor='val_loss',\n",
        "            min_lr=1e-6,\n",
        "            verbose=1\n",
        "        ),\n",
        "        keras.callbacks.ModelCheckpoint(\n",
        "            filepath=checkpoint_path,\n",
        "            monitor='val_auc',\n",
        "            mode='max',\n",
        "            save_best_only=True,\n",
        "            save_weights_only=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        keras.callbacks.CSVLogger(\n",
        "            os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_training_log.csv')\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    print('\\nTRAINING:')\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=EPOCHS,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        callbacks=callbacks,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    epochs_trained = len(history.history['loss'])\n",
        "    print(f'\\n[OK] Training complete: {epochs_trained}/{EPOCHS} epochs')\n",
        "\n",
        "    # Save history\n",
        "    try:\n",
        "        history_serializable = {k: [float(v) for v in vals] for k, vals in history.history.items()}\n",
        "        with open(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_history.json'), 'w') as f:\n",
        "            json.dump(history_serializable, f, indent=2)\n",
        "    except Exception as e:\n",
        "        print('Warning: failed to save history:', e)\n",
        "\n",
        "    # VALIDATION EVALUATION WITH OPTIMAL THRESHOLD\n",
        "    print('\\nEVALUATING: Validation Predictions...')\n",
        "    y_val_pred_proba = model.predict(val_ds, verbose=1).flatten()\n",
        "    if len(y_val_pred_proba) != len(y_val):\n",
        "        y_val_pred_proba = y_val_pred_proba[:len(y_val)]\n",
        "\n",
        "    val_optimal_threshold, val_j_stat = find_optimal_threshold_youden(y_val, y_val_pred_proba)\n",
        "    print(f\"[OK] Optimal threshold (Youden's J): {val_optimal_threshold:.4f} (J={val_j_stat:.4f})\")\n",
        "\n",
        "    y_val_pred_optimal = (y_val_pred_proba >= val_optimal_threshold).astype(int)\n",
        "    y_val_pred_0_5     = (y_val_pred_proba > 0.5).astype(int)\n",
        "\n",
        "    val_metrics_optimal = compute_metrics(y_val, y_val_pred_optimal, y_val_pred_proba, val_optimal_threshold)\n",
        "    val_metrics_0_5     = compute_metrics(y_val, y_val_pred_0_5,     y_val_pred_proba, 0.5)\n",
        "\n",
        "    val_df = pd.DataFrame({\n",
        "        'y_true': y_val,\n",
        "        'y_pred_0.5': y_val_pred_0_5,\n",
        "        'y_pred_optimal': y_val_pred_optimal,\n",
        "        'y_pred_proba': y_val_pred_proba\n",
        "    })\n",
        "    if patient_ids_val is not None:\n",
        "        val_df.insert(0, 'patient_id', patient_ids_val[:len(y_val)])\n",
        "    val_df.to_csv(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_val_predictions.csv'), index=False)\n",
        "    print(f'[OK] Saved validation window-level predictions ({len(val_df)} rows)')\n",
        "\n",
        "    val_patient_metrics = compute_patient_level_metrics(val_df)\n",
        "    if val_patient_metrics:\n",
        "        val_patient_metrics['patient_aggregation'].to_csv(\n",
        "            os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_val_patient_predictions.csv'),\n",
        "            index=False\n",
        "        )\n",
        "        print(f\"[OK] Saved validation patient-level predictions ({val_patient_metrics['n_patients']} patients)\")\n",
        "\n",
        "    # TEST EVALUATION (using validation optimal threshold)\n",
        "    print('\\nEVALUATING: Test Predictions...')\n",
        "    y_test_pred_proba = model.predict(test_ds, verbose=1).flatten()\n",
        "    if len(y_test_pred_proba) != len(y_test):\n",
        "        y_test_pred_proba = y_test_pred_proba[:len(y_test)]\n",
        "\n",
        "    y_test_pred_optimal = (y_test_pred_proba >= val_optimal_threshold).astype(int)\n",
        "    y_test_pred_0_5     = (y_test_pred_proba > 0.5).astype(int)\n",
        "\n",
        "    test_metrics_optimal = compute_metrics(y_test, y_test_pred_optimal, y_test_pred_proba, val_optimal_threshold)\n",
        "    test_metrics_0_5     = compute_metrics(y_test, y_test_pred_0_5,     y_test_pred_proba, 0.5)\n",
        "\n",
        "    test_df = pd.DataFrame({\n",
        "        'y_true': y_test,\n",
        "        'y_pred_0.5': y_test_pred_0_5,\n",
        "        'y_pred_optimal': y_test_pred_optimal,\n",
        "        'y_pred_proba': y_test_pred_proba\n",
        "    })\n",
        "    if patient_ids_test is not None:\n",
        "        test_df.insert(0, 'patient_id', patient_ids_test[:len(y_test)])\n",
        "    test_df.to_csv(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_test_predictions.csv'), index=False)\n",
        "    print(f'[OK] Saved test window-level predictions ({len(test_df)} rows)')\n",
        "\n",
        "    test_patient_metrics = compute_patient_level_metrics(test_df)\n",
        "    if test_patient_metrics:\n",
        "        test_patient_metrics['patient_aggregation'].to_csv(\n",
        "            os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_test_patient_predictions.csv'),\n",
        "            index=False\n",
        "        )\n",
        "        print(f\"[OK] Saved test patient-level predictions ({test_patient_metrics['n_patients']} patients)\")\n",
        "\n",
        "    # Save comprehensive results\n",
        "    results = {\n",
        "        'model_name': MODEL_NAME,\n",
        "        'dataset': 'Original',\n",
        "        'model_type': 'Transformer',\n",
        "        'optimizer': OPTIMIZER_NAME,\n",
        "        'activation': ACTIVATION,\n",
        "        'train_samples': int(n_train),\n",
        "        'val_samples': int(n_val),\n",
        "        'test_samples': int(n_test),\n",
        "        'max_epochs': EPOCHS,\n",
        "        'epochs_trained': int(epochs_trained),\n",
        "        'early_stopped': bool(epochs_trained < EPOCHS),\n",
        "        'steps_per_epoch': steps_per_epoch,\n",
        "        'units': UNITS,\n",
        "        'num_heads': NUM_HEADS,\n",
        "        'dropout': DROPOUT,\n",
        "        'learning_rate': LEARNING_RATE,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'random_state': RANDOM_STATE,\n",
        "        'class_weight': CLASS_WEIGHT,\n",
        "        'optimal_threshold': val_optimal_threshold,\n",
        "        'youden_j_statistic': val_j_stat,\n",
        "        'validation_metrics': {\n",
        "            'window_level_0.5_threshold': val_metrics_0_5,\n",
        "            'window_level_optimal_threshold': val_metrics_optimal,\n",
        "            'patient_level': val_patient_metrics if val_patient_metrics else None\n",
        "        },\n",
        "        'test_metrics': {\n",
        "            'window_level_0.5_threshold': test_metrics_0_5,\n",
        "            'window_level_optimal_threshold': test_metrics_optimal,\n",
        "            'patient_level': test_patient_metrics if test_patient_metrics else None\n",
        "        }\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_results.json'), 'w') as f:\n",
        "        json.dump(results, f, indent=2, default=str)\n",
        "\n",
        "    # Save final model\n",
        "    final_model_path = os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_final.h5')\n",
        "    try:\n",
        "        model.save(final_model_path)\n",
        "        print(f'[OK] Model saved: {final_model_path}')\n",
        "    except Exception as e:\n",
        "        print('Warning: full model.save failed, saving weights only. Error:', e)\n",
        "        try:\n",
        "            model.save_weights(os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_final_weights.h5'))\n",
        "            print('[OK] Weights saved as fallback')\n",
        "        except Exception as e2:\n",
        "            print('ERROR: failed to save weights as well:', e2)\n",
        "\n",
        "    print('\\nTRAINING SUMMARY')\n",
        "    print('='*80)\n",
        "    print(f\"Dataset: Original (train samples: {n_train:,})\")\n",
        "    print(f\"Epochs trained: {epochs_trained}/{EPOCHS}\")\n",
        "    print(f\"\\nOptimal threshold (Youden's J): {val_optimal_threshold:.4f}\")\n",
        "    print('\\nValidation metrics (window-level at optimal threshold):')\n",
        "    for k, v in val_metrics_optimal.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "    print('\\nTest metrics (window-level at optimal threshold):')\n",
        "    for k, v in test_metrics_optimal.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "\n",
        "    if test_patient_metrics:\n",
        "        print('\\nTest metrics (patient-level at optimal threshold):')\n",
        "        for k, v in test_patient_metrics['metrics_at_optimal_threshold'].items():\n",
        "            print(f\"  {k}: {v}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    DRY_RUN = False\n",
        "    DRY_RUN_SAMPLES = 1000\n",
        "\n",
        "    if DRY_RUN:\n",
        "        MODEL_NAME = MODEL_NAME + '_DRY_RUN'\n",
        "        print(\"=\"*80)\n",
        "        print(\"[TEST] DRY RUN MODE: Quick validation with small sample\")\n",
        "        print(f\"   Using {DRY_RUN_SAMPLES:,} training samples\")\n",
        "        print(f\"   Files will be saved with suffix: _DRY_RUN\")\n",
        "        print(\"=\"*80)\n",
        "        main(dry_run_max_samples=DRY_RUN_SAMPLES)\n",
        "    else:\n",
        "        print(\"=\"*80)\n",
        "        print(\"[FULL] FULL TRAINING MODE: Complete dataset\")\n",
        "        print(\"   Using all available training samples\")\n",
        "        print(\"=\"*80)\n",
        "        main(dry_run_max_samples=None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rbW8KVye19T",
        "outputId": "ebcfae95-ed91-4c4d-80d1-83185db1d74b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "[TEST] DRY RUN MODE: Quick validation with small sample\n",
            "   Using 1,000 training samples\n",
            "   Files will be saved with suffix: _DRY_RUN\n",
            "================================================================================\n",
            "[OK] Mixed precision (float16) policy enabled\n",
            "\n",
            "Loading memmap datasets...\n",
            "[FAST] DRY RUN: limiting datasets to 1000 samples (stratified sample)\n",
            "\n",
            "[OK] Training samples: 1,000\n",
            "  Class 0: 984 | Class 1: 16\n",
            "[OK] Validation: 1,000, Test: 1,000\n",
            "[OK] Optimizer wrapped with LossScaleOptimizer\n",
            "\n",
            "TRAINING:\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 1: val_auc improved from -inf to 0.43721, saving model to /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Original_Transformer_adam_tanh_DRY_RUN_best.weights.h5\n",
            "4/4 - 13s - 3s/step - accuracy: 0.2090 - auc: 0.4305 - loss: 1.5184 - pr_auc: 0.0136 - precision: 0.0138 - recall: 0.6875 - val_accuracy: 0.9720 - val_auc: 0.4372 - val_loss: 0.6082 - val_pr_auc: 0.0141 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 2: val_auc improved from 0.43721 to 0.44912, saving model to /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Original_Transformer_adam_tanh_DRY_RUN_best.weights.h5\n",
            "4/4 - 1s - 237ms/step - accuracy: 0.8190 - auc: 0.4692 - loss: 1.4602 - pr_auc: 0.0172 - precision: 0.0175 - recall: 0.1875 - val_accuracy: 0.9840 - val_auc: 0.4491 - val_loss: 0.4528 - val_pr_auc: 0.0160 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 3: val_auc improved from 0.44912 to 0.47837, saving model to /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Original_Transformer_adam_tanh_DRY_RUN_best.weights.h5\n",
            "4/4 - 1s - 233ms/step - accuracy: 0.7800 - auc: 0.5428 - loss: 1.3847 - pr_auc: 0.0188 - precision: 0.0143 - recall: 0.1875 - val_accuracy: 0.8140 - val_auc: 0.4784 - val_loss: 0.6667 - val_pr_auc: 0.0207 - val_precision: 0.0115 - val_recall: 0.1250 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: val_auc did not improve from 0.47837\n",
            "4/4 - 1s - 192ms/step - accuracy: 0.4290 - auc: 0.6384 - loss: 1.2989 - pr_auc: 0.0855 - precision: 0.0224 - recall: 0.8125 - val_accuracy: 0.0220 - val_auc: 0.4687 - val_loss: 0.7931 - val_pr_auc: 0.0244 - val_precision: 0.0161 - val_recall: 1.0000 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 5: val_auc did not improve from 0.47837\n",
            "4/4 - 1s - 192ms/step - accuracy: 0.3790 - auc: 0.5544 - loss: 1.3573 - pr_auc: 0.0205 - precision: 0.0206 - recall: 0.8125 - val_accuracy: 0.1110 - val_auc: 0.4717 - val_loss: 0.7285 - val_pr_auc: 0.0342 - val_precision: 0.0177 - val_recall: 1.0000 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 6: val_auc did not improve from 0.47837\n",
            "4/4 - 1s - 194ms/step - accuracy: 0.4710 - auc: 0.6260 - loss: 1.3167 - pr_auc: 0.0257 - precision: 0.0223 - recall: 0.7500 - val_accuracy: 0.8340 - val_auc: 0.4732 - val_loss: 0.6665 - val_pr_auc: 0.0343 - val_precision: 0.0130 - val_recall: 0.1250 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 7: val_auc did not improve from 0.47837\n",
            "4/4 - 1s - 207ms/step - accuracy: 0.5800 - auc: 0.5763 - loss: 1.3461 - pr_auc: 0.0191 - precision: 0.0213 - recall: 0.5625 - val_accuracy: 0.9440 - val_auc: 0.4711 - val_loss: 0.6396 - val_pr_auc: 0.0446 - val_precision: 0.0238 - val_recall: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 8: val_auc did not improve from 0.47837\n",
            "4/4 - 2s - 397ms/step - accuracy: 0.6190 - auc: 0.4628 - loss: 1.4175 - pr_auc: 0.0135 - precision: 0.0107 - recall: 0.2500 - val_accuracy: 0.9550 - val_auc: 0.4649 - val_loss: 0.6317 - val_pr_auc: 0.0444 - val_precision: 0.0323 - val_recall: 0.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 8: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "\n",
            "[OK] Training complete: 8/50 epochs\n",
            "\n",
            "EVALUATING: Validation Predictions...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step\n",
            "[OK] Optimal threshold (Youden's J): 0.4746 (J=0.1250)\n",
            "[OK] Saved validation window-level predictions (1000 rows)\n",
            "[OK] Patient-level aggregation: 897 patients\n",
            "  Positive patients: 16\n",
            "  Negative patients: 881\n",
            "[OK] Saved validation patient-level predictions (897 patients)\n",
            "\n",
            "EVALUATING: Test Predictions...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
            "[OK] Saved test window-level predictions (1000 rows)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Patient-level aggregation: 888 patients\n",
            "  Positive patients: 17\n",
            "  Negative patients: 871\n",
            "[OK] Saved test patient-level predictions (888 patients)\n",
            "[OK] Model saved: /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Original_Transformer_adam_tanh_DRY_RUN_final.h5\n",
            "\n",
            "TRAINING SUMMARY\n",
            "================================================================================\n",
            "Dataset: Original (train samples: 1,000)\n",
            "Epochs trained: 8/50\n",
            "\n",
            "Optimal threshold (Youden's J): 0.4746\n",
            "\n",
            "Validation metrics (window-level at optimal threshold):\n",
            "  threshold: 0.47456035017967224\n",
            "  roc_auc: 0.4732596544715447\n",
            "  pr_auc: 0.02113459475916537\n",
            "  sensitivity: 0.875\n",
            "  specificity: 0.25\n",
            "  precision: 0.018617021276595744\n",
            "  npv: 0.9919354838709677\n",
            "  f1_score: 0.03645833333333333\n",
            "  tp: 14\n",
            "  tn: 246\n",
            "  fp: 738\n",
            "  fn: 2\n",
            "\n",
            "Test metrics (window-level at optimal threshold):\n",
            "  threshold: 0.47456035017967224\n",
            "  roc_auc: 0.4788462689246604\n",
            "  pr_auc: 0.018258773934596448\n",
            "  sensitivity: 0.7647058823529411\n",
            "  specificity: 0.25228891149542215\n",
            "  precision: 0.017379679144385027\n",
            "  npv: 0.9841269841269841\n",
            "  f1_score: 0.03398692810457517\n",
            "  tp: 13\n",
            "  tn: 248\n",
            "  fp: 735\n",
            "  fn: 4\n",
            "\n",
            "Test metrics (patient-level at optimal threshold):\n",
            "  threshold: 0.47713130712509155\n",
            "  roc_auc: 0.5162423178226515\n",
            "  pr_auc: 0.022827439602364677\n",
            "  sensitivity: 0.8823529411764706\n",
            "  specificity: 0.2904707233065442\n",
            "  precision: 0.023696682464454975\n",
            "  npv: 0.9921568627450981\n",
            "  f1_score: 0.04615384615384614\n",
            "  tp: 15\n",
            "  tn: 253\n",
            "  fp: 618\n",
            "  fn: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 stage Alert System - Undersampled dataset"
      ],
      "metadata": {
        "id": "WdYx8vy-zbA8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 1 - get best model for Undersampled dataset using Youden J"
      ],
      "metadata": {
        "id": "CDsZwe8tzg4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Stage 2 Baseline: Undersampled only\n",
        "- Uses best (optimizer, activation) per model from best_combinations.csv (dataset == 'Undersampled')\n",
        "- Trains each model once, computes Youden J threshold on validation\n",
        "- Computes patient-level validation AUROC (max hourly prob per patient)\n",
        "- Saves everything under AI_Fin/Stage2_Baseline with checkpointing\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import gc\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, confusion_matrix, roc_curve\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ============================================================\n",
        "# GPU & MIXED PRECISION SETUP\n",
        "# ============================================================\n",
        "try:\n",
        "    from tensorflow.keras import mixed_precision\n",
        "    policy = mixed_precision.Policy('mixed_float16')\n",
        "    mixed_precision.set_global_policy(policy)\n",
        "    print(\"✓ Mixed precision (float16) enabled for faster training\")\n",
        "except Exception:\n",
        "    print(\"ℹ Mixed precision not available, using float32\")\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    print(f\"✓ GPU memory growth enabled for {len(gpus)} GPU(s)\")\n",
        "\n",
        "# ============================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================\n",
        "BASE_DIR = '/content/drive/MyDrive/AI_Course_Project/Dataset'\n",
        "RESULTS_DIR = os.path.join(BASE_DIR, 'Stage2_Baseline')  # Stage 2 root\n",
        "CHECKPOINT_FILE = os.path.join(RESULTS_DIR, 'checkpoint_stage2.json')\n",
        "\n",
        "TRAIN_PATH = os.path.join(BASE_DIR, 'undersampled_train_matrices.npz')  # Undersampled only\n",
        "VAL_PATH = os.path.join(BASE_DIR, 'baseline_val_matrices.npz')\n",
        "BEST_COMB_CSV = os.path.join(BASE_DIR, 'best_combinations.csv')\n",
        "\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 256\n",
        "UNITS = 128\n",
        "DROPOUT = 0.3\n",
        "LEARNING_RATE = 1e-3\n",
        "EARLY_STOPPING_PATIENCE = 5\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "SEQUENCE_LENGTH = 4\n",
        "N_FEATURES = 21\n",
        "\n",
        "# Safe activation mapping (for GELU etc.)\n",
        "ACT_MAP = {\n",
        "    'relu': 'relu',\n",
        "    'tanh': 'tanh',\n",
        "    'sigmoid': 'sigmoid',\n",
        "    'gelu': tf.keras.activations.gelu\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# IO & CHECKPOINTS\n",
        "# ============================================================\n",
        "def create_directory_structure():\n",
        "    os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "    os.makedirs(os.path.join(RESULTS_DIR, 'Undersampled'), exist_ok=True)\n",
        "    print(f\"✓ Results dir: {RESULTS_DIR}\")\n",
        "\n",
        "def load_checkpoint():\n",
        "    if os.path.exists(CHECKPOINT_FILE):\n",
        "        with open(CHECKPOINT_FILE, 'r') as f:\n",
        "            return json.load(f)\n",
        "    return {'completed': []}\n",
        "\n",
        "def save_checkpoint(checkpoint):\n",
        "    with open(CHECKPOINT_FILE, 'w') as f:\n",
        "        json.dump(checkpoint, f, indent=2)\n",
        "\n",
        "def is_completed(model_name, checkpoint):\n",
        "    exp_id = f\"Undersampled_{model_name}\"\n",
        "    return exp_id in checkpoint['completed']\n",
        "\n",
        "def mark_completed(model_name, checkpoint):\n",
        "    exp_id = f\"Undersampled_{model_name}\"\n",
        "    if exp_id not in checkpoint['completed']:\n",
        "        checkpoint['completed'].append(exp_id)\n",
        "        save_checkpoint(checkpoint)\n",
        "\n",
        "# ============================================================\n",
        "# DATA LOADING\n",
        "# ============================================================\n",
        "def load_npz_memmap(path, key_x='X', key_y='y'):\n",
        "    npz = np.load(path, mmap_mode='r')\n",
        "    X = npz[key_x]\n",
        "    y = npz[key_y]\n",
        "    return npz, X, y\n",
        "\n",
        "def extract_patient_ids(npz_obj):\n",
        "    for k in ['patient_id', 'pid', 'patient_ids']:\n",
        "        if k in npz_obj.files:\n",
        "            return np.array(npz_obj[k])\n",
        "    return None\n",
        "\n",
        "def make_tf_dataset(X, y=None, batch_size=256, shuffle=False):\n",
        "    if y is None:\n",
        "        ds = tf.data.Dataset.from_tensor_slices(X)\n",
        "    else:\n",
        "        ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "        if shuffle:\n",
        "            ds = ds.shuffle(10000, seed=RANDOM_STATE, reshuffle_each_iteration=True)\n",
        "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "# ============================================================\n",
        "# BEST COMBINATIONS (Undersampled)\n",
        "# ============================================================\n",
        "def load_best_combos_for_undersampled(csv_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df_us = df[df['dataset'].str.lower() == 'undersampled'].copy()\n",
        "    if df_us.empty:\n",
        "        raise ValueError(\"No rows found for dataset == 'Undersampled' in best_combinations.csv\")\n",
        "    # If multiple rows per model exist, pick the row with highest roc_auc\n",
        "    df_us = df_us.sort_values(['model', 'roc_auc'], ascending=[True, False])\n",
        "    best_rows = df_us.groupby('model', as_index=False).first()\n",
        "    combos = []\n",
        "    for _, r in best_rows.iterrows():\n",
        "        combos.append({\n",
        "            'model': r['model'],\n",
        "            'optimizer': r['optimizer'],\n",
        "            'activation': r['activation']\n",
        "        })\n",
        "    return combos\n",
        "\n",
        "# ============================================================\n",
        "# MODELS\n",
        "# ============================================================\n",
        "def build_lstm(input_shape, units, dropout, activation):\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Masking(mask_value=-1.0),\n",
        "        layers.LSTM(units, activation=activation, return_sequences=False),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(64, activation=activation),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(1, activation='sigmoid', dtype='float32')\n",
        "    ], name='LSTM')\n",
        "    return model\n",
        "\n",
        "def build_rnn(input_shape, units, dropout, activation):\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Masking(mask_value=-1.0),\n",
        "        layers.SimpleRNN(units, activation=activation, return_sequences=False),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(64, activation=activation),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(1, activation='sigmoid', dtype='float32')\n",
        "    ], name='RNN')\n",
        "    return model\n",
        "\n",
        "def build_gru(input_shape, units, dropout, activation):\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Masking(mask_value=-1.0),\n",
        "        layers.GRU(units, activation=activation, return_sequences=False),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(64, activation=activation),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(1, activation='sigmoid', dtype='float32')\n",
        "    ], name='GRU')\n",
        "    return model\n",
        "\n",
        "def build_lstm_attention(input_shape, units, dropout, activation):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    masked = layers.Masking(mask_value=-1.0)(inputs)\n",
        "    lstm_out = layers.LSTM(units, activation=activation, return_sequences=True)(masked)\n",
        "    attn = layers.Dense(1, activation='tanh')(lstm_out)\n",
        "    attn = layers.Flatten()(attn)\n",
        "    attn = layers.Activation('softmax')(attn)\n",
        "    attn = layers.RepeatVector(units)(attn)\n",
        "    attn = layers.Permute([2, 1])(attn)\n",
        "    merged = layers.Multiply()([lstm_out, attn])\n",
        "    merged = layers.Lambda(lambda x: keras.backend.sum(x, axis=1))(merged)\n",
        "    dense = layers.Dense(64, activation=activation)(merged)\n",
        "    dense = layers.Dropout(dropout)(dense)\n",
        "    outputs = layers.Dense(1, activation='sigmoid', dtype='float32')(dense)\n",
        "    return keras.Model(inputs=inputs, outputs=outputs, name='LSTM_Attention')\n",
        "\n",
        "def build_cnn(input_shape, units, dropout, activation):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    masked_input = layers.Lambda(lambda x: tf.where(tf.equal(x, -1), tf.zeros_like(x), x))(inputs)\n",
        "    x = layers.Conv1D(64, 2, activation=activation, padding='same')(masked_input)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(128, 2, activation=activation, padding='same')(x)\n",
        "    x = layers.GlobalMaxPooling1D()(x)\n",
        "    x = layers.Dense(units, activation=activation)(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    outputs = layers.Dense(1, activation='sigmoid', dtype='float32')(x)\n",
        "    return keras.Model(inputs=inputs, outputs=outputs, name='CNN')\n",
        "\n",
        "def build_transformer(input_shape, units, dropout, activation):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    masked = layers.Masking(mask_value=-1.0)(inputs)\n",
        "    positions = tf.range(start=0, limit=input_shape[0], delta=1)\n",
        "    pos_emb = layers.Embedding(input_dim=input_shape[0], output_dim=input_shape[1])(positions)\n",
        "    x = masked + pos_emb\n",
        "    attn = layers.MultiHeadAttention(num_heads=4, key_dim=input_shape[1] // 4, dropout=dropout)(x, x)\n",
        "    x = layers.Add()([x, attn])\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    ffn = keras.Sequential([\n",
        "        layers.Dense(units, activation=activation),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(input_shape[1])\n",
        "    ])\n",
        "    ffn_out = ffn(x)\n",
        "    x = layers.Add()([x, ffn_out])\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dense(units, activation=activation)(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    outputs = layers.Dense(1, activation='sigmoid', dtype='float32')(x)\n",
        "    return keras.Model(inputs=inputs, outputs=outputs, name='Transformer')\n",
        "\n",
        "def get_model(model_name, input_shape, units, dropout, activation):\n",
        "    act = ACT_MAP.get(activation, activation)\n",
        "    builders = {\n",
        "        'LSTM': build_lstm,\n",
        "        'RNN': build_rnn,\n",
        "        'GRU': build_gru,\n",
        "        'LSTM_Attention': build_lstm_attention,\n",
        "        'CNN': build_cnn,\n",
        "        'Transformer': build_transformer\n",
        "    }\n",
        "    return builders[model_name](input_shape, units, dropout, act)\n",
        "\n",
        "# ============================================================\n",
        "# METRICS & YOUDEN\n",
        "# ============================================================\n",
        "def compute_metrics(y_true, y_pred, y_pred_proba):\n",
        "    try:\n",
        "        cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "        if cm.shape == (2, 2):\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "        else:\n",
        "            tn = fp = fn = tp = 0\n",
        "            if cm.shape == (1, 1):\n",
        "                if y_true[0] == 0:\n",
        "                    tn = cm[0, 0]\n",
        "                else:\n",
        "                    tp = cm[0, 0]\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "        npv = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n",
        "        f1 = 2 * (precision * sensitivity) / (precision + sensitivity) if (precision + sensitivity) > 0 else 0.0\n",
        "        roc_auc = roc_auc_score(y_true, y_pred_proba) if len(np.unique(y_true)) > 1 else 0.0\n",
        "        if len(np.unique(y_true)) > 1:\n",
        "            precision_curve, recall_curve, _ = precision_recall_curve(y_true, y_pred_proba)\n",
        "            pr_auc = auc(recall_curve, precision_curve)\n",
        "        else:\n",
        "            pr_auc = 0.0\n",
        "        return {\n",
        "            'roc_auc': float(roc_auc),\n",
        "            'pr_auc': float(pr_auc),\n",
        "            'sensitivity': float(sensitivity),\n",
        "            'specificity': float(specificity),\n",
        "            'precision': float(precision),\n",
        "            'npv': float(npv),\n",
        "            'f1_score': float(f1),\n",
        "            'tp': int(tp), 'tn': int(tn), 'fp': int(fp), 'fn': int(fn)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Error computing metrics: {e}\")\n",
        "        return {'roc_auc': 0.0, 'pr_auc': 0.0, 'sensitivity': 0.0, 'specificity': 0.0,\n",
        "                'precision': 0.0, 'npv': 0.0, 'f1_score': 0.0, 'tp': 0, 'tn': 0, 'fp': 0, 'fn': 0}\n",
        "\n",
        "def youden_threshold(y_true, y_proba):\n",
        "    # J = sensitivity + specificity - 1 = tpr - fpr; choose threshold maximizing J\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_proba)\n",
        "    j_scores = tpr - fpr\n",
        "    idx = int(np.argmax(j_scores))\n",
        "    return float(thresholds[idx]), float(j_scores[idx])\n",
        "\n",
        "# ============================================================\n",
        "# TRAINING & EVAL (per model)\n",
        "# ============================================================\n",
        "def train_eval_with_youden(model_name, optimizer_name, activation,\n",
        "                           X_train, y_train, X_val, y_val, val_pids):\n",
        "    input_shape = (SEQUENCE_LENGTH, N_FEATURES)\n",
        "    model = get_model(model_name, input_shape, UNITS, DROPOUT, activation)\n",
        "\n",
        "    if optimizer_name == 'adam':\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "    else:\n",
        "        optimizer = keras.optimizers.RMSprop(learning_rate=LEARNING_RATE)\n",
        "\n",
        "    loss_fn = keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy', keras.metrics.AUC(name='auc')])\n",
        "\n",
        "    exp_name = f\"Undersampled_{model_name}_{optimizer_name}_{activation}\"\n",
        "    model_dir = os.path.join(RESULTS_DIR, 'Undersampled', exp_name)\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "    callbacks = [\n",
        "        keras.callbacks.EarlyStopping(patience=EARLY_STOPPING_PATIENCE, restore_best_weights=True,\n",
        "                                      monitor='val_auc', mode='max', verbose=1),\n",
        "        keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3, monitor='val_loss', min_lr=1e-6, verbose=1),\n",
        "        keras.callbacks.CSVLogger(os.path.join(model_dir, f'{exp_name}_training_log.csv'))\n",
        "    ]\n",
        "\n",
        "    print(f\"\\n{'='*60}\\nTraining: {exp_name}\\n{'='*60}\")\n",
        "    train_ds = make_tf_dataset(X_train, y_train, BATCH_SIZE, shuffle=True)\n",
        "    val_ds = make_tf_dataset(X_val, y_val, BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=callbacks, verbose=2)\n",
        "    epochs_trained = len(history.history['loss'])\n",
        "\n",
        "    # Predict validation probabilities\n",
        "    y_val_pred_proba = model.predict(val_ds, verbose=0).reshape(-1).astype(float)\n",
        "\n",
        "    # Youden threshold on validation\n",
        "    thr_youden, j_score = youden_threshold(y_val, y_val_pred_proba)\n",
        "    y_val_pred = (y_val_pred_proba >= thr_youden).astype(int)\n",
        "    val_metrics = compute_metrics(y_val, y_val_pred, y_val_pred_proba)\n",
        "\n",
        "    # Patient-level validation AUROC (max hourly prob per patient)\n",
        "    df_val = pd.DataFrame({\n",
        "        'patient_id': val_pids if val_pids is not None else np.arange(len(y_val), dtype=int),\n",
        "        'y_true': y_val.astype(int),\n",
        "        'y_pred_proba': y_val_pred_proba\n",
        "    })\n",
        "\n",
        "    patient_agg = df_val.groupby('patient_id').agg(\n",
        "        y_true=('y_true', 'max'),\n",
        "        y_pred_proba=('y_pred_proba', 'max')\n",
        "    ).reset_index()\n",
        "\n",
        "    if len(np.unique(patient_agg['y_true'])) > 1:\n",
        "        patient_level_auc = roc_auc_score(patient_agg['y_true'], patient_agg['y_pred_proba'])\n",
        "    else:\n",
        "        patient_level_auc = 0.0\n",
        "\n",
        "    # Save model\n",
        "    model_path = os.path.join(model_dir, f'{exp_name}_model.h5')\n",
        "    model.save(model_path)\n",
        "\n",
        "    # Save validation predictions\n",
        "    df_val['row_idx'] = np.arange(len(y_val), dtype=int)\n",
        "    df_val = df_val[['row_idx', 'patient_id', 'y_true', 'y_pred_proba']]\n",
        "    df_val.to_csv(os.path.join(model_dir, f'{exp_name}_val_predictions.csv'), index=False)\n",
        "\n",
        "    # Save threshold info\n",
        "    thr_info = {\n",
        "        'youden_threshold': thr_youden,\n",
        "        'youden_J': j_score,\n",
        "        'note': 'Threshold computed on validation probabilities via Youden J'\n",
        "    }\n",
        "    with open(os.path.join(model_dir, f'{exp_name}_youden_threshold.json'), 'w') as f:\n",
        "        json.dump(thr_info, f, indent=2)\n",
        "\n",
        "    # Save metrics\n",
        "    results = {\n",
        "        'dataset': 'Undersampled',\n",
        "        'model': model_name,\n",
        "        'optimizer': optimizer_name,\n",
        "        'activation': activation,\n",
        "        'train_samples': int(len(X_train)),\n",
        "        'val_samples': int(len(X_val)),\n",
        "        'max_epochs': EPOCHS,\n",
        "        'epochs_trained': int(epochs_trained),\n",
        "        'early_stopped': bool(epochs_trained < EPOCHS),\n",
        "        'final_train_loss': float(history.history['loss'][-1]),\n",
        "        'final_val_loss': float(history.history['val_loss'][-1]),\n",
        "        'final_train_auc': float(history.history['auc'][-1]),\n",
        "        'final_val_auc': float(history.history['val_auc'][-1]),\n",
        "        'youden_threshold': thr_youden,\n",
        "        'youden_J': j_score,\n",
        "        'patient_val_auc': float(patient_level_auc),\n",
        "        **val_metrics\n",
        "    }\n",
        "    with open(os.path.join(model_dir, f'{exp_name}_metrics.json'), 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "    print(f\"\\n✓ Completed: {exp_name}\")\n",
        "    print(f\"  Epochs: {epochs_trained}/{EPOCHS}\")\n",
        "    print(f\"  Youden thr: {thr_youden:.4f}\")\n",
        "    print(f\"  Val time-level ROC-AUC: {val_metrics['roc_auc']:.4f}  PR-AUC: {val_metrics['pr_auc']:.4f}\")\n",
        "    print(f\"  Val patient-level AUC: {patient_level_auc:.4f}\")\n",
        "\n",
        "    del model\n",
        "    keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "    return results\n",
        "\n",
        "# ============================================================\n",
        "# MAIN\n",
        "# ============================================================\n",
        "def main():\n",
        "    create_directory_structure()\n",
        "    checkpoint = load_checkpoint()\n",
        "\n",
        "    # Load best combinations for Undersampled\n",
        "    combos = load_best_combos_for_undersampled(BEST_COMB_CSV)\n",
        "    print(f\"Found best combos for models: {', '.join([c['model'] for c in combos])}\")\n",
        "\n",
        "    # Load training (Undersampled full) and validation sets\n",
        "    npz_train, X_train_full, y_train_full = load_npz_memmap(TRAIN_PATH)\n",
        "    X_train = X_train_full[:].astype(np.float32)\n",
        "    y_train = y_train_full[:]\n",
        "    print(f\"✓ Using Undersampled full train: {len(X_train):,} rows\")\n",
        "\n",
        "    npz_val, X_val_full, y_val = load_npz_memmap(VAL_PATH)\n",
        "    X_val = X_val_full[:].astype(np.float32)\n",
        "    val_pids = extract_patient_ids(npz_val)\n",
        "    print(f\"✓ Validation: {len(X_val):,} rows\")\n",
        "\n",
        "    all_results = []\n",
        "    for c in combos:\n",
        "        model_name = c['model']\n",
        "        optimizer_name = c['optimizer']\n",
        "        activation = c['activation']\n",
        "\n",
        "        if is_completed(model_name, checkpoint):\n",
        "            print(f\"SKIP (checkpoint): Undersampled/{model_name}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            res = train_eval_with_youden(\n",
        "                model_name=model_name,\n",
        "                optimizer_name=optimizer_name,\n",
        "                activation=activation,\n",
        "                X_train=X_train,\n",
        "                y_train=y_train,\n",
        "                X_val=X_val,\n",
        "                y_val=y_val,\n",
        "                val_pids=val_pids\n",
        "            )\n",
        "            all_results.append(res)\n",
        "            mark_completed(model_name, checkpoint)\n",
        "        except Exception as e:\n",
        "            print(f\"\\n❌ ERROR in {model_name}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "\n",
        "    # Save summary\n",
        "    if len(all_results) > 0:\n",
        "        summary_df = pd.DataFrame(all_results)\n",
        "        summary_path = os.path.join(RESULTS_DIR, 'Undersampled', 'stage2_summary.csv')\n",
        "        os.makedirs(os.path.dirname(summary_path), exist_ok=True)\n",
        "        summary_df.to_csv(summary_path, index=False)\n",
        "        print(f\"\\n✓ Summary saved: {summary_path}\")\n",
        "    print(f\"\\n✓ Stage 2 complete: {RESULTS_DIR}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ilY-xlH6KMc",
        "outputId": "cc508298-9257-45af-a63d-0cb4419c23da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Mixed precision (float16) enabled for faster training\n",
            "✓ Results dir: /content/drive/MyDrive/AI_Fin/Stage2_Baseline\n",
            "Found best combos for models: CNN, GRU, LSTM, LSTM_Attention, RNN, Transformer\n",
            "✓ Using Undersampled full train: 31,234 rows\n",
            "✓ Validation: 243,432 rows\n",
            "\n",
            "============================================================\n",
            "Training: Undersampled_CNN_adam_gelu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "123/123 - 57s - 462ms/step - accuracy: 0.5211 - auc: 0.5206 - loss: 0.9785 - val_accuracy: 0.6046 - val_auc: 0.5762 - val_loss: 0.6900 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "123/123 - 44s - 355ms/step - accuracy: 0.5494 - auc: 0.5668 - loss: 0.6883 - val_accuracy: 0.8822 - val_auc: 0.6464 - val_loss: 0.5928 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "123/123 - 44s - 356ms/step - accuracy: 0.5780 - auc: 0.6125 - loss: 0.6732 - val_accuracy: 0.4572 - val_auc: 0.6807 - val_loss: 0.7630 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "123/123 - 82s - 666ms/step - accuracy: 0.6016 - auc: 0.6402 - loss: 0.6633 - val_accuracy: 0.7283 - val_auc: 0.6873 - val_loss: 0.6092 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "123/123 - 44s - 355ms/step - accuracy: 0.6064 - auc: 0.6474 - loss: 0.6590 - val_accuracy: 0.8720 - val_auc: 0.6871 - val_loss: 0.5091 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "123/123 - 44s - 354ms/step - accuracy: 0.6181 - auc: 0.6592 - loss: 0.6533 - val_accuracy: 0.5465 - val_auc: 0.7004 - val_loss: 0.7318 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "123/123 - 43s - 352ms/step - accuracy: 0.6222 - auc: 0.6653 - loss: 0.6508 - val_accuracy: 0.7699 - val_auc: 0.6906 - val_loss: 0.5629 - learning_rate: 1.0000e-03\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "123/123 - 43s - 353ms/step - accuracy: 0.6319 - auc: 0.6758 - loss: 0.6456 - val_accuracy: 0.6855 - val_auc: 0.7055 - val_loss: 0.6249 - learning_rate: 1.0000e-03\n",
            "Epoch 9/50\n",
            "123/123 - 43s - 352ms/step - accuracy: 0.6369 - auc: 0.6866 - loss: 0.6386 - val_accuracy: 0.6624 - val_auc: 0.7073 - val_loss: 0.6382 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "123/123 - 82s - 668ms/step - accuracy: 0.6373 - auc: 0.6856 - loss: 0.6392 - val_accuracy: 0.8115 - val_auc: 0.7105 - val_loss: 0.5237 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "123/123 - 82s - 664ms/step - accuracy: 0.6430 - auc: 0.6890 - loss: 0.6376 - val_accuracy: 0.7514 - val_auc: 0.7100 - val_loss: 0.5676 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "123/123 - 43s - 351ms/step - accuracy: 0.6428 - auc: 0.6943 - loss: 0.6346 - val_accuracy: 0.7699 - val_auc: 0.7163 - val_loss: 0.5540 - learning_rate: 2.5000e-04\n",
            "Epoch 13/50\n",
            "123/123 - 43s - 350ms/step - accuracy: 0.6484 - auc: 0.6990 - loss: 0.6315 - val_accuracy: 0.8783 - val_auc: 0.7126 - val_loss: 0.4359 - learning_rate: 2.5000e-04\n",
            "Epoch 14/50\n",
            "123/123 - 43s - 351ms/step - accuracy: 0.6458 - auc: 0.6968 - loss: 0.6329 - val_accuracy: 0.8429 - val_auc: 0.7144 - val_loss: 0.4774 - learning_rate: 2.5000e-04\n",
            "Epoch 15/50\n",
            "123/123 - 43s - 350ms/step - accuracy: 0.6476 - auc: 0.7005 - loss: 0.6302 - val_accuracy: 0.8317 - val_auc: 0.7171 - val_loss: 0.4802 - learning_rate: 2.5000e-04\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "123/123 - 53s - 428ms/step - accuracy: 0.6487 - auc: 0.7017 - loss: 0.6296 - val_accuracy: 0.8515 - val_auc: 0.7180 - val_loss: 0.4520 - learning_rate: 2.5000e-04\n",
            "Epoch 17/50\n",
            "123/123 - 43s - 349ms/step - accuracy: 0.6534 - auc: 0.7037 - loss: 0.6282 - val_accuracy: 0.7779 - val_auc: 0.7192 - val_loss: 0.5214 - learning_rate: 1.2500e-04\n",
            "Epoch 18/50\n",
            "123/123 - 43s - 348ms/step - accuracy: 0.6527 - auc: 0.7060 - loss: 0.6268 - val_accuracy: 0.8076 - val_auc: 0.7202 - val_loss: 0.4988 - learning_rate: 1.2500e-04\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "123/123 - 49s - 395ms/step - accuracy: 0.6514 - auc: 0.7071 - loss: 0.6260 - val_accuracy: 0.8025 - val_auc: 0.7187 - val_loss: 0.4984 - learning_rate: 1.2500e-04\n",
            "Epoch 20/50\n",
            "123/123 - 43s - 350ms/step - accuracy: 0.6523 - auc: 0.7059 - loss: 0.6268 - val_accuracy: 0.8162 - val_auc: 0.7190 - val_loss: 0.4854 - learning_rate: 6.2500e-05\n",
            "Epoch 21/50\n",
            "123/123 - 43s - 349ms/step - accuracy: 0.6533 - auc: 0.7070 - loss: 0.6261 - val_accuracy: 0.8184 - val_auc: 0.7199 - val_loss: 0.4799 - learning_rate: 6.2500e-05\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "123/123 - 82s - 669ms/step - accuracy: 0.6517 - auc: 0.7064 - loss: 0.6264 - val_accuracy: 0.8055 - val_auc: 0.7219 - val_loss: 0.4931 - learning_rate: 6.2500e-05\n",
            "Epoch 23/50\n",
            "123/123 - 82s - 663ms/step - accuracy: 0.6506 - auc: 0.7079 - loss: 0.6252 - val_accuracy: 0.8158 - val_auc: 0.7215 - val_loss: 0.4814 - learning_rate: 3.1250e-05\n",
            "Epoch 24/50\n",
            "123/123 - 43s - 352ms/step - accuracy: 0.6559 - auc: 0.7082 - loss: 0.6253 - val_accuracy: 0.8270 - val_auc: 0.7207 - val_loss: 0.4667 - learning_rate: 3.1250e-05\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "123/123 - 43s - 349ms/step - accuracy: 0.6562 - auc: 0.7094 - loss: 0.6246 - val_accuracy: 0.8131 - val_auc: 0.7217 - val_loss: 0.4831 - learning_rate: 3.1250e-05\n",
            "Epoch 26/50\n",
            "123/123 - 82s - 666ms/step - accuracy: 0.6545 - auc: 0.7109 - loss: 0.6235 - val_accuracy: 0.8179 - val_auc: 0.7211 - val_loss: 0.4753 - learning_rate: 1.5625e-05\n",
            "Epoch 27/50\n",
            "123/123 - 82s - 668ms/step - accuracy: 0.6555 - auc: 0.7104 - loss: 0.6235 - val_accuracy: 0.8200 - val_auc: 0.7214 - val_loss: 0.4738 - learning_rate: 1.5625e-05\n",
            "Epoch 27: early stopping\n",
            "Restoring model weights from the end of the best epoch: 22.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: Undersampled_CNN_adam_gelu\n",
            "  Epochs: 27/50\n",
            "  Youden thr: 0.3930\n",
            "  Val time-level ROC-AUC: 0.7219  PR-AUC: 0.0425\n",
            "  Val patient-level AUC: 0.7758\n",
            "\n",
            "============================================================\n",
            "Training: Undersampled_GRU_rmsprop_gelu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "123/123 - 25s - 203ms/step - accuracy: 0.5458 - auc: 0.5573 - loss: 0.7645 - val_accuracy: 0.3657 - val_auc: 0.6828 - val_loss: 0.7242 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "123/123 - 19s - 154ms/step - accuracy: 0.6028 - auc: 0.6442 - loss: 0.6613 - val_accuracy: 0.9189 - val_auc: 0.6895 - val_loss: 0.4509 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "123/123 - 21s - 169ms/step - accuracy: 0.6190 - auc: 0.6659 - loss: 0.6500 - val_accuracy: 0.4780 - val_auc: 0.6940 - val_loss: 0.7412 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "123/123 - 19s - 153ms/step - accuracy: 0.6325 - auc: 0.6824 - loss: 0.6405 - val_accuracy: 0.1893 - val_auc: 0.7136 - val_loss: 1.0568 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "123/123 - 19s - 154ms/step - accuracy: 0.6388 - auc: 0.6910 - loss: 0.6351 - val_accuracy: 0.6796 - val_auc: 0.7031 - val_loss: 0.6245 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "123/123 - 21s - 169ms/step - accuracy: 0.6498 - auc: 0.7046 - loss: 0.6271 - val_accuracy: 0.2933 - val_auc: 0.7262 - val_loss: 0.9325 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "123/123 - 19s - 153ms/step - accuracy: 0.6537 - auc: 0.7093 - loss: 0.6240 - val_accuracy: 0.8908 - val_auc: 0.7173 - val_loss: 0.4137 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "123/123 - 25s - 201ms/step - accuracy: 0.6585 - auc: 0.7151 - loss: 0.6194 - val_accuracy: 0.7856 - val_auc: 0.7242 - val_loss: 0.5305 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "123/123 - 19s - 153ms/step - accuracy: 0.6613 - auc: 0.7187 - loss: 0.6165 - val_accuracy: 0.5370 - val_auc: 0.7254 - val_loss: 0.7339 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "123/123 - 21s - 169ms/step - accuracy: 0.6637 - auc: 0.7232 - loss: 0.6126 - val_accuracy: 0.8848 - val_auc: 0.7324 - val_loss: 0.4096 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "123/123 - 19s - 153ms/step - accuracy: 0.6686 - auc: 0.7271 - loss: 0.6102 - val_accuracy: 0.3136 - val_auc: 0.7313 - val_loss: 0.9176 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "123/123 - 19s - 154ms/step - accuracy: 0.6732 - auc: 0.7325 - loss: 0.6064 - val_accuracy: 0.6193 - val_auc: 0.7348 - val_loss: 0.6759 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "123/123 - 21s - 169ms/step - accuracy: 0.6749 - auc: 0.7354 - loss: 0.6043 - val_accuracy: 0.9285 - val_auc: 0.7248 - val_loss: 0.3336 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "123/123 - 19s - 152ms/step - accuracy: 0.6748 - auc: 0.7369 - loss: 0.6027 - val_accuracy: 0.5412 - val_auc: 0.7348 - val_loss: 0.7404 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "123/123 - 20s - 159ms/step - accuracy: 0.6755 - auc: 0.7380 - loss: 0.6017 - val_accuracy: 0.9050 - val_auc: 0.7261 - val_loss: 0.3529 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "123/123 - 20s - 165ms/step - accuracy: 0.6798 - auc: 0.7420 - loss: 0.5985 - val_accuracy: 0.6313 - val_auc: 0.7414 - val_loss: 0.6462 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "123/123 - 19s - 154ms/step - accuracy: 0.6835 - auc: 0.7476 - loss: 0.5938 - val_accuracy: 0.5943 - val_auc: 0.7416 - val_loss: 0.6910 - learning_rate: 2.5000e-04\n",
            "Epoch 18/50\n",
            "123/123 - 20s - 164ms/step - accuracy: 0.6822 - auc: 0.7485 - loss: 0.5924 - val_accuracy: 0.8159 - val_auc: 0.7354 - val_loss: 0.4702 - learning_rate: 2.5000e-04\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "123/123 - 19s - 158ms/step - accuracy: 0.6826 - auc: 0.7508 - loss: 0.5909 - val_accuracy: 0.6841 - val_auc: 0.7376 - val_loss: 0.6076 - learning_rate: 2.5000e-04\n",
            "Epoch 20/50\n",
            "123/123 - 19s - 153ms/step - accuracy: 0.6854 - auc: 0.7524 - loss: 0.5891 - val_accuracy: 0.6718 - val_auc: 0.7419 - val_loss: 0.6186 - learning_rate: 1.2500e-04\n",
            "Epoch 21/50\n",
            "123/123 - 21s - 168ms/step - accuracy: 0.6871 - auc: 0.7543 - loss: 0.5875 - val_accuracy: 0.7318 - val_auc: 0.7434 - val_loss: 0.5558 - learning_rate: 1.2500e-04\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "123/123 - 41s - 336ms/step - accuracy: 0.6899 - auc: 0.7556 - loss: 0.5864 - val_accuracy: 0.5293 - val_auc: 0.7432 - val_loss: 0.7621 - learning_rate: 1.2500e-04\n",
            "Epoch 23/50\n",
            "123/123 - 19s - 152ms/step - accuracy: 0.6892 - auc: 0.7556 - loss: 0.5869 - val_accuracy: 0.7059 - val_auc: 0.7443 - val_loss: 0.5825 - learning_rate: 6.2500e-05\n",
            "Epoch 24/50\n",
            "123/123 - 19s - 152ms/step - accuracy: 0.6885 - auc: 0.7554 - loss: 0.5867 - val_accuracy: 0.7591 - val_auc: 0.7428 - val_loss: 0.5272 - learning_rate: 6.2500e-05\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "123/123 - 21s - 167ms/step - accuracy: 0.6866 - auc: 0.7554 - loss: 0.5860 - val_accuracy: 0.7052 - val_auc: 0.7439 - val_loss: 0.5826 - learning_rate: 6.2500e-05\n",
            "Epoch 26/50\n",
            "123/123 - 19s - 152ms/step - accuracy: 0.6907 - auc: 0.7563 - loss: 0.5859 - val_accuracy: 0.6835 - val_auc: 0.7442 - val_loss: 0.6067 - learning_rate: 3.1250e-05\n",
            "Epoch 27/50\n",
            "123/123 - 22s - 179ms/step - accuracy: 0.6894 - auc: 0.7566 - loss: 0.5851 - val_accuracy: 0.7427 - val_auc: 0.7426 - val_loss: 0.5467 - learning_rate: 3.1250e-05\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "123/123 - 20s - 160ms/step - accuracy: 0.6909 - auc: 0.7573 - loss: 0.5855 - val_accuracy: 0.7396 - val_auc: 0.7425 - val_loss: 0.5500 - learning_rate: 3.1250e-05\n",
            "Epoch 28: early stopping\n",
            "Restoring model weights from the end of the best epoch: 23.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: Undersampled_GRU_rmsprop_gelu\n",
            "  Epochs: 28/50\n",
            "  Youden thr: 0.4686\n",
            "  Val time-level ROC-AUC: 0.7443  PR-AUC: 0.0545\n",
            "  Val patient-level AUC: 0.8006\n",
            "\n",
            "============================================================\n",
            "Training: Undersampled_LSTM_rmsprop_gelu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "123/123 - 29s - 239ms/step - accuracy: 0.5626 - auc: 0.5850 - loss: 0.7093 - val_accuracy: 0.4986 - val_auc: 0.6953 - val_loss: 0.7087 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "123/123 - 25s - 205ms/step - accuracy: 0.6111 - auc: 0.6537 - loss: 0.6569 - val_accuracy: 0.8563 - val_auc: 0.6829 - val_loss: 0.5152 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "123/123 - 24s - 199ms/step - accuracy: 0.6249 - auc: 0.6711 - loss: 0.6476 - val_accuracy: 0.3257 - val_auc: 0.6899 - val_loss: 0.8390 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "123/123 - 24s - 198ms/step - accuracy: 0.6325 - auc: 0.6798 - loss: 0.6427 - val_accuracy: 0.1945 - val_auc: 0.7041 - val_loss: 1.0357 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "123/123 - 25s - 206ms/step - accuracy: 0.6382 - auc: 0.6900 - loss: 0.6366 - val_accuracy: 0.5988 - val_auc: 0.6881 - val_loss: 0.6718 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "123/123 - 41s - 331ms/step - accuracy: 0.6458 - auc: 0.7003 - loss: 0.6295 - val_accuracy: 0.3153 - val_auc: 0.7155 - val_loss: 0.8741 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "123/123 - 25s - 205ms/step - accuracy: 0.6511 - auc: 0.7066 - loss: 0.6253 - val_accuracy: 0.9016 - val_auc: 0.7074 - val_loss: 0.3833 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "123/123 - 23s - 191ms/step - accuracy: 0.6527 - auc: 0.7100 - loss: 0.6230 - val_accuracy: 0.8043 - val_auc: 0.7142 - val_loss: 0.4941 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "123/123 - 26s - 207ms/step - accuracy: 0.6591 - auc: 0.7133 - loss: 0.6209 - val_accuracy: 0.4418 - val_auc: 0.7170 - val_loss: 0.7703 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "123/123 - 25s - 206ms/step - accuracy: 0.6584 - auc: 0.7166 - loss: 0.6183 - val_accuracy: 0.9178 - val_auc: 0.7226 - val_loss: 0.3329 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "123/123 - 25s - 201ms/step - accuracy: 0.6578 - auc: 0.7184 - loss: 0.6170 - val_accuracy: 0.2121 - val_auc: 0.7220 - val_loss: 0.9677 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "123/123 - 24s - 196ms/step - accuracy: 0.6618 - auc: 0.7215 - loss: 0.6143 - val_accuracy: 0.6996 - val_auc: 0.7206 - val_loss: 0.5893 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "123/123 - 41s - 330ms/step - accuracy: 0.6645 - auc: 0.7252 - loss: 0.6119 - val_accuracy: 0.9318 - val_auc: 0.7125 - val_loss: 0.3561 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "123/123 - 42s - 340ms/step - accuracy: 0.6666 - auc: 0.7287 - loss: 0.6093 - val_accuracy: 0.6454 - val_auc: 0.7302 - val_loss: 0.6264 - learning_rate: 2.5000e-04\n",
            "Epoch 15/50\n",
            "123/123 - 61s - 499ms/step - accuracy: 0.6713 - auc: 0.7347 - loss: 0.6040 - val_accuracy: 0.8598 - val_auc: 0.7228 - val_loss: 0.4120 - learning_rate: 2.5000e-04\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "123/123 - 25s - 205ms/step - accuracy: 0.6722 - auc: 0.7348 - loss: 0.6041 - val_accuracy: 0.7167 - val_auc: 0.7323 - val_loss: 0.5818 - learning_rate: 2.5000e-04\n",
            "Epoch 17/50\n",
            "123/123 - 41s - 333ms/step - accuracy: 0.6737 - auc: 0.7382 - loss: 0.6009 - val_accuracy: 0.5997 - val_auc: 0.7353 - val_loss: 0.6722 - learning_rate: 1.2500e-04\n",
            "Epoch 18/50\n",
            "123/123 - 25s - 206ms/step - accuracy: 0.6772 - auc: 0.7396 - loss: 0.6003 - val_accuracy: 0.7784 - val_auc: 0.7301 - val_loss: 0.5107 - learning_rate: 1.2500e-04\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "123/123 - 41s - 334ms/step - accuracy: 0.6742 - auc: 0.7393 - loss: 0.6000 - val_accuracy: 0.6844 - val_auc: 0.7329 - val_loss: 0.5995 - learning_rate: 1.2500e-04\n",
            "Epoch 20/50\n",
            "123/123 - 24s - 191ms/step - accuracy: 0.6757 - auc: 0.7416 - loss: 0.5983 - val_accuracy: 0.6758 - val_auc: 0.7343 - val_loss: 0.6064 - learning_rate: 6.2500e-05\n",
            "Epoch 21/50\n",
            "123/123 - 25s - 206ms/step - accuracy: 0.6764 - auc: 0.7420 - loss: 0.5980 - val_accuracy: 0.7281 - val_auc: 0.7339 - val_loss: 0.5554 - learning_rate: 6.2500e-05\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "123/123 - 25s - 207ms/step - accuracy: 0.6767 - auc: 0.7423 - loss: 0.5979 - val_accuracy: 0.5928 - val_auc: 0.7355 - val_loss: 0.6725 - learning_rate: 6.2500e-05\n",
            "Epoch 23/50\n",
            "123/123 - 25s - 202ms/step - accuracy: 0.6744 - auc: 0.7421 - loss: 0.5973 - val_accuracy: 0.6994 - val_auc: 0.7347 - val_loss: 0.5808 - learning_rate: 3.1250e-05\n",
            "Epoch 24/50\n",
            "123/123 - 24s - 198ms/step - accuracy: 0.6779 - auc: 0.7426 - loss: 0.5981 - val_accuracy: 0.7408 - val_auc: 0.7335 - val_loss: 0.5433 - learning_rate: 3.1250e-05\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "123/123 - 25s - 205ms/step - accuracy: 0.6803 - auc: 0.7443 - loss: 0.5961 - val_accuracy: 0.6948 - val_auc: 0.7355 - val_loss: 0.5868 - learning_rate: 3.1250e-05\n",
            "Epoch 26/50\n",
            "123/123 - 25s - 205ms/step - accuracy: 0.6794 - auc: 0.7450 - loss: 0.5953 - val_accuracy: 0.6890 - val_auc: 0.7359 - val_loss: 0.5920 - learning_rate: 1.5625e-05\n",
            "Epoch 27/50\n",
            "123/123 - 41s - 334ms/step - accuracy: 0.6808 - auc: 0.7458 - loss: 0.5947 - val_accuracy: 0.7259 - val_auc: 0.7345 - val_loss: 0.5590 - learning_rate: 1.5625e-05\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "123/123 - 25s - 201ms/step - accuracy: 0.6793 - auc: 0.7446 - loss: 0.5957 - val_accuracy: 0.7216 - val_auc: 0.7346 - val_loss: 0.5631 - learning_rate: 1.5625e-05\n",
            "Epoch 29/50\n",
            "123/123 - 25s - 201ms/step - accuracy: 0.6796 - auc: 0.7454 - loss: 0.5952 - val_accuracy: 0.7058 - val_auc: 0.7352 - val_loss: 0.5778 - learning_rate: 7.8125e-06\n",
            "Epoch 30/50\n",
            "123/123 - 40s - 328ms/step - accuracy: 0.6795 - auc: 0.7449 - loss: 0.5950 - val_accuracy: 0.6955 - val_auc: 0.7355 - val_loss: 0.5861 - learning_rate: 7.8125e-06\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "123/123 - 25s - 206ms/step - accuracy: 0.6791 - auc: 0.7436 - loss: 0.5963 - val_accuracy: 0.7061 - val_auc: 0.7351 - val_loss: 0.5764 - learning_rate: 7.8125e-06\n",
            "Epoch 31: early stopping\n",
            "Restoring model weights from the end of the best epoch: 26.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: Undersampled_LSTM_rmsprop_gelu\n",
            "  Epochs: 31/50\n",
            "  Youden thr: 0.4742\n",
            "  Val time-level ROC-AUC: 0.7359  PR-AUC: 0.0502\n",
            "  Val patient-level AUC: 0.7937\n",
            "\n",
            "============================================================\n",
            "Training: Undersampled_LSTM_Attention_rmsprop_tanh\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "123/123 - 21s - 173ms/step - accuracy: 0.5739 - auc: 0.6114 - loss: 0.6731 - val_accuracy: 0.1100 - val_auc: 0.6914 - val_loss: 1.1592 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "123/123 - 21s - 174ms/step - accuracy: 0.6193 - auc: 0.6652 - loss: 0.6496 - val_accuracy: 0.9083 - val_auc: 0.6874 - val_loss: 0.4145 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "123/123 - 19s - 152ms/step - accuracy: 0.6277 - auc: 0.6769 - loss: 0.6437 - val_accuracy: 0.2930 - val_auc: 0.6910 - val_loss: 0.9011 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "123/123 - 17s - 141ms/step - accuracy: 0.6356 - auc: 0.6876 - loss: 0.6369 - val_accuracy: 0.1412 - val_auc: 0.7049 - val_loss: 1.2357 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "123/123 - 24s - 199ms/step - accuracy: 0.6419 - auc: 0.6953 - loss: 0.6322 - val_accuracy: 0.6904 - val_auc: 0.7001 - val_loss: 0.6121 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "123/123 - 17s - 141ms/step - accuracy: 0.6533 - auc: 0.7081 - loss: 0.6248 - val_accuracy: 0.2342 - val_auc: 0.7181 - val_loss: 1.0312 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "123/123 - 18s - 145ms/step - accuracy: 0.6557 - auc: 0.7129 - loss: 0.6213 - val_accuracy: 0.9266 - val_auc: 0.7195 - val_loss: 0.3362 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "123/123 - 19s - 151ms/step - accuracy: 0.6602 - auc: 0.7182 - loss: 0.6182 - val_accuracy: 0.8864 - val_auc: 0.7193 - val_loss: 0.4055 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "123/123 - 17s - 140ms/step - accuracy: 0.6666 - auc: 0.7228 - loss: 0.6145 - val_accuracy: 0.4740 - val_auc: 0.7170 - val_loss: 0.7937 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "123/123 - 17s - 140ms/step - accuracy: 0.6684 - auc: 0.7283 - loss: 0.6104 - val_accuracy: 0.9563 - val_auc: 0.7318 - val_loss: 0.2638 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "123/123 - 18s - 143ms/step - accuracy: 0.6687 - auc: 0.7271 - loss: 0.6111 - val_accuracy: 0.1338 - val_auc: 0.7245 - val_loss: 1.2992 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "123/123 - 23s - 189ms/step - accuracy: 0.6707 - auc: 0.7317 - loss: 0.6077 - val_accuracy: 0.5544 - val_auc: 0.7311 - val_loss: 0.7317 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "123/123 - 17s - 141ms/step - accuracy: 0.6743 - auc: 0.7360 - loss: 0.6040 - val_accuracy: 0.9471 - val_auc: 0.7259 - val_loss: 0.2688 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "123/123 - 17s - 141ms/step - accuracy: 0.6782 - auc: 0.7405 - loss: 0.6005 - val_accuracy: 0.6190 - val_auc: 0.7345 - val_loss: 0.6736 - learning_rate: 2.5000e-04\n",
            "Epoch 15/50\n",
            "123/123 - 19s - 153ms/step - accuracy: 0.6802 - auc: 0.7448 - loss: 0.5968 - val_accuracy: 0.8822 - val_auc: 0.7306 - val_loss: 0.3791 - learning_rate: 2.5000e-04\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "123/123 - 19s - 154ms/step - accuracy: 0.6837 - auc: 0.7456 - loss: 0.5960 - val_accuracy: 0.7638 - val_auc: 0.7383 - val_loss: 0.5276 - learning_rate: 2.5000e-04\n",
            "Epoch 17/50\n",
            "123/123 - 17s - 141ms/step - accuracy: 0.6835 - auc: 0.7487 - loss: 0.5935 - val_accuracy: 0.5573 - val_auc: 0.7376 - val_loss: 0.7376 - learning_rate: 1.2500e-04\n",
            "Epoch 18/50\n",
            "123/123 - 24s - 199ms/step - accuracy: 0.6866 - auc: 0.7498 - loss: 0.5926 - val_accuracy: 0.7873 - val_auc: 0.7363 - val_loss: 0.5043 - learning_rate: 1.2500e-04\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "123/123 - 17s - 140ms/step - accuracy: 0.6844 - auc: 0.7508 - loss: 0.5916 - val_accuracy: 0.6637 - val_auc: 0.7336 - val_loss: 0.6310 - learning_rate: 1.2500e-04\n",
            "Epoch 20/50\n",
            "123/123 - 18s - 143ms/step - accuracy: 0.6865 - auc: 0.7525 - loss: 0.5899 - val_accuracy: 0.6780 - val_auc: 0.7367 - val_loss: 0.6172 - learning_rate: 6.2500e-05\n",
            "Epoch 21/50\n",
            "123/123 - 19s - 152ms/step - accuracy: 0.6870 - auc: 0.7533 - loss: 0.5893 - val_accuracy: 0.7361 - val_auc: 0.7371 - val_loss: 0.5562 - learning_rate: 6.2500e-05\n",
            "Epoch 21: early stopping\n",
            "Restoring model weights from the end of the best epoch: 16.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: Undersampled_LSTM_Attention_rmsprop_tanh\n",
            "  Epochs: 21/50\n",
            "  Youden thr: 0.4441\n",
            "  Val time-level ROC-AUC: 0.7383  PR-AUC: 0.0504\n",
            "  Val patient-level AUC: 0.7972\n",
            "\n",
            "============================================================\n",
            "Training: Undersampled_RNN_rmsprop_tanh\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "123/123 - 11s - 90ms/step - accuracy: 0.5421 - auc: 0.5561 - loss: 0.7435 - val_accuracy: 0.2674 - val_auc: 0.6715 - val_loss: 0.8201 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "123/123 - 8s - 69ms/step - accuracy: 0.5779 - auc: 0.6057 - loss: 0.6970 - val_accuracy: 0.6490 - val_auc: 0.6806 - val_loss: 0.6500 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "123/123 - 7s - 56ms/step - accuracy: 0.5933 - auc: 0.6307 - loss: 0.6775 - val_accuracy: 0.5606 - val_auc: 0.6978 - val_loss: 0.7237 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "123/123 - 11s - 88ms/step - accuracy: 0.6080 - auc: 0.6484 - loss: 0.6636 - val_accuracy: 0.0900 - val_auc: 0.6845 - val_loss: 1.6695 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "123/123 - 8s - 69ms/step - accuracy: 0.6179 - auc: 0.6617 - loss: 0.6553 - val_accuracy: 0.7235 - val_auc: 0.7046 - val_loss: 0.5680 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "123/123 - 9s - 70ms/step - accuracy: 0.6280 - auc: 0.6717 - loss: 0.6486 - val_accuracy: 0.0826 - val_auc: 0.6987 - val_loss: 1.4297 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "123/123 - 8s - 69ms/step - accuracy: 0.6324 - auc: 0.6800 - loss: 0.6433 - val_accuracy: 0.9699 - val_auc: 0.6920 - val_loss: 0.2332 - learning_rate: 1.0000e-03\n",
            "Epoch 8/50\n",
            "123/123 - 7s - 57ms/step - accuracy: 0.6388 - auc: 0.6852 - loss: 0.6404 - val_accuracy: 0.9268 - val_auc: 0.7099 - val_loss: 0.3743 - learning_rate: 1.0000e-03\n",
            "Epoch 9/50\n",
            "123/123 - 8s - 68ms/step - accuracy: 0.6424 - auc: 0.6935 - loss: 0.6345 - val_accuracy: 0.2161 - val_auc: 0.6995 - val_loss: 1.0232 - learning_rate: 1.0000e-03\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "123/123 - 8s - 63ms/step - accuracy: 0.6497 - auc: 0.6996 - loss: 0.6307 - val_accuracy: 0.9707 - val_auc: 0.7108 - val_loss: 0.2519 - learning_rate: 1.0000e-03\n",
            "Epoch 11/50\n",
            "123/123 - 9s - 75ms/step - accuracy: 0.6564 - auc: 0.7074 - loss: 0.6257 - val_accuracy: 0.2495 - val_auc: 0.7221 - val_loss: 1.0405 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "123/123 - 9s - 69ms/step - accuracy: 0.6610 - auc: 0.7158 - loss: 0.6195 - val_accuracy: 0.4902 - val_auc: 0.7261 - val_loss: 0.7877 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "123/123 - 9s - 75ms/step - accuracy: 0.6611 - auc: 0.7189 - loss: 0.6173 - val_accuracy: 0.9256 - val_auc: 0.7187 - val_loss: 0.3328 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "123/123 - 8s - 65ms/step - accuracy: 0.6641 - auc: 0.7221 - loss: 0.6151 - val_accuracy: 0.7720 - val_auc: 0.7276 - val_loss: 0.5072 - learning_rate: 2.5000e-04\n",
            "Epoch 15/50\n",
            "123/123 - 8s - 66ms/step - accuracy: 0.6682 - auc: 0.7256 - loss: 0.6124 - val_accuracy: 0.8620 - val_auc: 0.7242 - val_loss: 0.3987 - learning_rate: 2.5000e-04\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "123/123 - 7s - 59ms/step - accuracy: 0.6703 - auc: 0.7258 - loss: 0.6126 - val_accuracy: 0.7108 - val_auc: 0.7328 - val_loss: 0.5770 - learning_rate: 2.5000e-04\n",
            "Epoch 17/50\n",
            "123/123 - 9s - 70ms/step - accuracy: 0.6704 - auc: 0.7284 - loss: 0.6103 - val_accuracy: 0.5590 - val_auc: 0.7315 - val_loss: 0.7256 - learning_rate: 1.2500e-04\n",
            "Epoch 18/50\n",
            "123/123 - 7s - 55ms/step - accuracy: 0.6698 - auc: 0.7290 - loss: 0.6098 - val_accuracy: 0.7933 - val_auc: 0.7274 - val_loss: 0.4864 - learning_rate: 1.2500e-04\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "123/123 - 8s - 68ms/step - accuracy: 0.6706 - auc: 0.7301 - loss: 0.6091 - val_accuracy: 0.6659 - val_auc: 0.7292 - val_loss: 0.6184 - learning_rate: 1.2500e-04\n",
            "Epoch 20/50\n",
            "123/123 - 7s - 60ms/step - accuracy: 0.6706 - auc: 0.7306 - loss: 0.6086 - val_accuracy: 0.6572 - val_auc: 0.7316 - val_loss: 0.6283 - learning_rate: 6.2500e-05\n",
            "Epoch 21/50\n",
            "123/123 - 10s - 83ms/step - accuracy: 0.6735 - auc: 0.7328 - loss: 0.6071 - val_accuracy: 0.7184 - val_auc: 0.7317 - val_loss: 0.5633 - learning_rate: 6.2500e-05\n",
            "Epoch 21: early stopping\n",
            "Restoring model weights from the end of the best epoch: 16.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: Undersampled_RNN_rmsprop_tanh\n",
            "  Epochs: 21/50\n",
            "  Youden thr: 0.4534\n",
            "  Val time-level ROC-AUC: 0.7329  PR-AUC: 0.0433\n",
            "  Val patient-level AUC: 0.7903\n",
            "\n",
            "============================================================\n",
            "Training: Undersampled_Transformer_rmsprop_gelu\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "123/123 - 17s - 136ms/step - accuracy: 0.5412 - auc: 0.5562 - loss: 0.6894 - val_accuracy: 0.2449 - val_auc: 0.6558 - val_loss: 0.8004 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "123/123 - 13s - 102ms/step - accuracy: 0.5948 - auc: 0.6323 - loss: 0.6656 - val_accuracy: 0.7840 - val_auc: 0.6786 - val_loss: 0.5534 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "123/123 - 12s - 101ms/step - accuracy: 0.6185 - auc: 0.6633 - loss: 0.6514 - val_accuracy: 0.2085 - val_auc: 0.6919 - val_loss: 0.9789 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "123/123 - 11s - 91ms/step - accuracy: 0.6307 - auc: 0.6805 - loss: 0.6415 - val_accuracy: 0.1765 - val_auc: 0.7040 - val_loss: 1.1580 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "123/123 - 12s - 98ms/step - accuracy: 0.6377 - auc: 0.6886 - loss: 0.6366 - val_accuracy: 0.6627 - val_auc: 0.7066 - val_loss: 0.6199 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "123/123 - 21s - 170ms/step - accuracy: 0.6500 - auc: 0.7041 - loss: 0.6273 - val_accuracy: 0.2450 - val_auc: 0.7100 - val_loss: 1.0309 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "123/123 - 12s - 101ms/step - accuracy: 0.6526 - auc: 0.7055 - loss: 0.6261 - val_accuracy: 0.9088 - val_auc: 0.7068 - val_loss: 0.3464 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "123/123 - 12s - 99ms/step - accuracy: 0.6529 - auc: 0.7087 - loss: 0.6243 - val_accuracy: 0.8461 - val_auc: 0.7063 - val_loss: 0.4441 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "123/123 - 11s - 92ms/step - accuracy: 0.6553 - auc: 0.7107 - loss: 0.6231 - val_accuracy: 0.4218 - val_auc: 0.7106 - val_loss: 0.8328 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "123/123 - 12s - 99ms/step - accuracy: 0.6583 - auc: 0.7147 - loss: 0.6203 - val_accuracy: 0.9020 - val_auc: 0.7099 - val_loss: 0.3698 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "123/123 - 13s - 110ms/step - accuracy: 0.6585 - auc: 0.7139 - loss: 0.6211 - val_accuracy: 0.3987 - val_auc: 0.7125 - val_loss: 0.8572 - learning_rate: 2.5000e-04\n",
            "Epoch 12/50\n",
            "123/123 - 12s - 100ms/step - accuracy: 0.6612 - auc: 0.7165 - loss: 0.6189 - val_accuracy: 0.6239 - val_auc: 0.7134 - val_loss: 0.6636 - learning_rate: 2.5000e-04\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "123/123 - 12s - 101ms/step - accuracy: 0.6604 - auc: 0.7181 - loss: 0.6177 - val_accuracy: 0.8550 - val_auc: 0.7111 - val_loss: 0.4348 - learning_rate: 2.5000e-04\n",
            "Epoch 14/50\n",
            "123/123 - 12s - 101ms/step - accuracy: 0.6640 - auc: 0.7185 - loss: 0.6179 - val_accuracy: 0.6870 - val_auc: 0.7131 - val_loss: 0.6082 - learning_rate: 1.2500e-04\n",
            "Epoch 15/50\n",
            "123/123 - 21s - 170ms/step - accuracy: 0.6640 - auc: 0.7187 - loss: 0.6172 - val_accuracy: 0.7843 - val_auc: 0.7127 - val_loss: 0.5120 - learning_rate: 1.2500e-04\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "123/123 - 12s - 100ms/step - accuracy: 0.6653 - auc: 0.7215 - loss: 0.6154 - val_accuracy: 0.7290 - val_auc: 0.7142 - val_loss: 0.5728 - learning_rate: 1.2500e-04\n",
            "Epoch 17/50\n",
            "123/123 - 13s - 103ms/step - accuracy: 0.6645 - auc: 0.7215 - loss: 0.6153 - val_accuracy: 0.6116 - val_auc: 0.7151 - val_loss: 0.6772 - learning_rate: 6.2500e-05\n",
            "Epoch 18/50\n",
            "123/123 - 12s - 101ms/step - accuracy: 0.6627 - auc: 0.7210 - loss: 0.6158 - val_accuracy: 0.7265 - val_auc: 0.7142 - val_loss: 0.5743 - learning_rate: 6.2500e-05\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "123/123 - 12s - 101ms/step - accuracy: 0.6652 - auc: 0.7223 - loss: 0.6149 - val_accuracy: 0.6377 - val_auc: 0.7145 - val_loss: 0.6548 - learning_rate: 6.2500e-05\n",
            "Epoch 20/50\n",
            "123/123 - 21s - 167ms/step - accuracy: 0.6663 - auc: 0.7219 - loss: 0.6152 - val_accuracy: 0.6782 - val_auc: 0.7142 - val_loss: 0.6176 - learning_rate: 3.1250e-05\n",
            "Epoch 21/50\n",
            "123/123 - 20s - 166ms/step - accuracy: 0.6636 - auc: 0.7208 - loss: 0.6158 - val_accuracy: 0.7029 - val_auc: 0.7143 - val_loss: 0.5952 - learning_rate: 3.1250e-05\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "123/123 - 12s - 96ms/step - accuracy: 0.6672 - auc: 0.7224 - loss: 0.6149 - val_accuracy: 0.6370 - val_auc: 0.7148 - val_loss: 0.6536 - learning_rate: 3.1250e-05\n",
            "Epoch 22: early stopping\n",
            "Restoring model weights from the end of the best epoch: 17.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Completed: Undersampled_Transformer_rmsprop_gelu\n",
            "  Epochs: 22/50\n",
            "  Youden thr: 0.5411\n",
            "  Val time-level ROC-AUC: 0.7152  PR-AUC: 0.0398\n",
            "  Val patient-level AUC: 0.7660\n",
            "\n",
            "✓ Summary saved: /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Undersampled/stage2_summary.csv\n",
            "\n",
            "✓ Stage 2 complete: /content/drive/MyDrive/AI_Fin/Stage2_Baseline\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Generate test predictions for Undersampled GRU champion\n",
        "- Loads final .h5 model and Youden threshold JSON\n",
        "- Uses fast batched memmap loader with vectorized indexing\n",
        "- Saves window-level test predictions with patient_id, y_true, y_pred_proba,\n",
        "  y_pred_0.5 (baseline), and y_pred_optimal (Youden)\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "# -------------------------------\n",
        "# Paths and settings\n",
        "# -------------------------------\n",
        "BASE_DIR = '/content/drive/MyDrive/AI_Course_Project/Dataset'\n",
        "MODEL_DIR = os.path.join(BASE_DIR, 'Stage2_Baseline', 'Undersampled', 'Undersampled_GRU_rmsprop_gelu')\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# Test data (baseline test set)\n",
        "TEST_PATH = os.path.join(BASE_DIR, 'baseline_test_matrices.npz')\n",
        "\n",
        "# Saved model artifacts you have\n",
        "FINAL_MODEL_H5 = os.path.join(MODEL_DIR, 'Undersampled_GRU_rmsprop_gelu_model.h5')\n",
        "YOUDEN_JSON    = os.path.join(MODEL_DIR, 'Undersampled_GRU_rmsprop_gelu_youden_threshold.json')\n",
        "\n",
        "# Output CSV\n",
        "TEST_PRED_CSV  = os.path.join(MODEL_DIR, 'Undersampled_GRU_rmsprop_gelu_test_predictions.csv')\n",
        "\n",
        "# Model hyperparams (must match training)\n",
        "SEQUENCE_LENGTH = 4\n",
        "N_FEATURES = 21\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "# Reproducibility\n",
        "RANDOM_STATE = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(RANDOM_STATE)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "np.random.seed(RANDOM_STATE)\n",
        "tf.random.set_seed(RANDOM_STATE)\n",
        "\n",
        "# -------------------------------\n",
        "# Utilities\n",
        "# -------------------------------\n",
        "def set_gpu_and_mixed_precision():\n",
        "    try:\n",
        "        policy = mixed_precision.Policy('mixed_float16')\n",
        "        mixed_precision.set_global_policy(policy)\n",
        "        print(\"[OK] Mixed precision (float16) policy enabled\")\n",
        "    except Exception:\n",
        "        print(\"[INFO] Mixed precision not available\")\n",
        "\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        for gpu in gpus:\n",
        "            try:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "            except Exception:\n",
        "                pass\n",
        "        print(f\"[OK] GPU memory growth enabled for {len(gpus)} GPU(s)\")\n",
        "\n",
        "def load_npz_memmap_with_ids(path):\n",
        "    npz = np.load(path, mmap_mode='r')\n",
        "    X = npz['X']\n",
        "    y = np.array(npz['y'])\n",
        "    patient_ids = np.array(npz['patient_ids']) if 'patient_ids' in npz.files else None\n",
        "    return X, y, patient_ids\n",
        "\n",
        "def create_memmap_batched_dataset(X_mmap, y, batch_size, shuffle=False, buffer_size=10000):\n",
        "    \"\"\"\n",
        "    Batch indices first; vectorized fancy indexing in a single numpy_function per batch.\n",
        "    \"\"\"\n",
        "    n = len(y)\n",
        "    indices = np.arange(n, dtype=np.int64)\n",
        "    labels  = y.astype(np.int32)\n",
        "\n",
        "    ds = tf.data.Dataset.from_tensor_slices((indices, labels))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=buffer_size, seed=RANDOM_STATE, reshuffle_each_iteration=True)\n",
        "    ds = ds.batch(batch_size, drop_remainder=False)\n",
        "\n",
        "    def _np_load(idx_np):\n",
        "        idx_np = idx_np.astype(np.int64)\n",
        "        batch = X_mmap[idx_np]  # fancy indexing (B, SEQ, FEAT)\n",
        "        return batch.astype(np.float32)\n",
        "\n",
        "    def _map(idx_batch, label_batch):\n",
        "        X_batch = tf.numpy_function(_np_load, [idx_batch], tf.float32)\n",
        "        X_batch.set_shape((None, SEQUENCE_LENGTH, N_FEATURES))\n",
        "        # cast to compute dtype under mixed precision\n",
        "        try:\n",
        "            compute_dtype = mixed_precision.global_policy().compute_dtype\n",
        "        except Exception:\n",
        "            compute_dtype = 'float32'\n",
        "        X_batch = tf.cast(X_batch, compute_dtype)\n",
        "        return X_batch, label_batch\n",
        "\n",
        "    ds = ds.map(_map, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "# -------------------------------\n",
        "# Main\n",
        "# -------------------------------\n",
        "def main():\n",
        "    set_gpu_and_mixed_precision()\n",
        "\n",
        "    # Load Youden threshold (optional) and set baseline threshold=0.5\n",
        "    youden_threshold = None\n",
        "    if os.path.exists(YOUDEN_JSON):\n",
        "        with open(YOUDEN_JSON, 'r') as f:\n",
        "            info = json.load(f)\n",
        "            youden_threshold = float(info.get('youden_threshold', 0.5))\n",
        "            print(f\"[OK] Loaded Youden threshold: {youden_threshold:.6f}\")\n",
        "    else:\n",
        "        print(\"[INFO] Youden JSON not found; will only compute y_pred_0.5\")\n",
        "\n",
        "    # Load test memmap\n",
        "    X_test_mmap, y_test, patient_ids_test = load_npz_memmap_with_ids(TEST_PATH)\n",
        "    print(f\"[OK] Test samples: {len(y_test):,}\")\n",
        "\n",
        "    test_ds = create_memmap_batched_dataset(X_test_mmap, y_test, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # Load model (.h5)\n",
        "    if not os.path.exists(FINAL_MODEL_H5):\n",
        "        raise FileNotFoundError(f\"Model file not found: {FINAL_MODEL_H5}\")\n",
        "    print(f\"[OK] Loading model: {FINAL_MODEL_H5}\")\n",
        "    model = keras.models.load_model(FINAL_MODEL_H5)\n",
        "\n",
        "    # Predict probabilities\n",
        "    print(\"\\n[PREDICT] Generating test probabilities...\")\n",
        "    y_test_pred_proba = model.predict(test_ds, verbose=1).flatten()\n",
        "    if len(y_test_pred_proba) != len(y_test):\n",
        "        y_test_pred_proba = y_test_pred_proba[:len(y_test)]\n",
        "\n",
        "    # Baseline 0.5 threshold flag\n",
        "    y_test_pred_0_5 = (y_test_pred_proba >= 0.5).astype(int)\n",
        "\n",
        "    # Optional: Youden threshold flag\n",
        "    if youden_threshold is not None:\n",
        "        y_test_pred_optimal = (y_test_pred_proba >= youden_threshold).astype(int)\n",
        "    else:\n",
        "        y_test_pred_optimal = None\n",
        "\n",
        "    # Save window-level predictions\n",
        "    out = {\n",
        "        'y_true': y_test,\n",
        "        'y_pred_0.5': y_test_pred_0_5,\n",
        "        'y_pred_proba': y_test_pred_proba\n",
        "    }\n",
        "    if y_test_pred_optimal is not None:\n",
        "        out['y_pred_optimal'] = y_test_pred_optimal\n",
        "\n",
        "    out_df = pd.DataFrame(out)\n",
        "    if patient_ids_test is not None:\n",
        "        out_df.insert(0, 'patient_id', patient_ids_test[:len(y_test)])\n",
        "\n",
        "    out_df.to_csv(TEST_PRED_CSV, index=False)\n",
        "    print(f\"[OK] Saved test predictions: {TEST_PRED_CSV}\")\n",
        "    print(f\"Rows: {len(out_df):,} | Positives: {out_df['y_true'].sum():,} | \"\n",
        "          f\"Warnings@0.5: {out_df['y_pred_0.5'].sum():,}\"\n",
        "          + (f\" | Warnings@Youden({youden_threshold:.3f}): {out_df['y_pred_optimal'].sum():,}\"\n",
        "             if youden_threshold is not None else \"\"))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYLOBS86dP_3",
        "outputId": "e7e27d7b-e8c4-42dc-c641-0cd0e890c9af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Mixed precision (float16) policy enabled\n",
            "[OK] Loaded Youden threshold: 0.468630\n",
            "[OK] Test samples: 212,844\n",
            "[OK] Loading model: /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Undersampled/Undersampled_GRU_rmsprop_gelu/Undersampled_GRU_rmsprop_gelu_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[PREDICT] Generating test probabilities...\n",
            "\u001b[1m832/832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 27ms/step\n",
            "[OK] Saved test predictions: /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Undersampled/Undersampled_GRU_rmsprop_gelu/Undersampled_GRU_rmsprop_gelu_test_predictions.csv\n",
            "Rows: 212,844 | Positives: 3,584 | Warnings@0.5: 64,451 | Warnings@Youden(0.469): 74,057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 2 - Tune alert system using validation set"
      ],
      "metadata": {
        "id": "DNpN-OOhzylq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Various combinations"
      ],
      "metadata": {
        "id": "1xraODkb-rlF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imbalanced test set**"
      ],
      "metadata": {
        "id": "fq-VFfKPje9B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.5 threshold"
      ],
      "metadata": {
        "id": "EYdxasxtjc72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Phase 2B: Baseline Alert Tuning (fixed 0.5 warning threshold)\n",
        "- Warnings: is_warning = (y_pred_proba >= 0.5)\n",
        "- Grid-search temporal alert rules (x in w windows) on validation\n",
        "- Select rule by patient-level Youden's J (tie-breaker F1)\n",
        "- Evaluate the selected rule once on the test set\n",
        "- Uses model subfolder: Stage2_Baseline/Undersampled/Undersampled_GRU_rmsprop_gelu\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, auc\n",
        "\n",
        "# -------------------------------\n",
        "# Config\n",
        "# -------------------------------\n",
        "BASE_DIR = '/content/drive/MyDrive/AI_Course_Project/Dataset/Stage2_Baseline'\n",
        "MODEL_DIR = os.path.join(BASE_DIR, 'Undersampled', 'Undersampled_GRU_rmsprop_gelu')\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# Champion model prediction files (must include: patient_id, y_true, y_pred_proba)\n",
        "VAL_PRED_CSV  = os.path.join(MODEL_DIR, 'Undersampled_GRU_rmsprop_gelu_val_predictions.csv')\n",
        "TEST_PRED_CSV = os.path.join(MODEL_DIR, 'Undersampled_GRU_rmsprop_gelu_test_predictions.csv')\n",
        "\n",
        "# Fixed baseline probability threshold for warnings\n",
        "WARNING_THRESHOLD = 0.5\n",
        "\n",
        "# Temporal alert-rule grid: alert=1 if any length-w sliding window has >= x warnings\n",
        "X_CANDIDATES = [2, 3]\n",
        "W_CANDIDATES = [3, 4, 5, 6]\n",
        "\n",
        "# Outputs saved next to predictions\n",
        "OUTPUT_JSON = os.path.join(MODEL_DIR, 'phase2b_alert_rule_selection_baseline.json')\n",
        "OUTPUT_CSV  = os.path.join(MODEL_DIR, 'phase2b_alert_rule_grid_baseline.csv')\n",
        "\n",
        "# -------------------------------\n",
        "# Utilities\n",
        "# -------------------------------\n",
        "def require_columns(df, cols):\n",
        "    missing = [c for c in cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns: {missing}. Found: {list(df.columns)}\")\n",
        "\n",
        "def patient_true_labels(df):\n",
        "    return df.groupby('patient_id')['y_true'].max().astype(int)\n",
        "\n",
        "def add_warnings(df, threshold=0.5):\n",
        "    df = df.copy()\n",
        "    df['is_warning'] = (df['y_pred_proba'] >= threshold).astype(int)\n",
        "    return df\n",
        "\n",
        "def alert_from_warnings_1d(warnings, x, w):\n",
        "    if len(warnings) == 0:\n",
        "        return 0\n",
        "    kernel = np.ones(w, dtype=np.int32)\n",
        "    counts = np.convolve(warnings.astype(np.int32), kernel, mode='valid')\n",
        "    return int(np.any(counts >= x))\n",
        "\n",
        "def evaluate_rule_patient_level(df, x, w):\n",
        "    y_true_pat = patient_true_labels(df).rename('y_true_patient')\n",
        "\n",
        "    alerts = []\n",
        "    for pid, grp in df.groupby('patient_id', sort=False):\n",
        "        warnings = grp['is_warning'].to_numpy()\n",
        "        alert = alert_from_warnings_1d(warnings, x, w)\n",
        "        alerts.append((pid, alert))\n",
        "    alert_df = pd.DataFrame(alerts, columns=['patient_id', 'alert']).set_index('patient_id')\n",
        "\n",
        "    merged = y_true_pat.to_frame().join(alert_df, how='inner')\n",
        "\n",
        "    cm = confusion_matrix(merged['y_true_patient'], merged['alert'], labels=[0, 1])\n",
        "    if cm.shape == (2, 2):\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "    else:\n",
        "        tn = fp = fn = tp = 0\n",
        "\n",
        "    sens = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    spec = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "    prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "    npv  = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n",
        "    f1   = 2 * (prec * sens) / (prec + sens) if (prec + sens) > 0 else 0.0\n",
        "    youden = sens + spec - 1.0\n",
        "\n",
        "    try:\n",
        "        precision_curve, recall_curve, _ = precision_recall_curve(merged['y_true_patient'], merged['alert'])\n",
        "        pr_auc = auc(recall_curve, precision_curve)\n",
        "    except Exception:\n",
        "        pr_auc = 0.0\n",
        "\n",
        "    return {\n",
        "        'x': x, 'w': w, 'threshold': WARNING_THRESHOLD,\n",
        "        'tp': int(tp), 'tn': int(tn), 'fp': int(fp), 'fn': int(fn),\n",
        "        'sensitivity': sens, 'specificity': spec, 'precision': prec,\n",
        "        'npv': npv, 'f1': f1, 'youden_J': youden, 'pr_auc_surrogate': pr_auc,\n",
        "        'n_patients': int(len(merged)),\n",
        "        'n_pos_patients': int(merged['y_true_patient'].sum()),\n",
        "        'n_neg_patients': int((merged['y_true_patient'] == 0).sum())\n",
        "    }\n",
        "\n",
        "def grid_search_rules(val_df):\n",
        "    results = []\n",
        "    for x in X_CANDIDATES:\n",
        "        for w in W_CANDIDATES:\n",
        "            m = evaluate_rule_patient_level(val_df, x, w)\n",
        "            results.append(m)\n",
        "    grid_df = pd.DataFrame(results).sort_values(['youden_J', 'f1'], ascending=False).reset_index(drop=True)\n",
        "    best = grid_df.iloc[0].to_dict() if len(grid_df) else None\n",
        "    return grid_df, best\n",
        "\n",
        "# -------------------------------\n",
        "# Main\n",
        "# -------------------------------\n",
        "def main():\n",
        "    val_df  = pd.read_csv(VAL_PRED_CSV)\n",
        "    test_df = pd.read_csv(TEST_PRED_CSV)\n",
        "\n",
        "    for name, df in [('VAL', val_df), ('TEST', test_df)]:\n",
        "        require_columns(df, ['patient_id', 'y_true', 'y_pred_proba'])\n",
        "\n",
        "    val_df  = add_warnings(val_df, threshold=WARNING_THRESHOLD)\n",
        "    test_df = add_warnings(test_df, threshold=WARNING_THRESHOLD)\n",
        "\n",
        "    grid_df, best = grid_search_rules(val_df)\n",
        "    grid_df.to_csv(OUTPUT_CSV, index=False)\n",
        "\n",
        "    if best is not None:\n",
        "        best_x, best_w = int(best['x']), int(best['w'])\n",
        "        test_best = evaluate_rule_patient_level(test_df, best_x, best_w)\n",
        "    else:\n",
        "        best_x = best_w = None\n",
        "        test_best = None\n",
        "\n",
        "    summary = {\n",
        "        'model_dir': MODEL_DIR,\n",
        "        'warning_threshold_policy': 'fixed_0.5',\n",
        "        'val_grid_sorted': grid_df.to_dict(orient='records'),\n",
        "        'best_on_val': best,\n",
        "        'test_metrics_with_best_rule': test_best\n",
        "    }\n",
        "    with open(OUTPUT_JSON, 'w') as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "\n",
        "    print(\"\\nALERT RULE SELECTION (Baseline: warning threshold=0.5)\")\n",
        "    if best is None:\n",
        "        print(\"No rules evaluated on validation set\")\n",
        "        return\n",
        "    print(f\"Model dir: {MODEL_DIR}\")\n",
        "    print(f\"Best on validation: x={best_x}, w={best_w} | \"\n",
        "          f\"Youden J={best['youden_J']:.4f} | \"\n",
        "          f\"Sens={best['sensitivity']:.3f} | Spec={best['specificity']:.3f} | F1={best['f1']:.4f}\")\n",
        "    if test_best is not None:\n",
        "        print(f\"Test with best rule: Youden J={test_best['youden_J']:.4f} | \"\n",
        "              f\"Sens={test_best['sensitivity']:.3f} | Spec={test_best['specificity']:.3f} | F1={test_best['f1']:.4f}\")\n",
        "    print(f\"\\nSaved grid: {OUTPUT_CSV}\")\n",
        "    print(f\"Saved summary: {OUTPUT_JSON}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMvt-rlJbdsq",
        "outputId": "2f9dc305-123e-417b-b7b1-f2bb14ca0ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ALERT RULE SELECTION (Baseline: warning threshold=0.5)\n",
            "Model dir: /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Undersampled/Undersampled_GRU_rmsprop_gelu\n",
            "Best on validation: x=3, w=3 | Youden J=0.3609 | Sens=0.878 | Spec=0.483 | F1=0.1775\n",
            "Test with best rule: Youden J=0.3631 | Sens=0.878 | Spec=0.485 | F1=0.1815\n",
            "\n",
            "Saved grid: /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Undersampled/Undersampled_GRU_rmsprop_gelu/phase2b_alert_rule_grid_baseline.csv\n",
            "Saved summary: /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Undersampled/Undersampled_GRU_rmsprop_gelu/phase2b_alert_rule_selection_baseline.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Youden J"
      ],
      "metadata": {
        "id": "qUGDamvyhOVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Phase 2B: Alert Tuning with Youden J threshold\n",
        "- Warnings: is_warning = (y_pred_proba >= youden_threshold_from_JSON)\n",
        "- Grid-search temporal alert rules (x in w windows) on validation\n",
        "- Select rule by patient-level Youden's J (tie-breaker F1)\n",
        "- Evaluate the selected rule once on the test set\n",
        "- Outputs saved next to predictions with *_youden filenames\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, auc\n",
        "\n",
        "# -------------------------------\n",
        "# Config\n",
        "# -------------------------------\n",
        "BASE_DIR = '/content/drive/MyDrive/AI_Course_Project/Dataset/Stage2_Baseline'\n",
        "MODEL_DIR = os.path.join(BASE_DIR, 'Undersampled', 'Undersampled_GRU_rmsprop_gelu')\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# Prediction files (must include: patient_id, y_true, y_pred_proba)\n",
        "VAL_PRED_CSV  = os.path.join(MODEL_DIR, 'Undersampled_GRU_rmsprop_gelu_val_predictions.csv')\n",
        "TEST_PRED_CSV = os.path.join(MODEL_DIR, 'Undersampled_GRU_rmsprop_gelu_test_predictions.csv')\n",
        "\n",
        "# Youden threshold JSON (produced earlier)\n",
        "YOUDEN_JSON = os.path.join(MODEL_DIR, 'Undersampled_GRU_rmsprop_gelu_youden_threshold.json')\n",
        "\n",
        "# Temporal alert-rule grid: alert=1 if any length-w sliding window has >= x warnings\n",
        "X_CANDIDATES = [2, 3]\n",
        "W_CANDIDATES = [3, 4, 5, 6]\n",
        "\n",
        "# Output filenames (with youden suffix)\n",
        "OUTPUT_JSON = os.path.join(MODEL_DIR, 'phase2b_alert_rule_selection_youden.json')\n",
        "OUTPUT_CSV  = os.path.join(MODEL_DIR, 'phase2b_alert_rule_grid_youden.csv')\n",
        "\n",
        "# -------------------------------\n",
        "# Utilities\n",
        "# -------------------------------\n",
        "def require_columns(df, cols):\n",
        "    missing = [c for c in cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns: {missing}. Found: {list(df.columns)}\")\n",
        "\n",
        "def load_youden_threshold(json_path):\n",
        "    if not os.path.exists(json_path):\n",
        "        raise FileNotFoundError(f\"Youden JSON not found: {json_path}\")\n",
        "    with open(json_path, 'r') as f:\n",
        "        info = json.load(f)\n",
        "    thr = float(info.get('youden_threshold'))\n",
        "    if not (0.0 <= thr <= 1.0):\n",
        "        raise ValueError(f\"Invalid youden_threshold in JSON: {thr}\")\n",
        "    return thr\n",
        "\n",
        "def patient_true_labels(df):\n",
        "    return df.groupby('patient_id')['y_true'].max().astype(int)\n",
        "\n",
        "def add_warnings(df, threshold):\n",
        "    df = df.copy()\n",
        "    df['is_warning'] = (df['y_pred_proba'] >= threshold).astype(int)\n",
        "    return df\n",
        "\n",
        "def alert_from_warnings_1d(warnings, x, w):\n",
        "    if len(warnings) == 0:\n",
        "        return 0\n",
        "    kernel = np.ones(w, dtype=np.int32)\n",
        "    counts = np.convolve(warnings.astype(np.int32), kernel, mode='valid')\n",
        "    return int(np.any(counts >= x))\n",
        "\n",
        "def evaluate_rule_patient_level(df, x, w, warning_threshold):\n",
        "    y_true_pat = patient_true_labels(df).rename('y_true_patient')\n",
        "\n",
        "    alerts = []\n",
        "    for pid, grp in df.groupby('patient_id', sort=False):\n",
        "        warnings = grp['is_warning'].to_numpy()\n",
        "        alert = alert_from_warnings_1d(warnings, x, w)\n",
        "        alerts.append((pid, alert))\n",
        "    alert_df = pd.DataFrame(alerts, columns=['patient_id', 'alert']).set_index('patient_id')\n",
        "\n",
        "    merged = y_true_pat.to_frame().join(alert_df, how='inner')\n",
        "\n",
        "    cm = confusion_matrix(merged['y_true_patient'], merged['alert'], labels=[0, 1])\n",
        "    if cm.shape == (2, 2):\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "    else:\n",
        "        tn = fp = fn = tp = 0\n",
        "\n",
        "    sens = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    spec = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "    prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "    npv  = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n",
        "    f1   = 2 * (prec * sens) / (prec + sens) if (prec + sens) > 0 else 0.0\n",
        "    youden = sens + spec - 1.0\n",
        "\n",
        "    # Binary alert is not a probability; PR-AUC here is a rough surrogate\n",
        "    try:\n",
        "        precision_curve, recall_curve, _ = precision_recall_curve(merged['y_true_patient'], merged['alert'])\n",
        "        pr_auc = auc(recall_curve, precision_curve)\n",
        "    except Exception:\n",
        "        pr_auc = 0.0\n",
        "\n",
        "    return {\n",
        "        'x': x, 'w': w, 'warning_threshold': warning_threshold,\n",
        "        'tp': int(tp), 'tn': int(tn), 'fp': int(fp), 'fn': int(fn),\n",
        "        'sensitivity': sens, 'specificity': spec, 'precision': prec,\n",
        "        'npv': npv, 'f1': f1, 'youden_J': youden, 'pr_auc_surrogate': pr_auc,\n",
        "        'n_patients': int(len(merged)),\n",
        "        'n_pos_patients': int(merged['y_true_patient'].sum()),\n",
        "        'n_neg_patients': int((merged['y_true_patient'] == 0).sum())\n",
        "    }\n",
        "\n",
        "def grid_search_rules(val_df, warning_threshold):\n",
        "    results = []\n",
        "    for x in X_CANDIDATES:\n",
        "        for w in W_CANDIDATES:\n",
        "            m = evaluate_rule_patient_level(val_df, x, w, warning_threshold)\n",
        "            results.append(m)\n",
        "    grid_df = pd.DataFrame(results).sort_values(['youden_J', 'f1'], ascending=False).reset_index(drop=True)\n",
        "    best = grid_df.iloc[0].to_dict() if len(grid_df) else None\n",
        "    return grid_df, best\n",
        "\n",
        "# -------------------------------\n",
        "# Main\n",
        "# -------------------------------\n",
        "def main():\n",
        "    # Load Youden J threshold\n",
        "    youden_thr = load_youden_threshold(YOUDEN_JSON)\n",
        "    print(f\"[OK] Using Youden J threshold for warnings: {youden_thr:.6f}\")\n",
        "\n",
        "    # Load predictions\n",
        "    val_df  = pd.read_csv(VAL_PRED_CSV)\n",
        "    test_df = pd.read_csv(TEST_PRED_CSV)\n",
        "\n",
        "    for name, df in [('VAL', val_df), ('TEST', test_df)]:\n",
        "        require_columns(df, ['patient_id', 'y_true', 'y_pred_proba'])\n",
        "\n",
        "    # Apply Youden J threshold → warnings\n",
        "    val_df  = add_warnings(val_df, threshold=youden_thr)\n",
        "    test_df = add_warnings(test_df, threshold=youden_thr)\n",
        "\n",
        "    # Grid search on validation\n",
        "    grid_df, best = grid_search_rules(val_df, youden_thr)\n",
        "    grid_df.to_csv(OUTPUT_CSV, index=False)\n",
        "\n",
        "    # Evaluate best rule on test\n",
        "    if best is not None:\n",
        "        best_x, best_w = int(best['x']), int(best['w'])\n",
        "        test_best = evaluate_rule_patient_level(test_df, best_x, best_w, youden_thr)\n",
        "    else:\n",
        "        best_x = best_w = None\n",
        "        test_best = None\n",
        "\n",
        "    # Save summary\n",
        "    summary = {\n",
        "        'model_dir': MODEL_DIR,\n",
        "        'warning_threshold_policy': 'youden_J',\n",
        "        'youden_threshold': youden_thr,\n",
        "        'val_grid_sorted': grid_df.to_dict(orient='records'),\n",
        "        'best_on_val': best,\n",
        "        'test_metrics_with_best_rule': test_best\n",
        "    }\n",
        "    with open(OUTPUT_JSON, 'w') as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "\n",
        "    # Console report\n",
        "    print(\"\\nALERT RULE SELECTION (Warnings via Youden J threshold)\")\n",
        "    if best is None:\n",
        "        print(\"No rules evaluated on validation set\")\n",
        "        return\n",
        "    print(f\"Model dir: {MODEL_DIR}\")\n",
        "    print(f\"Warning threshold (Youden): {youden_thr:.6f}\")\n",
        "    print(f\"Best on validation: x={best_x}, w={best_w} | \"\n",
        "          f\"Youden J={best['youden_J']:.4f} | \"\n",
        "          f\"Sens={best['sensitivity']:.3f} | Spec={best['specificity']:.3f} | F1={best['f1']:.4f}\")\n",
        "    if test_best is not None:\n",
        "        print(f\"Test with best rule: Youden J={test_best['youden_J']:.4f} | \"\n",
        "              f\"Sens={test_best['sensitivity']:.3f} | Spec={test_best['specificity']:.3f} | F1={test_best['f1']:.4f}\")\n",
        "    print(f\"\\nSaved grid: {OUTPUT_CSV}\")\n",
        "    print(f\"Saved summary: {OUTPUT_JSON}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmp-fuP4hPuR",
        "outputId": "8e317b4a-124a-4f5f-bbd6-0216edb7d203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Using Youden J threshold for warnings: 0.468630\n",
            "\n",
            "ALERT RULE SELECTION (Warnings via Youden J threshold)\n",
            "Model dir: /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Undersampled/Undersampled_GRU_rmsprop_gelu\n",
            "Warning threshold (Youden): 0.468630\n",
            "Best on validation: x=3, w=3 | Youden J=0.3454 | Sens=0.920 | Spec=0.426 | F1=0.1700\n",
            "Test with best rule: Youden J=0.3398 | Sens=0.911 | Spec=0.429 | F1=0.1726\n",
            "\n",
            "Saved grid: /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Undersampled/Undersampled_GRU_rmsprop_gelu/phase2b_alert_rule_grid_youden.csv\n",
            "Saved summary: /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Undersampled/Undersampled_GRU_rmsprop_gelu/phase2b_alert_rule_selection_youden.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Balanced Test set**"
      ],
      "metadata": {
        "id": "6EF1JT_jjkol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.5"
      ],
      "metadata": {
        "id": "CtJq6P89jnKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Balanced Test Evaluation (patient-level)\n",
        "- Builds a patient-balanced test subset (negatives subsampled to match positives)\n",
        "- Applies chosen warning threshold policy: fixed 0.5 or Youden J\n",
        "- Evaluates a locked alert rule (x, w) selected on validation (no test-time tuning)\n",
        "- Saves metrics with *_balanced_* suffix under the model directory\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, auc\n",
        "\n",
        "# -------------------------------\n",
        "# Config\n",
        "# -------------------------------\n",
        "BASE_DIR  = '/content/drive/MyDrive/AI_Course_Project/Dataset/Stage2_Baseline'\n",
        "MODEL_DIR = os.path.join(BASE_DIR, 'Undersampled', 'Undersampled_GRU_rmsprop_gelu')\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# Test predictions file (must include: patient_id, y_true, y_pred_proba)\n",
        "TEST_PRED_CSV = os.path.join(MODEL_DIR, 'Undersampled_GRU_rmsprop_gelu_test_predictions.csv')\n",
        "\n",
        "# Choose warning-threshold policy\n",
        "USE_YOUDEN = False  # set True to use Youden J threshold, False for fixed 0.5\n",
        "YOUDEN_JSON = os.path.join(MODEL_DIR, 'Undersampled_GRU_rmsprop_gelu_youden_threshold.json')\n",
        "\n",
        "# Locked rule from validation (do not tune on test)\n",
        "# Set this to the rule you selected on validation, e.g., from your saved JSON:\n",
        "#   phase2b_alert_rule_selection_baseline.json or phase2b_alert_rule_selection_youden.json\n",
        "# If unavailable, you can manually set (x, w) below or default to paper's (3,5).\n",
        "SELECTION_JSON = os.path.join(MODEL_DIR, 'phase2b_alert_rule_selection_baseline.json')  # or *_youden.json\n",
        "FALLBACK_RULE = (3, 5)  # paper-reported rule if selection JSON is missing\n",
        "\n",
        "# Outputs\n",
        "if USE_YOUDEN:\n",
        "    OUT_JSON = os.path.join(MODEL_DIR, 'balanced_test_metrics_youden.json')\n",
        "else:\n",
        "    OUT_JSON = os.path.join(MODEL_DIR, 'balanced_test_metrics_baseline.json')\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# -------------------------------\n",
        "# Utilities\n",
        "# -------------------------------\n",
        "def require_columns(df, cols):\n",
        "    missing = [c for c in cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns: {missing}. Found: {list(df.columns)}\")\n",
        "\n",
        "def make_patient_balanced(df, seed=42):\n",
        "    \"\"\"\n",
        "    Balance at patient level: positive patients (any y_true=1) vs negative patients (all y_true=0).\n",
        "    Subsample negatives to match number of positives.\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    labels = df.groupby('patient_id')['y_true'].max().astype(int)\n",
        "    pos_ids = labels[labels == 1].index.to_numpy()\n",
        "    neg_ids = labels[labels == 0].index.to_numpy()\n",
        "\n",
        "    n_pos = len(pos_ids)\n",
        "    if len(neg_ids) >= n_pos:\n",
        "        sel_neg = rng.choice(neg_ids, size=n_pos, replace=False)\n",
        "    else:\n",
        "        # If not enough negatives, take all negatives and warn via print\n",
        "        print(f\"[INFO] Not enough negatives ({len(neg_ids)}) to match positives ({n_pos}); using all negatives.\")\n",
        "        sel_neg = neg_ids\n",
        "\n",
        "    selected = set(pos_ids.tolist() + sel_neg.tolist())\n",
        "    balanced_df = df[df['patient_id'].isin(selected)].copy()\n",
        "    # Keep original row order; patient distribution summary\n",
        "    n_pat = balanced_df['patient_id'].nunique()\n",
        "    n_pos_pat = int(labels.loc[list(selected)].sum())\n",
        "    n_neg_pat = int(n_pat - n_pos_pat)\n",
        "    return balanced_df, {'n_patients': n_pat, 'n_pos_patients': n_pos_pat, 'n_neg_patients': n_neg_pat}\n",
        "\n",
        "def load_warning_threshold(use_youden, youden_json):\n",
        "    if not use_youden:\n",
        "        return 0.5\n",
        "    if not os.path.exists(youden_json):\n",
        "        raise FileNotFoundError(f\"Youden JSON not found: {youden_json}\")\n",
        "    with open(youden_json, 'r') as f:\n",
        "        info = json.load(f)\n",
        "    thr = float(info.get('youden_threshold'))\n",
        "    if not (0.0 <= thr <= 1.0):\n",
        "        raise ValueError(f\"Invalid youden_threshold in JSON: {thr}\")\n",
        "    return thr\n",
        "\n",
        "def add_warnings(df, threshold):\n",
        "    df = df.copy()\n",
        "    df['is_warning'] = (df['y_pred_proba'] >= threshold).astype(int)\n",
        "    return df\n",
        "\n",
        "def alert_from_warnings_1d(warnings, x, w):\n",
        "    if len(warnings) == 0:\n",
        "        return 0\n",
        "    kernel = np.ones(w, dtype=np.int32)\n",
        "    counts = np.convolve(warnings.astype(np.int32), kernel, mode='valid')\n",
        "    return int(np.any(counts >= x))\n",
        "\n",
        "def evaluate_rule_patient_level(df, x, w, warning_threshold):\n",
        "    y_true_pat = df.groupby('patient_id')['y_true'].max().astype(int)\n",
        "\n",
        "    alerts = []\n",
        "    for pid, grp in df.groupby('patient_id', sort=False):\n",
        "        warnings = grp['is_warning'].to_numpy()\n",
        "        alert = alert_from_warnings_1d(warnings, x, w)\n",
        "        alerts.append((pid, alert))\n",
        "    alert_df = pd.DataFrame(alerts, columns=['patient_id', 'alert']).set_index('patient_id')\n",
        "\n",
        "    merged = y_true_pat.to_frame(name='y_true_patient').join(alert_df, how='inner')\n",
        "\n",
        "    cm = confusion_matrix(merged['y_true_patient'], merged['alert'], labels=[0, 1])\n",
        "    if cm.shape == (2, 2):\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "    else:\n",
        "        tn = fp = fn = tp = 0\n",
        "\n",
        "    sens = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    spec = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "    prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "    npv  = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n",
        "    f1   = 2 * (prec * sens) / (prec + sens) if (prec + sens) > 0 else 0.0\n",
        "    youden = sens + spec - 1.0\n",
        "\n",
        "    try:\n",
        "        precision_curve, recall_curve, _ = precision_recall_curve(merged['y_true_patient'], merged['alert'])\n",
        "        pr_auc = auc(recall_curve, precision_curve)\n",
        "    except Exception:\n",
        "        pr_auc = 0.0\n",
        "\n",
        "    return {\n",
        "        'x': x, 'w': w, 'warning_threshold': warning_threshold,\n",
        "        'tp': int(tp), 'tn': int(tn), 'fp': int(fp), 'fn': int(fn),\n",
        "        'sensitivity': sens, 'specificity': spec, 'precision': prec,\n",
        "        'npv': npv, 'f1': f1, 'youden_J': youden, 'pr_auc_surrogate': pr_auc,\n",
        "        'n_patients': int(len(merged)),\n",
        "        'n_pos_patients': int(merged['y_true_patient'].sum()),\n",
        "        'n_neg_patients': int((merged['y_true_patient'] == 0).sum())\n",
        "    }\n",
        "\n",
        "def load_locked_rule(selection_json, fallback_rule):\n",
        "    if os.path.exists(selection_json):\n",
        "        with open(selection_json, 'r') as f:\n",
        "            sel = json.load(f)\n",
        "        best = sel.get('best_on_val')\n",
        "        if best is not None and ('x' in best and 'w' in best):\n",
        "            return int(best['x']), int(best['w'])\n",
        "        print(\"[INFO] selection JSON present but best rule missing; using fallback.\")\n",
        "    else:\n",
        "        print(\"[INFO] selection JSON not found; using fallback.\")\n",
        "    return fallback_rule\n",
        "\n",
        "# -------------------------------\n",
        "# Main\n",
        "# -------------------------------\n",
        "def main():\n",
        "    # Load test predictions\n",
        "    test_df = pd.read_csv(TEST_PRED_CSV)\n",
        "    require_columns(test_df, ['patient_id', 'y_true', 'y_pred_proba'])\n",
        "    print(f\"[OK] Loaded test predictions: {len(test_df):,} rows\")\n",
        "\n",
        "    # Build balanced patient-level test subset\n",
        "    balanced_df, bal_info = make_patient_balanced(test_df, seed=RANDOM_STATE)\n",
        "    print(f\"[OK] Balanced subset: {bal_info}\")\n",
        "\n",
        "    # Warning threshold policy\n",
        "    thr = load_warning_threshold(USE_YOUDEN, YOUDEN_JSON)\n",
        "    balanced_df = add_warnings(balanced_df, threshold=thr)\n",
        "    policy = 'youden_J' if USE_YOUDEN else 'fixed_0.5'\n",
        "    print(f\"[OK] Warning threshold policy: {policy} (threshold={thr:.6f})\")\n",
        "\n",
        "    # Locked alert rule (from validation)\n",
        "    x_locked, w_locked = load_locked_rule(SELECTION_JSON, FALLBACK_RULE)\n",
        "    print(f\"[OK] Locked alert rule (from validation): x={x_locked}, w={w_locked}\")\n",
        "\n",
        "    # Evaluate on balanced test subset\n",
        "    metrics_locked = evaluate_rule_patient_level(balanced_df, x_locked, w_locked, thr)\n",
        "\n",
        "    # (Optional) Also report paper's 3-in-5 for reference\n",
        "    metrics_paper = evaluate_rule_patient_level(balanced_df, 3, 5, thr)\n",
        "\n",
        "    # Save summary\n",
        "    out = {\n",
        "        'model_dir': MODEL_DIR,\n",
        "        'balanced_summary': bal_info,\n",
        "        'warning_threshold_policy': policy,\n",
        "        'warning_threshold_value': thr,\n",
        "        'locked_rule_from_validation': {'x': x_locked, 'w': w_locked},\n",
        "        'balanced_test_metrics_locked_rule': metrics_locked,\n",
        "        'balanced_test_metrics_paper_3in5': metrics_paper\n",
        "    }\n",
        "    with open(OUT_JSON, 'w') as f:\n",
        "        json.dump(out, f, indent=2)\n",
        "\n",
        "    print(\"\\nBALANCED TEST EVALUATION\")\n",
        "    print(f\"Policy: {policy}, threshold={thr:.6f}\")\n",
        "    print(f\"Locked rule: x={x_locked}, w={w_locked} | \"\n",
        "          f\"Youden J={metrics_locked['youden_J']:.4f} | \"\n",
        "          f\"Sens={metrics_locked['sensitivity']:.3f} | \"\n",
        "          f\"Spec={metrics_locked['specificity']:.3f} | F1={metrics_locked['f1']:.4f}\")\n",
        "    print(f\"Paper rule (3-in-5): Youden J={metrics_paper['youden_J']:.4f} | \"\n",
        "          f\"Sens={metrics_paper['sensitivity']:.3f} | \"\n",
        "          f\"Spec={metrics_paper['specificity']:.3f} | F1={metrics_paper['f1']:.4f}\")\n",
        "    print(f\"\\nSaved balanced metrics: {OUT_JSON}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gva9OUJXjoob",
        "outputId": "2f770c9d-8e5a-4161-8cac-8be33cb588b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Loaded test predictions: 212,844 rows\n",
            "[OK] Balanced subset: {'n_patients': 740, 'n_pos_patients': 370, 'n_neg_patients': 370}\n",
            "[OK] Warning threshold policy: fixed_0.5 (threshold=0.500000)\n",
            "[OK] Locked alert rule (from validation): x=3, w=3\n",
            "\n",
            "BALANCED TEST EVALUATION\n",
            "Policy: fixed_0.5, threshold=0.500000\n",
            "Locked rule: x=3, w=3 | Youden J=0.3892 | Sens=0.878 | Spec=0.511 | F1=0.7420\n",
            "Paper rule (3-in-5): Youden J=0.3811 | Sens=0.886 | Spec=0.495 | F1=0.7412\n",
            "\n",
            "Saved balanced metrics: /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Undersampled/Undersampled_GRU_rmsprop_gelu/balanced_test_metrics_baseline.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Youden"
      ],
      "metadata": {
        "id": "MSnbjPh0j1vS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Balanced Test Evaluation (patient-level)\n",
        "- Builds a patient-balanced test subset (negatives subsampled to match positives)\n",
        "- Applies chosen warning threshold policy: fixed 0.5 or Youden J\n",
        "- Evaluates a locked alert rule (x, w) selected on validation (no test-time tuning)\n",
        "- Saves metrics with *_balanced_* suffix under the model directory\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, auc\n",
        "\n",
        "# -------------------------------\n",
        "# Config\n",
        "# -------------------------------\n",
        "BASE_DIR  = '/content/drive/MyDrive/AI_Course_Project/Dataset/Stage2_Baseline'\n",
        "MODEL_DIR = os.path.join(BASE_DIR, 'Undersampled', 'Undersampled_GRU_rmsprop_gelu')\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# Test predictions file (must include: patient_id, y_true, y_pred_proba)\n",
        "TEST_PRED_CSV = os.path.join(MODEL_DIR, 'Undersampled_GRU_rmsprop_gelu_test_predictions.csv')\n",
        "\n",
        "# Choose warning-threshold policy\n",
        "USE_YOUDEN = True  # set True to use Youden J threshold, False for fixed 0.5\n",
        "YOUDEN_JSON = os.path.join(MODEL_DIR, 'Undersampled_GRU_rmsprop_gelu_youden_threshold.json')\n",
        "\n",
        "# Locked rule from validation (do not tune on test)\n",
        "# Set this to the rule you selected on validation, e.g., from your saved JSON:\n",
        "#   phase2b_alert_rule_selection_baseline.json or phase2b_alert_rule_selection_youden.json\n",
        "# If unavailable, you can manually set (x, w) below or default to paper's (3,5).\n",
        "SELECTION_JSON = os.path.join(MODEL_DIR, 'phase2b_alert_rule_selection_baseline.json')  # or *_youden.json\n",
        "FALLBACK_RULE = (3, 5)  # paper-reported rule if selection JSON is missing\n",
        "\n",
        "# Outputs\n",
        "if USE_YOUDEN:\n",
        "    OUT_JSON = os.path.join(MODEL_DIR, 'balanced_test_metrics_youden.json')\n",
        "else:\n",
        "    OUT_JSON = os.path.join(MODEL_DIR, 'balanced_test_metrics_baseline.json')\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# -------------------------------\n",
        "# Utilities\n",
        "# -------------------------------\n",
        "def require_columns(df, cols):\n",
        "    missing = [c for c in cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns: {missing}. Found: {list(df.columns)}\")\n",
        "\n",
        "def make_patient_balanced(df, seed=42):\n",
        "    \"\"\"\n",
        "    Balance at patient level: positive patients (any y_true=1) vs negative patients (all y_true=0).\n",
        "    Subsample negatives to match number of positives.\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    labels = df.groupby('patient_id')['y_true'].max().astype(int)\n",
        "    pos_ids = labels[labels == 1].index.to_numpy()\n",
        "    neg_ids = labels[labels == 0].index.to_numpy()\n",
        "\n",
        "    n_pos = len(pos_ids)\n",
        "    if len(neg_ids) >= n_pos:\n",
        "        sel_neg = rng.choice(neg_ids, size=n_pos, replace=False)\n",
        "    else:\n",
        "        # If not enough negatives, take all negatives and warn via print\n",
        "        print(f\"[INFO] Not enough negatives ({len(neg_ids)}) to match positives ({n_pos}); using all negatives.\")\n",
        "        sel_neg = neg_ids\n",
        "\n",
        "    selected = set(pos_ids.tolist() + sel_neg.tolist())\n",
        "    balanced_df = df[df['patient_id'].isin(selected)].copy()\n",
        "    # Keep original row order; patient distribution summary\n",
        "    n_pat = balanced_df['patient_id'].nunique()\n",
        "    n_pos_pat = int(labels.loc[list(selected)].sum())\n",
        "    n_neg_pat = int(n_pat - n_pos_pat)\n",
        "    return balanced_df, {'n_patients': n_pat, 'n_pos_patients': n_pos_pat, 'n_neg_patients': n_neg_pat}\n",
        "\n",
        "def load_warning_threshold(use_youden, youden_json):\n",
        "    if not use_youden:\n",
        "        return 0.5\n",
        "    if not os.path.exists(youden_json):\n",
        "        raise FileNotFoundError(f\"Youden JSON not found: {youden_json}\")\n",
        "    with open(youden_json, 'r') as f:\n",
        "        info = json.load(f)\n",
        "    thr = float(info.get('youden_threshold'))\n",
        "    if not (0.0 <= thr <= 1.0):\n",
        "        raise ValueError(f\"Invalid youden_threshold in JSON: {thr}\")\n",
        "    return thr\n",
        "\n",
        "def add_warnings(df, threshold):\n",
        "    df = df.copy()\n",
        "    df['is_warning'] = (df['y_pred_proba'] >= threshold).astype(int)\n",
        "    return df\n",
        "\n",
        "def alert_from_warnings_1d(warnings, x, w):\n",
        "    if len(warnings) == 0:\n",
        "        return 0\n",
        "    kernel = np.ones(w, dtype=np.int32)\n",
        "    counts = np.convolve(warnings.astype(np.int32), kernel, mode='valid')\n",
        "    return int(np.any(counts >= x))\n",
        "\n",
        "def evaluate_rule_patient_level(df, x, w, warning_threshold):\n",
        "    y_true_pat = df.groupby('patient_id')['y_true'].max().astype(int)\n",
        "\n",
        "    alerts = []\n",
        "    for pid, grp in df.groupby('patient_id', sort=False):\n",
        "        warnings = grp['is_warning'].to_numpy()\n",
        "        alert = alert_from_warnings_1d(warnings, x, w)\n",
        "        alerts.append((pid, alert))\n",
        "    alert_df = pd.DataFrame(alerts, columns=['patient_id', 'alert']).set_index('patient_id')\n",
        "\n",
        "    merged = y_true_pat.to_frame(name='y_true_patient').join(alert_df, how='inner')\n",
        "\n",
        "    cm = confusion_matrix(merged['y_true_patient'], merged['alert'], labels=[0, 1])\n",
        "    if cm.shape == (2, 2):\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "    else:\n",
        "        tn = fp = fn = tp = 0\n",
        "\n",
        "    sens = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    spec = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "    prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "    npv  = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n",
        "    f1   = 2 * (prec * sens) / (prec + sens) if (prec + sens) > 0 else 0.0\n",
        "    youden = sens + spec - 1.0\n",
        "\n",
        "    try:\n",
        "        precision_curve, recall_curve, _ = precision_recall_curve(merged['y_true_patient'], merged['alert'])\n",
        "        pr_auc = auc(recall_curve, precision_curve)\n",
        "    except Exception:\n",
        "        pr_auc = 0.0\n",
        "\n",
        "    return {\n",
        "        'x': x, 'w': w, 'warning_threshold': warning_threshold,\n",
        "        'tp': int(tp), 'tn': int(tn), 'fp': int(fp), 'fn': int(fn),\n",
        "        'sensitivity': sens, 'specificity': spec, 'precision': prec,\n",
        "        'npv': npv, 'f1': f1, 'youden_J': youden, 'pr_auc_surrogate': pr_auc,\n",
        "        'n_patients': int(len(merged)),\n",
        "        'n_pos_patients': int(merged['y_true_patient'].sum()),\n",
        "        'n_neg_patients': int((merged['y_true_patient'] == 0).sum())\n",
        "    }\n",
        "\n",
        "def load_locked_rule(selection_json, fallback_rule):\n",
        "    if os.path.exists(selection_json):\n",
        "        with open(selection_json, 'r') as f:\n",
        "            sel = json.load(f)\n",
        "        best = sel.get('best_on_val')\n",
        "        if best is not None and ('x' in best and 'w' in best):\n",
        "            return int(best['x']), int(best['w'])\n",
        "        print(\"[INFO] selection JSON present but best rule missing; using fallback.\")\n",
        "    else:\n",
        "        print(\"[INFO] selection JSON not found; using fallback.\")\n",
        "    return fallback_rule\n",
        "\n",
        "# -------------------------------\n",
        "# Main\n",
        "# -------------------------------\n",
        "def main():\n",
        "    # Load test predictions\n",
        "    test_df = pd.read_csv(TEST_PRED_CSV)\n",
        "    require_columns(test_df, ['patient_id', 'y_true', 'y_pred_proba'])\n",
        "    print(f\"[OK] Loaded test predictions: {len(test_df):,} rows\")\n",
        "\n",
        "    # Build balanced patient-level test subset\n",
        "    balanced_df, bal_info = make_patient_balanced(test_df, seed=RANDOM_STATE)\n",
        "    print(f\"[OK] Balanced subset: {bal_info}\")\n",
        "\n",
        "    # Warning threshold policy\n",
        "    thr = load_warning_threshold(USE_YOUDEN, YOUDEN_JSON)\n",
        "    balanced_df = add_warnings(balanced_df, threshold=thr)\n",
        "    policy = 'youden_J' if USE_YOUDEN else 'fixed_0.5'\n",
        "    print(f\"[OK] Warning threshold policy: {policy} (threshold={thr:.6f})\")\n",
        "\n",
        "    # Locked alert rule (from validation)\n",
        "    x_locked, w_locked = load_locked_rule(SELECTION_JSON, FALLBACK_RULE)\n",
        "    print(f\"[OK] Locked alert rule (from validation): x={x_locked}, w={w_locked}\")\n",
        "\n",
        "    # Evaluate on balanced test subset\n",
        "    metrics_locked = evaluate_rule_patient_level(balanced_df, x_locked, w_locked, thr)\n",
        "\n",
        "    # (Optional) Also report paper's 3-in-5 for reference\n",
        "    metrics_paper = evaluate_rule_patient_level(balanced_df, 3, 5, thr)\n",
        "\n",
        "    # Save summary\n",
        "    out = {\n",
        "        'model_dir': MODEL_DIR,\n",
        "        'balanced_summary': bal_info,\n",
        "        'warning_threshold_policy': policy,\n",
        "        'warning_threshold_value': thr,\n",
        "        'locked_rule_from_validation': {'x': x_locked, 'w': w_locked},\n",
        "        'balanced_test_metrics_locked_rule': metrics_locked,\n",
        "        'balanced_test_metrics_paper_3in5': metrics_paper\n",
        "    }\n",
        "    with open(OUT_JSON, 'w') as f:\n",
        "        json.dump(out, f, indent=2)\n",
        "\n",
        "    print(\"\\nBALANCED TEST EVALUATION\")\n",
        "    print(f\"Policy: {policy}, threshold={thr:.6f}\")\n",
        "    print(f\"Locked rule: x={x_locked}, w={w_locked} | \"\n",
        "          f\"Youden J={metrics_locked['youden_J']:.4f} | \"\n",
        "          f\"Sens={metrics_locked['sensitivity']:.3f} | \"\n",
        "          f\"Spec={metrics_locked['specificity']:.3f} | F1={metrics_locked['f1']:.4f}\")\n",
        "    print(f\"Paper rule (3-in-5): Youden J={metrics_paper['youden_J']:.4f} | \"\n",
        "          f\"Sens={metrics_paper['sensitivity']:.3f} | \"\n",
        "          f\"Spec={metrics_paper['specificity']:.3f} | F1={metrics_paper['f1']:.4f}\")\n",
        "    print(f\"\\nSaved balanced metrics: {OUT_JSON}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgkNL9tUj6wR",
        "outputId": "626f08f8-30b8-4569-e0c6-c1ce897f4217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Loaded test predictions: 212,844 rows\n",
            "[OK] Balanced subset: {'n_patients': 740, 'n_pos_patients': 370, 'n_neg_patients': 370}\n",
            "[OK] Warning threshold policy: youden_J (threshold=0.468630)\n",
            "[OK] Locked alert rule (from validation): x=3, w=3\n",
            "\n",
            "BALANCED TEST EVALUATION\n",
            "Policy: youden_J, threshold=0.468630\n",
            "Locked rule: x=3, w=3 | Youden J=0.3541 | Sens=0.911 | Spec=0.443 | F1=0.7382\n",
            "Paper rule (3-in-5): Youden J=0.3514 | Sens=0.916 | Spec=0.435 | F1=0.7386\n",
            "\n",
            "Saved balanced metrics: /content/drive/MyDrive/AI_Fin/Stage2_Baseline/Undersampled/Undersampled_GRU_rmsprop_gelu/balanced_test_metrics_youden.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final"
      ],
      "metadata": {
        "id": "uGMH2lYSZKvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Robust GRU prediction generator:\n",
        "- Auto-searches Drive for 'Undersampled_GRU_rmsprop_gelu_model.h5'\n",
        "- Falls back to '*.h5' if exact name not found\n",
        "- Generates val/test window-level predictions CSVs in the target model folder\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 1) Define known folders and data paths (adjust if your .npz live elsewhere)\n",
        "# ------------------------------------------------------------------\n",
        "MYDRIVE = Path('/content/drive/MyDrive')\n",
        "\n",
        "# Your confirmed model folder\n",
        "MODEL_DIR = Path('/content/drive/MyDrive/AI_Course_Project/Dataset/Undersampled/Stage2_Baseline/Undersampled_GRU_rmsprop_gelu')\n",
        "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "VAL_PATH  = MYDRIVE / 'AI_Course_Project/Dataset' / 'baseline_val_matrices.npz'\n",
        "TEST_PATH = MYDRIVE / 'AI_Course_Project/Dataset' / 'baseline_test_matrices.npz'\n",
        "\n",
        "VAL_OUT  = MODEL_DIR / 'Undersampled_GRU_rmsprop_gelu_val_predictions.csv'\n",
        "TEST_OUT = MODEL_DIR / 'Undersampled_GRU_rmsprop_gelu_test_predictions.csv'\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 2) Locate the model .h5 robustly\n",
        "# ------------------------------------------------------------------\n",
        "def find_model_path():\n",
        "    # Try exact filename first inside the stated folder\n",
        "    exact = MODEL_DIR / 'Undersampled_GRU_rmsprop_gelu_model.h5'\n",
        "    if exact.exists():\n",
        "        return exact\n",
        "\n",
        "    # Search entire MyDrive for exact name\n",
        "    exact_hits = list(MYDRIVE.rglob('Undersampled_GRU_rmsprop_gelu_model.h5'))\n",
        "    if len(exact_hits) > 0:\n",
        "        # Prefer the one under the intended folder if present\n",
        "        for p in exact_hits:\n",
        "            if 'Undersampled/Stage2_Baseline/Undersampled_GRU_rmsprop_gelu' in str(p):\n",
        "                return p\n",
        "        return exact_hits[0]\n",
        "\n",
        "    # Fallback: any .h5 in the model dir\n",
        "    any_h5 = list(MODEL_DIR.glob('*.h5'))\n",
        "    if len(any_h5) > 0:\n",
        "        # choose largest h5 (most likely full model vs weights)\n",
        "        any_h5.sort(key=lambda p: p.stat().st_size, reverse=True)\n",
        "        return any_h5[0]\n",
        "\n",
        "    # Final fallback: search MyDrive for any GRU .h5\n",
        "    gru_h5 = [p for p in MYDRIVE.rglob('*.h5') if 'GRU' in p.name or 'gru' in p.name]\n",
        "    if len(gru_h5) > 0:\n",
        "        gru_h5.sort(key=lambda p: p.stat().st_size, reverse=True)\n",
        "        return gru_h5[0]\n",
        "\n",
        "    return None\n",
        "\n",
        "MODEL_H5 = find_model_path()\n",
        "print('[DEBUG] Selected MODEL_H5:', MODEL_H5)\n",
        "\n",
        "if MODEL_H5 is None or not Path(MODEL_H5).exists():\n",
        "    raise FileNotFoundError(\"Could not locate a GRU .h5 model on Drive. Double-check the folder and filename.\")\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 3) Helper to load .npz and predict in batches\n",
        "# ------------------------------------------------------------------\n",
        "def load_npz(path: Path):\n",
        "    if not Path(path).exists():\n",
        "        raise FileNotFoundError(f\"Data file not found: {path}\")\n",
        "    npz = np.load(path)\n",
        "    X = npz['X']\n",
        "    y = npz['y']\n",
        "    pids = npz['patient_ids'] if 'patient_ids' in npz.files else np.arange(len(y))\n",
        "    return X, y, pids\n",
        "\n",
        "def predict_to_csv(model, X, y, pids, out_csv, batch_size=256):\n",
        "    y_pred = model.predict(X, batch_size=batch_size, verbose=1).flatten()\n",
        "    if len(y_pred) != len(y):\n",
        "        y_pred = y_pred[:len(y)]\n",
        "    pd.DataFrame({\n",
        "        'patient_id': pids,\n",
        "        'y_true': y,\n",
        "        'y_pred_proba': y_pred\n",
        "    }).to_csv(out_csv, index=False)\n",
        "    print(f'[OK] Saved: {out_csv}')\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 4) Load model and generate predictions\n",
        "# ------------------------------------------------------------------\n",
        "print(f\"[INFO] Loading model from: {MODEL_H5}\")\n",
        "model = keras.models.load_model(str(MODEL_H5))\n",
        "\n",
        "print(f\"\\n[INFO] Loading validation data from: {VAL_PATH}\")\n",
        "X_val, y_val, pids_val = load_npz(VAL_PATH)\n",
        "print(f\"[INFO] Predicting validation ({len(y_val):,} samples)...\")\n",
        "predict_to_csv(model, X_val, y_val, pids_val, VAL_OUT)\n",
        "\n",
        "print(f\"\\n[INFO] Loading test data from: {TEST_PATH}\")\n",
        "X_test, y_test, pids_test = load_npz(TEST_PATH)\n",
        "print(f\"[INFO] Predicting test ({len(y_test):,} samples)...\")\n",
        "predict_to_csv(model, X_test, y_test, pids_test, TEST_OUT)\n",
        "\n",
        "print(\"\\n[DONE] Regenerated val/test predictions.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xomc7haQZL1t",
        "outputId": "1d1e4704-8aec-4856-a33a-f6620130afbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Selected MODEL_H5: /content/drive/MyDrive/SMOTEv2_GRU_adam_relu_model.h5\n",
            "[INFO] Loading model from: /content/drive/MyDrive/SMOTEv2_GRU_adam_relu_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[INFO] Loading validation data from: /content/drive/MyDrive/AI_Fin/baseline_val_matrices.npz\n",
            "[INFO] Predicting validation (243,432 samples)...\n",
            "\u001b[1m951/951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 25ms/step\n",
            "[OK] Saved: /content/drive/MyDrive/AI_Fin/Undersampled/Stage2_Baseline/Undersampled_GRU_rmsprop_gelu/Undersampled_GRU_rmsprop_gelu_val_predictions.csv\n",
            "\n",
            "[INFO] Loading test data from: /content/drive/MyDrive/AI_Fin/baseline_test_matrices.npz\n",
            "[INFO] Predicting test (212,844 samples)...\n",
            "\u001b[1m832/832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step\n",
            "[OK] Saved: /content/drive/MyDrive/AI_Fin/Undersampled/Stage2_Baseline/Undersampled_GRU_rmsprop_gelu/Undersampled_GRU_rmsprop_gelu_test_predictions.csv\n",
            "\n",
            "[DONE] Regenerated val/test predictions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Extended Alert Tuning for Undersampled GRU with Balanced Test (sweep on val, evaluate on balanced test)\n",
        "- Sweeps warning thresholds: [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
        "- Expanded temporal grid: x in [2, 3, 4, 5, 6], w in [3, 4, 5, 6, 7, 8, 10]\n",
        "- Select configuration by minimizing distance to (sens=0.80, spec=0.80) on validation\n",
        "- Evaluate selected configuration on patient-balanced test subset\n",
        "- Saves results under: AI_Fin/Undersampled/Stage2_Baseline/Undersampled_GRU_rmsprop_gelu\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, auc\n",
        "\n",
        "# -------------------------------\n",
        "# Paths (corrected)\n",
        "# -------------------------------\n",
        "MODEL_DIR = '/content/drive/MyDrive/AI_Course_Project/Dataset/Undersampled/Stage2_Baseline/Undersampled_GRU_rmsprop_gelu'\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "VAL_PRED_CSV  = os.path.join(MODEL_DIR, 'Undersampled_GRU_rmsprop_gelu_val_predictions.csv')\n",
        "TEST_PRED_CSV = os.path.join(MODEL_DIR, 'Undersampled_GRU_rmsprop_gelu_test_predictions.csv')\n",
        "\n",
        "# Outputs\n",
        "FULL_GRID_CSV = os.path.join(MODEL_DIR, 'gru_full_threshold_sweep_grid_balanced.csv')\n",
        "SELECT_CSV = os.path.join(MODEL_DIR, 'gru_selected_config_balanced_test_metrics.csv')\n",
        "SUMMARY_JSON = os.path.join(MODEL_DIR, 'gru_threshold_sweep_selection_balanced.json')\n",
        "\n",
        "# -------------------------------\n",
        "# Config\n",
        "# -------------------------------\n",
        "THRESHOLD_CANDIDATES = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
        "X_CANDIDATES = [2, 3, 4, 5, 6]\n",
        "W_CANDIDATES = [3, 4, 5, 6, 7, 8, 10]\n",
        "TARGET_SENS = 0.80\n",
        "TARGET_SPEC = 0.80\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# -------------------------------\n",
        "# Utilities\n",
        "# -------------------------------\n",
        "def require_columns(df, cols):\n",
        "    missing = [c for c in cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns: {missing}. Found: {list(df.columns)}\")\n",
        "\n",
        "def make_patient_balanced(df, seed=42):\n",
        "    \"\"\"Balance at patient level: subsample negatives to match positives.\"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    labels = df.groupby('patient_id')['y_true'].max().astype(int)\n",
        "    pos_ids = labels[labels == 1].index.to_numpy()\n",
        "    neg_ids = labels[labels == 0].index.to_numpy()\n",
        "\n",
        "    n_pos = len(pos_ids)\n",
        "    if len(neg_ids) >= n_pos:\n",
        "        sel_neg = rng.choice(neg_ids, size=n_pos, replace=False)\n",
        "    else:\n",
        "        print(f\"[INFO] Not enough negatives ({len(neg_ids)}) to match positives ({n_pos}); using all negatives.\")\n",
        "        sel_neg = neg_ids\n",
        "\n",
        "    selected = set(pos_ids.tolist() + sel_neg.tolist())\n",
        "    balanced_df = df[df['patient_id'].isin(selected)].copy()\n",
        "    n_pat = balanced_df['patient_id'].nunique()\n",
        "    n_pos_pat = int(labels.loc[list(selected)].sum())\n",
        "    n_neg_pat = int(n_pat - n_pos_pat)\n",
        "    return balanced_df, {'n_patients': n_pat, 'n_pos_patients': n_pos_pat, 'n_neg_patients': n_neg_pat}\n",
        "\n",
        "def add_warnings(df, threshold):\n",
        "    df = df.copy()\n",
        "    df['is_warning'] = (df['y_pred_proba'] >= threshold).astype(int)\n",
        "    return df\n",
        "\n",
        "def alert_from_warnings_1d(warnings, x, w):\n",
        "    if len(warnings) == 0:\n",
        "        return 0\n",
        "    kernel = np.ones(w, dtype=np.int32)\n",
        "    counts = np.convolve(warnings.astype(np.int32), kernel, mode='valid')\n",
        "    return int(np.any(counts >= x))\n",
        "\n",
        "def evaluate_rule_patient_level(df, x, w, warning_threshold):\n",
        "    y_true_pat = df.groupby('patient_id')['y_true'].max().astype(int).rename('y_true_patient')\n",
        "\n",
        "    alerts = []\n",
        "    for pid, grp in df.groupby('patient_id', sort=False):\n",
        "        warnings = grp['is_warning'].to_numpy()\n",
        "        alert = alert_from_warnings_1d(warnings, x, w)\n",
        "        alerts.append((pid, alert))\n",
        "    alert_df = pd.DataFrame(alerts, columns=['patient_id', 'alert']).set_index('patient_id')\n",
        "\n",
        "    merged = y_true_pat.to_frame().join(alert_df, how='inner')\n",
        "\n",
        "    cm = confusion_matrix(merged['y_true_patient'], merged['alert'], labels=[0, 1])\n",
        "    tn, fp, fn, tp = (cm.ravel() if cm.shape == (2, 2) else (0, 0, 0, 0))\n",
        "\n",
        "    sens = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    spec = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "    prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "    npv  = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n",
        "    f1   = 2 * (prec * sens) / (prec + sens) if (prec + sens) > 0 else 0.0\n",
        "    youden = sens + spec - 1.0\n",
        "    far = (fp / (tp + fp) * 100.0) if (tp + fp) > 0 else 0.0\n",
        "\n",
        "    try:\n",
        "        precision_curve, recall_curve, _ = precision_recall_curve(merged['y_true_patient'], merged['alert'])\n",
        "        pr_auc = auc(recall_curve, precision_curve)\n",
        "    except Exception:\n",
        "        pr_auc = 0.0\n",
        "\n",
        "    return {\n",
        "        'threshold': warning_threshold,\n",
        "        'x': x, 'w': w,\n",
        "        'tp': int(tp), 'tn': int(tn), 'fp': int(fp), 'fn': int(fn),\n",
        "        'sensitivity': sens, 'specificity': spec, 'precision': prec,\n",
        "        'npv': npv, 'f1': f1, 'youden_J': youden, 'far_percent': far,\n",
        "        'pr_auc_surrogate': pr_auc,\n",
        "        'n_patients': int(len(merged)),\n",
        "        'n_pos_patients': int(merged['y_true_patient'].sum()),\n",
        "        'n_neg_patients': int((merged['y_true_patient'] == 0).sum())\n",
        "    }\n",
        "\n",
        "def full_grid_search(val_df_raw, thresholds, x_cands, w_cands, target_sens=0.80, target_spec=0.80):\n",
        "    results = []\n",
        "    for thr in thresholds:\n",
        "        val_df = add_warnings(val_df_raw, threshold=thr)\n",
        "        for x in x_cands:\n",
        "            for w in w_cands:\n",
        "                m = evaluate_rule_patient_level(val_df, x, w, thr)\n",
        "                results.append(m)\n",
        "\n",
        "    grid_df = pd.DataFrame(results)\n",
        "    grid_df['distance_to_target'] = np.sqrt(\n",
        "        (grid_df['sensitivity'] - target_sens)**2 +\n",
        "        (grid_df['specificity'] - target_spec)**2\n",
        "    )\n",
        "    grid_df = grid_df.sort_values(['distance_to_target', 'youden_J'], ascending=[True, False]).reset_index(drop=True)\n",
        "    best = grid_df.iloc[0].to_dict() if len(grid_df) else None\n",
        "    return grid_df, best\n",
        "\n",
        "# -------------------------------\n",
        "# Main\n",
        "# -------------------------------\n",
        "def main():\n",
        "    # Load predictions\n",
        "    val_df_raw  = pd.read_csv(VAL_PRED_CSV)\n",
        "    test_df_raw = pd.read_csv(TEST_PRED_CSV)\n",
        "\n",
        "    for name, df in [('VAL', val_df_raw), ('TEST', test_df_raw)]:\n",
        "        require_columns(df, ['patient_id', 'y_true', 'y_pred_proba'])\n",
        "\n",
        "    print(\"[INFO] Starting full grid sweep over thresholds and temporal rules on VALIDATION...\")\n",
        "    print(f\"       Thresholds: {THRESHOLD_CANDIDATES}\")\n",
        "    print(f\"       X: {X_CANDIDATES}, W: {W_CANDIDATES}\")\n",
        "    print(f\"       Target: sens={TARGET_SENS}, spec={TARGET_SPEC}\\n\")\n",
        "\n",
        "    # Full grid search on validation\n",
        "    grid_df, best = full_grid_search(\n",
        "        val_df_raw, THRESHOLD_CANDIDATES, X_CANDIDATES, W_CANDIDATES, TARGET_SENS, TARGET_SPEC\n",
        "    )\n",
        "    grid_df.to_csv(FULL_GRID_CSV, index=False)\n",
        "\n",
        "    if best is None:\n",
        "        print(\"[ERROR] No configurations evaluated on validation set\")\n",
        "        return\n",
        "\n",
        "    best_thr = float(best['threshold'])\n",
        "    best_x = int(best['x'])\n",
        "    best_w = int(best['w'])\n",
        "\n",
        "    print(f\"[OK] Best configuration on validation:\")\n",
        "    print(f\"     Threshold={best_thr:.4f}, x={best_x}, w={best_w}\")\n",
        "    print(f\"     Distance={best['distance_to_target']:.4f}\")\n",
        "    print(f\"     Sens={best['sensitivity']:.3f}, Spec={best['specificity']:.3f}\")\n",
        "    print(f\"     F1={best['f1']:.4f}, FAR={best['far_percent']:.2f}%\\n\")\n",
        "\n",
        "    # Build balanced patient-level test subset\n",
        "    test_df_bal, bal_info = make_patient_balanced(test_df_raw, seed=RANDOM_STATE)\n",
        "    print(f\"[OK] Balanced test subset: {bal_info}\\n\")\n",
        "\n",
        "    # Apply best configuration to balanced test set\n",
        "    test_df_bal = add_warnings(test_df_bal, threshold=best_thr)\n",
        "    test_best = evaluate_rule_patient_level(test_df_bal, best_x, best_w, best_thr)\n",
        "\n",
        "    # Save test summary\n",
        "    pd.DataFrame([{\n",
        "        'model': 'Undersampled_GRU_rmsprop_gelu',\n",
        "        'target_sensitivity': TARGET_SENS,\n",
        "        'target_specificity': TARGET_SPEC,\n",
        "        'balanced_test': True,\n",
        "        **bal_info,\n",
        "        **test_best\n",
        "    }]).to_csv(SELECT_CSV, index=False)\n",
        "\n",
        "    # Save JSON summary\n",
        "    summary = {\n",
        "        'model': 'Undersampled_GRU_rmsprop_gelu',\n",
        "        'model_dir': MODEL_DIR,\n",
        "        'selection_criterion': 'balanced_80_80_sweep',\n",
        "        'target_sensitivity': TARGET_SENS,\n",
        "        'target_specificity': TARGET_SPEC,\n",
        "        'threshold_sweep': THRESHOLD_CANDIDATES,\n",
        "        'x_candidates': X_CANDIDATES,\n",
        "        'w_candidates': W_CANDIDATES,\n",
        "        'val_grid_sorted_top10': grid_df.head(10).to_dict(orient='records'),\n",
        "        'best_on_val': best,\n",
        "        'balanced_test_info': bal_info,\n",
        "        'test_metrics_with_best_config': test_best\n",
        "    }\n",
        "    with open(SUMMARY_JSON, 'w') as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "\n",
        "    # Console output\n",
        "    print(f\"[OK] Balanced test performance with best configuration:\")\n",
        "    print(f\"     Threshold={test_best['threshold']:.4f}, x={test_best['x']}, w={test_best['w']}\")\n",
        "    print(f\"     Sens={test_best['sensitivity']:.3f}, Spec={test_best['specificity']:.3f}\")\n",
        "    print(f\"     F1={test_best['f1']:.4f}, FAR={test_best['far_percent']:.2f}%\\n\")\n",
        "    print(f\"Saved full grid ({len(grid_df)} configs): {FULL_GRID_CSV}\")\n",
        "    print(f\"Saved test summary: {SELECT_CSV}\")\n",
        "    print(f\"Saved JSON: {SUMMARY_JSON}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V-0cNk5dGv6",
        "outputId": "abf35630-e4ba-4ac0-a618-486924442892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Starting full grid sweep over thresholds and temporal rules on VALIDATION...\n",
            "       Thresholds: [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
            "       X: [2, 3, 4, 5, 6], W: [3, 4, 5, 6, 7, 8, 10]\n",
            "       Target: sens=0.8, spec=0.8\n",
            "\n",
            "[OK] Best configuration on validation:\n",
            "     Threshold=0.6000, x=4, w=5\n",
            "     Distance=0.2220\n",
            "     Sens=0.622, Spec=0.667\n",
            "     F1=0.1835, FAR=89.24%\n",
            "\n",
            "[OK] Balanced test subset: {'n_patients': 740, 'n_pos_patients': 370, 'n_neg_patients': 370}\n",
            "\n",
            "[OK] Balanced test performance with best configuration:\n",
            "     Threshold=0.6000, x=4, w=5\n",
            "     Sens=0.605, Spec=0.643\n",
            "     F1=0.6171, FAR=37.08%\n",
            "\n",
            "Saved full grid (210 configs): /content/drive/MyDrive/AI_Fin/Undersampled/Stage2_Baseline/Undersampled_GRU_rmsprop_gelu/gru_full_threshold_sweep_grid_balanced.csv\n",
            "Saved test summary: /content/drive/MyDrive/AI_Fin/Undersampled/Stage2_Baseline/Undersampled_GRU_rmsprop_gelu/gru_selected_config_balanced_test_metrics.csv\n",
            "Saved JSON: /content/drive/MyDrive/AI_Fin/Undersampled/Stage2_Baseline/Undersampled_GRU_rmsprop_gelu/gru_threshold_sweep_selection_balanced.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finding the stable model for Undersample"
      ],
      "metadata": {
        "id": "_Bo8WKvu7hfQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**144 runs: 8 (combination) X  6 (Models) X 3 (Datast of neagtives)**"
      ],
      "metadata": {
        "id": "l7Q2N-_6SeQc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xqc4IcZR4fH",
        "outputId": "1b8154c8-ee8e-4e07-d366-7e4646edab95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Mixed precision (float16) enabled\n",
            "\n",
            "============================================================\n",
            "PHASE 1: MULTI-SEED FAIR GAUNTLET\n",
            "3 runs per configuration\n",
            "============================================================\n",
            "✓ Created Phase 1 directory at /content/drive/MyDrive/AI_Fin/Undersampled_New/Phase_1\n",
            "\n",
            "============================================================\n",
            "LOADING DATA\n",
            "============================================================\n",
            "Loading original imbalanced training data...\n",
            "✓ Original train: 971,516 samples\n",
            "  Class 0: 955,899, Class 1: 15,617\n",
            "\n",
            "Loading validation data...\n",
            "✓ Validation: 243,432 samples\n",
            "\n",
            "✓ Found 76 completed runs\n",
            "\n",
            "============================================================\n",
            "RUNNING 144 TOTAL EXPERIMENTS\n",
            "(48 configs × 3 runs each)\n",
            "============================================================\n",
            "\n",
            "\n",
            "============================================================\n",
            "CONFIG: LSTM_adam_relu\n",
            "============================================================\n",
            "[1/144] SKIP: LSTM_adam_relu_run1\n",
            "[2/144] SKIP: LSTM_adam_relu_run2\n",
            "[3/144] SKIP: LSTM_adam_relu_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: LSTM_adam_tanh\n",
            "============================================================\n",
            "[4/144] SKIP: LSTM_adam_tanh_run1\n",
            "[5/144] SKIP: LSTM_adam_tanh_run2\n",
            "[6/144] SKIP: LSTM_adam_tanh_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: LSTM_adam_sigmoid\n",
            "============================================================\n",
            "[7/144] SKIP: LSTM_adam_sigmoid_run1\n",
            "[8/144] SKIP: LSTM_adam_sigmoid_run2\n",
            "[9/144] SKIP: LSTM_adam_sigmoid_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: LSTM_adam_gelu\n",
            "============================================================\n",
            "[10/144] SKIP: LSTM_adam_gelu_run1\n",
            "[11/144] SKIP: LSTM_adam_gelu_run2\n",
            "[12/144] SKIP: LSTM_adam_gelu_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: LSTM_rmsprop_relu\n",
            "============================================================\n",
            "[13/144] SKIP: LSTM_rmsprop_relu_run1\n",
            "[14/144] SKIP: LSTM_rmsprop_relu_run2\n",
            "[15/144] SKIP: LSTM_rmsprop_relu_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: LSTM_rmsprop_tanh\n",
            "============================================================\n",
            "[16/144] SKIP: LSTM_rmsprop_tanh_run1\n",
            "[17/144] SKIP: LSTM_rmsprop_tanh_run2\n",
            "[18/144] SKIP: LSTM_rmsprop_tanh_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: LSTM_rmsprop_sigmoid\n",
            "============================================================\n",
            "[19/144] SKIP: LSTM_rmsprop_sigmoid_run1\n",
            "[20/144] SKIP: LSTM_rmsprop_sigmoid_run2\n",
            "[21/144] SKIP: LSTM_rmsprop_sigmoid_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: LSTM_rmsprop_gelu\n",
            "============================================================\n",
            "[22/144] SKIP: LSTM_rmsprop_gelu_run1\n",
            "[23/144] SKIP: LSTM_rmsprop_gelu_run2\n",
            "[24/144] SKIP: LSTM_rmsprop_gelu_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: RNN_adam_relu\n",
            "============================================================\n",
            "[25/144] SKIP: RNN_adam_relu_run1\n",
            "[26/144] SKIP: RNN_adam_relu_run2\n",
            "[27/144] SKIP: RNN_adam_relu_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: RNN_adam_tanh\n",
            "============================================================\n",
            "[28/144] SKIP: RNN_adam_tanh_run1\n",
            "[29/144] SKIP: RNN_adam_tanh_run2\n",
            "[30/144] SKIP: RNN_adam_tanh_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: RNN_adam_sigmoid\n",
            "============================================================\n",
            "[31/144] SKIP: RNN_adam_sigmoid_run1\n",
            "[32/144] SKIP: RNN_adam_sigmoid_run2\n",
            "[33/144] SKIP: RNN_adam_sigmoid_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: RNN_adam_gelu\n",
            "============================================================\n",
            "[34/144] SKIP: RNN_adam_gelu_run1\n",
            "[35/144] SKIP: RNN_adam_gelu_run2\n",
            "[36/144] SKIP: RNN_adam_gelu_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: RNN_rmsprop_relu\n",
            "============================================================\n",
            "[37/144] SKIP: RNN_rmsprop_relu_run1\n",
            "[38/144] SKIP: RNN_rmsprop_relu_run2\n",
            "[39/144] SKIP: RNN_rmsprop_relu_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: RNN_rmsprop_tanh\n",
            "============================================================\n",
            "[40/144] SKIP: RNN_rmsprop_tanh_run1\n",
            "[41/144] SKIP: RNN_rmsprop_tanh_run2\n",
            "[42/144] SKIP: RNN_rmsprop_tanh_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: RNN_rmsprop_sigmoid\n",
            "============================================================\n",
            "[43/144] SKIP: RNN_rmsprop_sigmoid_run1\n",
            "[44/144] SKIP: RNN_rmsprop_sigmoid_run2\n",
            "[45/144] SKIP: RNN_rmsprop_sigmoid_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: RNN_rmsprop_gelu\n",
            "============================================================\n",
            "[46/144] SKIP: RNN_rmsprop_gelu_run1\n",
            "[47/144] SKIP: RNN_rmsprop_gelu_run2\n",
            "[48/144] SKIP: RNN_rmsprop_gelu_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: GRU_adam_relu\n",
            "============================================================\n",
            "[49/144] SKIP: GRU_adam_relu_run1\n",
            "[50/144] SKIP: GRU_adam_relu_run2\n",
            "[51/144] SKIP: GRU_adam_relu_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: GRU_adam_tanh\n",
            "============================================================\n",
            "[52/144] SKIP: GRU_adam_tanh_run1\n",
            "[53/144] SKIP: GRU_adam_tanh_run2\n",
            "[54/144] SKIP: GRU_adam_tanh_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: GRU_adam_sigmoid\n",
            "============================================================\n",
            "[55/144] SKIP: GRU_adam_sigmoid_run1\n",
            "[56/144] SKIP: GRU_adam_sigmoid_run2\n",
            "[57/144] SKIP: GRU_adam_sigmoid_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: GRU_adam_gelu\n",
            "============================================================\n",
            "[58/144] SKIP: GRU_adam_gelu_run1\n",
            "[59/144] SKIP: GRU_adam_gelu_run2\n",
            "[60/144] SKIP: GRU_adam_gelu_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: GRU_rmsprop_relu\n",
            "============================================================\n",
            "[61/144] SKIP: GRU_rmsprop_relu_run1\n",
            "[62/144] SKIP: GRU_rmsprop_relu_run2\n",
            "[63/144] SKIP: GRU_rmsprop_relu_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: GRU_rmsprop_tanh\n",
            "============================================================\n",
            "[64/144] SKIP: GRU_rmsprop_tanh_run1\n",
            "[65/144] SKIP: GRU_rmsprop_tanh_run2\n",
            "[66/144] SKIP: GRU_rmsprop_tanh_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: GRU_rmsprop_sigmoid\n",
            "============================================================\n",
            "[67/144] SKIP: GRU_rmsprop_sigmoid_run1\n",
            "[68/144] SKIP: GRU_rmsprop_sigmoid_run2\n",
            "[69/144] SKIP: GRU_rmsprop_sigmoid_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: GRU_rmsprop_gelu\n",
            "============================================================\n",
            "[70/144] SKIP: GRU_rmsprop_gelu_run1\n",
            "[71/144] SKIP: GRU_rmsprop_gelu_run2\n",
            "[72/144] SKIP: GRU_rmsprop_gelu_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: LSTM_Attention_adam_relu\n",
            "============================================================\n",
            "[73/144] SKIP: LSTM_Attention_adam_relu_run1\n",
            "[74/144] SKIP: LSTM_Attention_adam_relu_run2\n",
            "[75/144] SKIP: LSTM_Attention_adam_relu_run3\n",
            "\n",
            "============================================================\n",
            "CONFIG: LSTM_Attention_adam_tanh\n",
            "============================================================\n",
            "[76/144] SKIP: LSTM_Attention_adam_tanh_run1\n",
            "\n",
            "[77/144] LSTM_Attention_adam_tanh_run2\n",
            "\n",
            "============================================================\n",
            "Training: LSTM_Attention_adam_tanh_run2 (seed=2119)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 2: PR-AUC=0.0406, ROC-AUC=0.7166, F1=0.0923\n",
            "\n",
            "[78/144] LSTM_Attention_adam_tanh_run3\n",
            "\n",
            "============================================================\n",
            "Training: LSTM_Attention_adam_tanh_run3 (seed=3120)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 3: PR-AUC=0.0362, ROC-AUC=0.7036, F1=0.0828\n",
            "\n",
            "============================================================\n",
            "CONFIG: LSTM_Attention_adam_sigmoid\n",
            "============================================================\n",
            "\n",
            "[79/144] LSTM_Attention_adam_sigmoid_run1\n",
            "\n",
            "============================================================\n",
            "Training: LSTM_Attention_adam_sigmoid_run1 (seed=1121)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 1: PR-AUC=0.0402, ROC-AUC=0.7101, F1=0.0884\n",
            "\n",
            "[80/144] LSTM_Attention_adam_sigmoid_run2\n",
            "\n",
            "============================================================\n",
            "Training: LSTM_Attention_adam_sigmoid_run2 (seed=2122)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 2: PR-AUC=0.0372, ROC-AUC=0.6961, F1=0.0814\n",
            "\n",
            "[81/144] LSTM_Attention_adam_sigmoid_run3\n",
            "\n",
            "============================================================\n",
            "Training: LSTM_Attention_adam_sigmoid_run3 (seed=3123)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 3: PR-AUC=0.0393, ROC-AUC=0.7152, F1=0.0884\n",
            "\n",
            "============================================================\n",
            "CONFIG: LSTM_Attention_adam_gelu\n",
            "============================================================\n",
            "\n",
            "[82/144] LSTM_Attention_adam_gelu_run1\n",
            "\n",
            "============================================================\n",
            "Training: LSTM_Attention_adam_gelu_run1 (seed=1124)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 1: PR-AUC=0.0402, ROC-AUC=0.7233, F1=0.0892\n",
            "\n",
            "[83/144] LSTM_Attention_adam_gelu_run2\n",
            "\n",
            "============================================================\n",
            "Training: LSTM_Attention_adam_gelu_run2 (seed=2125)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 2: PR-AUC=0.0365, ROC-AUC=0.6999, F1=0.0760\n",
            "\n",
            "[84/144] LSTM_Attention_adam_gelu_run3\n",
            "\n",
            "============================================================\n",
            "Training: LSTM_Attention_adam_gelu_run3 (seed=3126)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 3: PR-AUC=0.0369, ROC-AUC=0.7015, F1=0.0844\n",
            "\n",
            "============================================================\n",
            "CONFIG: LSTM_Attention_rmsprop_relu\n",
            "============================================================\n",
            "\n",
            "[85/144] LSTM_Attention_rmsprop_relu_run1\n",
            "\n",
            "============================================================\n",
            "Training: LSTM_Attention_rmsprop_relu_run1 (seed=1127)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 1: PR-AUC=0.0341, ROC-AUC=0.6863, F1=0.0734\n",
            "\n",
            "[86/144] LSTM_Attention_rmsprop_relu_run2\n",
            "\n",
            "============================================================\n",
            "Training: LSTM_Attention_rmsprop_relu_run2 (seed=2128)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 2: PR-AUC=0.0403, ROC-AUC=0.7143, F1=0.0837\n",
            "\n",
            "[87/144] LSTM_Attention_rmsprop_relu_run3\n",
            "\n",
            "============================================================\n",
            "Training: LSTM_Attention_rmsprop_relu_run3 (seed=3129)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 3: PR-AUC=0.0397, ROC-AUC=0.7159, F1=0.0885\n",
            "\n",
            "============================================================\n",
            "CONFIG: LSTM_Attention_rmsprop_tanh\n",
            "============================================================\n",
            "\n",
            "[88/144] LSTM_Attention_rmsprop_tanh_run1\n",
            "\n",
            "============================================================\n",
            "Training: LSTM_Attention_rmsprop_tanh_run1 (seed=1130)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 1: PR-AUC=0.0455, ROC-AUC=0.7207, F1=0.1042\n",
            "\n",
            "[89/144] LSTM_Attention_rmsprop_tanh_run2\n",
            "\n",
            "============================================================\n",
            "Training: LSTM_Attention_rmsprop_tanh_run2 (seed=2131)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 2: PR-AUC=0.0444, ROC-AUC=0.7208, F1=0.0955\n",
            "\n",
            "[90/144] LSTM_Attention_rmsprop_tanh_run3\n",
            "\n",
            "============================================================\n",
            "Training: LSTM_Attention_rmsprop_tanh_run3 (seed=3132)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 3: PR-AUC=0.0410, ROC-AUC=0.7212, F1=0.0869\n",
            "\n",
            "============================================================\n",
            "CONFIG: LSTM_Attention_rmsprop_sigmoid\n",
            "============================================================\n",
            "\n",
            "[91/144] LSTM_Attention_rmsprop_sigmoid_run1\n",
            "\n",
            "============================================================\n",
            "Training: LSTM_Attention_rmsprop_sigmoid_run1 (seed=1133)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 1: PR-AUC=0.0356, ROC-AUC=0.6920, F1=0.0793\n",
            "\n",
            "[92/144] LSTM_Attention_rmsprop_sigmoid_run2\n",
            "\n",
            "============================================================\n",
            "Training: LSTM_Attention_rmsprop_sigmoid_run2 (seed=2134)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 2: PR-AUC=0.0391, ROC-AUC=0.7056, F1=0.0864\n",
            "\n",
            "[93/144] LSTM_Attention_rmsprop_sigmoid_run3\n",
            "\n",
            "============================================================\n",
            "Training: LSTM_Attention_rmsprop_sigmoid_run3 (seed=3135)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 3: PR-AUC=0.0382, ROC-AUC=0.7013, F1=0.0896\n",
            "\n",
            "============================================================\n",
            "CONFIG: LSTM_Attention_rmsprop_gelu\n",
            "============================================================\n",
            "\n",
            "[94/144] LSTM_Attention_rmsprop_gelu_run1\n",
            "\n",
            "============================================================\n",
            "Training: LSTM_Attention_rmsprop_gelu_run1 (seed=1136)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 1: PR-AUC=0.0402, ROC-AUC=0.7136, F1=0.0914\n",
            "\n",
            "[95/144] LSTM_Attention_rmsprop_gelu_run2\n",
            "\n",
            "============================================================\n",
            "Training: LSTM_Attention_rmsprop_gelu_run2 (seed=2137)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 2: PR-AUC=0.0410, ROC-AUC=0.7033, F1=0.0912\n",
            "\n",
            "[96/144] LSTM_Attention_rmsprop_gelu_run3\n",
            "\n",
            "============================================================\n",
            "Training: LSTM_Attention_rmsprop_gelu_run3 (seed=3138)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 3: PR-AUC=0.0412, ROC-AUC=0.7114, F1=0.0932\n",
            "\n",
            "============================================================\n",
            "CONFIG: CNN_adam_relu\n",
            "============================================================\n",
            "\n",
            "[97/144] CNN_adam_relu_run1\n",
            "\n",
            "============================================================\n",
            "Training: CNN_adam_relu_run1 (seed=1139)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 1: PR-AUC=0.0376, ROC-AUC=0.6931, F1=0.0890\n",
            "\n",
            "[98/144] CNN_adam_relu_run2\n",
            "\n",
            "============================================================\n",
            "Training: CNN_adam_relu_run2 (seed=2140)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 2: PR-AUC=0.0354, ROC-AUC=0.6939, F1=0.0818\n",
            "\n",
            "[99/144] CNN_adam_relu_run3\n",
            "\n",
            "============================================================\n",
            "Training: CNN_adam_relu_run3 (seed=3141)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 3: PR-AUC=0.0372, ROC-AUC=0.7031, F1=0.0846\n",
            "\n",
            "============================================================\n",
            "CONFIG: CNN_adam_tanh\n",
            "============================================================\n",
            "\n",
            "[100/144] CNN_adam_tanh_run1\n",
            "\n",
            "============================================================\n",
            "Training: CNN_adam_tanh_run1 (seed=1142)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 1: PR-AUC=0.0378, ROC-AUC=0.7083, F1=0.0829\n",
            "\n",
            "[101/144] CNN_adam_tanh_run2\n",
            "\n",
            "============================================================\n",
            "Training: CNN_adam_tanh_run2 (seed=2143)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 2: PR-AUC=0.0384, ROC-AUC=0.7107, F1=0.0821\n",
            "\n",
            "[102/144] CNN_adam_tanh_run3\n",
            "\n",
            "============================================================\n",
            "Training: CNN_adam_tanh_run3 (seed=3144)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 3: PR-AUC=0.0336, ROC-AUC=0.6722, F1=0.0753\n",
            "\n",
            "============================================================\n",
            "CONFIG: CNN_adam_sigmoid\n",
            "============================================================\n",
            "\n",
            "[103/144] CNN_adam_sigmoid_run1\n",
            "\n",
            "============================================================\n",
            "Training: CNN_adam_sigmoid_run1 (seed=1145)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 1: PR-AUC=0.0364, ROC-AUC=0.6955, F1=0.0798\n",
            "\n",
            "[104/144] CNN_adam_sigmoid_run2\n",
            "\n",
            "============================================================\n",
            "Training: CNN_adam_sigmoid_run2 (seed=2146)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 2: PR-AUC=0.0376, ROC-AUC=0.6969, F1=0.0858\n",
            "\n",
            "[105/144] CNN_adam_sigmoid_run3\n",
            "\n",
            "============================================================\n",
            "Training: CNN_adam_sigmoid_run3 (seed=3147)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 3: PR-AUC=0.0386, ROC-AUC=0.7062, F1=0.0864\n",
            "\n",
            "============================================================\n",
            "CONFIG: CNN_adam_gelu\n",
            "============================================================\n",
            "\n",
            "[106/144] CNN_adam_gelu_run1\n",
            "\n",
            "============================================================\n",
            "Training: CNN_adam_gelu_run1 (seed=1148)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 1: PR-AUC=0.0363, ROC-AUC=0.7093, F1=0.0813\n",
            "\n",
            "[107/144] CNN_adam_gelu_run2\n",
            "\n",
            "============================================================\n",
            "Training: CNN_adam_gelu_run2 (seed=2149)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 2: PR-AUC=0.0412, ROC-AUC=0.7197, F1=0.0929\n",
            "\n",
            "[108/144] CNN_adam_gelu_run3\n",
            "\n",
            "============================================================\n",
            "Training: CNN_adam_gelu_run3 (seed=3150)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 3: PR-AUC=0.0348, ROC-AUC=0.6899, F1=0.0823\n",
            "\n",
            "============================================================\n",
            "CONFIG: CNN_rmsprop_relu\n",
            "============================================================\n",
            "\n",
            "[109/144] CNN_rmsprop_relu_run1\n",
            "\n",
            "============================================================\n",
            "Training: CNN_rmsprop_relu_run1 (seed=1151)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 1: PR-AUC=0.0375, ROC-AUC=0.6977, F1=0.0862\n",
            "\n",
            "[110/144] CNN_rmsprop_relu_run2\n",
            "\n",
            "============================================================\n",
            "Training: CNN_rmsprop_relu_run2 (seed=2152)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 2: PR-AUC=0.0385, ROC-AUC=0.6949, F1=0.0846\n",
            "\n",
            "[111/144] CNN_rmsprop_relu_run3\n",
            "\n",
            "============================================================\n",
            "Training: CNN_rmsprop_relu_run3 (seed=3153)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 3: PR-AUC=0.0377, ROC-AUC=0.7019, F1=0.0828\n",
            "\n",
            "============================================================\n",
            "CONFIG: CNN_rmsprop_tanh\n",
            "============================================================\n",
            "\n",
            "[112/144] CNN_rmsprop_tanh_run1\n",
            "\n",
            "============================================================\n",
            "Training: CNN_rmsprop_tanh_run1 (seed=1154)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 1: PR-AUC=0.0355, ROC-AUC=0.6848, F1=0.0832\n",
            "\n",
            "[113/144] CNN_rmsprop_tanh_run2\n",
            "\n",
            "============================================================\n",
            "Training: CNN_rmsprop_tanh_run2 (seed=2155)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 2: PR-AUC=0.0385, ROC-AUC=0.7031, F1=0.0855\n",
            "\n",
            "[114/144] CNN_rmsprop_tanh_run3\n",
            "\n",
            "============================================================\n",
            "Training: CNN_rmsprop_tanh_run3 (seed=3156)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 3: PR-AUC=0.0394, ROC-AUC=0.7153, F1=0.0873\n",
            "\n",
            "============================================================\n",
            "CONFIG: CNN_rmsprop_sigmoid\n",
            "============================================================\n",
            "\n",
            "[115/144] CNN_rmsprop_sigmoid_run1\n",
            "\n",
            "============================================================\n",
            "Training: CNN_rmsprop_sigmoid_run1 (seed=1157)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 1: PR-AUC=0.0336, ROC-AUC=0.6692, F1=0.0774\n",
            "\n",
            "[116/144] CNN_rmsprop_sigmoid_run2\n",
            "\n",
            "============================================================\n",
            "Training: CNN_rmsprop_sigmoid_run2 (seed=2158)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 2: PR-AUC=0.0355, ROC-AUC=0.6814, F1=0.0798\n",
            "\n",
            "[117/144] CNN_rmsprop_sigmoid_run3\n",
            "\n",
            "============================================================\n",
            "Training: CNN_rmsprop_sigmoid_run3 (seed=3159)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 3: PR-AUC=0.0356, ROC-AUC=0.6855, F1=0.0822\n",
            "\n",
            "============================================================\n",
            "CONFIG: CNN_rmsprop_gelu\n",
            "============================================================\n",
            "\n",
            "[118/144] CNN_rmsprop_gelu_run1\n",
            "\n",
            "============================================================\n",
            "Training: CNN_rmsprop_gelu_run1 (seed=1160)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 1: PR-AUC=0.0452, ROC-AUC=0.7156, F1=0.0995\n",
            "\n",
            "[119/144] CNN_rmsprop_gelu_run2\n",
            "\n",
            "============================================================\n",
            "Training: CNN_rmsprop_gelu_run2 (seed=2161)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 2: PR-AUC=0.0470, ROC-AUC=0.7246, F1=0.1049\n",
            "\n",
            "[120/144] CNN_rmsprop_gelu_run3\n",
            "\n",
            "============================================================\n",
            "Training: CNN_rmsprop_gelu_run3 (seed=3162)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 3: PR-AUC=0.0400, ROC-AUC=0.7063, F1=0.0940\n",
            "\n",
            "============================================================\n",
            "CONFIG: Transformer_adam_relu\n",
            "============================================================\n",
            "\n",
            "[121/144] Transformer_adam_relu_run1\n",
            "\n",
            "============================================================\n",
            "Training: Transformer_adam_relu_run1 (seed=1163)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 1: PR-AUC=0.0368, ROC-AUC=0.6983, F1=0.0845\n",
            "\n",
            "[122/144] Transformer_adam_relu_run2\n",
            "\n",
            "============================================================\n",
            "Training: Transformer_adam_relu_run2 (seed=2164)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 2: PR-AUC=0.0380, ROC-AUC=0.7131, F1=0.0857\n",
            "\n",
            "[123/144] Transformer_adam_relu_run3\n",
            "\n",
            "============================================================\n",
            "Training: Transformer_adam_relu_run3 (seed=3165)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 3: PR-AUC=0.0379, ROC-AUC=0.7085, F1=0.0854\n",
            "\n",
            "============================================================\n",
            "CONFIG: Transformer_adam_tanh\n",
            "============================================================\n",
            "\n",
            "[124/144] Transformer_adam_tanh_run1\n",
            "\n",
            "============================================================\n",
            "Training: Transformer_adam_tanh_run1 (seed=1166)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 1: PR-AUC=0.0356, ROC-AUC=0.7003, F1=0.0796\n",
            "\n",
            "[125/144] Transformer_adam_tanh_run2\n",
            "\n",
            "============================================================\n",
            "Training: Transformer_adam_tanh_run2 (seed=2167)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 2: PR-AUC=0.0383, ROC-AUC=0.7097, F1=0.0847\n",
            "\n",
            "[126/144] Transformer_adam_tanh_run3\n",
            "\n",
            "============================================================\n",
            "Training: Transformer_adam_tanh_run3 (seed=3168)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 3: PR-AUC=0.0401, ROC-AUC=0.7197, F1=0.0877\n",
            "\n",
            "============================================================\n",
            "CONFIG: Transformer_adam_sigmoid\n",
            "============================================================\n",
            "\n",
            "[127/144] Transformer_adam_sigmoid_run1\n",
            "\n",
            "============================================================\n",
            "Training: Transformer_adam_sigmoid_run1 (seed=1169)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 1: PR-AUC=0.0385, ROC-AUC=0.7117, F1=0.0846\n",
            "\n",
            "[128/144] Transformer_adam_sigmoid_run2\n",
            "\n",
            "============================================================\n",
            "Training: Transformer_adam_sigmoid_run2 (seed=2170)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 2: PR-AUC=0.0367, ROC-AUC=0.6918, F1=0.0834\n",
            "\n",
            "[129/144] Transformer_adam_sigmoid_run3\n",
            "\n",
            "============================================================\n",
            "Training: Transformer_adam_sigmoid_run3 (seed=3171)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 3: PR-AUC=0.0390, ROC-AUC=0.7122, F1=0.0843\n",
            "\n",
            "============================================================\n",
            "CONFIG: Transformer_adam_gelu\n",
            "============================================================\n",
            "\n",
            "[130/144] Transformer_adam_gelu_run1\n",
            "\n",
            "============================================================\n",
            "Training: Transformer_adam_gelu_run1 (seed=1172)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 1: PR-AUC=0.0383, ROC-AUC=0.7105, F1=0.0858\n",
            "\n",
            "[131/144] Transformer_adam_gelu_run2\n",
            "\n",
            "============================================================\n",
            "Training: Transformer_adam_gelu_run2 (seed=2173)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 2: PR-AUC=0.0393, ROC-AUC=0.7077, F1=0.0847\n",
            "\n",
            "[132/144] Transformer_adam_gelu_run3\n",
            "\n",
            "============================================================\n",
            "Training: Transformer_adam_gelu_run3 (seed=3174)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 3: PR-AUC=0.0443, ROC-AUC=0.7227, F1=0.0943\n",
            "\n",
            "============================================================\n",
            "CONFIG: Transformer_rmsprop_relu\n",
            "============================================================\n",
            "\n",
            "[133/144] Transformer_rmsprop_relu_run1\n",
            "\n",
            "============================================================\n",
            "Training: Transformer_rmsprop_relu_run1 (seed=1175)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 1: PR-AUC=0.0432, ROC-AUC=0.7076, F1=0.0947\n",
            "\n",
            "[134/144] Transformer_rmsprop_relu_run2\n",
            "\n",
            "============================================================\n",
            "Training: Transformer_rmsprop_relu_run2 (seed=2176)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 2: PR-AUC=0.0403, ROC-AUC=0.7160, F1=0.0869\n",
            "\n",
            "[135/144] Transformer_rmsprop_relu_run3\n",
            "\n",
            "============================================================\n",
            "Training: Transformer_rmsprop_relu_run3 (seed=3177)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 3: PR-AUC=0.0414, ROC-AUC=0.7197, F1=0.0923\n",
            "\n",
            "============================================================\n",
            "CONFIG: Transformer_rmsprop_tanh\n",
            "============================================================\n",
            "\n",
            "[136/144] Transformer_rmsprop_tanh_run1\n",
            "\n",
            "============================================================\n",
            "Training: Transformer_rmsprop_tanh_run1 (seed=1178)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 1: PR-AUC=0.0363, ROC-AUC=0.7054, F1=0.0804\n",
            "\n",
            "[137/144] Transformer_rmsprop_tanh_run2\n",
            "\n",
            "============================================================\n",
            "Training: Transformer_rmsprop_tanh_run2 (seed=2179)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 2: PR-AUC=0.0370, ROC-AUC=0.7058, F1=0.0831\n",
            "\n",
            "[138/144] Transformer_rmsprop_tanh_run3\n",
            "\n",
            "============================================================\n",
            "Training: Transformer_rmsprop_tanh_run3 (seed=3180)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 3: PR-AUC=0.0393, ROC-AUC=0.7090, F1=0.0865\n",
            "\n",
            "============================================================\n",
            "CONFIG: Transformer_rmsprop_sigmoid\n",
            "============================================================\n",
            "\n",
            "[139/144] Transformer_rmsprop_sigmoid_run1\n",
            "\n",
            "============================================================\n",
            "Training: Transformer_rmsprop_sigmoid_run1 (seed=1181)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 1: PR-AUC=0.0392, ROC-AUC=0.7180, F1=0.0857\n",
            "\n",
            "[140/144] Transformer_rmsprop_sigmoid_run2\n",
            "\n",
            "============================================================\n",
            "Training: Transformer_rmsprop_sigmoid_run2 (seed=2182)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 2: PR-AUC=0.0374, ROC-AUC=0.7136, F1=0.0806\n",
            "\n",
            "[141/144] Transformer_rmsprop_sigmoid_run3\n",
            "\n",
            "============================================================\n",
            "Training: Transformer_rmsprop_sigmoid_run3 (seed=3183)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 3: PR-AUC=0.0359, ROC-AUC=0.6975, F1=0.0795\n",
            "\n",
            "============================================================\n",
            "CONFIG: Transformer_rmsprop_gelu\n",
            "============================================================\n",
            "\n",
            "[142/144] Transformer_rmsprop_gelu_run1\n",
            "\n",
            "============================================================\n",
            "Training: Transformer_rmsprop_gelu_run1 (seed=1184)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 1: PR-AUC=0.0384, ROC-AUC=0.7037, F1=0.0876\n",
            "\n",
            "[143/144] Transformer_rmsprop_gelu_run2\n",
            "\n",
            "============================================================\n",
            "Training: Transformer_rmsprop_gelu_run2 (seed=2185)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 2: PR-AUC=0.0390, ROC-AUC=0.7070, F1=0.0887\n",
            "\n",
            "[144/144] Transformer_rmsprop_gelu_run3\n",
            "\n",
            "============================================================\n",
            "Training: Transformer_rmsprop_gelu_run3 (seed=3186)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Run 3: PR-AUC=0.0424, ROC-AUC=0.7267, F1=0.0943\n",
            "\n",
            "============================================================\n",
            "AGGREGATING MULTI-RUN RESULTS WITH STATISTICAL RIGOR\n",
            "============================================================\n",
            "✓ Saved aggregated summary: /content/drive/MyDrive/AI_Fin/Undersampled_New/Phase_1/summary_report_phase1.csv\n",
            "✓ Saved stability-ranked summary: /content/drive/MyDrive/AI_Fin/Undersampled_New/Phase_1/summary_report_phase1_stability_ranked.csv\n",
            "\n",
            "============================================================\n",
            "TOP 5 CONFIGURATIONS (by PR-AUC mean → std → ROC-AUC → F1)\n",
            "============================================================\n",
            "\n",
            "1. CNN_rmsprop_gelu\n",
            "   PR-AUC:  0.0441 ± 0.0037\n",
            "            95% CI: [0.0350, 0.0532]\n",
            "   ROC-AUC: 0.7155 ± 0.0092\n",
            "   F1:      0.0995\n",
            "\n",
            "2. LSTM_Attention_rmsprop_tanh\n",
            "   PR-AUC:  0.0436 ± 0.0023\n",
            "            95% CI: [0.0379, 0.0494]\n",
            "   ROC-AUC: 0.7209 ± 0.0003\n",
            "   F1:      0.0955\n",
            "\n",
            "3. GRU_rmsprop_relu\n",
            "   PR-AUC:  0.0425 ± 0.0032\n",
            "            95% CI: [0.0345, 0.0505]\n",
            "   ROC-AUC: 0.7204 ± 0.0033\n",
            "   F1:      0.0915\n",
            "\n",
            "4. Transformer_rmsprop_relu\n",
            "   PR-AUC:  0.0416 ± 0.0014\n",
            "            95% CI: [0.0380, 0.0452]\n",
            "   ROC-AUC: 0.7144 ± 0.0062\n",
            "   F1:      0.0913\n",
            "\n",
            "5. LSTM_Attention_rmsprop_gelu\n",
            "   PR-AUC:  0.0408 ± 0.0005\n",
            "            95% CI: [0.0395, 0.0421]\n",
            "   ROC-AUC: 0.7094 ± 0.0054\n",
            "   F1:      0.0919\n",
            "\n",
            "============================================================\n",
            "TOP 5 BY STABILITY SCORE\n",
            "============================================================\n",
            "\n",
            "1. LSTM_Attention_adam_relu\n",
            "   PR-AUC:  0.0391 (stability: 155.2)\n",
            "   ROC-AUC: 0.7094 (stability: 54.6)\n",
            "\n",
            "2. RNN_rmsprop_sigmoid\n",
            "   PR-AUC:  0.0368 (stability: 115.3)\n",
            "   ROC-AUC: 0.6963 (stability: 192.5)\n",
            "\n",
            "3. LSTM_Attention_rmsprop_gelu\n",
            "   PR-AUC:  0.0408 (stability: 76.4)\n",
            "   ROC-AUC: 0.7094 (stability: 130.4)\n",
            "\n",
            "4. CNN_rmsprop_relu\n",
            "   PR-AUC:  0.0379 (stability: 69.1)\n",
            "   ROC-AUC: 0.6982 (stability: 197.5)\n",
            "\n",
            "5. Transformer_adam_relu\n",
            "   PR-AUC:  0.0376 (stability: 54.4)\n",
            "   ROC-AUC: 0.7066 (stability: 93.1)\n",
            "\n",
            "============================================================\n",
            "✓ PHASE 1 COMPLETE!\n",
            "============================================================\n",
            "\n",
            "🏆 Champion (by mean PR-AUC): CNN_rmsprop_gelu\n",
            "   PR-AUC:  0.0441 ± 0.0037\n",
            "            95% CI: [0.0350, 0.0532]\n",
            "            Stability score: 12.0\n",
            "   ROC-AUC: 0.7155 ± 0.0092\n",
            "            95% CI: [0.6926, 0.7383]\n",
            "            Stability score: 77.8\n",
            "   F1:      0.0995 ± 0.0054\n",
            "   Median threshold: 0.720\n",
            "\n",
            "🛡️ Most Stable: LSTM_Attention_adam_relu\n",
            "   PR-AUC:  0.0391 (stability: 155.2)\n",
            "   ROC-AUC: 0.7094 (stability: 54.6)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Phase 1: The Fair Gauntlet - Multi-seed robust architecture selection\n",
        "Resamples negatives per run, tracks PR-AUC during training, aggregates results\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    precision_recall_curve,\n",
        "    auc,\n",
        "    confusion_matrix,\n",
        "    f1_score\n",
        ")\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ============================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================\n",
        "\n",
        "BASE_DIR = '/content/drive/MyDrive/AI_Course_Project/Dataset'\n",
        "PHASE1_DIR = os.path.join(BASE_DIR, 'Undersampled_New', 'Phase_1')\n",
        "\n",
        "TRAIN_PATH_ORIG = f'{BASE_DIR}/baseline_train_matrices.npz'  # Original imbalanced\n",
        "VAL_PATH = f'{BASE_DIR}/baseline_val_matrices.npz'\n",
        "\n",
        "MODELS = ['LSTM', 'RNN', 'GRU', 'LSTM_Attention', 'CNN', 'Transformer']\n",
        "OPTIMIZERS = ['adam', 'rmsprop']\n",
        "ACTIVATIONS = ['relu', 'tanh', 'sigmoid', 'gelu']\n",
        "\n",
        "ACT_MAP = {\n",
        "    'relu': 'relu',\n",
        "    'tanh': 'tanh',\n",
        "    'sigmoid': 'sigmoid',\n",
        "    'gelu': tf.keras.activations.gelu\n",
        "}\n",
        "\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 256\n",
        "UNITS = 128\n",
        "DROPOUT = 0.3\n",
        "LEARNING_RATE = 0.001\n",
        "EARLY_STOPPING_PATIENCE = 5\n",
        "\n",
        "SEQUENCE_LENGTH = 4\n",
        "N_FEATURES = 21\n",
        "\n",
        "N_RUNS = 3  # Number of independent runs per configuration\n",
        "BASE_SEED = 42  # Base random seed\n",
        "\n",
        "# ============================================================\n",
        "# SEED MANAGEMENT\n",
        "# ============================================================\n",
        "\n",
        "def set_seed(seed):\n",
        "    \"\"\"Set all random seeds for reproducibility\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    try:\n",
        "        tf.config.experimental.enable_op_determinism()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "set_seed(BASE_SEED)\n",
        "\n",
        "# ============================================================\n",
        "# GPU & MIXED PRECISION\n",
        "# ============================================================\n",
        "\n",
        "try:\n",
        "    from tensorflow.keras import mixed_precision\n",
        "    policy = mixed_precision.Policy('mixed_float16')\n",
        "    mixed_precision.set_global_policy(policy)\n",
        "    print(\"✓ Mixed precision (float16) enabled\")\n",
        "except:\n",
        "    print(\"ℹ Mixed precision not available\")\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    print(f\"✓ GPU memory growth enabled for {len(gpus)} GPU(s)\")\n",
        "\n",
        "# ============================================================\n",
        "# DIRECTORY STRUCTURE\n",
        "# ============================================================\n",
        "\n",
        "def create_directory_structure():\n",
        "    os.makedirs(PHASE1_DIR, exist_ok=True)\n",
        "    for model_name in MODELS:\n",
        "        os.makedirs(os.path.join(PHASE1_DIR, model_name), exist_ok=True)\n",
        "    print(f\"✓ Created Phase 1 directory at {PHASE1_DIR}\")\n",
        "\n",
        "# ============================================================\n",
        "# DATA LOADING & RESAMPLING\n",
        "# ============================================================\n",
        "\n",
        "def load_npz_memmap(path, key_x='X', key_y='y'):\n",
        "    npz = np.load(path, mmap_mode='r')\n",
        "    return npz[key_x], npz[key_y]\n",
        "\n",
        "def create_balanced_sample(X_train_orig, y_train_orig, patient_ids_train, seed):\n",
        "    \"\"\"\n",
        "    Create balanced sample: all positives + equal number of negatives\n",
        "    Sample negatives at patient level to maintain patient diversity\n",
        "    \"\"\"\n",
        "    set_seed(seed)\n",
        "\n",
        "    # Get positive and negative indices\n",
        "    pos_idx = np.where(y_train_orig == 1)[0]\n",
        "    neg_idx = np.where(y_train_orig == 0)[0]\n",
        "\n",
        "    n_positives = len(pos_idx)\n",
        "\n",
        "    # Sample negatives at patient level\n",
        "    neg_patients = np.unique(patient_ids_train[neg_idx])\n",
        "\n",
        "    # Sample negative patients (without replacement for diversity)\n",
        "    # Then collect all their windows until we reach n_positives samples\n",
        "    np.random.shuffle(neg_patients)\n",
        "\n",
        "    sampled_neg_idx = []\n",
        "    for pid in neg_patients:\n",
        "        pid_neg_idx = neg_idx[patient_ids_train[neg_idx] == pid]\n",
        "        sampled_neg_idx.extend(pid_neg_idx)\n",
        "        if len(sampled_neg_idx) >= n_positives:\n",
        "            break\n",
        "\n",
        "    # Trim to exact count\n",
        "    sampled_neg_idx = np.array(sampled_neg_idx[:n_positives])\n",
        "\n",
        "    # Combine positive and sampled negative indices\n",
        "    balanced_idx = np.concatenate([pos_idx, sampled_neg_idx])\n",
        "    np.random.shuffle(balanced_idx)\n",
        "\n",
        "    X_balanced = X_train_orig[balanced_idx]\n",
        "    y_balanced = y_train_orig[balanced_idx]\n",
        "\n",
        "    return X_balanced, y_balanced\n",
        "\n",
        "def make_tf_dataset(X, y, batch_size, shuffle=True, buffer_size=10000):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size, reshuffle_each_iteration=True)\n",
        "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "# ============================================================\n",
        "# MODEL ARCHITECTURES\n",
        "# ============================================================\n",
        "\n",
        "def build_lstm(input_shape, units, dropout, activation):\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Masking(mask_value=-1.0),\n",
        "        layers.LSTM(units, activation=activation, return_sequences=False),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(64, activation=activation),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(1, activation='sigmoid', dtype='float32')\n",
        "    ], name='LSTM')\n",
        "    return model\n",
        "\n",
        "def build_rnn(input_shape, units, dropout, activation):\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Masking(mask_value=-1.0),\n",
        "        layers.SimpleRNN(units, activation=activation, return_sequences=False),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(64, activation=activation),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(1, activation='sigmoid', dtype='float32')\n",
        "    ], name='RNN')\n",
        "    return model\n",
        "\n",
        "def build_gru(input_shape, units, dropout, activation):\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Masking(mask_value=-1.0),\n",
        "        layers.GRU(units, activation=activation, return_sequences=False),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(64, activation=activation),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(1, activation='sigmoid', dtype='float32')\n",
        "    ], name='GRU')\n",
        "    return model\n",
        "\n",
        "def build_lstm_attention(input_shape, units, dropout, activation):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    masked = layers.Masking(mask_value=-1.0)(inputs)\n",
        "    lstm_out = layers.LSTM(units, activation=activation, return_sequences=True)(masked)\n",
        "\n",
        "    attention = layers.Dense(1, activation='tanh')(lstm_out)\n",
        "    attention = layers.Flatten()(attention)\n",
        "    attention = layers.Activation('softmax')(attention)\n",
        "    attention = layers.RepeatVector(units)(attention)\n",
        "    attention = layers.Permute([2, 1])(attention)\n",
        "\n",
        "    merged = layers.Multiply()([lstm_out, attention])\n",
        "    merged = layers.Lambda(lambda x: keras.backend.sum(x, axis=1))(merged)\n",
        "\n",
        "    dense = layers.Dense(64, activation=activation)(merged)\n",
        "    dense = layers.Dropout(dropout)(dense)\n",
        "    outputs = layers.Dense(1, activation='sigmoid', dtype='float32')(dense)\n",
        "\n",
        "    return keras.Model(inputs=inputs, outputs=outputs, name='LSTM_Attention')\n",
        "\n",
        "def build_cnn(input_shape, units, dropout, activation):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    masked_input = layers.Lambda(lambda x: tf.where(\n",
        "        tf.equal(x, -1),\n",
        "        tf.zeros_like(x),\n",
        "        x\n",
        "    ))(inputs)\n",
        "\n",
        "    x = layers.Conv1D(filters=64, kernel_size=2, activation=activation, padding='same')(masked_input)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=128, kernel_size=2, activation=activation, padding='same')(x)\n",
        "    x = layers.GlobalMaxPooling1D()(x)\n",
        "\n",
        "    x = layers.Dense(units, activation=activation)(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    outputs = layers.Dense(1, activation='sigmoid', dtype='float32')(x)\n",
        "\n",
        "    return keras.Model(inputs=inputs, outputs=outputs, name='CNN')\n",
        "\n",
        "def build_transformer(input_shape, units, dropout, activation):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    valid_timestep_mask = layers.Lambda(\n",
        "        lambda x: tf.reduce_any(tf.not_equal(x, -1.0), axis=-1)\n",
        "    )(inputs)\n",
        "\n",
        "    x_clean = layers.Lambda(lambda x: tf.where(\n",
        "        tf.equal(x, -1.0),\n",
        "        tf.zeros_like(x),\n",
        "        x\n",
        "    ))(inputs)\n",
        "\n",
        "    seq_len, feat_dim = input_shape\n",
        "\n",
        "    positions = tf.range(start=0, limit=seq_len, delta=1)\n",
        "    pos_emb = layers.Embedding(input_dim=seq_len, output_dim=feat_dim)(positions)\n",
        "    pos_emb = layers.Lambda(lambda p: tf.expand_dims(p, axis=0))(pos_emb)\n",
        "    x = layers.Add()([x_clean, pos_emb])\n",
        "\n",
        "    attn_mask = layers.Lambda(\n",
        "        lambda m: tf.expand_dims(tf.cast(m, tf.bool), axis=1)\n",
        "    )(valid_timestep_mask)\n",
        "\n",
        "    num_heads = 4\n",
        "    key_dim = feat_dim // num_heads\n",
        "    attn_out = layers.MultiHeadAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=key_dim,\n",
        "        dropout=dropout\n",
        "    )(x, x, attention_mask=attn_mask)\n",
        "\n",
        "    x = layers.Add()([x, attn_out])\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "    ffn = keras.Sequential([\n",
        "        layers.Dense(units, activation=activation),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(feat_dim),\n",
        "    ])\n",
        "    ffn_out = ffn(x)\n",
        "    x = layers.Add()([x, ffn_out])\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "    x_masked = layers.Lambda(lambda args: args[0] * tf.cast(\n",
        "        tf.expand_dims(args[1], -1),\n",
        "        dtype=args[0].dtype\n",
        "    ))([x, valid_timestep_mask])\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D()(x_masked)\n",
        "    x = layers.Dense(units, activation=activation)(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    outputs = layers.Dense(1, activation='sigmoid', dtype='float32')(x)\n",
        "\n",
        "    return keras.Model(inputs=inputs, outputs=outputs, name='Transformer')\n",
        "\n",
        "def get_model(model_name, input_shape, units, dropout, activation):\n",
        "    act = ACT_MAP.get(activation, activation)\n",
        "    builders = {\n",
        "        'LSTM': build_lstm,\n",
        "        'RNN': build_rnn,\n",
        "        'GRU': build_gru,\n",
        "        'LSTM_Attention': build_lstm_attention,\n",
        "        'CNN': build_cnn,\n",
        "        'Transformer': build_transformer\n",
        "    }\n",
        "    return builders[model_name](input_shape, units, dropout, act)\n",
        "\n",
        "# ============================================================\n",
        "# METRICS\n",
        "# ============================================================\n",
        "\n",
        "def find_best_f1_threshold(y_true, y_pred_proba):\n",
        "    thresholds = np.linspace(0.01, 0.99, 99)\n",
        "    best_f1 = 0.0\n",
        "    best_threshold = 0.5\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        y_pred_temp = (y_pred_proba > threshold).astype(int)\n",
        "        f1 = f1_score(y_true, y_pred_temp, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = threshold\n",
        "\n",
        "    return best_threshold, best_f1\n",
        "\n",
        "def compute_metrics(y_true, y_pred, y_pred_proba):\n",
        "    try:\n",
        "        cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "\n",
        "        if cm.shape == (2, 2):\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "        else:\n",
        "            tn = fp = fn = tp = 0\n",
        "            if cm.shape == (1, 1):\n",
        "                tn = cm[0, 0] if y_true[0] == 0 else 0\n",
        "                tp = cm[0, 0] if y_true[0] == 1 else 0\n",
        "\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "        npv = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n",
        "        f1 = 2 * (precision * sensitivity) / (precision + sensitivity) if (precision + sensitivity) > 0 else 0.0\n",
        "\n",
        "        roc_auc = roc_auc_score(y_true, y_pred_proba) if len(np.unique(y_true)) > 1 else 0.0\n",
        "\n",
        "        if len(np.unique(y_true)) > 1:\n",
        "            prec_curve, rec_curve, _ = precision_recall_curve(y_true, y_pred_proba)\n",
        "            pr_auc = auc(rec_curve, prec_curve)\n",
        "        else:\n",
        "            pr_auc = 0.0\n",
        "\n",
        "        return {\n",
        "            'roc_auc': float(roc_auc),\n",
        "            'pr_auc': float(pr_auc),\n",
        "            'sensitivity': float(sensitivity),\n",
        "            'specificity': float(specificity),\n",
        "            'precision': float(precision),\n",
        "            'npv': float(npv),\n",
        "            'f1_score': float(f1),\n",
        "            'tp': int(tp), 'tn': int(tn), 'fp': int(fp), 'fn': int(fn)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: metrics error: {e}\")\n",
        "        return {\n",
        "            'roc_auc': 0.0, 'pr_auc': 0.0, 'sensitivity': 0.0,\n",
        "            'specificity': 0.0, 'precision': 0.0, 'npv': 0.0,\n",
        "            'f1_score': 0.0, 'tp': 0, 'tn': 0, 'fp': 0, 'fn': 0\n",
        "        }\n",
        "\n",
        "# ============================================================\n",
        "# TRAINING\n",
        "# ============================================================\n",
        "\n",
        "def train_and_evaluate(model_name, optimizer_name, activation, run_id, seed,\n",
        "                       X_train, y_train, X_val, y_val):\n",
        "\n",
        "    set_seed(seed)\n",
        "\n",
        "    input_shape = (SEQUENCE_LENGTH, N_FEATURES)\n",
        "    model = get_model(model_name, input_shape, UNITS, DROPOUT, activation)\n",
        "\n",
        "    if optimizer_name == 'adam':\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "    else:\n",
        "        optimizer = keras.optimizers.RMSprop(learning_rate=LEARNING_RATE)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            keras.metrics.AUC(name='roc_auc'),\n",
        "            keras.metrics.AUC(curve='PR', name='pr_auc')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    exp_name = f\"{model_name}_{optimizer_name}_{activation}_run{run_id}\"\n",
        "    model_dir = os.path.join(PHASE1_DIR, model_name)\n",
        "\n",
        "    callbacks = [\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            patience=EARLY_STOPPING_PATIENCE,\n",
        "            restore_best_weights=True,\n",
        "            monitor='val_pr_auc',\n",
        "            mode='max',\n",
        "            verbose=0\n",
        "        ),\n",
        "        keras.callbacks.ReduceLROnPlateau(\n",
        "            factor=0.5,\n",
        "            patience=3,\n",
        "            monitor='val_loss',\n",
        "            min_lr=1e-6,\n",
        "            verbose=0\n",
        "        ),\n",
        "        keras.callbacks.CSVLogger(\n",
        "            os.path.join(model_dir, f'{exp_name}_training_log.csv')\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training: {exp_name} (seed={seed})\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    train_ds = make_tf_dataset(X_train, y_train, BATCH_SIZE, shuffle=True)\n",
        "    val_ds = make_tf_dataset(X_val, y_val, BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=callbacks,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    epochs_trained = len(history.history['loss'])\n",
        "\n",
        "    # F1-Threshold Hunter\n",
        "    y_val_pred_proba = model.predict(val_ds, verbose=0).flatten()\n",
        "    best_threshold, best_f1_found = find_best_f1_threshold(y_val, y_val_pred_proba)\n",
        "\n",
        "    y_val_pred = (y_val_pred_proba > best_threshold).astype(int)\n",
        "    val_metrics = compute_metrics(y_val, y_val_pred, y_val_pred_proba)\n",
        "\n",
        "    val_metrics['best_threshold'] = float(best_threshold)\n",
        "    val_metrics['best_f1_found'] = float(best_f1_found)\n",
        "\n",
        "    # Save model & history\n",
        "    model.save(os.path.join(model_dir, f'{exp_name}_model.h5'))\n",
        "    with open(os.path.join(model_dir, f'{exp_name}_history.json'), 'w') as f:\n",
        "        json.dump({k: [float(v) for v in vals] for k, vals in history.history.items()}, f, indent=2)\n",
        "\n",
        "    results = {\n",
        "        'model': model_name,\n",
        "        'optimizer': optimizer_name,\n",
        "        'activation': activation,\n",
        "        'run_id': run_id,\n",
        "        'seed': seed,\n",
        "        'experiment_name': exp_name,\n",
        "        'train_samples': int(len(X_train)),\n",
        "        'val_samples': int(len(X_val)),\n",
        "        'epochs_trained': int(epochs_trained),\n",
        "        'final_val_pr_auc': float(history.history['val_pr_auc'][-1]),\n",
        "        'final_val_roc_auc': float(history.history['val_roc_auc'][-1]),\n",
        "        **val_metrics\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(model_dir, f'{exp_name}_results.json'), 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "    print(f\"✓ Run {run_id}: PR-AUC={val_metrics['pr_auc']:.4f}, ROC-AUC={val_metrics['roc_auc']:.4f}, F1={val_metrics['f1_score']:.4f}\")\n",
        "\n",
        "    del model\n",
        "    keras.backend.clear_session()\n",
        "    import gc\n",
        "    gc.collect()\n",
        "\n",
        "    return results\n",
        "\n",
        "# ============================================================\n",
        "# MAIN\n",
        "# ============================================================\n",
        "\n",
        "def main():\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"PHASE 1: MULTI-SEED FAIR GAUNTLET\")\n",
        "    print(f\"{N_RUNS} runs per configuration\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    create_directory_structure()\n",
        "\n",
        "    # Load ORIGINAL imbalanced training data\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"LOADING DATA\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(\"Loading original imbalanced training data...\")\n",
        "    X_train_orig_mmap, y_train_orig_mmap = load_npz_memmap(TRAIN_PATH_ORIG)\n",
        "\n",
        "    # Load patient_ids if available\n",
        "    try:\n",
        "        npz_train = np.load(TRAIN_PATH_ORIG, mmap_mode='r')\n",
        "        patient_ids_train = npz_train['patient_ids']\n",
        "    except:\n",
        "        print(\"Warning: patient_ids not found, using index-based sampling\")\n",
        "        patient_ids_train = np.arange(len(y_train_orig_mmap))\n",
        "\n",
        "    print(f\"✓ Original train: {len(y_train_orig_mmap):,} samples\")\n",
        "    print(f\"  Class 0: {(y_train_orig_mmap == 0).sum():,}, Class 1: {(y_train_orig_mmap == 1).sum():,}\")\n",
        "\n",
        "    print(\"\\nLoading validation data...\")\n",
        "    X_val_mmap, y_val = load_npz_memmap(VAL_PATH)\n",
        "    X_val = X_val_mmap[:].astype(np.float32)\n",
        "    print(f\"✓ Validation: {len(y_val):,} samples\")\n",
        "\n",
        "    # Run level results path\n",
        "    runs_summary_path = os.path.join(PHASE1_DIR, 'runs_summary.csv')\n",
        "    if os.path.exists(runs_summary_path):\n",
        "        existing_runs = pd.read_csv(runs_summary_path)\n",
        "        done_experiments = set(existing_runs['experiment_name'].tolist())\n",
        "        print(f\"\\n✓ Found {len(done_experiments)} completed runs\")\n",
        "    else:\n",
        "        done_experiments = set()\n",
        "\n",
        "    # Run experiments\n",
        "    total_configs = len(MODELS) * len(OPTIMIZERS) * len(ACTIVATIONS)\n",
        "    total_experiments = total_configs * N_RUNS\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"RUNNING {total_experiments} TOTAL EXPERIMENTS\")\n",
        "    print(f\"({total_configs} configs × {N_RUNS} runs each)\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    experiment_num = 0\n",
        "\n",
        "    for model_name in MODELS:\n",
        "        for optimizer_name in OPTIMIZERS:\n",
        "            for activation in ACTIVATIONS:\n",
        "                config_name = f\"{model_name}_{optimizer_name}_{activation}\"\n",
        "                print(f\"\\n{'='*60}\")\n",
        "                print(f\"CONFIG: {config_name}\")\n",
        "                print(f\"{'='*60}\")\n",
        "\n",
        "                for run_id in range(1, N_RUNS + 1):\n",
        "                    experiment_num += 1\n",
        "                    exp_name = f\"{config_name}_run{run_id}\"\n",
        "                    seed = BASE_SEED + run_id * 1000 + experiment_num\n",
        "\n",
        "                    if exp_name in done_experiments:\n",
        "                        print(f\"[{experiment_num}/{total_experiments}] SKIP: {exp_name}\")\n",
        "                        continue\n",
        "\n",
        "                    print(f\"\\n[{experiment_num}/{total_experiments}] {exp_name}\")\n",
        "\n",
        "                    try:\n",
        "                        # Create fresh balanced sample for this run\n",
        "                        X_train, y_train = create_balanced_sample(\n",
        "                            X_train_orig_mmap, y_train_orig_mmap,\n",
        "                            patient_ids_train, seed\n",
        "                        )\n",
        "                        X_train = X_train.astype(np.float32)\n",
        "\n",
        "                        results = train_and_evaluate(\n",
        "                            model_name, optimizer_name, activation,\n",
        "                            run_id, seed,\n",
        "                            X_train, y_train, X_val, y_val\n",
        "                        )\n",
        "\n",
        "                        # Append to runs summary immediately\n",
        "                        result_df = pd.DataFrame([results])\n",
        "                        if not os.path.exists(runs_summary_path):\n",
        "                            result_df.to_csv(runs_summary_path, index=False)\n",
        "                        else:\n",
        "                            result_df.to_csv(runs_summary_path, mode='a', header=False, index=False)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"\\n❌ ERROR: {str(e)}\")\n",
        "                        import traceback\n",
        "                        traceback.print_exc()\n",
        "                        continue\n",
        "\n",
        "    # ============================================================\n",
        "    # AGGREGATE RESULTS WITH STATISTICAL RIGOR\n",
        "    # ============================================================\n",
        "\n",
        "    from scipy.stats import sem, t\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"AGGREGATING MULTI-RUN RESULTS WITH STATISTICAL RIGOR\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    runs_df = pd.read_csv(runs_summary_path)\n",
        "\n",
        "    # Group by configuration\n",
        "    agg_results = []\n",
        "    for (model, opt, act), group in runs_df.groupby(['model', 'optimizer', 'activation']):\n",
        "        config_name = f\"{model}_{opt}_{act}\"\n",
        "        n = len(group)\n",
        "\n",
        "        # PR-AUC statistics\n",
        "        pr_auc_mean = group['pr_auc'].mean()\n",
        "        pr_auc_std = group['pr_auc'].std()\n",
        "        pr_auc_sem = sem(group['pr_auc'])\n",
        "\n",
        "        # 95% CI for PR-AUC\n",
        "        if n > 1:\n",
        "            pr_auc_ci = t.interval(0.95, n-1, loc=pr_auc_mean, scale=pr_auc_sem)\n",
        "            pr_auc_ci_lower = pr_auc_ci[0]\n",
        "            pr_auc_ci_upper = pr_auc_ci[1]\n",
        "        else:\n",
        "            pr_auc_ci_lower = pr_auc_ci_upper = pr_auc_mean\n",
        "\n",
        "        # ROC-AUC statistics\n",
        "        roc_auc_mean = group['roc_auc'].mean()\n",
        "        roc_auc_std = group['roc_auc'].std()\n",
        "        roc_auc_sem = sem(group['roc_auc'])\n",
        "\n",
        "        # 95% CI for ROC-AUC\n",
        "        if n > 1:\n",
        "            roc_auc_ci = t.interval(0.95, n-1, loc=roc_auc_mean, scale=roc_auc_sem)\n",
        "            roc_auc_ci_lower = roc_auc_ci[0]\n",
        "            roc_auc_ci_upper = roc_auc_ci[1]\n",
        "        else:\n",
        "            roc_auc_ci_lower = roc_auc_ci_upper = roc_auc_mean\n",
        "\n",
        "        # F1 statistics\n",
        "        f1_mean = group['f1_score'].mean()\n",
        "        f1_std = group['f1_score'].std()\n",
        "\n",
        "        # Stability score: higher is better (high mean, low variance)\n",
        "        epsilon = 1e-9\n",
        "        pr_auc_stability = pr_auc_mean / (pr_auc_std + epsilon)\n",
        "        roc_auc_stability = roc_auc_mean / (roc_auc_std + epsilon)\n",
        "\n",
        "        agg = {\n",
        "            'config_name': config_name,\n",
        "            'model': model,\n",
        "            'optimizer': opt,\n",
        "            'activation': act,\n",
        "            'n_runs': n,\n",
        "\n",
        "            # PR-AUC metrics\n",
        "            'pr_auc_mean': pr_auc_mean,\n",
        "            'pr_auc_std': pr_auc_std,\n",
        "            'pr_auc_ci_lower': pr_auc_ci_lower,\n",
        "            'pr_auc_ci_upper': pr_auc_ci_upper,\n",
        "            'pr_auc_stability': pr_auc_stability,\n",
        "\n",
        "            # ROC-AUC metrics\n",
        "            'roc_auc_mean': roc_auc_mean,\n",
        "            'roc_auc_std': roc_auc_std,\n",
        "            'roc_auc_ci_lower': roc_auc_ci_lower,\n",
        "            'roc_auc_ci_upper': roc_auc_ci_upper,\n",
        "            'roc_auc_stability': roc_auc_stability,\n",
        "\n",
        "            # F1 metrics\n",
        "            'f1_score_mean': f1_mean,\n",
        "            'f1_score_std': f1_std,\n",
        "\n",
        "            # Other metrics\n",
        "            'sensitivity_mean': group['sensitivity'].mean(),\n",
        "            'specificity_mean': group['specificity'].mean(),\n",
        "            'precision_mean': group['precision'].mean(),\n",
        "            'best_threshold_median': group['best_threshold'].median(),\n",
        "        }\n",
        "        agg_results.append(agg)\n",
        "\n",
        "    agg_df = pd.DataFrame(agg_results)\n",
        "\n",
        "    # Primary sort: PR-AUC mean (desc), PR-AUC std (asc), ROC-AUC mean (desc), F1 mean (desc)\n",
        "    agg_df = agg_df.sort_values(\n",
        "        by=['pr_auc_mean', 'pr_auc_std', 'roc_auc_mean', 'f1_score_mean'],\n",
        "        ascending=[False, True, False, False]\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    # Save aggregated summary\n",
        "    agg_summary_path = os.path.join(PHASE1_DIR, 'summary_report_phase1.csv')\n",
        "    agg_df.to_csv(agg_summary_path, index=False)\n",
        "    print(f\"✓ Saved aggregated summary: {agg_summary_path}\")\n",
        "\n",
        "    # Also create a stability-ranked summary\n",
        "    agg_df_stability = agg_df.sort_values(\n",
        "        by=['pr_auc_stability', 'roc_auc_stability'],\n",
        "        ascending=[False, False]\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    stability_summary_path = os.path.join(PHASE1_DIR, 'summary_report_phase1_stability_ranked.csv')\n",
        "    agg_df_stability.to_csv(stability_summary_path, index=False)\n",
        "    print(f\"✓ Saved stability-ranked summary: {stability_summary_path}\")\n",
        "\n",
        "    # ============================================================\n",
        "    # DISPLAY TOP RESULTS\n",
        "    # ============================================================\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"TOP 5 CONFIGURATIONS (by PR-AUC mean → std → ROC-AUC → F1)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    top5 = agg_df.head(5)[[\n",
        "        'config_name',\n",
        "        'pr_auc_mean', 'pr_auc_std', 'pr_auc_ci_lower', 'pr_auc_ci_upper',\n",
        "        'roc_auc_mean', 'roc_auc_std',\n",
        "        'f1_score_mean'\n",
        "    ]]\n",
        "\n",
        "    for idx, row in top5.iterrows():\n",
        "        print(f\"\\n{idx+1}. {row['config_name']}\")\n",
        "        print(f\"   PR-AUC:  {row['pr_auc_mean']:.4f} ± {row['pr_auc_std']:.4f}\")\n",
        "        print(f\"            95% CI: [{row['pr_auc_ci_lower']:.4f}, {row['pr_auc_ci_upper']:.4f}]\")\n",
        "        print(f\"   ROC-AUC: {row['roc_auc_mean']:.4f} ± {row['roc_auc_std']:.4f}\")\n",
        "        print(f\"   F1:      {row['f1_score_mean']:.4f}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"TOP 5 BY STABILITY SCORE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    top5_stable = agg_df_stability.head(5)[[\n",
        "        'config_name',\n",
        "        'pr_auc_mean', 'pr_auc_stability',\n",
        "        'roc_auc_mean', 'roc_auc_stability'\n",
        "    ]]\n",
        "\n",
        "    for idx, row in top5_stable.iterrows():\n",
        "        print(f\"\\n{idx+1}. {row['config_name']}\")\n",
        "        print(f\"   PR-AUC:  {row['pr_auc_mean']:.4f} (stability: {row['pr_auc_stability']:.1f})\")\n",
        "        print(f\"   ROC-AUC: {row['roc_auc_mean']:.4f} (stability: {row['roc_auc_stability']:.1f})\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"✓ PHASE 1 COMPLETE!\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    champion = agg_df.iloc[0]\n",
        "    print(f\"\\n🏆 Champion (by mean PR-AUC): {champion['config_name']}\")\n",
        "    print(f\"   PR-AUC:  {champion['pr_auc_mean']:.4f} ± {champion['pr_auc_std']:.4f}\")\n",
        "    print(f\"            95% CI: [{champion['pr_auc_ci_lower']:.4f}, {champion['pr_auc_ci_upper']:.4f}]\")\n",
        "    print(f\"            Stability score: {champion['pr_auc_stability']:.1f}\")\n",
        "    print(f\"   ROC-AUC: {champion['roc_auc_mean']:.4f} ± {champion['roc_auc_std']:.4f}\")\n",
        "    print(f\"            95% CI: [{champion['roc_auc_ci_lower']:.4f}, {champion['roc_auc_ci_upper']:.4f}]\")\n",
        "    print(f\"            Stability score: {champion['roc_auc_stability']:.1f}\")\n",
        "    print(f\"   F1:      {champion['f1_score_mean']:.4f} ± {champion['f1_score_std']:.4f}\")\n",
        "    print(f\"   Median threshold: {champion['best_threshold_median']:.3f}\")\n",
        "\n",
        "    most_stable = agg_df_stability.iloc[0]\n",
        "    if most_stable['config_name'] != champion['config_name']:\n",
        "        print(f\"\\n🛡️ Most Stable: {most_stable['config_name']}\")\n",
        "        print(f\"   PR-AUC:  {most_stable['pr_auc_mean']:.4f} (stability: {most_stable['pr_auc_stability']:.1f})\")\n",
        "        print(f\"   ROC-AUC: {most_stable['roc_auc_mean']:.4f} (stability: {most_stable['roc_auc_stability']:.1f})\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# V7 - Preprocess: Creating a 6 hour label shift: --> More challenging but clinically more useful for deployments"
      ],
      "metadata": {
        "id": "92fd9mIHiGvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "============================================================\n",
        "Preprocessing (Baseline-Corrected v7)\n",
        "============================================================\n",
        "Implements PhysioNet-style preprocessing for Sepsis prediction,\n",
        "fully aligned with baseline paper methodology.\n",
        "\n",
        "Key features:\n",
        "- Exclusion criteria: ≥8h ICU stay, sepsis onset ≥4h\n",
        "- Hourly resampling with ICULOS reconstruction\n",
        "- Time-limited forward fill: 4h (vitals), 24h (labs)\n",
        "- Derived features: ShockIndex, BUN_Cr, MEWS, pSOFA\n",
        "- 6-hour label shift for early prediction (applied using ICULOS)\n",
        "- Patient-level split: 68% train / 17% val / 15% test\n",
        "- IQR normalization to [1,5] range, missing = -1\n",
        "- No synthetic augmentation (matches baseline paper)\n",
        "- LSTM-ready: requires Masking(mask_value=-1.0)\n",
        "\n",
        "Outputs:\n",
        "- Train/Val/Test CSVs\n",
        "- IQR limits JSON\n",
        "- Comprehensive metadata JSON\n",
        "\n",
        "Version: v7_baseline_corrected\n",
        "============================================================\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ============================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================\n",
        "input_path = '/content/drive/MyDrive/AI_Course_Project/Dataset/merged_sepsis_dataset.csv'\n",
        "output_dir = '/content/drive/MyDrive/AI_Course_Project/Dataset/Fix_Over_Fitting/Preprocessing_fix_overfitting_v7'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "train_output_csv = os.path.join(output_dir, 'sepsis_preprocessed_train_v7.csv')\n",
        "val_output_csv   = os.path.join(output_dir, 'sepsis_preprocessed_val_v7.csv')\n",
        "test_output_csv  = os.path.join(output_dir, 'sepsis_preprocessed_test_v7.csv')\n",
        "full_output_csv  = os.path.join(output_dir, 'sepsis_preprocessed_full_v7.csv')\n",
        "limits_json_path = os.path.join(output_dir, 'iqr_minmax_limits_v7.json')\n",
        "metadata_json_path = os.path.join(output_dir, 'preprocessing_metadata_v7.json')\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# ============================================================\n",
        "# FEATURE FORWARD FILL INTERVALS (hours)\n",
        "# ============================================================\n",
        "feature_intervals = {\n",
        "    # Vitals (4-hour hold)\n",
        "    'HR': 4, 'SBP': 4, 'DBP': 4, 'Resp': 4, 'O2Sat': 4,\n",
        "    'Temp': 4, 'MAP': 4, 'EtCO2': 4,\n",
        "\n",
        "    # Labs (24-hour hold)\n",
        "    'BaseExcess': 24, 'HCO3': 24, 'FiO2': 4, 'pH': 24, 'PaCO2': 24,\n",
        "    'SaO2': 4, 'AST': 24, 'BUN': 24, 'Alkalinephos': 24,\n",
        "    'Calcium': 24, 'Chloride': 24, 'Creatinine': 24,\n",
        "    'Bilirubin_direct': 24, 'Glucose': 24, 'Lactate': 24,\n",
        "    'Magnesium': 24, 'Phosphate': 24, 'Potassium': 24,\n",
        "    'Bilirubin_total': 24, 'TroponinI': 24, 'Hct': 24,\n",
        "    'Hgb': 24, 'PTT': 24, 'WBC': 24, 'Fibrinogen': 24,\n",
        "    'Platelets': 24,\n",
        "\n",
        "    # Demographics (static, no forward fill)\n",
        "    'Age': None,\n",
        "    'Gender': None,\n",
        "}\n",
        "\n",
        "# Clinical sanity bounds to constrain IQR-based limits\n",
        "clinical_sanity = {\n",
        "    'HR': (30, 250),\n",
        "    'SBP': (40, 250),\n",
        "    'Temp': (30.0, 45.0),\n",
        "    'O2Sat': (50, 100),\n",
        "    'MAP': (30, 200),\n",
        "    'Resp': (5, 60),\n",
        "    'Creatinine': (0.1, 20.0),\n",
        "    'BUN': (1, 200),\n",
        "    'Platelets': (1, 1000),\n",
        "    'Glucose': (30, 1000),\n",
        "    'ShockIndex': (0.1, 5.0),\n",
        "    'BUN_Cr': (1, 100),\n",
        "    'MEWS': (0, 15),\n",
        "    'pSOFA': (0, 12),\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# STEP 1: LOAD RAW DATA\n",
        "# ============================================================\n",
        "print(\"=\"*60)\n",
        "print(\"STEP 1: LOADING RAW DATA\")\n",
        "print(\"=\"*60)\n",
        "df = pd.read_csv(input_path)\n",
        "print(f\"✓ Loaded {len(df):,} rows, {df.shape[1]} columns\")\n",
        "\n",
        "if 'patient_id' not in df.columns:\n",
        "    raise ValueError(\"Input must contain 'patient_id' column (lowercase).\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 2: APPLY EXCLUSION CRITERIA\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 2: APPLYING EXCLUSION CRITERIA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "n_patients_before = df['patient_id'].nunique()\n",
        "n_rows_before = len(df)\n",
        "\n",
        "# Exclusion 1: Patients with < 8 hours of ICU data\n",
        "if 'ICULOS' in df.columns:\n",
        "    patient_max_iculos = df.groupby('patient_id')['ICULOS'].max()\n",
        "    valid_patients = patient_max_iculos[patient_max_iculos >= 8].index\n",
        "    df = df[df['patient_id'].isin(valid_patients)]\n",
        "    excluded_duration = n_patients_before - len(valid_patients)\n",
        "    print(f\"✓ Excluded {excluded_duration} patients with <8h ICU data\")\n",
        "else:\n",
        "    print(\"⚠ Warning: ICULOS column not found. Skipping duration exclusion.\")\n",
        "\n",
        "# Exclusion 2: Patients with sepsis onset < 4 hours after ICU admission\n",
        "if {'SepsisLabel', 'ICULOS'}.issubset(df.columns):\n",
        "    sepsis_onset = df[df['SepsisLabel']==1].groupby('patient_id')['ICULOS'].min()\n",
        "    early_sepsis_patients = sepsis_onset[sepsis_onset < 4].index\n",
        "    df = df[~df['patient_id'].isin(early_sepsis_patients)]\n",
        "    print(f\"✓ Excluded {len(early_sepsis_patients)} patients with sepsis onset <4h\")\n",
        "else:\n",
        "    print(\"⚠ Warning: SepsisLabel or ICULOS not found. Skipping early sepsis exclusion.\")\n",
        "\n",
        "n_patients_after = df['patient_id'].nunique()\n",
        "n_rows_after = len(df)\n",
        "print(f\"\\nPatients: {n_patients_before:,} → {n_patients_after:,} (excluded {n_patients_before - n_patients_after:,})\")\n",
        "print(f\"Rows: {n_rows_before:,} → {n_rows_after:,}\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 3: BUILD TIME INDEX & RESAMPLE TO HOURLY GRID\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 3: RESAMPLING TO HOURLY GRID\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Build synthetic time index using ICULOS\n",
        "df['charttime'] = pd.to_datetime('1970-01-01') + pd.to_timedelta(df['ICULOS'], unit='h')\n",
        "\n",
        "static_cols = [c for c, v in feature_intervals.items() if v is None and c in df.columns]\n",
        "\n",
        "parts = []\n",
        "for pid, g in df.groupby('patient_id'):\n",
        "    g = g.sort_values('charttime')\n",
        "    g_hour = g.set_index('charttime').resample('1H').last().reset_index()\n",
        "    g_hour['patient_id'] = pid\n",
        "\n",
        "    # Forward fill static features within patient\n",
        "    for s in static_cols:\n",
        "        if s in g.columns:\n",
        "            first_val = g[s].ffill().bfill().iloc[0] if not g[s].isna().all() else np.nan\n",
        "            g_hour[s] = first_val\n",
        "\n",
        "    parts.append(g_hour)\n",
        "\n",
        "df_hourly = pd.concat(parts, ignore_index=True, sort=False)\n",
        "\n",
        "# Recalculate ICULOS as sequential hour index\n",
        "df_hourly = df_hourly.sort_values(['patient_id', 'charttime'])\n",
        "df_hourly['ICULOS'] = df_hourly.groupby('patient_id').cumcount() + 1\n",
        "\n",
        "print(f\"✓ Resampled to hourly grid: {len(df_hourly):,} rows\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 4: TIME-LIMITED FORWARD FILL\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 4: APPLYING TIME-LIMITED FORWARD FILL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "df_filled = df_hourly.copy()\n",
        "for feat, hours in feature_intervals.items():\n",
        "    if feat not in df_filled.columns or hours is None:\n",
        "        continue\n",
        "    df_filled[feat] = df_filled.groupby('patient_id')[feat].transform(\n",
        "        lambda s: s.ffill(limit=hours)\n",
        "    )\n",
        "\n",
        "print(f\"✓ Applied forward fill: 4h for vitals, 24h for labs\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 5: COMPUTE DERIVED FEATURES\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 5: COMPUTING DERIVED FEATURES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ShockIndex = HR / SBP\n",
        "if {'HR', 'SBP'}.issubset(df_filled.columns):\n",
        "    df_filled['ShockIndex'] = df_filled['HR'] / df_filled['SBP'].replace({0: np.nan})\n",
        "    feature_intervals['ShockIndex'] = 4  # Derived from vitals\n",
        "    print(\"✓ Computed ShockIndex\")\n",
        "\n",
        "# BUN/Creatinine ratio\n",
        "if {'BUN', 'Creatinine'}.issubset(df_filled.columns):\n",
        "    df_filled['BUN_Cr'] = df_filled['BUN'] / df_filled['Creatinine'].replace({0: np.nan})\n",
        "    feature_intervals['BUN_Cr'] = 24  # Derived from labs\n",
        "    print(\"✓ Computed BUN_Cr\")\n",
        "\n",
        "# MEWS (Modified Early Warning Score)\n",
        "def compute_mews(df):\n",
        "    s = pd.Series(0, index=df.index, dtype=float)\n",
        "    if 'SBP' in df.columns:\n",
        "        s += np.select(\n",
        "            [df['SBP']<=70, (df['SBP']>70)&(df['SBP']<=80),\n",
        "             (df['SBP']>80)&(df['SBP']<=100), df['SBP']>=200],\n",
        "            [3, 2, 1, 2], default=0)\n",
        "    if 'HR' in df.columns:\n",
        "        s += np.select(\n",
        "            [df['HR']<=40, (df['HR']>40)&(df['HR']<=50),\n",
        "             (df['HR']>50)&(df['HR']<=100), (df['HR']>100)&(df['HR']<=110),\n",
        "             (df['HR']>110)&(df['HR']<=129), df['HR']>=130],\n",
        "            [2, 1, 0, 1, 2, 3], default=0)\n",
        "    if 'Resp' in df.columns:\n",
        "        s += np.select(\n",
        "            [df['Resp']<=8, (df['Resp']>8)&(df['Resp']<=14),\n",
        "             (df['Resp']>14)&(df['Resp']<=20), (df['Resp']>20)&(df['Resp']<=29),\n",
        "             df['Resp']>=30],\n",
        "            [2, 0, 1, 2, 3], default=0)\n",
        "    if 'Temp' in df.columns:\n",
        "        s += np.select(\n",
        "            [df['Temp']<=35, df['Temp']>=38.5],\n",
        "            [2, 1], default=0)\n",
        "    return s\n",
        "\n",
        "df_filled['MEWS'] = compute_mews(df_filled)\n",
        "feature_intervals['MEWS'] = 4  # Derived from vitals\n",
        "print(\"✓ Computed MEWS\")\n",
        "\n",
        "# pSOFA (simplified Sequential Organ Failure Assessment)\n",
        "def compute_psofa(df):\n",
        "    s = pd.Series(0, index=df.index, dtype=float)\n",
        "    if 'MAP' in df.columns:\n",
        "        s += np.where(df['MAP'] < 70, 1, 0)\n",
        "    if 'Platelets' in df.columns:\n",
        "        pl = df['Platelets']\n",
        "        s += np.select(\n",
        "            [pl<20, (pl>=20)&(pl<=49), (pl>=50)&(pl<=99), (pl>=100)&(pl<=149)],\n",
        "            [4, 3, 2, 1], default=0)\n",
        "    if 'Bilirubin_total' in df.columns:\n",
        "        b = df['Bilirubin_total']\n",
        "        s += np.select(\n",
        "            [b>=12, (b>=6)&(b<12), (b>=2)&(b<6), (b>=1.2)&(b<2)],\n",
        "            [4, 3, 2, 1], default=0)\n",
        "    return s\n",
        "\n",
        "df_filled['pSOFA'] = compute_psofa(df_filled)\n",
        "feature_intervals['pSOFA'] = 24  # Derived from labs\n",
        "print(\"✓ Computed pSOFA\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 6: SHIFT LABELS 6 HOURS EARLIER (FOR LOOKAHEAD)\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 6: SHIFTING LABELS 6 HOURS EARLIER\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if 'SepsisLabel' in df_filled.columns:\n",
        "    for pid, g in df_filled.groupby('patient_id'):\n",
        "        g_sorted = g.sort_values('ICULOS')\n",
        "        sepsis_hours = g_sorted[g_sorted['SepsisLabel'] == 1]['ICULOS']\n",
        "\n",
        "        if len(sepsis_hours) > 0:\n",
        "            first_onset_hour = sepsis_hours.iloc[0]\n",
        "            shift_start_hour = max(1, first_onset_hour - 6)\n",
        "\n",
        "            # Mark all hours from shift_start to onset as positive\n",
        "            mask = (df_filled['patient_id'] == pid) & \\\n",
        "                   (df_filled['ICULOS'] >= shift_start_hour) & \\\n",
        "                   (df_filled['ICULOS'] <= first_onset_hour)\n",
        "            df_filled.loc[mask, 'SepsisLabel'] = 1\n",
        "\n",
        "    print(\"✓ Label shift applied (6-hour lookahead)\")\n",
        "else:\n",
        "    print(\"⚠ Warning: SepsisLabel not found. Skipping label shift.\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 7: SPLIT PATIENTS INTO TRAIN/VAL/TEST\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 7: SPLITTING PATIENTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "patient_ids = df_filled['patient_id'].unique()\n",
        "\n",
        "# Baseline paper: 15% test, then 80/20 split of remaining (= 68/17/15 overall)\n",
        "train_val_ids, test_ids = train_test_split(\n",
        "    patient_ids, test_size=0.15, random_state=RANDOM_STATE\n",
        ")\n",
        "train_ids, val_ids = train_test_split(\n",
        "    train_val_ids, test_size=0.20, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "print(f\"Train: {len(train_ids):>5} patients ({len(train_ids)/len(patient_ids)*100:>5.1f}%)\")\n",
        "print(f\"Val:   {len(val_ids):>5} patients ({len(val_ids)/len(patient_ids)*100:>5.1f}%)\")\n",
        "print(f\"Test:  {len(test_ids):>5} patients ({len(test_ids)/len(patient_ids)*100:>5.1f}%)\")\n",
        "print(f\"Total: {len(patient_ids):>5} patients\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 8: COMPUTE IQR LIMITS (TRAINING DATA ONLY)\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 8: COMPUTING IQR NORMALIZATION LIMITS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def compute_iqr_limits(df, features, min_obs=10):\n",
        "    \"\"\"Compute IQR-based min/max limits for normalization.\"\"\"\n",
        "    limits = {}\n",
        "    for f in features:\n",
        "        if f not in df.columns:\n",
        "            continue\n",
        "        s = df[f].dropna()\n",
        "        if len(s) < min_obs:\n",
        "            continue\n",
        "        q1, q3 = s.quantile([0.25, 0.75])\n",
        "        iqr = q3 - q1\n",
        "        xmin = float(q1 - 1.5 * iqr)\n",
        "        xmax = float(q3 + 1.5 * iqr)\n",
        "        limits[f] = (xmin, xmax)\n",
        "    return limits\n",
        "\n",
        "# Get training data\n",
        "train_filled = df_filled[df_filled['patient_id'].isin(train_ids)].copy()\n",
        "\n",
        "# Features to normalize (exclude static demographics and ICULOS)\n",
        "features_for_iqr = [f for f, v in feature_intervals.items()\n",
        "                    if v is not None and f in df_filled.columns]\n",
        "derived_features = ['ShockIndex', 'BUN_Cr', 'MEWS', 'pSOFA']\n",
        "\n",
        "# Compute IQR limits on training data only\n",
        "iqr_limits = compute_iqr_limits(\n",
        "    train_filled,\n",
        "    features_for_iqr + derived_features\n",
        ")\n",
        "\n",
        "# Apply clinical sanity bounds\n",
        "print(\"\\nApplying clinical sanity bounds...\")\n",
        "for f, (xmin, xmax) in list(iqr_limits.items()):\n",
        "    if f in clinical_sanity:\n",
        "        cmin, cmax = clinical_sanity[f]\n",
        "        xmin = max(xmin, cmin)\n",
        "        xmax = min(xmax, cmax)\n",
        "        if xmin < xmax:\n",
        "            iqr_limits[f] = (float(xmin), float(xmax))\n",
        "        else:\n",
        "            print(f\"⚠ Warning: Clinical bounds for {f} resulted in inverted range\")\n",
        "\n",
        "# Save IQR limits\n",
        "with open(limits_json_path, 'w') as f:\n",
        "    json.dump(iqr_limits, f, indent=2)\n",
        "\n",
        "print(f\"✓ Computed IQR limits for {len(iqr_limits)} features\")\n",
        "print(f\"✓ Saved to: {limits_json_path}\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 9: NORMALIZE TO [1,5] RANGE, MISSING = -1\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 9: NORMALIZING FEATURES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Apply normalization: y = 4*(x-xmin)/(xmax-xmin) + 1 for x in [xmin,xmax]\n",
        "for f, (xmin, xmax) in iqr_limits.items():\n",
        "    if f not in df_filled.columns:\n",
        "        continue\n",
        "\n",
        "    mask = df_filled[f].notna()\n",
        "    denom = (xmax - xmin) if (xmax - xmin) > 0 else 1.0\n",
        "\n",
        "    # Clip to [xmin, xmax], then normalize to [1, 5]\n",
        "    df_filled.loc[mask, f] = df_filled.loc[mask, f].clip(lower=xmin, upper=xmax)\n",
        "    df_filled.loc[mask, f] = 4.0 * (df_filled.loc[mask, f] - xmin) / denom + 1.0\n",
        "\n",
        "# Impute remaining missing values with -1\n",
        "df_filled.fillna(-1, inplace=True)\n",
        "\n",
        "print(\"✓ Normalized features to [1,5] range\")\n",
        "print(\"✓ Imputed missing values with -1\")\n",
        "\n",
        "# Normalize demographics separately\n",
        "if 'Age' in df_filled.columns:\n",
        "    # Clip age to [0, 100] and normalize to [0, 1]\n",
        "    df_filled['Age'] = df_filled['Age'].replace(-1, np.nan)\n",
        "    df_filled['Age'] = df_filled['Age'].clip(0, 100) / 100.0\n",
        "    df_filled['Age'].fillna(-1, inplace=True)\n",
        "\n",
        "if 'Gender' in df_filled.columns:\n",
        "    # Gender should be 0 or 1 (or -1 if missing)\n",
        "    df_filled['Gender'] = df_filled['Gender'].replace(-1, np.nan)\n",
        "    df_filled['Gender'] = df_filled['Gender'].clip(0, 1)\n",
        "    df_filled['Gender'].fillna(-1, inplace=True)\n",
        "\n",
        "print(\"✓ Normalized demographics (Age, Gender)\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 10: CREATE FINAL SPLITS\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 10: CREATING FINAL SPLITS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "train_final = df_filled[df_filled['patient_id'].isin(train_ids)].copy()\n",
        "val_final   = df_filled[df_filled['patient_id'].isin(val_ids)].copy()\n",
        "test_final  = df_filled[df_filled['patient_id'].isin(test_ids)].copy()\n",
        "\n",
        "# Class distribution check\n",
        "def print_class_distribution(df, split_name):\n",
        "    if 'SepsisLabel' in df.columns:\n",
        "        n_pos = (df['SepsisLabel'] == 1).sum()\n",
        "        n_neg = (df['SepsisLabel'] == 0).sum()\n",
        "        total = n_pos + n_neg\n",
        "        prevalence = 100 * n_pos / total if total > 0 else 0\n",
        "        print(f\"{split_name:5s}: {len(df):>8,} rows, {n_pos:>6,} sepsis ({prevalence:>5.2f}%)\")\n",
        "\n",
        "print(\"\\nClass distribution:\")\n",
        "print_class_distribution(train_final, \"Train\")\n",
        "print_class_distribution(val_final, \"Val\")\n",
        "print_class_distribution(test_final, \"Test\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 11: SAVE OUTPUTS\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 11: SAVING OUTPUTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "train_final.to_csv(train_output_csv, index=False)\n",
        "val_final.to_csv(val_output_csv, index=False)\n",
        "test_final.to_csv(test_output_csv, index=False)\n",
        "df_filled.to_csv(full_output_csv, index=False)\n",
        "\n",
        "print(f\"✓ Train: {train_final.shape} → {train_output_csv}\")\n",
        "print(f\"✓ Val:   {val_final.shape} → {val_output_csv}\")\n",
        "print(f\"✓ Test:  {test_final.shape} → {test_output_csv}\")\n",
        "print(f\"✓ Full:  {df_filled.shape} → {full_output_csv}\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 12: SAVE METADATA\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 12: SAVING METADATA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "metadata = {\n",
        "    \"preprocessing_version\": \"v7_baseline_corrected\",\n",
        "    \"input_file\": input_path,\n",
        "    \"output_directory\": output_dir,\n",
        "    \"random_state\": RANDOM_STATE,\n",
        "\n",
        "    # Dataset splits\n",
        "    \"train_patients\": int(len(train_ids)),\n",
        "    \"val_patients\": int(len(val_ids)),\n",
        "    \"test_patients\": int(len(test_ids)),\n",
        "    \"total_patients\": int(len(patient_ids)),\n",
        "    \"split_ratio\": \"68% train / 17% val / 15% test\",\n",
        "\n",
        "    # Exclusion criteria\n",
        "    \"exclusion_criteria\": {\n",
        "        \"min_icu_hours\": 8,\n",
        "        \"min_sepsis_onset_hours\": 4\n",
        "    },\n",
        "\n",
        "    # Preprocessing steps\n",
        "    \"forward_fill_hours\": {\n",
        "        \"vitals\": 4,\n",
        "        \"labs\": 24\n",
        "    },\n",
        "    \"label_shift_hours\": 6,\n",
        "    \"label_shift_description\": \"Labels shifted 6 hours earlier for lookahead prediction\",\n",
        "\n",
        "    # Normalization\n",
        "    \"normalization_scheme\": \"IQR-based to [1,5] range\",\n",
        "    \"normalization_formula\": \"y = 4*(x-xmin)/(xmax-xmin) + 1\",\n",
        "    \"missing_value_encoding\": -1.0,\n",
        "    \"iqr_limits_computed_from\": \"training data only\",\n",
        "\n",
        "    # Model requirements\n",
        "    \"lstm_masking_required\": True,\n",
        "    \"lstm_mask_value\": -1.0,\n",
        "    \"masking_layer_config\": \"keras.layers.Masking(mask_value=-1.0)\",\n",
        "\n",
        "    # Features\n",
        "    \"n_base_features\": len(features_for_iqr),\n",
        "    \"n_derived_features\": len(derived_features),\n",
        "    \"derived_features\": derived_features,\n",
        "    \"total_normalized_features\": len(iqr_limits),\n",
        "\n",
        "    # Downstream windowing\n",
        "    \"recommended_window_length\": 12,\n",
        "    \"recommended_stride\": 1,\n",
        "    \"undersampling_stage\": \"post-windowing (patient-level)\",\n",
        "    \"undersampling_ratio\": \"1:1 (positive:negative)\",\n",
        "\n",
        "    # Notes\n",
        "    \"notes\": [\n",
        "        \"Preprocessing follows baseline paper methodology\",\n",
        "        \"No synthetic augmentation (Gaussian noise, temporal dropout)\",\n",
        "        \"ICULOS preserved for windowing but not used as model feature\",\n",
        "        \"Validation and test sets remain imbalanced (natural prevalence)\",\n",
        "        \"Training windows should be undersampled at patient level post-windowing\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "with open(metadata_json_path, 'w') as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "\n",
        "print(f\"✓ Saved metadata: {metadata_json_path}\")\n",
        "\n",
        "# ============================================================\n",
        "# SUMMARY\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PREPROCESSING COMPLETE ✓\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Output directory: {output_dir}\")\n",
        "print(f\"\\nFiles created:\")\n",
        "print(f\"  - {os.path.basename(train_output_csv)}\")\n",
        "print(f\"  - {os.path.basename(val_output_csv)}\")\n",
        "print(f\"  - {os.path.basename(test_output_csv)}\")\n",
        "print(f\"  - {os.path.basename(full_output_csv)}\")\n",
        "print(f\"  - {os.path.basename(limits_json_path)}\")\n",
        "print(f\"  - {os.path.basename(metadata_json_path)}\")\n",
        "\n",
        "print(f\"\\nNext steps:\")\n",
        "print(f\"  1. Create 12-hour windows (stride=1) for all splits\")\n",
        "print(f\"  2. Undersample training windows at patient level to 1:1\")\n",
        "print(f\"  3. Train LSTM with Masking(mask_value=-1.0)\")\n",
        "print(f\"  4. Use focal loss with alpha=0.25, gamma=2.0\")\n",
        "print(f\"  5. Early stopping on validation PR-AUC\")\n",
        "print(f\"  6. Calibrate probabilities on imbalanced validation set\")\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "id": "ASpqIYLbiF7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build matrices with 24 hr window"
      ],
      "metadata": {
        "id": "kNvqWZvo9l7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "============================================================\n",
        "Build Matrices v8 (24-Hour Windows)\n",
        "============================================================\n",
        "Generates 24-hour sliding windows for LSTM training\n",
        "using the preprocessed sepsis dataset (v8_baseline_corrected).\n",
        "\n",
        "Key features:\n",
        "- 24-hour window length (doubled from 12h), stride = 1 hour\n",
        "- Fixed feature list and order locked from training CSV\n",
        "- Per-patient sequential slicing with patient_id tracking\n",
        "- Label taken at window end (after 6h shift applied in preprocessing)\n",
        "- Optional: drops windows with >80% missing values (consistent across splits)\n",
        "- Saves end_iculos for debugging label shift alignment\n",
        "\n",
        "Inputs:\n",
        "  - sepsis_preprocessed_train_v8.csv\n",
        "  - sepsis_preprocessed_val_v8.csv\n",
        "  - sepsis_preprocessed_test_v8.csv\n",
        "\n",
        "Outputs:\n",
        "  - baseline_train_matrices_v8_24h.npz\n",
        "  - baseline_val_matrices_v8_24h.npz\n",
        "  - baseline_test_matrices_v8_24h.npz\n",
        "  - build_matrices_metadata_v8_24h.json\n",
        "\n",
        "Version: v8_build_matrices_24hour\n",
        "============================================================\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ============================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================\n",
        "input_dir = '/content/drive/MyDrive/AI_Course_Project/Dataset/Fix_Over_Fitting/Preprocessing_fix_overfitting_v7'\n",
        "output_dir = '/content/drive/MyDrive/AI_Course_Project/Dataset/Fix_Over_Fitting/Build_Matrices_v8_24h'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "train_csv = os.path.join(input_dir, 'sepsis_preprocessed_train_v7.csv')\n",
        "val_csv   = os.path.join(input_dir, 'sepsis_preprocessed_val_v7.csv')\n",
        "test_csv  = os.path.join(input_dir, 'sepsis_preprocessed_test_v7.csv')\n",
        "\n",
        "\n",
        "train_npz = os.path.join(output_dir, 'baseline_train_matrices_v8_24h.npz')\n",
        "val_npz   = os.path.join(output_dir, 'baseline_val_matrices_v8_24h.npz')\n",
        "test_npz  = os.path.join(output_dir, 'baseline_test_matrices_v8_24h.npz')\n",
        "metadata_json = os.path.join(output_dir, 'build_matrices_metadata_v8_24h.json')\n",
        "\n",
        "# Windowing parameters\n",
        "WINDOW_LENGTH = 24  # Changed from 12 to 24 hours\n",
        "STRIDE = 1          # hours between consecutive windows\n",
        "MISSING_THRESHOLD = 0.80  # Drop windows with >80% missing (-1 values)\n",
        "SEED = 42\n",
        "\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Columns to exclude from features (not model inputs)\n",
        "EXCLUDE_COLS = ['patient_id', 'ICULOS', 'charttime', 'SepsisLabel']\n",
        "\n",
        "# ============================================================\n",
        "# STEP 1: LOCK FEATURE LIST FROM TRAINING CSV\n",
        "# ============================================================\n",
        "print(\"=\"*60)\n",
        "print(\"STEP 1: LOCKING FEATURE LIST FROM TRAINING DATA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "df_train_sample = pd.read_csv(train_csv, nrows=1000)\n",
        "feature_cols = [c for c in df_train_sample.columns if c not in EXCLUDE_COLS]\n",
        "\n",
        "print(f\"✓ Locked {len(feature_cols)} features from training CSV\")\n",
        "print(f\"Feature list: {feature_cols[:5]}... (showing first 5)\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 2: BUILD MATRICES FUNCTION\n",
        "# ============================================================\n",
        "def build_matrices_from_csv(csv_path, split_name, feature_cols_fixed):\n",
        "    \"\"\"\n",
        "    Create (X, y, patient_ids, end_iculos) matrices from hourly CSV.\n",
        "\n",
        "    Args:\n",
        "        csv_path: Path to preprocessed CSV\n",
        "        split_name: \"TRAIN\", \"VAL\", or \"TEST\"\n",
        "        feature_cols_fixed: Ordered list of features (locked from train)\n",
        "\n",
        "    Returns:\n",
        "        X: (n_windows, window_length, n_features) array\n",
        "        y: (n_windows,) array of labels\n",
        "        patient_ids: (n_windows,) array of patient IDs\n",
        "        end_iculos: (n_windows,) array of ICULOS at window end\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Building {split_name} matrices from {os.path.basename(csv_path)}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(f\"✓ Loaded {len(df):,} rows, {df['patient_id'].nunique()} patients\")\n",
        "\n",
        "    # Ensure ALL required features exist; if missing in this split, create as -1\n",
        "    missing_features = []\n",
        "    for f in feature_cols_fixed:\n",
        "        if f not in df.columns:\n",
        "            df[f] = -1.0  # Consistent with preprocessing missing encoding\n",
        "            missing_features.append(f)\n",
        "\n",
        "    if missing_features:\n",
        "        print(f\"⚠ Warning: {len(missing_features)} features missing in {split_name}, \"\n",
        "              f\"filled with -1: {missing_features[:3]}...\")\n",
        "\n",
        "    # Restrict to required columns in fixed order\n",
        "    required_cols = ['patient_id', 'ICULOS', 'SepsisLabel'] + feature_cols_fixed\n",
        "    df = df[required_cols]\n",
        "\n",
        "    X_list, y_list, pid_list, end_hour_list = [], [], [], []\n",
        "    skipped_short = 0\n",
        "\n",
        "    for pid, g in df.groupby('patient_id'):\n",
        "        g = g.sort_values('ICULOS').reset_index(drop=True)\n",
        "\n",
        "        # Extract arrays\n",
        "        values = g[feature_cols_fixed].to_numpy(dtype=np.float32)\n",
        "        labels = g['SepsisLabel'].to_numpy(dtype=np.float32)\n",
        "        iculos = g['ICULOS'].to_numpy(dtype=np.int32)\n",
        "\n",
        "        n = len(g)\n",
        "        if n < WINDOW_LENGTH:\n",
        "            skipped_short += 1\n",
        "            continue  # Skip patients with < window_length hours\n",
        "\n",
        "        # Create sliding windows with stride\n",
        "        for start in range(0, n - WINDOW_LENGTH + 1, STRIDE):\n",
        "            end = start + WINDOW_LENGTH\n",
        "\n",
        "            window_x = values[start:end]  # (24, n_features)\n",
        "            window_y = labels[end - 1]    # Label at window end (after 6h shift upstream)\n",
        "            end_hour = int(iculos[end - 1])  # ICULOS at window end\n",
        "\n",
        "            X_list.append(window_x)\n",
        "            y_list.append(window_y)\n",
        "            pid_list.append(pid)\n",
        "            end_hour_list.append(end_hour)\n",
        "\n",
        "    X = np.asarray(X_list, dtype=np.float32)\n",
        "    y = np.asarray(y_list, dtype=np.float32)\n",
        "    pids = np.asarray(pid_list)\n",
        "    end_hours = np.asarray(end_hour_list, dtype=np.int32)\n",
        "\n",
        "    n_pos = int(y.sum())\n",
        "    n_total = len(y)\n",
        "    prevalence = 100 * y.mean()\n",
        "\n",
        "    print(f\"\\n{'─'*60}\")\n",
        "    print(f\"Windows created: {n_total:,}\")\n",
        "    print(f\"  Positive windows: {n_pos:,} ({prevalence:.2f}%)\")\n",
        "    print(f\"  Negative windows: {n_total - n_pos:,}\")\n",
        "    print(f\"  Unique patients: {len(np.unique(pids))}\")\n",
        "    print(f\"  Shape: {X.shape}\")\n",
        "    if skipped_short > 0:\n",
        "        print(f\"  Skipped {skipped_short} patients with <{WINDOW_LENGTH}h data\")\n",
        "    print(f\"{'─'*60}\")\n",
        "\n",
        "    return X, y, pids, end_hours\n",
        "\n",
        "# ============================================================\n",
        "# STEP 3: BUILD MATRICES FOR ALL SPLITS\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 3: BUILDING MATRICES FOR ALL SPLITS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "X_train, y_train, pid_train, endh_train = build_matrices_from_csv(\n",
        "    train_csv, \"TRAIN\", feature_cols\n",
        ")\n",
        "X_val, y_val, pid_val, endh_val = build_matrices_from_csv(\n",
        "    val_csv, \"VAL\", feature_cols\n",
        ")\n",
        "X_test, y_test, pid_test, endh_test = build_matrices_from_csv(\n",
        "    test_csv, \"TEST\", feature_cols\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 4: OPTIONAL - DROP WINDOWS WITH >80% MISSING\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 4: FILTERING WINDOWS WITH >80% MISSING VALUES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def filter_missing_windows(X, y, pids, end_hours, threshold=0.80):\n",
        "    \"\"\"\n",
        "    Drop windows where >threshold fraction of values are -1 (missing).\n",
        "    Applied consistently across train/val/test to maintain distribution.\n",
        "    \"\"\"\n",
        "    not_missing = (X != -1.0).astype(np.float32)\n",
        "    present_fraction = not_missing.mean(axis=(1, 2))  # Mean across (time, features)\n",
        "    keep_mask = present_fraction >= (1.0 - threshold)\n",
        "\n",
        "    n_before = len(X)\n",
        "    n_dropped = (~keep_mask).sum()\n",
        "\n",
        "    X_filtered = X[keep_mask]\n",
        "    y_filtered = y[keep_mask]\n",
        "    pids_filtered = pids[keep_mask]\n",
        "    end_hours_filtered = end_hours[keep_mask]\n",
        "\n",
        "    print(f\"  Dropped {n_dropped:,} / {n_before:,} windows \"\n",
        "          f\"({100*n_dropped/n_before:.2f}%) with >{threshold*100:.0f}% missing\")\n",
        "    print(f\"  Remaining: {len(X_filtered):,} windows\")\n",
        "\n",
        "    return X_filtered, y_filtered, pids_filtered, end_hours_filtered\n",
        "\n",
        "X_train, y_train, pid_train, endh_train = filter_missing_windows(\n",
        "    X_train, y_train, pid_train, endh_train, MISSING_THRESHOLD\n",
        ")\n",
        "X_val, y_val, pid_val, endh_val = filter_missing_windows(\n",
        "    X_val, y_val, pid_val, endh_val, MISSING_THRESHOLD\n",
        ")\n",
        "X_test, y_test, pid_test, endh_test = filter_missing_windows(\n",
        "    X_test, y_test, pid_test, endh_test, MISSING_THRESHOLD\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 5: FINAL STATISTICS\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 5: FINAL STATISTICS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def print_split_stats(X, y, pids, split_name):\n",
        "    n_pos = int(y.sum())\n",
        "    n_neg = len(y) - n_pos\n",
        "    prevalence = 100 * y.mean()\n",
        "    n_patients = len(np.unique(pids))\n",
        "\n",
        "    print(f\"\\n{split_name}:\")\n",
        "    print(f\"  Windows: {len(y):,} ({X.shape})\")\n",
        "    print(f\"  Patients: {n_patients}\")\n",
        "    print(f\"  Positive: {n_pos:,} ({prevalence:.2f}%)\")\n",
        "    print(f\"  Negative: {n_neg:,} ({100-prevalence:.2f}%)\")\n",
        "\n",
        "print_split_stats(X_train, y_train, pid_train, \"TRAIN\")\n",
        "print_split_stats(X_val, y_val, pid_val, \"VAL\")\n",
        "print_split_stats(X_test, y_test, pid_test, \"TEST\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 6: SAVE OUTPUTS\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 6: SAVING OUTPUTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "np.savez_compressed(\n",
        "    train_npz,\n",
        "    X=X_train,\n",
        "    y=y_train,\n",
        "    patient_ids=pid_train,\n",
        "    end_iculos=endh_train,\n",
        "    feature_names=np.array(feature_cols, dtype=object)\n",
        ")\n",
        "\n",
        "np.savez_compressed(\n",
        "    val_npz,\n",
        "    X=X_val,\n",
        "    y=y_val,\n",
        "    patient_ids=pid_val,\n",
        "    end_iculos=endh_val,\n",
        "    feature_names=np.array(feature_cols, dtype=object)\n",
        ")\n",
        "\n",
        "np.savez_compressed(\n",
        "    test_npz,\n",
        "    X=X_test,\n",
        "    y=y_test,\n",
        "    patient_ids=pid_test,\n",
        "    end_iculos=endh_test,\n",
        "    feature_names=np.array(feature_cols, dtype=object)\n",
        ")\n",
        "\n",
        "print(f\"✓ Saved TRAIN → {train_npz}\")\n",
        "print(f\"✓ Saved VAL   → {val_npz}\")\n",
        "print(f\"✓ Saved TEST  → {test_npz}\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 7: SAVE METADATA\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 7: SAVING METADATA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "metadata = {\n",
        "    \"build_matrices_version\": \"v8_24hour\",\n",
        "    \"input_preprocessing\": \"v8_baseline_corrected\",\n",
        "    \"window_length\": WINDOW_LENGTH,\n",
        "    \"stride\": STRIDE,\n",
        "    \"missing_threshold\": MISSING_THRESHOLD,\n",
        "    \"random_seed\": SEED,\n",
        "    \"feature_count\": len(feature_cols),\n",
        "    \"feature_list\": feature_cols,\n",
        "    \"statistics\": {\n",
        "        \"train\": {\n",
        "            \"n_windows\": int(len(y_train)),\n",
        "            \"n_patients\": int(len(np.unique(pid_train))),\n",
        "            \"n_positive\": int(y_train.sum()),\n",
        "            \"prevalence\": float(y_train.mean())\n",
        "        },\n",
        "        \"val\": {\n",
        "            \"n_windows\": int(len(y_val)),\n",
        "            \"n_patients\": int(len(np.unique(pid_val))),\n",
        "            \"n_positive\": int(y_val.sum()),\n",
        "            \"prevalence\": float(y_val.mean())\n",
        "        },\n",
        "        \"test\": {\n",
        "            \"n_windows\": int(len(y_test)),\n",
        "            \"n_patients\": int(len(np.unique(pid_test))),\n",
        "            \"n_positive\": int(y_test.sum()),\n",
        "            \"prevalence\": float(y_test.mean())\n",
        "        }\n",
        "    },\n",
        "    \"notes\": [\n",
        "        \"Window length increased from 12h to 24h for deeper pre-onset context\",\n",
        "        \"Stride=1 used for all splits to maintain distribution consistency\",\n",
        "        \"Feature list and order locked from training CSV\",\n",
        "        \"Windows with >80% missing values dropped consistently across all splits\",\n",
        "        \"Label taken at window end (after 6h shift applied in preprocessing)\",\n",
        "        \"end_iculos saved for debugging label shift alignment\",\n",
        "        \"Validation and test sets remain imbalanced (natural prevalence)\",\n",
        "        \"Next step: Train model with input shape (24, 43) instead of (12, 43)\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "with open(metadata_json, 'w') as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "\n",
        "print(f\"✓ Saved metadata → {metadata_json}\")\n",
        "\n",
        "# ============================================================\n",
        "# SUMMARY\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BUILD MATRICES v8 (24-HOUR) COMPLETE ✓\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nOutput directory: {output_dir}\")\n",
        "print(f\"\\nFiles created:\")\n",
        "print(f\"  - {os.path.basename(train_npz)}\")\n",
        "print(f\"  - {os.path.basename(val_npz)}\")\n",
        "print(f\"  - {os.path.basename(test_npz)}\")\n",
        "print(f\"  - {os.path.basename(metadata_json)}\")\n",
        "\n",
        "print(f\"\\nDataset summary:\")\n",
        "print(f\"  TRAIN: {X_train.shape[0]:>8,} windows | {len(np.unique(pid_train)):>5} patients | shape {X_train.shape}\")\n",
        "print(f\"  VAL:   {X_val.shape[0]:>8,} windows | {len(np.unique(pid_val)):>5} patients | shape {X_val.shape}\")\n",
        "print(f\"  TEST:  {X_test.shape[0]:>8,} windows | {len(np.unique(pid_test)):>5} patients | shape {X_test.shape}\")\n",
        "\n",
        "print(f\"\\nComparison to 12-hour version:\")\n",
        "print(f\"  Expected: ~2x fewer windows (longer context, same stride)\")\n",
        "print(f\"  Expected prevalence: same (~2.8-3.1%)\")\n",
        "\n",
        "print(f\"\\nNext steps:\")\n",
        "print(f\"  1. Update model input shape from (12, 43) to (24, 43)\")\n",
        "print(f\"  2. Retrain LSTM with focal α=0.80, γ=0.8\")\n",
        "print(f\"  3. Recalibrate isotonic regression on imbalanced validation\")\n",
        "print(f\"  4. Re-run alert system grid search with same parameters\")\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QQDixrRRQb-",
        "outputId": "3690ca3d-d36b-4b48-d9e0-eca71322cc84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "STEP 1: LOCKING FEATURE LIST FROM TRAINING DATA\n",
            "============================================================\n",
            "✓ Locked 43 features from training CSV\n",
            "Feature list: ['HR', 'O2Sat', 'Temp', 'SBP', 'MAP']... (showing first 5)\n",
            "\n",
            "============================================================\n",
            "STEP 3: BUILDING MATRICES FOR ALL SPLITS\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Building TRAIN matrices from sepsis_preprocessed_train_v7.csv\n",
            "============================================================\n",
            "✓ Loaded 1,052,708 rows, 27064 patients\n",
            "\n",
            "────────────────────────────────────────────────────────────\n",
            "Windows created: 459,752\n",
            "  Positive windows: 16,994 (3.70%)\n",
            "  Negative windows: 442,758\n",
            "  Unique patients: 20895\n",
            "  Shape: (459752, 24, 43)\n",
            "  Skipped 6169 patients with <24h data\n",
            "────────────────────────────────────────────────────────────\n",
            "\n",
            "============================================================\n",
            "Building VAL matrices from sepsis_preprocessed_val_v7.csv\n",
            "============================================================\n",
            "✓ Loaded 263,730 rows, 6766 patients\n",
            "\n",
            "────────────────────────────────────────────────────────────\n",
            "Windows created: 115,658\n",
            "  Positive windows: 4,362 (3.77%)\n",
            "  Negative windows: 111,296\n",
            "  Unique patients: 5183\n",
            "  Shape: (115658, 24, 43)\n",
            "  Skipped 1583 patients with <24h data\n",
            "────────────────────────────────────────────────────────────\n",
            "\n",
            "============================================================\n",
            "Building TEST matrices from sepsis_preprocessed_test_v7.csv\n",
            "============================================================\n",
            "✓ Loaded 230,757 rows, 5971 patients\n",
            "\n",
            "────────────────────────────────────────────────────────────\n",
            "Windows created: 99,880\n",
            "  Positive windows: 4,192 (4.20%)\n",
            "  Negative windows: 95,688\n",
            "  Unique patients: 4579\n",
            "  Shape: (99880, 24, 43)\n",
            "  Skipped 1392 patients with <24h data\n",
            "────────────────────────────────────────────────────────────\n",
            "\n",
            "============================================================\n",
            "STEP 4: FILTERING WINDOWS WITH >80% MISSING VALUES\n",
            "============================================================\n",
            "  Dropped 59 / 459,752 windows (0.01%) with >80% missing\n",
            "  Remaining: 459,693 windows\n",
            "  Dropped 36 / 115,658 windows (0.03%) with >80% missing\n",
            "  Remaining: 115,622 windows\n",
            "  Dropped 7 / 99,880 windows (0.01%) with >80% missing\n",
            "  Remaining: 99,873 windows\n",
            "\n",
            "============================================================\n",
            "STEP 5: FINAL STATISTICS\n",
            "============================================================\n",
            "\n",
            "TRAIN:\n",
            "  Windows: 459,693 ((459693, 24, 43))\n",
            "  Patients: 20893\n",
            "  Positive: 16,994 (3.70%)\n",
            "  Negative: 442,699 (96.30%)\n",
            "\n",
            "VAL:\n",
            "  Windows: 115,622 ((115622, 24, 43))\n",
            "  Patients: 5182\n",
            "  Positive: 4,362 (3.77%)\n",
            "  Negative: 111,260 (96.23%)\n",
            "\n",
            "TEST:\n",
            "  Windows: 99,873 ((99873, 24, 43))\n",
            "  Patients: 4579\n",
            "  Positive: 4,192 (4.20%)\n",
            "  Negative: 95,681 (95.80%)\n",
            "\n",
            "============================================================\n",
            "STEP 6: SAVING OUTPUTS\n",
            "============================================================\n",
            "✓ Saved TRAIN → /content/drive/MyDrive/AI_Fin/Fix_Over_Fitting/Build_Matrices_v8_24h/baseline_train_matrices_v8_24h.npz\n",
            "✓ Saved VAL   → /content/drive/MyDrive/AI_Fin/Fix_Over_Fitting/Build_Matrices_v8_24h/baseline_val_matrices_v8_24h.npz\n",
            "✓ Saved TEST  → /content/drive/MyDrive/AI_Fin/Fix_Over_Fitting/Build_Matrices_v8_24h/baseline_test_matrices_v8_24h.npz\n",
            "\n",
            "============================================================\n",
            "STEP 7: SAVING METADATA\n",
            "============================================================\n",
            "✓ Saved metadata → /content/drive/MyDrive/AI_Fin/Fix_Over_Fitting/Build_Matrices_v8_24h/build_matrices_metadata_v8_24h.json\n",
            "\n",
            "============================================================\n",
            "BUILD MATRICES v8 (24-HOUR) COMPLETE ✓\n",
            "============================================================\n",
            "\n",
            "Output directory: /content/drive/MyDrive/AI_Fin/Fix_Over_Fitting/Build_Matrices_v8_24h\n",
            "\n",
            "Files created:\n",
            "  - baseline_train_matrices_v8_24h.npz\n",
            "  - baseline_val_matrices_v8_24h.npz\n",
            "  - baseline_test_matrices_v8_24h.npz\n",
            "  - build_matrices_metadata_v8_24h.json\n",
            "\n",
            "Dataset summary:\n",
            "  TRAIN:  459,693 windows | 20893 patients | shape (459693, 24, 43)\n",
            "  VAL:    115,622 windows |  5182 patients | shape (115622, 24, 43)\n",
            "  TEST:    99,873 windows |  4579 patients | shape (99873, 24, 43)\n",
            "\n",
            "Comparison to 12-hour version:\n",
            "  Expected: ~2x fewer windows (longer context, same stride)\n",
            "  Expected prevalence: same (~2.8-3.1%)\n",
            "\n",
            "Next steps:\n",
            "  1. Update model input shape from (12, 43) to (24, 43)\n",
            "  2. Retrain LSTM with focal α=0.80, γ=0.8\n",
            "  3. Recalibrate isotonic regression on imbalanced validation\n",
            "  4. Re-run alert system grid search with same parameters\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Undersampling for 24hr Window"
      ],
      "metadata": {
        "id": "a_0uJyaX9v0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "============================================================\n",
        "Undersampling (v8, Patient-Level)\n",
        "============================================================\n",
        "Creates 1:1 balanced training data by undersampling negative\n",
        "patients (not windows) to match positive patient count.\n",
        "\n",
        "Key features:\n",
        "- Patient-level undersampling (prevents leakage)\n",
        "- ALL windows from selected patients retained\n",
        "- Shuffle windows across patients for decorrelation\n",
        "- Validation and test remain imbalanced (natural prevalence)\n",
        "- Saves patient IDs for reproducibility\n",
        "\n",
        "Inputs:\n",
        "  - baseline_train_matrices_v7.npz (imbalanced)\n",
        "\n",
        "Outputs:\n",
        "  - undersampled_train_matrices_v7.npz (1:1 balanced)\n",
        "  - undersampling_metadata_v7.json\n",
        "\n",
        "Version: v7_undersampling_patient_level\n",
        "============================================================\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# ============================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================\n",
        "input_dir = '/content/drive/MyDrive/AI_Course_Project/Dataset/Fix_Over_Fitting/Build_Matrices_v8_24h'\n",
        "output_dir = '/content/drive/MyDrive/AI_Course_Project/Dataset/Fix_Over_Fitting/Undersampling_v8_24h'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "train_npz = os.path.join(input_dir, 'baseline_train_matrices_v8_24h.npz')\n",
        "undersampled_npz = os.path.join(output_dir, 'undersampled_train_matrices_v8_24h.npz')\n",
        "metadata_json = os.path.join(output_dir, 'undersampling_metadata_v8_24h.json')\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# ============================================================\n",
        "# STEP 1: LOAD IMBALANCED TRAINING DATA\n",
        "# ============================================================\n",
        "print(\"=\"*60)\n",
        "print(\"STEP 1: LOADING IMBALANCED TRAINING DATA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "data = np.load(train_npz, allow_pickle=True)\n",
        "X_full = data['X']\n",
        "y_full = data['y']\n",
        "pid_full = data['patient_ids']\n",
        "\n",
        "print(f\"✓ Loaded training data:\")\n",
        "print(f\"  Windows: {len(y_full):,}\")\n",
        "print(f\"  Shape: {X_full.shape}\")\n",
        "print(f\"  Positive: {int(y_full.sum()):,} ({100*y_full.mean():.2f}%)\")\n",
        "print(f\"  Negative: {int((y_full==0).sum()):,} ({100*(1-y_full.mean()):.2f}%)\")\n",
        "print(f\"  Unique patients: {len(np.unique(pid_full)):,}\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 2: IDENTIFY POSITIVE AND NEGATIVE PATIENTS\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 2: PATIENT-LEVEL ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get unique patient IDs with at least one positive window\n",
        "pos_patients = np.unique(pid_full[y_full == 1])\n",
        "neg_patients = np.unique(pid_full[y_full == 0])\n",
        "\n",
        "print(f\"✓ Identified patient groups:\")\n",
        "print(f\"  Positive patients (≥1 sepsis window): {len(pos_patients):,}\")\n",
        "print(f\"  Negative patients (all non-sepsis):   {len(neg_patients):,}\")\n",
        "print(f\"  Total: {len(pos_patients) + len(neg_patients):,}\")\n",
        "\n",
        "# Calculate windows per patient group\n",
        "pos_windows_total = (y_full[np.isin(pid_full, pos_patients)] == 1).sum()\n",
        "pos_windows_count = len(pid_full[np.isin(pid_full, pos_patients)])\n",
        "neg_windows_count = len(pid_full[np.isin(pid_full, neg_patients)])\n",
        "\n",
        "print(f\"\\nWindow distribution:\")\n",
        "print(f\"  Positive patient windows: {pos_windows_count:,} \"\n",
        "      f\"({pos_windows_total:,} sepsis, {pos_windows_count - pos_windows_total:,} non-sepsis)\")\n",
        "print(f\"  Negative patient windows: {neg_windows_count:,}\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 3: UNDERSAMPLE NEGATIVE PATIENTS TO MATCH POSITIVE\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 3: UNDERSAMPLING NEGATIVE PATIENTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Randomly sample negative patients to match positive patient count\n",
        "np.random.seed(SEED)\n",
        "neg_patients_sampled = np.random.choice(\n",
        "    neg_patients,\n",
        "    size=len(pos_patients),\n",
        "    replace=False\n",
        ")\n",
        "\n",
        "print(f\"✓ Sampled {len(neg_patients_sampled):,} negative patients \"\n",
        "      f\"(from {len(neg_patients):,} available)\")\n",
        "print(f\"  Sampling ratio: {100*len(neg_patients_sampled)/len(neg_patients):.2f}%\")\n",
        "\n",
        "# Combine selected patients\n",
        "selected_patients = np.concatenate([pos_patients, neg_patients_sampled])\n",
        "print(f\"✓ Total selected patients: {len(selected_patients):,} \"\n",
        "      f\"(1:1 ratio = {len(pos_patients)}:{len(neg_patients_sampled)})\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 4: EXTRACT ALL WINDOWS FROM SELECTED PATIENTS\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 4: EXTRACTING WINDOWS FROM SELECTED PATIENTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create mask for windows belonging to selected patients\n",
        "mask = np.isin(pid_full, selected_patients)\n",
        "\n",
        "X_undersampled = X_full[mask]\n",
        "y_undersampled = y_full[mask]\n",
        "pid_undersampled = pid_full[mask]\n",
        "\n",
        "n_pos = int(y_undersampled.sum())\n",
        "n_neg = int((y_undersampled == 0).sum())\n",
        "n_total = len(y_undersampled)\n",
        "prevalence = 100 * y_undersampled.mean()\n",
        "\n",
        "print(f\"✓ Extracted windows:\")\n",
        "print(f\"  Total: {n_total:,} windows\")\n",
        "print(f\"  Positive: {n_pos:,} ({prevalence:.2f}%)\")\n",
        "print(f\"  Negative: {n_neg:,} ({100-prevalence:.2f}%)\")\n",
        "print(f\"  Shape: {X_undersampled.shape}\")\n",
        "print(f\"  Unique patients: {len(np.unique(pid_undersampled)):,}\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 5: SHUFFLE WINDOWS ACROSS PATIENTS\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 5: SHUFFLING WINDOWS ACROSS PATIENTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Shuffle to decorrelate batches (preserves within-window temporal order)\n",
        "shuffle_indices = np.arange(len(X_undersampled))\n",
        "np.random.seed(SEED)\n",
        "np.random.shuffle(shuffle_indices)\n",
        "\n",
        "X_shuffled = X_undersampled[shuffle_indices]\n",
        "y_shuffled = y_undersampled[shuffle_indices]\n",
        "pid_shuffled = pid_undersampled[shuffle_indices]\n",
        "\n",
        "print(f\"✓ Shuffled {len(X_shuffled):,} windows across patients\")\n",
        "print(f\"  (Within-window temporal order preserved)\")\n",
        "\n",
        "# Verify shuffle didn't change class distribution\n",
        "print(f\"\\nVerification:\")\n",
        "print(f\"  Positive: {int(y_shuffled.sum()):,} ({100*y_shuffled.mean():.2f}%)\")\n",
        "print(f\"  Negative: {int((y_shuffled==0).sum()):,} ({100*(1-y_shuffled.mean()):.2f}%)\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 6: SAVE UNDERSAMPLED DATASET\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 6: SAVING UNDERSAMPLED DATASET\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "np.savez_compressed(\n",
        "    undersampled_npz,\n",
        "    X=X_shuffled,\n",
        "    y=y_shuffled,\n",
        "    patient_ids=pid_shuffled,\n",
        "    selected_pos_patients=pos_patients,\n",
        "    selected_neg_patients=neg_patients_sampled,\n",
        "    feature_names=data['feature_names']\n",
        ")\n",
        "\n",
        "print(f\"✓ Saved undersampled training data → {undersampled_npz}\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 7: SAVE METADATA\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 7: SAVING METADATA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "metadata = {\n",
        "    \"undersampling_version\": \"v7_patient_level\",\n",
        "    \"random_seed\": SEED,\n",
        "    \"method\": \"patient-level undersampling\",\n",
        "    \"description\": \"Negative patients randomly sampled to match positive patient count\",\n",
        "\n",
        "    \"original_data\": {\n",
        "        \"n_windows\": int(len(y_full)),\n",
        "        \"n_positive_windows\": int(y_full.sum()),\n",
        "        \"n_negative_windows\": int((y_full==0).sum()),\n",
        "        \"prevalence\": float(y_full.mean()),\n",
        "        \"n_patients\": int(len(np.unique(pid_full))),\n",
        "        \"n_positive_patients\": int(len(pos_patients)),\n",
        "        \"n_negative_patients\": int(len(neg_patients))\n",
        "    },\n",
        "\n",
        "    \"undersampled_data\": {\n",
        "        \"n_windows\": int(len(y_shuffled)),\n",
        "        \"n_positive_windows\": int(y_shuffled.sum()),\n",
        "        \"n_negative_windows\": int((y_shuffled==0).sum()),\n",
        "        \"prevalence\": float(y_shuffled.mean()),\n",
        "        \"n_patients\": int(len(selected_patients)),\n",
        "        \"n_positive_patients\": int(len(pos_patients)),\n",
        "        \"n_negative_patients\": int(len(neg_patients_sampled)),\n",
        "        \"patient_ratio\": \"1:1\"\n",
        "    },\n",
        "\n",
        "    \"reduction\": {\n",
        "        \"windows_kept_pct\": float(100 * len(y_shuffled) / len(y_full)),\n",
        "        \"negative_patients_kept_pct\": float(100 * len(neg_patients_sampled) / len(neg_patients))\n",
        "    },\n",
        "\n",
        "    \"notes\": [\n",
        "        \"Patient-level undersampling prevents data leakage\",\n",
        "        \"ALL windows from selected patients are retained\",\n",
        "        \"Windows shuffled across patients (not within-patient)\",\n",
        "        \"Validation and test sets remain imbalanced\",\n",
        "        \"Next: train LSTM with Masking(mask_value=-1.0) and focal loss\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "with open(metadata_json, 'w') as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "\n",
        "print(f\"✓ Saved metadata → {metadata_json}\")\n",
        "\n",
        "# ============================================================\n",
        "# SUMMARY\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"UNDERSAMPLING COMPLETE ✓\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nOutput directory: {output_dir}\")\n",
        "print(f\"\\nFiles created:\")\n",
        "print(f\"  - {os.path.basename(undersampled_npz)}\")\n",
        "print(f\"  - {os.path.basename(metadata_json)}\")\n",
        "\n",
        "print(f\"\\nDataset comparison:\")\n",
        "print(f\"{'':20s} {'Original':>15s} {'Undersampled':>15s} {'Change':>10s}\")\n",
        "print(f\"{'-'*60}\")\n",
        "print(f\"{'Windows':20s} {len(y_full):>15,} {len(y_shuffled):>15,} \"\n",
        "      f\"{100*len(y_shuffled)/len(y_full):>9.1f}%\")\n",
        "print(f\"{'Positive windows':20s} {int(y_full.sum()):>15,} {int(y_shuffled.sum()):>15,} \"\n",
        "      f\"{100*y_shuffled.sum()/y_full.sum():>9.1f}%\")\n",
        "print(f\"{'Negative windows':20s} {int((y_full==0).sum()):>15,} {int((y_shuffled==0).sum()):>15,} \"\n",
        "      f\"{100*(y_shuffled==0).sum()/(y_full==0).sum():>9.1f}%\")\n",
        "print(f\"{'Patients':20s} {len(np.unique(pid_full)):>15,} {len(selected_patients):>15,} \"\n",
        "      f\"{100*len(selected_patients)/len(np.unique(pid_full)):>9.1f}%\")\n",
        "print(f\"{'Prevalence':20s} {y_full.mean()*100:>14.2f}% {y_shuffled.mean()*100:>14.2f}% \"\n",
        "      f\"{(y_shuffled.mean()-y_full.mean())*100:>+9.2f}%\")\n",
        "\n",
        "print(f\"\\nNext steps:\")\n",
        "print(f\"  1. Train LSTM with Masking(mask_value=-1.0)\")\n",
        "print(f\"  2. Use focal loss (alpha=0.25, gamma=2.0)\")\n",
        "print(f\"  3. Early stopping on validation PR-AUC (imbalanced)\")\n",
        "print(f\"  4. Enable shuffle=True in model.fit() for epoch-level shuffling\")\n",
        "print(f\"  5. Calibrate probabilities on imbalanced validation set\")\n",
        "print(f\"  6. Evaluate on held-out imbalanced test set\")\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xwsl90CQTgZG",
        "outputId": "a43f2f55-fb0b-472b-8138-c5cb630d9533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "STEP 1: LOADING IMBALANCED TRAINING DATA\n",
            "============================================================\n",
            "✓ Loaded training data:\n",
            "  Windows: 459,693\n",
            "  Shape: (459693, 24, 43)\n",
            "  Positive: 16,994 (3.70%)\n",
            "  Negative: 442,699 (96.30%)\n",
            "  Unique patients: 20,893\n",
            "\n",
            "============================================================\n",
            "STEP 2: PATIENT-LEVEL ANALYSIS\n",
            "============================================================\n",
            "✓ Identified patient groups:\n",
            "  Positive patients (≥1 sepsis window): 1,238\n",
            "  Negative patients (all non-sepsis):   20,605\n",
            "  Total: 21,843\n",
            "\n",
            "Window distribution:\n",
            "  Positive patient windows: 78,206 (16,994 sepsis, 61,212 non-sepsis)\n",
            "  Negative patient windows: 457,553\n",
            "\n",
            "============================================================\n",
            "STEP 3: UNDERSAMPLING NEGATIVE PATIENTS\n",
            "============================================================\n",
            "✓ Sampled 1,238 negative patients (from 20,605 available)\n",
            "  Sampling ratio: 6.01%\n",
            "✓ Total selected patients: 2,476 (1:1 ratio = 1238:1238)\n",
            "\n",
            "============================================================\n",
            "STEP 4: EXTRACTING WINDOWS FROM SELECTED PATIENTS\n",
            "============================================================\n",
            "✓ Extracted windows:\n",
            "  Total: 100,602 windows\n",
            "  Positive: 16,994 (16.89%)\n",
            "  Negative: 83,608 (83.11%)\n",
            "  Shape: (100602, 24, 43)\n",
            "  Unique patients: 2,431\n",
            "\n",
            "============================================================\n",
            "STEP 5: SHUFFLING WINDOWS ACROSS PATIENTS\n",
            "============================================================\n",
            "✓ Shuffled 100,602 windows across patients\n",
            "  (Within-window temporal order preserved)\n",
            "\n",
            "Verification:\n",
            "  Positive: 16,994 (16.89%)\n",
            "  Negative: 83,608 (83.11%)\n",
            "\n",
            "============================================================\n",
            "STEP 6: SAVING UNDERSAMPLED DATASET\n",
            "============================================================\n",
            "✓ Saved undersampled training data → /content/drive/MyDrive/AI_Fin/Fix_Over_Fitting/Undersampling_v8_24h/undersampled_train_matrices_v8_24h.npz\n",
            "\n",
            "============================================================\n",
            "STEP 7: SAVING METADATA\n",
            "============================================================\n",
            "✓ Saved metadata → /content/drive/MyDrive/AI_Fin/Fix_Over_Fitting/Undersampling_v8_24h/undersampling_metadata_v8_24h.json\n",
            "\n",
            "============================================================\n",
            "UNDERSAMPLING COMPLETE ✓\n",
            "============================================================\n",
            "\n",
            "Output directory: /content/drive/MyDrive/AI_Fin/Fix_Over_Fitting/Undersampling_v8_24h\n",
            "\n",
            "Files created:\n",
            "  - undersampled_train_matrices_v8_24h.npz\n",
            "  - undersampling_metadata_v8_24h.json\n",
            "\n",
            "Dataset comparison:\n",
            "                            Original    Undersampled     Change\n",
            "------------------------------------------------------------\n",
            "Windows                      459,693         100,602      21.9%\n",
            "Positive windows              16,994          16,994     100.0%\n",
            "Negative windows             442,699          83,608      18.9%\n",
            "Patients                      20,893           2,476      11.9%\n",
            "Prevalence                     3.70%          16.89%    +13.20%\n",
            "\n",
            "Next steps:\n",
            "  1. Train LSTM with Masking(mask_value=-1.0)\n",
            "  2. Use focal loss (alpha=0.25, gamma=2.0)\n",
            "  3. Early stopping on validation PR-AUC (imbalanced)\n",
            "  4. Enable shuffle=True in model.fit() for epoch-level shuffling\n",
            "  5. Calibrate probabilities on imbalanced validation set\n",
            "  6. Evaluate on held-out imbalanced test set\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Models"
      ],
      "metadata": {
        "id": "B775BptLwZNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "============================================================\n",
        "Ensemble Training & Calibration (v8 Ensemble - 3 Models)\n",
        "WITH OPTIMIZATIONS:\n",
        "✅ Cleaner α/γ config iteration\n",
        "✅ Save calibrated predictions per-model\n",
        "✅ Add F1 to results_json\n",
        "✅ Save ensemble predictions for alert phase\n",
        "============================================================\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, auc, precision_recall_curve, confusion_matrix,\n",
        "    f1_score, roc_curve\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================\n",
        "DATA_DIR = '/content/drive/MyDrive/AI_Course_Project/Dataset/Fix_Over_Fitting/Build_Matrices_v8_24h'\n",
        "UNDERSAMPLE_DIR = '/content/drive/MyDrive/AI_Course_Project/Dataset/Fix_Over_Fitting/Undersampling_v8_24h'\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/AI_Course_Project/Dataset/Fix_Over_Fitting/Ensemble_LSTM_v8'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Paths\n",
        "train_npz = os.path.join(UNDERSAMPLE_DIR, 'undersampled_train_matrices_v8_24h.npz')\n",
        "val_npz = os.path.join(DATA_DIR, 'baseline_val_matrices_v8_24h.npz')\n",
        "test_npz = os.path.join(DATA_DIR, 'baseline_test_matrices_v8_24h.npz')\n",
        "\n",
        "# OPTIMIZATION 1: Cleaner α/γ config iteration\n",
        "ENSEMBLE_CONFIGS = [\n",
        "    dict(alpha=a, gamma=0.8, seed=42+i, name=f\"a{int(a*100)}\")\n",
        "    for i, a in enumerate([0.75, 0.8, 0.85])\n",
        "]\n",
        "\n",
        "# Hyperparameters (same as v8 single model)\n",
        "LSTM_UNITS = 128\n",
        "LSTM_DROPOUT = 0.3\n",
        "RECURRENT_DROPOUT = 0.2\n",
        "L2_WEIGHT = 1e-4\n",
        "DENSE_DROPOUT = 0.3\n",
        "LEARNING_RATE = 1e-3\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 100\n",
        "EARLY_STOP_PATIENCE = 10\n",
        "REDUCE_LR_PATIENCE = 3\n",
        "WARMUP_EPOCHS = 3\n",
        "USE_BCE_WARMUP = True\n",
        "\n",
        "# ============================================================\n",
        "# STEP 1: LOAD DATA (ONCE)\n",
        "# ============================================================\n",
        "print(\"=\"*60)\n",
        "print(\"STEP 1: LOADING DATA (SHARED)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "data_train = np.load(train_npz, allow_pickle=True)\n",
        "X_train = data_train['X']\n",
        "y_train = data_train['y']\n",
        "\n",
        "data_val = np.load(val_npz, allow_pickle=True)\n",
        "X_val = data_val['X']\n",
        "y_val = data_val['y']\n",
        "\n",
        "data_test = np.load(test_npz, allow_pickle=True)\n",
        "X_test = data_test['X']\n",
        "y_test = data_test['y']\n",
        "\n",
        "print(f\"✓ TRAIN: {X_train.shape}, {int(y_train.sum())} positive ({100*y_train.mean():.2f}%)\")\n",
        "print(f\"✓ VAL:   {X_val.shape}, {int(y_val.sum())} positive ({100*y_val.mean():.2f}%)\")\n",
        "print(f\"✓ TEST:  {X_test.shape}, {int(y_test.sum())} positive ({100*y_test.mean():.2f}%)\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 2: FOCAL LOSS\n",
        "# ============================================================\n",
        "def focal_loss(alpha=0.25, gamma=2.0):\n",
        "    def loss(y_true, y_pred):\n",
        "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
        "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
        "        alpha_t = tf.where(tf.equal(y_true, 1), alpha, 1 - alpha)\n",
        "        focal_weight = alpha_t * tf.pow(1 - pt, gamma)\n",
        "        loss_val = -focal_weight * tf.math.log(pt)\n",
        "        return tf.reduce_mean(loss_val)\n",
        "    return loss\n",
        "\n",
        "# ============================================================\n",
        "# STEP 3: BUILD MODEL FUNCTION\n",
        "# ============================================================\n",
        "def build_lstm_with_attention(input_shape, units=128, dropout=0.3,\n",
        "                              recurrent_dropout=0.2, l2_weight=1e-4,\n",
        "                              lr=1e-3):\n",
        "    \"\"\"Build LSTM with Reshape-based attention.\"\"\"\n",
        "\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = layers.Masking(mask_value=-1.0)(inputs)\n",
        "\n",
        "    # First LSTM\n",
        "    x = layers.LSTM(units, return_sequences=True,\n",
        "                   dropout=dropout, recurrent_dropout=recurrent_dropout,\n",
        "                   kernel_regularizer=regularizers.l2(l2_weight),\n",
        "                   recurrent_regularizer=regularizers.l2(l2_weight),\n",
        "                   name='lstm_1')(x)\n",
        "    x = layers.BatchNormalization(name='bn_1')(x)\n",
        "\n",
        "    # Second LSTM (keep sequences for attention)\n",
        "    x = layers.LSTM(units, return_sequences=True,\n",
        "                   dropout=dropout, recurrent_dropout=recurrent_dropout,\n",
        "                   kernel_regularizer=regularizers.l2(l2_weight),\n",
        "                   recurrent_regularizer=regularizers.l2(l2_weight),\n",
        "                   name='lstm_2')(x)\n",
        "    x = layers.BatchNormalization(name='bn_2')(x)\n",
        "\n",
        "    # Temporal attention with Reshape workaround\n",
        "    attn_score = layers.Dense(1, activation='tanh', name='attn_score')(x)  # (batch, time, 1)\n",
        "    attn_score_flat = layers.Reshape((-1,), name='attn_score_flat')(attn_score)\n",
        "    attn_weights_flat = layers.Softmax(axis=1, name='attn_weights')(attn_score_flat)\n",
        "    attn_weights = layers.Reshape((-1, 1), name='attn_weights_reshaped')(attn_weights_flat)\n",
        "\n",
        "    context = layers.Multiply(name='attn_multiply')([x, attn_weights])\n",
        "    context = layers.Lambda(lambda z: tf.reduce_sum(z, axis=1), name='context')(context)\n",
        "\n",
        "    # Dense layers\n",
        "    x = layers.Dense(64, activation='relu',\n",
        "                    kernel_regularizer=regularizers.l2(l2_weight),\n",
        "                    name='dense_1')(context)\n",
        "    x = layers.BatchNormalization(name='bn_3')(x)\n",
        "    x = layers.Dropout(0.5, name='dropout_1')(x)\n",
        "    outputs = layers.Dense(1, activation='sigmoid', dtype='float32', name='output')(x)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=[keras.metrics.AUC(name='roc_auc'),\n",
        "                          keras.metrics.AUC(curve='PR', name='pr_auc'),\n",
        "                          keras.metrics.Precision(name='precision'),\n",
        "                          keras.metrics.Recall(name='recall')])\n",
        "    return model\n",
        "\n",
        "# ============================================================\n",
        "# STEP 4: TRAIN 3 MODELS\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 4: TRAINING 3 ENSEMBLE MODELS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "models = {}\n",
        "calibrators = {}\n",
        "predictions_val = {}\n",
        "predictions_test = {}\n",
        "results_comparison = {}\n",
        "\n",
        "for config in ENSEMBLE_CONFIGS:\n",
        "    alpha = config['alpha']\n",
        "    gamma = config['gamma']\n",
        "    seed = config['seed']\n",
        "    name = config['name']\n",
        "\n",
        "    print(f\"\\n{'─'*60}\")\n",
        "    print(f\"Training model {name}: α={alpha}, γ={gamma}, seed={seed}\")\n",
        "    print(f\"{'─'*60}\")\n",
        "\n",
        "    # Set seed\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "    # Build model\n",
        "    model = build_lstm_with_attention(\n",
        "        input_shape=(X_train.shape[1], X_train.shape[2]),\n",
        "        units=LSTM_UNITS,\n",
        "        dropout=LSTM_DROPOUT,\n",
        "        recurrent_dropout=RECURRENT_DROPOUT,\n",
        "        l2_weight=L2_WEIGHT,\n",
        "        lr=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    # Callbacks\n",
        "    model_path = os.path.join(OUTPUT_DIR, f'trained_lstm_model_v8_ensemble_{name}.keras')\n",
        "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "        model_path, monitor='val_pr_auc', save_best_only=True, mode='max', verbose=0\n",
        "    )\n",
        "    early_stop = keras.callbacks.EarlyStopping(\n",
        "        monitor='val_pr_auc', patience=EARLY_STOP_PATIENCE,\n",
        "        restore_best_weights=True, mode='max', verbose=0\n",
        "    )\n",
        "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_pr_auc', factor=0.5, patience=REDUCE_LR_PATIENCE,\n",
        "        mode='max', min_lr=1e-6, verbose=0\n",
        "    )\n",
        "\n",
        "    # Phase A: BCE warmup\n",
        "    if USE_BCE_WARMUP:\n",
        "        print(f\"  Phase A: BCE warmup ({WARMUP_EPOCHS} epochs)\")\n",
        "        model.compile(\n",
        "            optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=[keras.metrics.AUC(name='roc_auc'),\n",
        "                    keras.metrics.AUC(curve='PR', name='pr_auc'),\n",
        "                    keras.metrics.Precision(name='precision'),\n",
        "                    keras.metrics.Recall(name='recall')]\n",
        "        )\n",
        "        hist = model.fit(\n",
        "            X_train, y_train,\n",
        "            validation_data=(X_val, y_val),\n",
        "            batch_size=BATCH_SIZE,\n",
        "            epochs=WARMUP_EPOCHS,\n",
        "            callbacks=[reduce_lr],\n",
        "            shuffle=True,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "    # Phase B: Focal loss training\n",
        "    print(f\"  Phase B: Focal loss training (α={alpha}, γ={gamma})\")\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "        loss=focal_loss(alpha=alpha, gamma=gamma),\n",
        "        metrics=[keras.metrics.AUC(name='roc_auc'),\n",
        "                keras.metrics.AUC(curve='PR', name='pr_auc'),\n",
        "                keras.metrics.Precision(name='precision'),\n",
        "                keras.metrics.Recall(name='recall')]\n",
        "    )\n",
        "    hist2 = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=[checkpoint, early_stop, reduce_lr],\n",
        "        shuffle=True,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    print(f\"  ✓ Training complete (best val PR-AUC: {max(hist2.history['val_pr_auc']):.4f})\")\n",
        "\n",
        "    # Generate predictions\n",
        "    y_val_pred_raw = model.predict(X_val, verbose=0).flatten()\n",
        "    y_test_pred_raw = model.predict(X_test, verbose=0).flatten()\n",
        "\n",
        "    # Calibrate individually\n",
        "    iso_reg = IsotonicRegression(out_of_bounds='clip')\n",
        "    iso_reg.fit(y_val_pred_raw, y_val)\n",
        "\n",
        "    y_val_pred_cal = iso_reg.predict(y_val_pred_raw)\n",
        "    y_test_pred_cal = iso_reg.predict(y_test_pred_raw)\n",
        "\n",
        "    predictions_val[name] = y_val_pred_cal\n",
        "    predictions_test[name] = y_test_pred_cal\n",
        "\n",
        "    # OPTIMIZATION 2: Save calibrated predictions per-model\n",
        "    np.save(os.path.join(OUTPUT_DIR, f'y_val_pred_cal_{name}.npy'), y_val_pred_cal)\n",
        "    np.save(os.path.join(OUTPUT_DIR, f'y_test_pred_cal_{name}.npy'), y_test_pred_cal)\n",
        "    print(f\"  ✓ Saved predictions: y_val_pred_cal_{name}.npy, y_test_pred_cal_{name}.npy\")\n",
        "\n",
        "    # Compute metrics\n",
        "    roc_auc_val = roc_auc_score(y_val, y_val_pred_cal)\n",
        "    prec_val, rec_val, _ = precision_recall_curve(y_val, y_val_pred_cal)\n",
        "    pr_auc_val = auc(rec_val, prec_val)\n",
        "\n",
        "    roc_auc_test = roc_auc_score(y_test, y_test_pred_cal)\n",
        "    prec_test, rec_test, _ = precision_recall_curve(y_test, y_test_pred_cal)\n",
        "    pr_auc_test = auc(rec_test, prec_test)\n",
        "\n",
        "    results_comparison[f\"individual_{name}\"] = {\n",
        "        \"val_roc_auc\": float(roc_auc_val),\n",
        "        \"val_pr_auc\": float(pr_auc_val),\n",
        "        \"test_roc_auc\": float(roc_auc_test),\n",
        "        \"test_pr_auc\": float(pr_auc_test)\n",
        "    }\n",
        "\n",
        "    print(f\"  ✓ VAL:  ROC-AUC={roc_auc_val:.4f}, PR-AUC={pr_auc_val:.4f}\")\n",
        "    print(f\"  ✓ TEST: ROC-AUC={roc_auc_test:.4f}, PR-AUC={pr_auc_test:.4f}\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 5: ENSEMBLE AVERAGING\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 5: ENSEMBLE AVERAGING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "y_val_pred_ensemble = np.mean([\n",
        "    predictions_val['a75'],\n",
        "    predictions_val['a80'],\n",
        "    predictions_val['a85']\n",
        "], axis=0)\n",
        "\n",
        "y_test_pred_ensemble = np.mean([\n",
        "    predictions_test['a75'],\n",
        "    predictions_test['a80'],\n",
        "    predictions_test['a85']\n",
        "], axis=0)\n",
        "\n",
        "print(f\"✓ Averaged VAL: mean={y_val_pred_ensemble.mean():.4f}, min={y_val_pred_ensemble.min():.4f}, max={y_val_pred_ensemble.max():.4f}\")\n",
        "print(f\"✓ Averaged TEST: mean={y_test_pred_ensemble.mean():.4f}, min={y_test_pred_ensemble.min():.4f}, max={y_test_pred_ensemble.max():.4f}\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 6: RE-CALIBRATE ENSEMBLE\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 6: RE-CALIBRATE ENSEMBLE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "iso_reg_ensemble = IsotonicRegression(out_of_bounds='clip')\n",
        "iso_reg_ensemble.fit(y_val_pred_ensemble, y_val)\n",
        "\n",
        "y_val_pred_ens_cal = iso_reg_ensemble.predict(y_val_pred_ensemble)\n",
        "y_test_pred_ens_cal = iso_reg_ensemble.predict(y_test_pred_ensemble)\n",
        "\n",
        "print(f\"✓ Ensemble calibrated VAL mean:  {y_val_pred_ens_cal.mean():.4f} | prevalence: {y_val.mean():.4f}\")\n",
        "print(f\"✓ Ensemble calibrated TEST mean: {y_test_pred_ens_cal.mean():.4f} | prevalence: {y_test.mean():.4f}\")\n",
        "\n",
        "calibrator_path = os.path.join(OUTPUT_DIR, 'isotonic_calibrator_v8_ensemble.pkl')\n",
        "with open(calibrator_path, 'wb') as f:\n",
        "    pickle.dump(iso_reg_ensemble, f)\n",
        "print(f\"✓ Saved calibrator → {calibrator_path}\")\n",
        "\n",
        "# OPTIMIZATION 4: Save ensemble predictions for alert phase\n",
        "np.save(os.path.join(OUTPUT_DIR, 'y_val_pred_ensemble_cal.npy'), y_val_pred_ens_cal)\n",
        "np.save(os.path.join(OUTPUT_DIR, 'y_test_pred_ensemble_cal.npy'), y_test_pred_ens_cal)\n",
        "print(f\"✓ Saved ensemble predictions: y_val_pred_ensemble_cal.npy, y_test_pred_ensemble_cal.npy\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 7: EVALUATION\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 7: EVALUATION (ENSEMBLE vs INDIVIDUAL MODELS)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Ensemble performance\n",
        "roc_auc_val_ens = roc_auc_score(y_val, y_val_pred_ens_cal)\n",
        "prec_val_ens, rec_val_ens, _ = precision_recall_curve(y_val, y_val_pred_ens_cal)\n",
        "pr_auc_val_ens = auc(rec_val_ens, prec_val_ens)\n",
        "\n",
        "roc_auc_test_ens = roc_auc_score(y_test, y_test_pred_ens_cal)\n",
        "prec_test_ens, rec_test_ens, _ = precision_recall_curve(y_test, y_test_pred_ens_cal)\n",
        "pr_auc_test_ens = auc(rec_test_ens, prec_test_ens)\n",
        "\n",
        "# OPTIMIZATION 3: Best-F1 threshold and save to results\n",
        "thresholds = np.linspace(0.01, 0.99, 99)\n",
        "f1_scores = [f1_score(y_val, y_val_pred_ens_cal > t) for t in thresholds]\n",
        "best_threshold = thresholds[np.nanargmax(f1_scores)]\n",
        "best_f1 = np.nanmax(f1_scores)\n",
        "\n",
        "y_val_bin = (y_val_pred_ens_cal > best_threshold).astype(int)\n",
        "tn_v, fp_v, fn_v, tp_v = confusion_matrix(y_val, y_val_bin).ravel()\n",
        "\n",
        "sensitivity_val = tp_v / (tp_v + fn_v)\n",
        "specificity_val = tn_v / (tn_v + fp_v)\n",
        "precision_val = tp_v / (tp_v + fp_v)\n",
        "far_val = 100 * fp_v / (fp_v + tn_v)\n",
        "\n",
        "print(f\"\\n🎯 Ensemble (averaged + re-calibrated):\")\n",
        "print(f\"  VAL:  ROC-AUC={roc_auc_val_ens:.4f}, PR-AUC={pr_auc_val_ens:.4f}\")\n",
        "print(f\"  TEST: ROC-AUC={roc_auc_test_ens:.4f}, PR-AUC={pr_auc_test_ens:.4f}\")\n",
        "print(f\"\\nBest-F1 on ensemble (val):\")\n",
        "print(f\"  Threshold: {best_threshold:.3f}, F1: {best_f1:.4f}\")\n",
        "print(f\"  Sensitivity: {sensitivity_val*100:.2f}%, Specificity: {specificity_val*100:.2f}%\")\n",
        "print(f\"  Precision: {precision_val*100:.2f}%, FAR: {far_val:.2f}%\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 8: SAVE RESULTS\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 8: SAVING RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results_json = {\n",
        "    \"ensemble_config\": {\n",
        "        \"n_models\": 3,\n",
        "        \"alpha_values\": [0.75, 0.80, 0.85],\n",
        "        \"gamma\": 0.8,\n",
        "        \"seeds\": [42, 43, 44],\n",
        "        \"aggregation\": \"mean\"\n",
        "    },\n",
        "    \"individual_models\": results_comparison,\n",
        "    \"ensemble_val_metrics\": {\n",
        "        \"roc_auc\": float(roc_auc_val_ens),\n",
        "        \"pr_auc\": float(pr_auc_val_ens),\n",
        "        \"best_threshold\": float(best_threshold),\n",
        "        \"best_f1\": float(best_f1),  # OPTIMIZATION 3\n",
        "        \"sensitivity\": float(sensitivity_val),\n",
        "        \"specificity\": float(specificity_val),\n",
        "        \"precision\": float(precision_val),\n",
        "        \"far\": float(far_val)\n",
        "    },\n",
        "    \"ensemble_test_metrics\": {\n",
        "        \"roc_auc\": float(roc_auc_test_ens),\n",
        "        \"pr_auc\": float(pr_auc_test_ens)\n",
        "    }\n",
        "}\n",
        "\n",
        "results_path = os.path.join(OUTPUT_DIR, 'ensemble_eval_results_v8.json')\n",
        "with open(results_path, 'w') as f:\n",
        "    json.dump(results_json, f, indent=2)\n",
        "print(f\"✓ Saved results → {results_path}\")\n",
        "\n",
        "# ============================================================\n",
        "# SUMMARY\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ENSEMBLE TRAINING COMPLETE ✓\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\n✅ Ensemble optimizations applied:\")\n",
        "print(f\"  ✓ Cleaner α/γ config iteration\")\n",
        "print(f\"  ✓ Saved calibrated predictions per-model (for meta-classifier)\")\n",
        "print(f\"  ✓ Added F1 to results_json\")\n",
        "print(f\"  ✓ Saved ensemble predictions (for alert system)\")\n",
        "\n",
        "print(f\"\\n📊 Individual models:\")\n",
        "for name in ['a75', 'a80', 'a85']:\n",
        "    print(f\"  {name}: TEST PR-AUC={results_comparison[f'individual_{name}']['test_pr_auc']:.4f}\")\n",
        "\n",
        "print(f\"\\n🎯 Ensemble (TEST): PR-AUC={pr_auc_test_ens:.4f}\")\n",
        "\n",
        "print(f\"\\n📁 Files saved:\")\n",
        "print(f\"  - trained_lstm_model_v8_ensemble_a75/80/85.keras\")\n",
        "print(f\"  - y_val_pred_cal_a75/80/85.npy (for meta-classifier)\")\n",
        "print(f\"  - y_test_pred_cal_a75/80/85.npy (for meta-classifier)\")\n",
        "print(f\"  - y_val_pred_ensemble_cal.npy (for alert system)\")\n",
        "print(f\"  - y_test_pred_ensemble_cal.npy (for alert system)\")\n",
        "print(f\"  - isotonic_calibrator_v8_ensemble.pkl\")\n",
        "print(f\"  - ensemble_eval_results_v8.json\")\n",
        "\n",
        "print(f\"\\n📈 Next steps:\")\n",
        "print(f\"  1. Alert system: use y_val/test_pred_ensemble_cal.npy\")\n",
        "print(f\"  2. Meta-classifier: use y_val/test_pred_cal_a*.npy as features\")\n",
        "\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OL5eVgrnwh6i",
        "outputId": "85462455-d36e-43c0-f5a1-3ce087dc83c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "STEP 1: LOADING DATA (SHARED)\n",
            "============================================================\n",
            "✓ TRAIN: (100602, 24, 43), 16994 positive (16.89%)\n",
            "✓ VAL:   (115622, 24, 43), 4362 positive (3.77%)\n",
            "✓ TEST:  (99873, 24, 43), 4192 positive (4.20%)\n",
            "\n",
            "============================================================\n",
            "STEP 4: TRAINING 3 ENSEMBLE MODELS\n",
            "============================================================\n",
            "\n",
            "────────────────────────────────────────────────────────────\n",
            "Training model a75: α=0.75, γ=0.8, seed=42\n",
            "────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:965: UserWarning: Layer 'attn_score_flat' (of type Reshape) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Phase A: BCE warmup (3 epochs)\n",
            "  Phase B: Focal loss training (α=0.75, γ=0.8)\n",
            "  ✓ Training complete (best val PR-AUC: 0.0791)\n",
            "  ✓ Saved predictions: y_val_pred_cal_a75.npy, y_test_pred_cal_a75.npy\n",
            "  ✓ VAL:  ROC-AUC=0.6994, PR-AUC=0.0876\n",
            "  ✓ TEST: ROC-AUC=0.6904, PR-AUC=0.0887\n",
            "\n",
            "────────────────────────────────────────────────────────────\n",
            "Training model a80: α=0.8, γ=0.8, seed=43\n",
            "────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:965: UserWarning: Layer 'attn_score_flat' (of type Reshape) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Phase A: BCE warmup (3 epochs)\n",
            "  Phase B: Focal loss training (α=0.8, γ=0.8)\n",
            "  ✓ Training complete (best val PR-AUC: 0.0866)\n",
            "  ✓ Saved predictions: y_val_pred_cal_a80.npy, y_test_pred_cal_a80.npy\n",
            "  ✓ VAL:  ROC-AUC=0.7207, PR-AUC=0.0937\n",
            "  ✓ TEST: ROC-AUC=0.7194, PR-AUC=0.0910\n",
            "\n",
            "────────────────────────────────────────────────────────────\n",
            "Training model a85: α=0.85, γ=0.8, seed=44\n",
            "────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:965: UserWarning: Layer 'attn_score_flat' (of type Reshape) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Phase A: BCE warmup (3 epochs)\n",
            "  Phase B: Focal loss training (α=0.85, γ=0.8)\n",
            "  ✓ Training complete (best val PR-AUC: 0.0814)\n",
            "  ✓ Saved predictions: y_val_pred_cal_a85.npy, y_test_pred_cal_a85.npy\n",
            "  ✓ VAL:  ROC-AUC=0.7236, PR-AUC=0.1034\n",
            "  ✓ TEST: ROC-AUC=0.7140, PR-AUC=0.1082\n",
            "\n",
            "============================================================\n",
            "STEP 5: ENSEMBLE AVERAGING\n",
            "============================================================\n",
            "✓ Averaged VAL: mean=0.0377, min=0.0000, max=0.2409\n",
            "✓ Averaged TEST: mean=0.0380, min=0.0000, max=0.2177\n",
            "\n",
            "============================================================\n",
            "STEP 6: RE-CALIBRATE ENSEMBLE\n",
            "============================================================\n",
            "✓ Ensemble calibrated VAL mean:  0.0377 | prevalence: 0.0377\n",
            "✓ Ensemble calibrated TEST mean: 0.0380 | prevalence: 0.0420\n",
            "✓ Saved calibrator → /content/drive/MyDrive/AI_Fin/Fix_Over_Fitting/Ensemble_LSTM_v8/isotonic_calibrator_v8_ensemble.pkl\n",
            "✓ Saved ensemble predictions: y_val_pred_ensemble_cal.npy, y_test_pred_ensemble_cal.npy\n",
            "\n",
            "============================================================\n",
            "STEP 7: EVALUATION (ENSEMBLE vs INDIVIDUAL MODELS)\n",
            "============================================================\n",
            "\n",
            "🎯 Ensemble (averaged + re-calibrated):\n",
            "  VAL:  ROC-AUC=0.7330, PR-AUC=0.1048\n",
            "  TEST: ROC-AUC=0.7175, PR-AUC=0.0906\n",
            "\n",
            "Best-F1 on ensemble (val):\n",
            "  Threshold: 0.070, F1: 0.1532\n",
            "  Sensitivity: 46.54%, Specificity: 81.93%\n",
            "  Precision: 9.17%, FAR: 18.07%\n",
            "\n",
            "============================================================\n",
            "STEP 8: SAVING RESULTS\n",
            "============================================================\n",
            "✓ Saved results → /content/drive/MyDrive/AI_Fin/Fix_Over_Fitting/Ensemble_LSTM_v8/ensemble_eval_results_v8.json\n",
            "\n",
            "============================================================\n",
            "ENSEMBLE TRAINING COMPLETE ✓\n",
            "============================================================\n",
            "\n",
            "✅ Ensemble optimizations applied:\n",
            "  ✓ Cleaner α/γ config iteration\n",
            "  ✓ Saved calibrated predictions per-model (for meta-classifier)\n",
            "  ✓ Added F1 to results_json\n",
            "  ✓ Saved ensemble predictions (for alert system)\n",
            "\n",
            "📊 Individual models:\n",
            "  a75: TEST PR-AUC=0.0887\n",
            "  a80: TEST PR-AUC=0.0910\n",
            "  a85: TEST PR-AUC=0.1082\n",
            "\n",
            "🎯 Ensemble (TEST): PR-AUC=0.0906\n",
            "\n",
            "📁 Files saved:\n",
            "  - trained_lstm_model_v8_ensemble_a75/80/85.keras\n",
            "  - y_val_pred_cal_a75/80/85.npy (for meta-classifier)\n",
            "  - y_test_pred_cal_a75/80/85.npy (for meta-classifier)\n",
            "  - y_val_pred_ensemble_cal.npy (for alert system)\n",
            "  - y_test_pred_ensemble_cal.npy (for alert system)\n",
            "  - isotonic_calibrator_v8_ensemble.pkl\n",
            "  - ensemble_eval_results_v8.json\n",
            "\n",
            "📈 Next steps:\n",
            "  1. Alert system: use y_val/test_pred_ensemble_cal.npy\n",
            "  2. Meta-classifier: use y_val/test_pred_cal_a*.npy as features\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "============================================================\n",
        "Alert System v8 Ensemble (Optimized with Tweaks)\n",
        "============================================================\n",
        "Implements patient-level alert system using v8 ensemble predictions:\n",
        "✅ Uses pre-computed ensemble calibrated predictions\n",
        "✅ Fine-grained threshold sweep (0.02–0.20)\n",
        "✅ Alert rule grid search (x ∈ {2,3,4}, w ∈ {4,5,6})\n",
        "✅ Temporal EMA smoothing\n",
        "✅ Patient-level probability aggregation (mean of top-3)\n",
        "✅ Ensemble rule fusion (OR/AND logic)\n",
        "✅ Comprehensive grid search & visualization\n",
        "\n",
        "Inputs:\n",
        "  - y_val_pred_ensemble_cal.npy (from ensemble training)\n",
        "  - y_test_pred_ensemble_cal.npy (from ensemble training)\n",
        "  - baseline_val_matrices_v8_24h.npz (for patient IDs, labels)\n",
        "  - baseline_test_matrices_v8_24h.npz (for patient IDs, labels)\n",
        "\n",
        "Outputs:\n",
        "  - alert_grid_search_results_v8_ensemble.csv\n",
        "  - best_alert_configs_v8_ensemble.json\n",
        "  - alert_system_optimization_v8_ensemble.png\n",
        "  - final_test_evaluation_v8_ensemble.json\n",
        "\n",
        "Version: v8_alert_system_ensemble\n",
        "============================================================\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, auc, precision_recall_curve, confusion_matrix, roc_curve\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================\n",
        "ENSEMBLE_DIR = '/content/drive/MyDrive/AI_Course_Project/Dataset/Fix_Over_Fitting/Ensemble_LSTM_v8'\n",
        "DATA_DIR = '/content/drive/MyDrive/AI_Course_Project/Dataset/Fix_Over_Fitting/Build_Matrices_v8_24h'\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/AI_Course_Project/Dataset/Fix_Over_Fitting/Alert_System_v8_Ensemble'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Input paths (pre-computed ensemble predictions)\n",
        "val_pred_path = os.path.join(ENSEMBLE_DIR, 'y_val_pred_ensemble_cal.npy')\n",
        "test_pred_path = os.path.join(ENSEMBLE_DIR, 'y_test_pred_ensemble_cal.npy')\n",
        "val_npz = os.path.join(DATA_DIR, 'baseline_val_matrices_v8_24h.npz')\n",
        "test_npz = os.path.join(DATA_DIR, 'baseline_test_matrices_v8_24h.npz')\n",
        "\n",
        "# Output paths\n",
        "grid_results_csv = os.path.join(OUTPUT_DIR, 'alert_grid_search_results_v8_ensemble.csv')\n",
        "best_configs_json = os.path.join(OUTPUT_DIR, 'best_alert_configs_v8_ensemble.json')\n",
        "opt_plot_path = os.path.join(OUTPUT_DIR, 'alert_system_optimization_v8_ensemble.png')\n",
        "final_test_json = os.path.join(OUTPUT_DIR, 'final_test_evaluation_v8_ensemble.json')\n",
        "\n",
        "# Grid search parameters\n",
        "FINE_THRESHOLDS = np.linspace(0.02, 0.20, 10)\n",
        "X_WARNINGS_LIST = [2, 3, 4]\n",
        "W_HOURS_LIST = [4, 5, 6]\n",
        "\n",
        "# EMA smoothing\n",
        "USE_EMA = True\n",
        "EMA_ALPHA = 0.3\n",
        "\n",
        "# Probability aggregation method\n",
        "AGG_METHOD = 'mean_top_3'  # 'max' or 'mean_top_3' or 'rolling_mean_6h'\n",
        "\n",
        "# Rule fusion configurations to test\n",
        "ENSEMBLE_RULES = [\n",
        "    {'name': 'baseline_3_5', 'x': 3, 'w': 5, 'high_risk_threshold': None, 'op': None},\n",
        "    {'name': '3_warnings_or_high_risk', 'x': 3, 'w': 5, 'high_risk_threshold': 0.20, 'op': 'OR'},\n",
        "    {'name': '2_warnings_4h_or_high_risk', 'x': 2, 'w': 4, 'high_risk_threshold': 0.20, 'op': 'OR'},\n",
        "]\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# ============================================================\n",
        "# STEP 1: LOAD ENSEMBLE PREDICTIONS\n",
        "# ============================================================\n",
        "print(\"=\"*60)\n",
        "print(\"STEP 1: LOADING ENSEMBLE PREDICTIONS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "y_val_pred_cal = np.load(val_pred_path)\n",
        "y_test_pred_cal = np.load(test_pred_path)\n",
        "\n",
        "print(f\"✓ Loaded VAL predictions: {y_val_pred_cal.shape}, mean={y_val_pred_cal.mean():.4f}\")\n",
        "print(f\"✓ Loaded TEST predictions: {y_test_pred_cal.shape}, mean={y_test_pred_cal.mean():.4f}\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 2: LOAD DATA (for patient IDs, labels, ICULOS)\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 2: LOADING DATA (Patient IDs, Labels)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "data_val = np.load(val_npz, allow_pickle=True)\n",
        "y_val = data_val['y']\n",
        "pid_val = data_val['patient_ids']\n",
        "end_iculos_val = data_val.get('end_iculos', None)\n",
        "\n",
        "data_test = np.load(test_npz, allow_pickle=True)\n",
        "y_test = data_test['y']\n",
        "pid_test = data_test['patient_ids']\n",
        "end_iculos_test = data_test.get('end_iculos', None)\n",
        "\n",
        "print(f\"VAL:  {len(y_val):,} windows, {len(np.unique(pid_val))} patients\")\n",
        "print(f\"TEST: {len(y_test):,} windows, {len(np.unique(pid_test))} patients\")\n",
        "\n",
        "# Verify shapes match\n",
        "assert len(y_val) == len(y_val_pred_cal), \"VAL: prediction and label lengths mismatch\"\n",
        "assert len(y_test) == len(y_test_pred_cal), \"TEST: prediction and label lengths mismatch\"\n",
        "print(\"✓ Shapes verified\")\n",
        "\n",
        "# ============================================================\n",
        "# UTILITY FUNCTIONS\n",
        "# ============================================================\n",
        "\n",
        "def ema_smooth(series, alpha=0.3):\n",
        "    \"\"\"Exponential moving average smoothing.\"\"\"\n",
        "    out = np.zeros_like(series, dtype=np.float32)\n",
        "    out[0] = series[0]\n",
        "    for i in range(1, len(series)):\n",
        "        out[i] = alpha * series[i] + (1 - alpha) * out[i-1]\n",
        "    return out\n",
        "\n",
        "def aggregate_patient_prob(probs, method='max'):\n",
        "    \"\"\"Aggregate window probabilities to patient risk score.\"\"\"\n",
        "    if method == 'max':\n",
        "        return np.max(probs)\n",
        "    elif method == 'mean_top_3':\n",
        "        sorted_probs = np.sort(probs)[-min(3, len(probs)):]\n",
        "        return np.mean(sorted_probs) if len(sorted_probs) > 0 else probs[-1]\n",
        "    elif method == 'rolling_mean_6h':\n",
        "        return np.mean(probs[-min(6, len(probs)):])\n",
        "    else:\n",
        "        return np.max(probs)\n",
        "\n",
        "def generate_patient_alerts_optimized(y_pred_cal, y_true, patient_ids, end_iculos,\n",
        "                                     threshold, x_warnings=3, w_hours=5,\n",
        "                                     use_ema=False, ema_alpha=0.3,\n",
        "                                     agg_method='max',\n",
        "                                     high_risk_threshold=None, ensemble_op=None):\n",
        "    \"\"\"Generate patient-level alerts with all tweaks.\"\"\"\n",
        "    df = pd.DataFrame({\n",
        "        'patient_id': patient_ids,\n",
        "        'prob': y_pred_cal,\n",
        "        'label': y_true,\n",
        "        'iculos': end_iculos if end_iculos is not None else range(len(y_true))\n",
        "    })\n",
        "\n",
        "    patient_results = []\n",
        "\n",
        "    for pid, g in df.groupby('patient_id'):\n",
        "        g = g.sort_values('iculos').reset_index(drop=True)\n",
        "        patient_label = int(g['label'].max())\n",
        "\n",
        "        # Apply EMA smoothing if enabled\n",
        "        if use_ema:\n",
        "            probs_smooth = ema_smooth(g['prob'].values, alpha=ema_alpha)\n",
        "        else:\n",
        "            probs_smooth = g['prob'].values\n",
        "\n",
        "        # Generate warnings with threshold\n",
        "        warnings = (probs_smooth > threshold).astype(int)\n",
        "\n",
        "        # Sliding window rule: check for x warnings in w hours\n",
        "        window_alert = 0\n",
        "        n_windows = len(warnings)\n",
        "        for i in range(max(0, n_windows - w_hours + 1)):\n",
        "            window_warnings = warnings[i:i+w_hours].sum()\n",
        "            if window_warnings >= x_warnings:\n",
        "                window_alert = 1\n",
        "                break\n",
        "\n",
        "        # Aggregate patient risk score for ROC/PR curves\n",
        "        max_prob = aggregate_patient_prob(g['prob'].values, method=agg_method)\n",
        "\n",
        "        # Ensemble rule: check high-risk threshold\n",
        "        alert_triggered = window_alert\n",
        "        if high_risk_threshold is not None:\n",
        "            high_risk_alert = 1 if max_prob > high_risk_threshold else 0\n",
        "            if ensemble_op == 'OR':\n",
        "                alert_triggered = max(alert_triggered, high_risk_alert)\n",
        "            elif ensemble_op == 'AND':\n",
        "                alert_triggered = min(alert_triggered, high_risk_alert)\n",
        "\n",
        "        patient_results.append({\n",
        "            'patient_id': pid,\n",
        "            'true_label': patient_label,\n",
        "            'alert': alert_triggered,\n",
        "            'max_prob': max_prob,\n",
        "            'n_warnings': int(warnings.sum()),\n",
        "            'n_windows': n_windows\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(patient_results)\n",
        "\n",
        "# ============================================================\n",
        "# STEP 3: GRID SEARCH ON VALIDATION\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 3: GRID SEARCH (Thresholds × Alert Rules)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "grid_results = []\n",
        "\n",
        "print(f\"\\nTesting {len(FINE_THRESHOLDS)} thresholds × \"\n",
        "      f\"{len(X_WARNINGS_LIST)} x_warnings × {len(W_HOURS_LIST)} w_hours = \"\n",
        "      f\"{len(FINE_THRESHOLDS) * len(X_WARNINGS_LIST) * len(W_HOURS_LIST)} configs\\n\")\n",
        "\n",
        "for t_idx, t_star in enumerate(FINE_THRESHOLDS):\n",
        "    for x_warn in X_WARNINGS_LIST:\n",
        "        for w_hr in W_HOURS_LIST:\n",
        "            # Generate alerts with optimizations\n",
        "            df_val_patient = generate_patient_alerts_optimized(\n",
        "                y_val_pred_cal, y_val, pid_val, end_iculos_val,\n",
        "                threshold=t_star,\n",
        "                x_warnings=x_warn,\n",
        "                w_hours=w_hr,\n",
        "                use_ema=USE_EMA,\n",
        "                ema_alpha=EMA_ALPHA,\n",
        "                agg_method=AGG_METHOD\n",
        "            )\n",
        "\n",
        "            # Patient-level metrics\n",
        "            y_true_p = df_val_patient['true_label'].values\n",
        "            y_alert_p = df_val_patient['alert'].values\n",
        "            y_score_p = df_val_patient['max_prob'].values\n",
        "\n",
        "            # Confusion matrix\n",
        "            tn_p, fp_p, fn_p, tp_p = confusion_matrix(y_true_p, y_alert_p).ravel()\n",
        "\n",
        "            sens_p = tp_p / (tp_p + fn_p) if (tp_p + fn_p) > 0 else 0.0\n",
        "            spec_p = tn_p / (tn_p + fp_p) if (tn_p + fp_p) > 0 else 0.0\n",
        "            prec_p = tp_p / (tp_p + fp_p) if (tp_p + fp_p) > 0 else 0.0\n",
        "            far_p = 100 * fp_p / (fp_p + tn_p) if (fp_p + tn_p) > 0 else 0.0\n",
        "\n",
        "            # F1 score\n",
        "            f1_p = 2 * (prec_p * sens_p) / (prec_p + sens_p + 1e-8)\n",
        "\n",
        "            # ROC-AUC and PR-AUC\n",
        "            roc_auc_p = roc_auc_score(y_true_p, y_score_p)\n",
        "            prec_p_curve, rec_p_curve, _ = precision_recall_curve(y_true_p, y_score_p)\n",
        "            pr_auc_p = auc(rec_p_curve, prec_p_curve)\n",
        "\n",
        "            grid_results.append({\n",
        "                'threshold': float(t_star),\n",
        "                'x_warnings': int(x_warn),\n",
        "                'w_hours': int(w_hr),\n",
        "                'sensitivity': float(sens_p),\n",
        "                'specificity': float(spec_p),\n",
        "                'precision': float(prec_p),\n",
        "                'far': float(far_p),\n",
        "                'f1': float(f1_p),\n",
        "                'roc_auc': float(roc_auc_p),\n",
        "                'pr_auc': float(pr_auc_p),\n",
        "                'tp': int(tp_p),\n",
        "                'fp': int(fp_p),\n",
        "                'tn': int(tn_p),\n",
        "                'fn': int(fn_p)\n",
        "            })\n",
        "\n",
        "# Convert to DataFrame\n",
        "df_grid = pd.DataFrame(grid_results)\n",
        "\n",
        "# Sort by F1 and save\n",
        "df_grid_sorted = df_grid.sort_values('f1', ascending=False)\n",
        "df_grid.to_csv(grid_results_csv, index=False)\n",
        "print(f\"✓ Saved full grid search results → {grid_results_csv}\")\n",
        "\n",
        "# Display top 10 configs by F1\n",
        "print(\"\\nTop 10 configurations by F1 score:\")\n",
        "print(df_grid_sorted[['threshold', 'x_warnings', 'w_hours', 'sensitivity',\n",
        "                      'specificity', 'precision', 'far', 'f1']].head(10).to_string(index=False))\n",
        "\n",
        "# ============================================================\n",
        "# STEP 4: TEST ENSEMBLE RULES\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 4: TESTING ENSEMBLE RULES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Pick best non-ensemble config\n",
        "best_non_ensemble = df_grid_sorted.iloc[0]\n",
        "best_t = best_non_ensemble['threshold']\n",
        "\n",
        "ensemble_results = {}\n",
        "\n",
        "for rule_config in ENSEMBLE_RULES:\n",
        "    name = rule_config['name']\n",
        "    x = rule_config['x']\n",
        "    w = rule_config['w']\n",
        "    high_risk_t = rule_config['high_risk_threshold']\n",
        "    op = rule_config['op']\n",
        "\n",
        "    df_val_patient = generate_patient_alerts_optimized(\n",
        "        y_val_pred_cal, y_val, pid_val, end_iculos_val,\n",
        "        threshold=best_t,\n",
        "        x_warnings=x,\n",
        "        w_hours=w,\n",
        "        use_ema=USE_EMA,\n",
        "        ema_alpha=EMA_ALPHA,\n",
        "        agg_method=AGG_METHOD,\n",
        "        high_risk_threshold=high_risk_t,\n",
        "        ensemble_op=op\n",
        "    )\n",
        "\n",
        "    y_true_p = df_val_patient['true_label'].values\n",
        "    y_alert_p = df_val_patient['alert'].values\n",
        "    y_score_p = df_val_patient['max_prob'].values\n",
        "\n",
        "    tn_p, fp_p, fn_p, tp_p = confusion_matrix(y_true_p, y_alert_p).ravel()\n",
        "\n",
        "    sens_p = tp_p / (tp_p + fn_p) if (tp_p + fn_p) > 0 else 0.0\n",
        "    spec_p = tn_p / (tn_p + fp_p) if (tn_p + fp_p) > 0 else 0.0\n",
        "    prec_p = tp_p / (tp_p + fp_p) if (tp_p + fp_p) > 0 else 0.0\n",
        "    far_p = 100 * fp_p / (fp_p + tn_p) if (fp_p + tn_p) > 0 else 0.0\n",
        "    f1_p = 2 * (prec_p * sens_p) / (prec_p + sens_p + 1e-8)\n",
        "\n",
        "    roc_auc_p = roc_auc_score(y_true_p, y_score_p)\n",
        "    prec_p_curve, rec_p_curve, _ = precision_recall_curve(y_true_p, y_score_p)\n",
        "    pr_auc_p = auc(rec_p_curve, prec_p_curve)\n",
        "\n",
        "    ensemble_results[name] = {\n",
        "        'threshold': float(best_t),\n",
        "        'x_warnings': x,\n",
        "        'w_hours': w,\n",
        "        'high_risk_threshold': high_risk_t,\n",
        "        'ensemble_op': op,\n",
        "        'sensitivity': float(sens_p),\n",
        "        'specificity': float(spec_p),\n",
        "        'precision': float(prec_p),\n",
        "        'far': float(far_p),\n",
        "        'f1': float(f1_p),\n",
        "        'roc_auc': float(roc_auc_p),\n",
        "        'pr_auc': float(pr_auc_p)\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"  Sensitivity: {sens_p*100:.2f}%\")\n",
        "    print(f\"  Specificity: {spec_p*100:.2f}%\")\n",
        "    print(f\"  Precision:   {prec_p*100:.2f}%\")\n",
        "    print(f\"  FAR:         {far_p:.2f}%\")\n",
        "    print(f\"  F1:          {f1_p:.4f}\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 5: SELECT BEST CONFIG AND EVALUATE ON TEST\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 5: FINAL TEST SET EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Pick best F1 config overall\n",
        "best_config = df_grid_sorted.iloc[0]\n",
        "best_threshold = best_config['threshold']\n",
        "best_x = int(best_config['x_warnings'])\n",
        "best_w = int(best_config['w_hours'])\n",
        "\n",
        "print(f\"\\nBest config from grid search:\")\n",
        "print(f\"  Threshold: {best_threshold:.4f}\")\n",
        "print(f\"  x_warnings: {best_x}, w_hours: {best_w}\")\n",
        "print(f\"  Validation F1: {best_config['f1']:.4f}\")\n",
        "\n",
        "# Evaluate on test\n",
        "df_test_patient = generate_patient_alerts_optimized(\n",
        "    y_test_pred_cal, y_test, pid_test, end_iculos_test,\n",
        "    threshold=best_threshold,\n",
        "    x_warnings=best_x,\n",
        "    w_hours=best_w,\n",
        "    use_ema=USE_EMA,\n",
        "    ema_alpha=EMA_ALPHA,\n",
        "    agg_method=AGG_METHOD\n",
        ")\n",
        "\n",
        "y_true_test_p = df_test_patient['true_label'].values\n",
        "y_alert_test_p = df_test_patient['alert'].values\n",
        "y_score_test_p = df_test_patient['max_prob'].values\n",
        "\n",
        "tn_test, fp_test, fn_test, tp_test = confusion_matrix(y_true_test_p, y_alert_test_p).ravel()\n",
        "\n",
        "sens_test = tp_test / (tp_test + fn_test) if (tp_test + fn_test) > 0 else 0.0\n",
        "spec_test = tn_test / (tn_test + fp_test) if (tn_test + fp_test) > 0 else 0.0\n",
        "prec_test = tp_test / (tp_test + fp_test) if (tp_test + fp_test) > 0 else 0.0\n",
        "far_test = 100 * fp_test / (fp_test + tn_test) if (fp_test + tn_test) > 0 else 0.0\n",
        "\n",
        "roc_auc_test = roc_auc_score(y_true_test_p, y_score_test_p)\n",
        "prec_test_curve, rec_test_curve, _ = precision_recall_curve(y_true_test_p, y_score_test_p)\n",
        "pr_auc_test = auc(rec_test_curve, prec_test_curve)\n",
        "\n",
        "print(f\"\\nTest set results:\")\n",
        "print(f\"  Sensitivity: {sens_test*100:.2f}%\")\n",
        "print(f\"  Specificity: {spec_test*100:.2f}%\")\n",
        "print(f\"  Precision:   {prec_test*100:.2f}%\")\n",
        "print(f\"  FAR:         {far_test:.2f}%\")\n",
        "print(f\"  ROC-AUC:     {roc_auc_test:.4f}\")\n",
        "print(f\"  PR-AUC:      {pr_auc_test:.4f}\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 6: SAVE RESULTS & VISUALIZATIONS\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 6: SAVING RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "best_configs = {\n",
        "    'grid_search_best': {\n",
        "        'threshold': float(best_threshold),\n",
        "        'x_warnings': int(best_x),\n",
        "        'w_hours': int(best_w),\n",
        "        'settings': {\n",
        "            'use_ema': USE_EMA,\n",
        "            'ema_alpha': EMA_ALPHA,\n",
        "            'aggregation_method': AGG_METHOD\n",
        "        },\n",
        "        'validation_metrics': {\n",
        "            'sensitivity': float(best_config['sensitivity']),\n",
        "            'specificity': float(best_config['specificity']),\n",
        "            'precision': float(best_config['precision']),\n",
        "            'far': float(best_config['far']),\n",
        "            'f1': float(best_config['f1']),\n",
        "            'roc_auc': float(best_config['roc_auc']),\n",
        "            'pr_auc': float(best_config['pr_auc'])\n",
        "        }\n",
        "    },\n",
        "    'ensemble_rules': ensemble_results\n",
        "}\n",
        "\n",
        "with open(best_configs_json, 'w') as f:\n",
        "    json.dump(best_configs, f, indent=2)\n",
        "print(f\"✓ Saved best configs → {best_configs_json}\")\n",
        "\n",
        "final_test_results = {\n",
        "    'best_config': {\n",
        "        'threshold': float(best_threshold),\n",
        "        'x_warnings': int(best_x),\n",
        "        'w_hours': int(best_w),\n",
        "        'settings': {\n",
        "            'use_ema': USE_EMA,\n",
        "            'ema_alpha': EMA_ALPHA,\n",
        "            'aggregation_method': AGG_METHOD\n",
        "        }\n",
        "    },\n",
        "    'test_metrics': {\n",
        "        'sensitivity': float(sens_test),\n",
        "        'specificity': float(spec_test),\n",
        "        'precision': float(prec_test),\n",
        "        'far': float(far_test),\n",
        "        'roc_auc': float(roc_auc_test),\n",
        "        'pr_auc': float(pr_auc_test),\n",
        "        'confusion_matrix': {\n",
        "            'tp': int(tp_test),\n",
        "            'fp': int(fp_test),\n",
        "            'tn': int(tn_test),\n",
        "            'fn': int(fn_test)\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(final_test_json, 'w') as f:\n",
        "    json.dump(final_test_results, f, indent=2)\n",
        "print(f\"✓ Saved final test results → {final_test_json}\")\n",
        "\n",
        "# Visualization (same as v7, reuse plotting code)\n",
        "# [Include full plotting code from v7 here - omitted for brevity]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ALERT SYSTEM (V8 ENSEMBLE) COMPLETE ✓\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\n✅ Using ensemble predictions (3 models averaged)\")\n",
        "print(f\"\\n🎯 Test Performance (Best Config):\")\n",
        "print(f\"  Sensitivity: {sens_test*100:.2f}%\")\n",
        "print(f\"  Specificity: {spec_test*100:.2f}%\")\n",
        "print(f\"  Precision:   {prec_test*100:.2f}%\")\n",
        "print(f\"  FAR:         {far_test:.2f}%\")\n",
        "print(f\"  ROC-AUC:     {roc_auc_test:.4f}\")\n",
        "print(f\"  PR-AUC:      {pr_auc_test:.4f}\")\n",
        "\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm2DhmqQ9so_",
        "outputId": "89fb78b8-9896-49e3-ca22-8386494314ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "STEP 1: LOADING ENSEMBLE PREDICTIONS\n",
            "============================================================\n",
            "✓ Loaded VAL predictions: (115622,), mean=0.0377\n",
            "✓ Loaded TEST predictions: (99873,), mean=0.0380\n",
            "\n",
            "============================================================\n",
            "STEP 2: LOADING DATA (Patient IDs, Labels)\n",
            "============================================================\n",
            "VAL:  115,622 windows, 5182 patients\n",
            "TEST: 99,873 windows, 4579 patients\n",
            "✓ Shapes verified\n",
            "\n",
            "============================================================\n",
            "STEP 3: GRID SEARCH (Thresholds × Alert Rules)\n",
            "============================================================\n",
            "\n",
            "Testing 10 thresholds × 3 x_warnings × 3 w_hours = 90 configs\n",
            "\n",
            "✓ Saved full grid search results → /content/drive/MyDrive/AI_Fin/Fix_Over_Fitting/Alert_System_v8_Ensemble/alert_grid_search_results_v8_ensemble.csv\n",
            "\n",
            "Top 10 configurations by F1 score:\n",
            " threshold  x_warnings  w_hours  sensitivity  specificity  precision      far       f1\n",
            "      0.08           4        4     0.360390     0.924908   0.232704 7.509233 0.282803\n",
            "      0.08           4        5     0.357143     0.924703   0.230608 7.529750 0.280255\n",
            "      0.08           4        6     0.353896     0.924908   0.229474 7.509233 0.278416\n",
            "      0.08           3        4     0.360390     0.921009   0.223790 7.899056 0.276119\n",
            "      0.08           2        4     0.366883     0.917727   0.219844 8.227329 0.274939\n",
            "      0.08           3        5     0.357143     0.921009   0.222222 7.899056 0.273973\n",
            "      0.08           2        5     0.363636     0.917727   0.218324 8.227329 0.272838\n",
            "      0.08           3        6     0.353896     0.921215   0.221095 7.878539 0.272160\n",
            "      0.10           3        4     0.227273     0.971686   0.336538 2.831350 0.271318\n",
            "      0.10           3        5     0.227273     0.971686   0.336538 2.831350 0.271318\n",
            "\n",
            "============================================================\n",
            "STEP 4: TESTING ENSEMBLE RULES\n",
            "============================================================\n",
            "\n",
            "baseline_3_5:\n",
            "  Sensitivity: 35.71%\n",
            "  Specificity: 92.10%\n",
            "  Precision:   22.22%\n",
            "  FAR:         7.90%\n",
            "  F1:          0.2740\n",
            "\n",
            "3_warnings_or_high_risk:\n",
            "  Sensitivity: 35.71%\n",
            "  Specificity: 92.10%\n",
            "  Precision:   22.22%\n",
            "  FAR:         7.90%\n",
            "  F1:          0.2740\n",
            "\n",
            "2_warnings_4h_or_high_risk:\n",
            "  Sensitivity: 36.69%\n",
            "  Specificity: 91.77%\n",
            "  Precision:   21.98%\n",
            "  FAR:         8.23%\n",
            "  F1:          0.2749\n",
            "\n",
            "============================================================\n",
            "STEP 5: FINAL TEST SET EVALUATION\n",
            "============================================================\n",
            "\n",
            "Best config from grid search:\n",
            "  Threshold: 0.0800\n",
            "  x_warnings: 4, w_hours: 4\n",
            "  Validation F1: 0.2828\n",
            "\n",
            "Test set results:\n",
            "  Sensitivity: 31.54%\n",
            "  Specificity: 92.41%\n",
            "  Precision:   22.43%\n",
            "  FAR:         7.59%\n",
            "  ROC-AUC:     0.7632\n",
            "  PR-AUC:      0.1872\n",
            "\n",
            "============================================================\n",
            "STEP 6: SAVING RESULTS\n",
            "============================================================\n",
            "✓ Saved best configs → /content/drive/MyDrive/AI_Fin/Fix_Over_Fitting/Alert_System_v8_Ensemble/best_alert_configs_v8_ensemble.json\n",
            "✓ Saved final test results → /content/drive/MyDrive/AI_Fin/Fix_Over_Fitting/Alert_System_v8_Ensemble/final_test_evaluation_v8_ensemble.json\n",
            "\n",
            "============================================================\n",
            "ALERT SYSTEM (V8 ENSEMBLE) COMPLETE ✓\n",
            "============================================================\n",
            "\n",
            "✅ Using ensemble predictions (3 models averaged)\n",
            "\n",
            "🎯 Test Performance (Best Config):\n",
            "  Sensitivity: 31.54%\n",
            "  Specificity: 92.41%\n",
            "  Precision:   22.43%\n",
            "  FAR:         7.59%\n",
            "  ROC-AUC:     0.7632\n",
            "  PR-AUC:      0.1872\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 2B: CREATE BALANCED TEST SET (50% pos, 50% neg)\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 2B: CREATING BALANCED TEST SET\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get patient-level labels\n",
        "df_test_windows = pd.DataFrame({\n",
        "    'patient_id': pid_test,\n",
        "    'label': y_test,\n",
        "    'pred': y_test_pred_cal\n",
        "})\n",
        "\n",
        "# Get unique patients and their true labels\n",
        "patients_test = df_test_windows.groupby('patient_id')['label'].max().reset_index()\n",
        "patients_test.columns = ['patient_id', 'true_label']\n",
        "\n",
        "pos_patients_test = patients_test[patients_test['true_label'] == 1]['patient_id'].values\n",
        "neg_patients_test = patients_test[patients_test['true_label'] == 0]['patient_id'].values\n",
        "\n",
        "print(f\"Test set before balancing:\")\n",
        "print(f\"  Positive patients: {len(pos_patients_test)}\")\n",
        "print(f\"  Negative patients: {len(neg_patients_test)}\")\n",
        "\n",
        "# Balance: sample equal number of negative patients\n",
        "n_pos = len(pos_patients_test)\n",
        "neg_patients_balanced = np.random.choice(neg_patients_test, size=n_pos, replace=False)\n",
        "\n",
        "balanced_patients = np.concatenate([pos_patients_test, neg_patients_balanced])\n",
        "\n",
        "print(f\"\\nTest set after balancing:\")\n",
        "print(f\"  Total patients: {len(balanced_patients)}\")\n",
        "print(f\"  Positive: {len(pos_patients_test)}\")\n",
        "print(f\"  Negative: {len(neg_patients_balanced)}\")\n",
        "\n",
        "# Filter to balanced patients\n",
        "mask_balanced_test = np.isin(pid_test, balanced_patients)\n",
        "y_test_balanced = y_test[mask_balanced_test]\n",
        "pid_test_balanced = pid_test[mask_balanced_test]\n",
        "y_test_pred_cal_balanced = y_test_pred_cal[mask_balanced_test]\n",
        "end_iculos_test_balanced = end_iculos_test[mask_balanced_test] if end_iculos_test is not None else None\n",
        "\n",
        "print(f\"\\nBalanced test windows: {len(y_test_balanced):,}\")\n",
        "print(f\"  Positive: {int(y_test_balanced.sum()):,} ({100*y_test_balanced.mean():.2f}%)\")\n",
        "print(f\"  Negative: {int((y_test_balanced==0).sum()):,} ({100*(1-y_test_balanced.mean()):.2f}%)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUNsvnx5A-xv",
        "outputId": "7673b81e-d53d-47bc-e234-f520c8c308ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 2B: CREATING BALANCED TEST SET\n",
            "============================================================\n",
            "Test set before balancing:\n",
            "  Positive patients: 298\n",
            "  Negative patients: 4281\n",
            "\n",
            "Test set after balancing:\n",
            "  Total patients: 596\n",
            "  Positive: 298\n",
            "  Negative: 298\n",
            "\n",
            "Balanced test windows: 23,187\n",
            "  Positive: 4,192 (18.08%)\n",
            "  Negative: 18,995 (81.92%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 5: SELECT BEST CONFIG AND EVALUATE ON BALANCED TEST\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 5: FINAL BALANCED TEST SET EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Pick best F1 config overall\n",
        "best_config = df_grid_sorted.iloc[0]\n",
        "best_threshold = best_config['threshold']\n",
        "best_x = int(best_config['x_warnings'])\n",
        "best_w = int(best_config['w_hours'])\n",
        "\n",
        "print(f\"\\nBest config from grid search:\")\n",
        "print(f\"  Threshold: {best_threshold:.4f}\")\n",
        "print(f\"  x_warnings: {best_x}, w_hours: {best_w}\")\n",
        "print(f\"  Validation F1: {best_config['f1']:.4f}\")\n",
        "\n",
        "# Evaluate on BALANCED test\n",
        "df_test_patient_balanced = generate_patient_alerts_optimized(\n",
        "    y_test_pred_cal_balanced, y_test_balanced, pid_test_balanced, end_iculos_test_balanced,\n",
        "    threshold=best_threshold,\n",
        "    x_warnings=best_x,\n",
        "    w_hours=best_w,\n",
        "    use_ema=USE_EMA,\n",
        "    ema_alpha=EMA_ALPHA,\n",
        "    agg_method=AGG_METHOD\n",
        ")\n",
        "\n",
        "y_true_test_p = df_test_patient_balanced['true_label'].values\n",
        "y_alert_test_p = df_test_patient_balanced['alert'].values\n",
        "y_score_test_p = df_test_patient_balanced['max_prob'].values\n",
        "\n",
        "tn_test, fp_test, fn_test, tp_test = confusion_matrix(y_true_test_p, y_alert_test_p).ravel()\n",
        "\n",
        "sens_test = tp_test / (tp_test + fn_test) if (tp_test + fn_test) > 0 else 0.0\n",
        "spec_test = tn_test / (tn_test + fp_test) if (tn_test + fp_test) > 0 else 0.0\n",
        "prec_test = tp_test / (tp_test + fp_test) if (tp_test + fp_test) > 0 else 0.0\n",
        "far_test = 100 * fp_test / (fp_test + tn_test) if (fp_test + tn_test) > 0 else 0.0\n",
        "\n",
        "roc_auc_test = roc_auc_score(y_true_test_p, y_score_test_p)\n",
        "prec_test_curve, rec_test_curve, _ = precision_recall_curve(y_true_test_p, y_score_test_p)\n",
        "pr_auc_test = auc(rec_test_curve, prec_test_curve)\n",
        "\n",
        "print(f\"\\nBalanced Test set results:\")\n",
        "print(f\"  Sensitivity: {sens_test*100:.2f}%\")\n",
        "print(f\"  Specificity: {spec_test*100:.2f}%\")\n",
        "print(f\"  Precision:   {prec_test*100:.2f}%\")\n",
        "print(f\"  FAR:         {far_test:.2f}%\")\n",
        "print(f\"  ROC-AUC:     {roc_auc_test:.4f}\")\n",
        "print(f\"  PR-AUC:      {pr_auc_test:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhBsLRA0AzAe",
        "outputId": "b12f9146-a0ae-4462-ae21-050da5c48771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 5: FINAL BALANCED TEST SET EVALUATION\n",
            "============================================================\n",
            "\n",
            "Best config from grid search:\n",
            "  Threshold: 0.0800\n",
            "  x_warnings: 4, w_hours: 4\n",
            "  Validation F1: 0.2828\n",
            "\n",
            "Balanced Test set results:\n",
            "  Sensitivity: 31.54%\n",
            "  Specificity: 90.60%\n",
            "  Precision:   77.05%\n",
            "  FAR:         9.40%\n",
            "  ROC-AUC:     0.7362\n",
            "  PR-AUC:      0.7319\n"
          ]
        }
      ]
    }
  ]
}